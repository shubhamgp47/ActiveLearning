Train set shape: (26880, 5)
Val set shape:   (5760, 5)
Test set shape:  (5760, 5)
Selected images DataFrame (Random Sampling):
   Query_Iteration                                     Selected_Image
0                1  Spule035_Image0269.jpg,Spule020_Image0191.jpg,...
1                2  Spule025_Image0644.jpg,Spule016_Image0456.jpg,...
2                3  Spule030_Image0131.jpg,Spule019_Image0823.jpg,...
3                4  Spule027_Image0752.jpg,Spule008_Image0267.jpg,...
4                5  Spule035_Image0294.jpg,Spule032_Image0887.jpg,...

Query 1: Using the exact images and labels from the CSV for this iteration.

Query 1: Using images from iteration=1 (random sampling).
Number of samples used for training in Query 1 is 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.5397[0m        [32m0.7199[0m       [35m0.2366[0m      [31m0.4075[0m        [94m0.6918[0m     +  0.0000  7.8448
      2      [36m0.7685[0m        [32m0.6332[0m       [35m0.2977[0m      [31m0.4651[0m        [94m0.6737[0m     +  0.0000  7.3060
      3      0.7222        [32m0.6126[0m       0.2891      0.4490        0.6851        0.0000  7.3481
      4      0.7685        [32m0.5906[0m       0.2866      0.4126        [94m0.6720[0m     +  0.0000  7.5332
      5      [36m0.8214[0m        [32m0.5791[0m       [35m0.3149[0m      0.4194        0.6747        0.0000  7.5001
      6      [36m0.8333[0m        [32m0.5650[0m       0.3080      0.4270        0.6802        0.0000  7.4531
      7      0.7500        [32m0.5549[0m       0.3108      0.4356        0.6763        0.0000  7.5712
      8      0.8320        [32m0.5393[0m       0.3054      0.4401        0.6766        0.0000  7.5551
      9      [36m0.9259[0m        [32m0.4947[0m       0.3064      0.4353        0.6741        0.0000  7.5860
     10      0.8320        0.5007       0.3007      0.4438        0.6771        0.0000  7.6237
     11      0.9259        0.4997       0.3042      0.4434        0.6759        0.0000  7.5897
     12      0.8333        0.5083       0.3050      0.4436        0.6744        0.0000  7.6011
     13      0.8320        0.5050       0.2997      0.4446        0.6762        0.0000  7.6859
     14      0.8690        0.4999       0.3061      0.4481        0.6746        0.0000  7.6699
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 1 Test Accuracy: 0.3240
Iteration 1 Test F1 Score (micro): 0.4812
Iteration 1 Test F1 Score (macro): 0.4708
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_0.pt

Query 2: Using the exact images and labels from the CSV for this iteration.

Query 2: Using images from iteration=2 (random sampling).
Number of samples used for training in Query 2 is 24
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.5867[0m        [32m0.6367[0m       [35m0.3342[0m      [31m0.4829[0m        [94m0.6463[0m     +  0.0000  7.8130
      2      [36m0.7159[0m        [32m0.5794[0m       0.2700      [31m0.4943[0m        [94m0.6202[0m     +  0.0000  7.7287
      3      [36m0.8208[0m        [32m0.5354[0m       [35m0.3670[0m      0.4936        [94m0.6126[0m     +  0.0000  7.8326
      4      0.7732        [32m0.5106[0m       0.3108      0.4901        [94m0.5972[0m     +  0.0000  7.7029
      5      0.7829        [32m0.4854[0m       [35m0.4470[0m      [31m0.6891[0m        0.6071        0.0000  7.7469
      6      0.8010        0.5114       0.3936      0.5553        [94m0.5796[0m     +  0.0000  7.8282
      7      [36m0.8532[0m        [32m0.4648[0m       0.3911      0.5685        [94m0.5740[0m     +  0.0000  7.7697
      8      [36m0.8725[0m        [32m0.4586[0m       0.3953      0.5722        [94m0.5689[0m     +  0.0000  7.7916
      9      0.8413        [32m0.4501[0m       0.4047      0.5757        [94m0.5656[0m     +  0.0000  7.8263
     10      [36m0.8968[0m        0.4514       0.4080      0.5944        [94m0.5632[0m     +  0.0000  7.8397
     11      [36m0.8999[0m        [32m0.4385[0m       0.4115      0.5982        [94m0.5618[0m     +  0.0000  7.7185
     12      [36m0.9152[0m        [32m0.4210[0m       0.4122      0.6006        [94m0.5607[0m     +  0.0000  7.7188
     13      0.8410        0.4546       0.4127      0.5932        [94m0.5602[0m     +  0.0000  7.7220
     14      0.8139        0.4408       0.4168      0.5992        [94m0.5589[0m     +  0.0000  7.7676
     15      [36m0.9330[0m        [32m0.4156[0m       0.4170      0.5968        [94m0.5581[0m     +  0.0000  7.6918
     16      0.8190        0.4374       0.4177      0.5982        [94m0.5576[0m     +  0.0000  7.7396
     17      0.8782        0.4224       0.4193      0.5996        [94m0.5574[0m     +  0.0000  7.8284
     18      0.8968        0.4276       0.4207      0.5991        [94m0.5571[0m     +  0.0000  7.7670
     19      0.8868        0.4483       0.4208      0.5996        [94m0.5566[0m     +  0.0000  7.8251
     20      0.8968        0.4214       0.4215      0.5981        [94m0.5564[0m     +  0.0000  7.7118
     21      0.9330        [32m0.3910[0m       0.4224      0.5999        [94m0.5563[0m     +  0.0000  7.7263
     22      0.8392        0.4260       0.4229      0.6009        [94m0.5561[0m     +  0.0000  7.7642
     23      0.9042        0.4251       0.4233      0.6013        [94m0.5560[0m     +  0.0000  7.8292
     24      0.8868        0.4306       0.4250      0.6042        [94m0.5558[0m     +  0.0000  7.7203
     25      0.8929        0.4037       0.4257      0.6047        [94m0.5558[0m     +  0.0000  7.7595
     26      0.9029        0.4231       0.4257      0.6047        [94m0.5558[0m     +  0.0000  7.7225
     27      0.8675        0.4485       0.4257      0.6047        [94m0.5557[0m     +  0.0000  7.6861
     28      0.8924        0.4320       0.4259      0.6047        [94m0.5557[0m     +  0.0000  7.7675
     29      0.8968        0.4081       0.4255      0.6046        [94m0.5556[0m     +  0.0000  7.7035
     30      0.8968        0.4279       0.4259      0.6049        [94m0.5555[0m     +  0.0000  7.8101
     31      0.9028        0.3987       0.4259      0.6049        [94m0.5555[0m     +  0.0000  7.8282
     32      0.9250        0.4055       0.4259      0.6049        [94m0.5555[0m     +  0.0000  7.7272
     33      0.9076        0.4095       0.4257      0.6049        [94m0.5555[0m     +  0.0000  7.7195
     34      0.8933        0.4263       0.4257      0.6049        [94m0.5555[0m     +  0.0000  7.7356
     35      0.8857        0.4313       0.4257      0.6049        [94m0.5554[0m     +  0.0000  7.7373
     36      0.8968        0.4241       0.4257      0.6049        [94m0.5554[0m     +  0.0000  7.7671
     37      0.8870        0.4315       0.4257      0.6049        [94m0.5554[0m     +  0.0000  7.7292
     38      0.9122        0.4256       0.4257      0.6049        [94m0.5554[0m     +  0.0000  7.7490
     39      0.8998        0.4325       0.4257      0.6048        [94m0.5554[0m     +  0.0000  7.7335
     40      0.8603        0.4219       0.4257      0.6050        [94m0.5554[0m     +  0.0000  7.7660
     41      0.9143        0.4389       0.4257      0.6050        [94m0.5554[0m     +  0.0000  7.7511
     42      0.9143        0.4229       0.4257      0.6050        [94m0.5554[0m     +  0.0000  7.7940
     43      0.8778        0.4348       0.4257      0.6050        [94m0.5554[0m     +  0.0000  7.7151
     44      0.8825        0.4427       0.4257      0.6050        [94m0.5554[0m     +  0.0000  7.7503
     45      0.8952        0.4306       0.4257      0.6050        [94m0.5554[0m     +  0.0000  7.7538
     46      0.8868        0.4313       0.4257      0.6050        [94m0.5554[0m     +  0.0000  7.7126
     47      0.8968        0.4082       0.4257      0.6050        [94m0.5554[0m     +  0.0000  7.6856
     48      0.8952        0.4122       0.4257      0.6050        [94m0.5554[0m     +  0.0000  7.8263
     49      0.8968        0.4114       0.4257      0.6050        [94m0.5554[0m     +  0.0000  7.7716
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 2 Test Accuracy: 0.4641
Iteration 2 Test F1 Score (micro): 0.6648
Iteration 2 Test F1 Score (macro): 0.6375
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_1.pt

Query 3: Using the exact images and labels from the CSV for this iteration.

Query 3: Using images from iteration=3 (random sampling).
Number of samples used for training in Query 3 is 56
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.6358[0m        [32m0.5158[0m       [35m0.3309[0m      [31m0.6257[0m        [94m0.6451[0m     +  0.0000  7.8435
      2      [36m0.6642[0m        0.6218       [35m0.5024[0m      0.2426        [94m0.5648[0m     +  0.0000  7.8035
      3      0.4474        0.5245       [35m0.6469[0m      [31m0.8172[0m        [94m0.4847[0m     +  0.0000  7.8368
      4      [36m0.9248[0m        [32m0.4300[0m       [35m0.6655[0m      0.7756        [94m0.4688[0m     +  0.0000  7.8352
      5      0.8867        [32m0.4281[0m       [35m0.6910[0m      [31m0.8311[0m        [94m0.4542[0m     +  0.0000  7.7661
      6      [36m0.9465[0m        [32m0.4046[0m       [35m0.7063[0m      0.8266        [94m0.4464[0m     +  0.0000  7.7509
      7      0.9249        0.4061       0.7052      0.8239        [94m0.4423[0m     +  0.0000  7.7833
      8      0.9305        [32m0.3915[0m       [35m0.7092[0m      0.8271        [94m0.4382[0m     +  0.0000  7.8607
      9      0.9383        [32m0.3867[0m       [35m0.7094[0m      0.8278        [94m0.4347[0m     +  0.0000  7.8855
     10      0.9356        [32m0.3783[0m       [35m0.7109[0m      0.8274        [94m0.4321[0m     +  0.0000  7.8294
     11      0.9257        0.3872       0.7108      0.8270        [94m0.4312[0m     +  0.0000  7.8271
     12      0.9304        0.3875       [35m0.7123[0m      0.8287        [94m0.4300[0m     +  0.0000  7.8909
     13      0.9276        0.3817       0.7120      0.8280        [94m0.4293[0m     +  0.0000  7.8174
     14      0.9271        [32m0.3765[0m       [35m0.7142[0m      0.8306        [94m0.4281[0m     +  0.0000  7.7964
     15      0.9444        [32m0.3698[0m       0.7134      0.8297        [94m0.4270[0m     +  0.0000  7.7622
     16      0.9289        0.3827       0.7123      0.8290        [94m0.4267[0m     +  0.0000  7.8484
     17      [36m0.9526[0m        [32m0.3628[0m       0.7123      0.8289        [94m0.4264[0m     +  0.0000  7.7723
     18      0.9122        0.3760       0.7132      0.8295        [94m0.4260[0m     +  0.0000  7.9162
     19      0.9471        0.3837       0.7128      0.8291        [94m0.4257[0m     +  0.0000  7.8372
     20      0.9451        0.3696       0.7142      0.8304        [94m0.4254[0m     +  0.0000  7.8302
     21      0.9402        0.3681       0.7142      0.8305        [94m0.4253[0m     +  0.0000  7.7662
     22      [36m0.9607[0m        [32m0.3614[0m       [35m0.7144[0m      0.8306        [94m0.4252[0m     +  0.0000  7.7765
     23      0.9426        0.3761       [35m0.7148[0m      0.8307        [94m0.4250[0m     +  0.0000  7.7180
     24      0.9356        0.3680       [35m0.7151[0m      0.8308        [94m0.4249[0m     +  0.0000  7.6920
     25      0.9243        0.3700       [35m0.7155[0m      [31m0.8313[0m        [94m0.4248[0m     +  0.0000  7.7508
     26      0.9429        0.3684       0.7155      0.8313        [94m0.4248[0m     +  0.0000  7.7747
     27      0.9437        [32m0.3581[0m       0.7155      0.8312        [94m0.4247[0m     +  0.0000  7.7854
     28      0.9493        0.3708       0.7155      0.8312        [94m0.4246[0m     +  0.0000  7.7324
     29      0.9487        0.3652       0.7155      0.8313        [94m0.4246[0m     +  0.0000  7.7476
     30      0.9372        0.3802       0.7155      0.8313        [94m0.4245[0m     +  0.0000  7.8282
     31      0.9426        0.3724       0.7155      0.8313        [94m0.4245[0m     +  0.0000  7.7669
     32      0.9463        0.3747       0.7155      0.8313        [94m0.4245[0m     +  0.0000  7.6841
     33      0.9424        0.3677       0.7155      0.8313        [94m0.4245[0m     +  0.0000  7.7143
     34      0.9532        0.3720       0.7155      0.8313        [94m0.4245[0m     +  0.0000  7.7395
     35      [36m0.9645[0m        0.3612       0.7155      0.8313        [94m0.4245[0m     +  0.0000  7.7405
     36      0.9273        0.3713       0.7155      0.8313        [94m0.4245[0m     +  0.0000  7.7346
     37      0.9366        0.3750       0.7155      0.8312        [94m0.4244[0m     +  0.0000  7.7328
     38      0.9295        0.3761       0.7155      0.8312        [94m0.4244[0m     +  0.0000  7.7547
     39      0.9024        0.3747       0.7155      0.8312        [94m0.4244[0m     +  0.0000  7.7812
     40      0.9264        0.3719       0.7155      0.8312        [94m0.4244[0m     +  0.0000  7.7553
     41      0.9231        0.3638       0.7155      0.8312        [94m0.4244[0m     +  0.0000  7.6902
     42      0.9242        0.3707       0.7155      0.8311        [94m0.4244[0m     +  0.0000  7.7452
     43      0.9564        0.3654       0.7155      0.8311        [94m0.4244[0m     +  0.0000  7.8180
     44      0.9282        0.3605       0.7155      0.8311        [94m0.4244[0m     +  0.0000  7.7261
     45      0.9381        0.3646       0.7155      0.8311        [94m0.4244[0m     +  0.0000  7.7088
     46      0.9218        0.3725       0.7155      0.8311        [94m0.4244[0m     +  0.0000  7.7861
     47      0.9363        0.3721       0.7155      0.8311        [94m0.4244[0m     +  0.0000  7.7224
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 3 Test Accuracy: 0.7227
Iteration 3 Test F1 Score (micro): 0.8583
Iteration 3 Test F1 Score (macro): 0.8415
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_2.pt

Query 4: Using the exact images and labels from the CSV for this iteration.

Query 4: Using images from iteration=4 (random sampling).
Number of samples used for training in Query 4 is 112
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8876[0m        [32m0.3972[0m       [35m0.5118[0m      [31m0.3957[0m        [94m0.5097[0m     +  0.0000  8.1148
      2      0.4800        0.4766       [35m0.6299[0m      [31m0.7922[0m        [94m0.4713[0m     +  0.0000  7.9271
      3      0.8109        0.4607       [35m0.6648[0m      [31m0.8025[0m        [94m0.4110[0m     +  0.0000  7.9043
      4      0.8795        [32m0.3754[0m       [35m0.7208[0m      [31m0.8385[0m        [94m0.3813[0m     +  0.0000  7.8949
      5      0.8840        [32m0.3488[0m       0.7149      [31m0.8410[0m        [94m0.3763[0m     +  0.0000  7.9071
      6      [36m0.9031[0m        [32m0.3359[0m       0.7191      [31m0.8423[0m        [94m0.3725[0m     +  0.0000  7.8921
      7      0.8991        [32m0.3320[0m       0.7205      [31m0.8433[0m        [94m0.3704[0m     +  0.0000  7.9328
      8      [36m0.9038[0m        0.3348       0.7208      0.8427        [94m0.3683[0m     +  0.0000  7.9148
      9      0.8862        [32m0.3312[0m       [35m0.7224[0m      [31m0.8441[0m        [94m0.3669[0m     +  0.0000  7.8940
     10      [36m0.9100[0m        [32m0.3241[0m       [35m0.7229[0m      [31m0.8442[0m        [94m0.3656[0m     +  0.0000  7.9351
     11      0.8911        [32m0.3232[0m       [35m0.7231[0m      0.8441        [94m0.3649[0m     +  0.0000  7.9253
     12      0.8911        0.3355       [35m0.7234[0m      [31m0.8445[0m        [94m0.3643[0m     +  0.0000  7.9064
     13      [36m0.9152[0m        0.3236       [35m0.7240[0m      0.8444        [94m0.3638[0m     +  0.0000  7.8926
     14      0.8906        0.3321       [35m0.7250[0m      [31m0.8451[0m        [94m0.3632[0m     +  0.0000  7.8939
     15      [36m0.9262[0m        [32m0.3218[0m       0.7250      0.8450        [94m0.3626[0m     +  0.0000  7.9530
     16      0.9084        0.3246       0.7245      0.8447        [94m0.3625[0m     +  0.0000  7.8595
     17      0.8971        0.3289       0.7243      0.8447        [94m0.3624[0m     +  0.0000  7.8912
     18      0.9132        0.3253       [35m0.7253[0m      [31m0.8451[0m        [94m0.3621[0m     +  0.0000  7.9062
     19      0.9132        0.3246       [35m0.7255[0m      [31m0.8453[0m        [94m0.3619[0m     +  0.0000  7.8956
     20      [36m0.9280[0m        [32m0.3209[0m       0.7253      0.8452        [94m0.3618[0m     +  0.0000  7.8895
     21      0.9085        0.3314       0.7253      0.8452        [94m0.3617[0m     +  0.0000  7.8882
     22      0.9009        0.3309       0.7253      0.8451        [94m0.3616[0m     +  0.0000  7.8892
     23      0.9139        0.3232       0.7255      0.8453        [94m0.3615[0m     +  0.0000  8.0002
     24      [36m0.9333[0m        0.3231       0.7253      0.8450        [94m0.3615[0m     +  0.0000  7.9219
     25      0.9062        0.3290       0.7253      0.8449        [94m0.3614[0m     +  0.0000  7.9271
     26      0.9227        0.3210       0.7252      0.8448        [94m0.3614[0m     +  0.0000  7.9127
     27      0.9216        0.3240       0.7252      0.8448        [94m0.3614[0m     +  0.0000  7.9535
     28      0.9056        0.3262       0.7250      0.8447        [94m0.3613[0m     +  0.0000  7.9228
     29      0.9177        [32m0.3202[0m       0.7255      0.8450        [94m0.3613[0m     +  0.0000  7.9341
     30      0.9134        0.3246       0.7253      0.8449        [94m0.3613[0m     +  0.0000  7.8730
     31      0.9113        0.3262       0.7253      0.8449        [94m0.3613[0m     +  0.0000  7.9684
     32      0.9138        0.3238       0.7253      0.8449        [94m0.3613[0m     +  0.0000  7.8751
     33      0.9133        0.3256       0.7253      0.8449        [94m0.3612[0m     +  0.0000  7.8666
     34      0.9063        0.3290       0.7253      0.8449        [94m0.3612[0m     +  0.0000  7.8874
     35      0.9031        0.3361       0.7253      0.8449        [94m0.3612[0m     +  0.0000  7.8801
     36      0.9147        0.3260       0.7253      0.8449        [94m0.3612[0m     +  0.0000  7.9465
     37      0.9084        0.3247       0.7253      0.8449        [94m0.3612[0m     +  0.0000  7.9672
     38      0.9163        0.3246       0.7253      0.8449        [94m0.3612[0m     +  0.0000  7.9188
     39      0.8878        0.3264       0.7253      0.8449        [94m0.3612[0m     +  0.0000  7.8919
     40      0.9128        0.3279       0.7253      0.8449        [94m0.3612[0m     +  0.0000  7.9273
     41      0.9329        0.3258       0.7253      0.8449        [94m0.3612[0m     +  0.0000  7.9098
     42      0.9099        0.3229       0.7253      0.8449        [94m0.3612[0m     +  0.0000  7.9225
     43      0.9277        0.3257       0.7253      0.8449        [94m0.3612[0m     +  0.0000  7.9218
     44      0.9216        0.3218       0.7253      0.8449        [94m0.3612[0m     +  0.0000  7.9529
     45      0.9118        0.3219       0.7253      0.8449        [94m0.3612[0m     +  0.0000  7.9790
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 4 Test Accuracy: 0.7394
Iteration 4 Test F1 Score (micro): 0.8733
Iteration 4 Test F1 Score (macro): 0.8579
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_3.pt

Query 5: Using the exact images and labels from the CSV for this iteration.

Query 5: Using images from iteration=5 (random sampling).
Number of samples used for training in Query 5 is 208
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8589[0m        [32m0.3530[0m       [35m0.4359[0m      [31m0.6881[0m        [94m0.5873[0m     +  0.0000  8.3277
      2      0.7298        0.5142       [35m0.7377[0m      [31m0.8545[0m        [94m0.3459[0m     +  0.0000  8.1446
      3      [36m0.8971[0m        [32m0.3180[0m       0.7358      [31m0.8563[0m        [94m0.3374[0m     +  0.0000  8.1837
      4      0.8850        [32m0.3139[0m       0.7332      0.8554        [94m0.3343[0m     +  0.0000  8.1267
      5      [36m0.9145[0m        [32m0.2991[0m       0.7372      [31m0.8571[0m        [94m0.3304[0m     +  0.0000  8.1406
      6      0.9041        [32m0.2963[0m       0.7349      0.8549        [94m0.3287[0m     +  0.0000  8.1248
      7      0.9097        [32m0.2936[0m       [35m0.7391[0m      0.8557        [94m0.3267[0m     +  0.0000  8.1788
      8      0.9143        0.3000       0.7380      0.8569        [94m0.3266[0m     +  0.0000  8.1741
      9      0.9128        [32m0.2917[0m       0.7344      0.8540        [94m0.3255[0m     +  0.0000  8.1413
     10      0.9065        [32m0.2897[0m       0.7345      0.8540        [94m0.3247[0m     +  0.0000  8.1609
     11      0.9111        [32m0.2885[0m       0.7351      0.8539        [94m0.3242[0m     +  0.0000  8.1744
     12      0.9126        0.2895       0.7351      0.8546        [94m0.3239[0m     +  0.0000  8.1569
     13      [36m0.9283[0m        [32m0.2878[0m       0.7351      0.8544        [94m0.3235[0m     +  0.0000  8.1874
     14      0.9066        0.2928       0.7361      0.8554        [94m0.3232[0m     +  0.0000  8.1983
     15      0.9242        [32m0.2853[0m       0.7354      0.8541        [94m0.3228[0m     +  0.0000  8.1767
     16      0.9233        0.2873       0.7351      0.8538        [94m0.3226[0m     +  0.0000  8.1742
     17      0.9162        0.2870       0.7356      0.8541        [94m0.3225[0m     +  0.0000  8.1573
     18      0.9186        [32m0.2834[0m       0.7359      0.8541        [94m0.3223[0m     +  0.0000  8.1572
     19      0.9001        0.2876       0.7354      0.8539        [94m0.3222[0m     +  0.0000  8.1813
     20      0.9089        0.2870       0.7359      0.8540        [94m0.3220[0m     +  0.0000  8.1722
     21      0.9113        0.2870       0.7361      0.8542        [94m0.3220[0m     +  0.0000  8.1628
     22      0.9162        0.2915       0.7363      0.8540        [94m0.3219[0m     +  0.0000  8.1343
     23      0.9098        0.2864       0.7370      0.8543        [94m0.3218[0m     +  0.0000  8.2082
     24      0.9161        0.2872       0.7366      0.8543        [94m0.3218[0m     +  0.0000  8.1354
     25      0.9200        0.2864       0.7366      0.8545        [94m0.3217[0m     +  0.0000  8.1574
     26      0.9081        0.2850       0.7366      0.8543        [94m0.3217[0m     +  0.0000  8.1582
     27      0.9009        0.2941       0.7368      0.8543        [94m0.3217[0m     +  0.0000  8.1798
     28      0.9087        0.2872       0.7366      0.8544        [94m0.3217[0m     +  0.0000  8.1833
     29      0.9167        0.2917       0.7366      0.8544        [94m0.3217[0m     +  0.0000  8.2200
     30      0.9225        [32m0.2792[0m       0.7366      0.8545        [94m0.3217[0m     +  0.0000  8.1721
     31      0.9173        0.2866       0.7366      0.8545        [94m0.3217[0m     +  0.0000  8.1905
     32      0.9095        0.2857       0.7366      0.8545        [94m0.3217[0m     +  0.0000  8.1523
     33      0.9178        0.2857       0.7366      0.8545        [94m0.3216[0m     +  0.0000  8.1480
     34      0.9173        0.2833       0.7366      0.8545        [94m0.3216[0m     +  0.0000  8.1670
     35      0.9180        0.2931       0.7361      0.8543        [94m0.3216[0m     +  0.0000  8.1245
     36      0.9173        0.2860       0.7365      0.8545        [94m0.3216[0m     +  0.0000  8.1958
     37      0.9132        0.2877       0.7365      0.8544        [94m0.3216[0m     +  0.0000  8.1582
     38      0.9019        0.2851       0.7361      0.8542        0.3216        0.0000  8.0964
     39      0.8992        0.2866       0.7365      0.8544        [94m0.3216[0m     +  0.0000  8.1721
     40      0.9148        0.2880       0.7365      0.8544        [94m0.3216[0m     +  0.0000  8.1718
     41      0.9213        0.2859       0.7365      0.8544        0.3216        0.0000  8.1844
     42      0.9102        0.2840       0.7365      0.8544        [94m0.3216[0m     +  0.0000  8.1509
     43      0.9135        0.2850       0.7365      0.8544        [94m0.3216[0m     +  0.0000  8.1770
     44      0.9143        0.2833       0.7365      0.8544        [94m0.3216[0m     +  0.0000  8.1138
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 5 Test Accuracy: 0.7500
Iteration 5 Test F1 Score (micro): 0.8798
Iteration 5 Test F1 Score (macro): 0.8655
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_4.pt

Query 6: Using the exact images and labels from the CSV for this iteration.

Query 6: Using images from iteration=6 (random sampling).
Number of samples used for training in Query 6 is 384
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8118[0m        [32m0.3576[0m       [35m0.6405[0m      [31m0.7826[0m        [94m0.3712[0m     +  0.0000  8.7055
      2      [36m0.8686[0m        [32m0.3023[0m       [35m0.7385[0m      [31m0.8409[0m        [94m0.3070[0m     +  0.0000  8.6218
      3      [36m0.8965[0m        [32m0.2793[0m       0.7175      0.8220        [94m0.3070[0m     +  0.0000  8.5976
      4      0.8915        [32m0.2762[0m       0.7372      0.8294        [94m0.3013[0m     +  0.0000  8.5985
      5      [36m0.9039[0m        [32m0.2703[0m       0.7198      0.8217        0.3015        0.0000  8.6040
      6      0.8952        [32m0.2702[0m       0.7283      0.8376        [94m0.2956[0m     +  0.0000  8.6582
      7      [36m0.9061[0m        [32m0.2624[0m       0.7363      [31m0.8446[0m        [94m0.2938[0m     +  0.0000  8.6097
      8      [36m0.9118[0m        [32m0.2604[0m       0.7314      0.8410        [94m0.2938[0m     +  0.0000  8.7292
      9      0.9039        0.2620       0.7314      0.8394        [94m0.2928[0m     +  0.0000  8.6010
     10      0.9073        0.2617       0.7283      0.8378        [94m0.2927[0m     +  0.0000  8.5946
     11      0.9076        0.2613       0.7312      0.8413        [94m0.2919[0m     +  0.0000  8.6337
     12      0.9111        [32m0.2599[0m       0.7356      [31m0.8446[0m        [94m0.2911[0m     +  0.0000  8.6265
     13      0.9086        0.2600       0.7361      [31m0.8446[0m        [94m0.2907[0m     +  0.0000  8.6329
     14      0.9016        0.2635       0.7354      0.8446        [94m0.2906[0m     +  0.0000  8.6319
     15      [36m0.9158[0m        [32m0.2533[0m       0.7368      [31m0.8453[0m        [94m0.2901[0m     +  0.0000  8.5903
     16      0.9137        [32m0.2522[0m       0.7358      0.8451        [94m0.2900[0m     +  0.0000  8.5735
     17      0.9094        0.2530       0.7356      0.8450        [94m0.2900[0m     +  0.0000  8.6375
     18      0.9114        0.2594       0.7352      0.8450        [94m0.2899[0m     +  0.0000  8.5827
     19      [36m0.9177[0m        0.2554       0.7354      0.8450        [94m0.2898[0m     +  0.0000  8.6109
     20      0.9156        0.2526       0.7378      [31m0.8458[0m        [94m0.2894[0m     +  0.0000  8.6208
     21      0.9143        0.2606       0.7375      [31m0.8459[0m        0.2894        0.0000  8.6105
     22      0.9077        0.2555       0.7380      [31m0.8463[0m        [94m0.2893[0m     +  0.0000  8.6130
     23      [36m0.9178[0m        [32m0.2503[0m       0.7375      0.8462        0.2893        0.0000  8.6193
     24      0.9091        0.2551       0.7372      0.8460        [94m0.2893[0m     +  0.0000  8.5963
     25      0.9117        0.2580       0.7375      0.8461        [94m0.2893[0m     +  0.0000  8.6057
     26      0.9104        0.2530       0.7372      0.8460        [94m0.2892[0m     +  0.0000  8.6005
     27      0.9073        0.2542       0.7368      0.8459        0.2892        0.0000  8.6632
     28      [36m0.9190[0m        0.2538       0.7370      0.8460        0.2892        0.0000  8.6449
     29      0.9070        0.2558       0.7368      0.8459        [94m0.2892[0m     +  0.0000  8.6464
     30      0.9082        0.2548       0.7365      0.8458        [94m0.2892[0m     +  0.0000  8.6614
     31      0.9044        0.2559       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.6307
     32      0.9156        0.2555       0.7363      0.8458        0.2892        0.0000  8.5542
     33      [36m0.9231[0m        0.2529       0.7363      0.8458        [94m0.2892[0m     +  0.0000  8.7027
     34      0.9161        0.2559       0.7363      0.8458        [94m0.2892[0m     +  0.0000  8.5813
     35      0.9066        0.2588       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.6675
     36      0.9147        0.2518       0.7368      0.8460        [94m0.2892[0m     +  0.0000  8.6341
     37      0.9186        0.2516       0.7366      0.8459        0.2892        0.0000  8.5873
     38      0.9089        0.2580       0.7365      0.8458        0.2892        0.0000  8.6457
     39      0.9208        0.2551       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.5826
     40      0.9150        0.2571       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.5689
     41      0.9172        0.2526       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.6294
     42      0.9075        0.2527       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.6070
     43      0.9075        0.2568       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.6488
     44      0.9122        0.2560       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.5946
     45      0.9128        0.2554       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.5870
     46      0.9042        0.2560       0.7366      0.8459        0.2892        0.0000  8.5940
     47      0.9074        0.2560       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.6247
     48      0.9117        0.2538       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.5860
     49      0.9069        0.2577       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.6182
     50      0.9130        0.2531       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.6924
     51      0.9130        0.2544       0.7366      0.8459        [94m0.2892[0m     +  0.0000  8.6359
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 6 Test Accuracy: 0.7727
Iteration 6 Test F1 Score (micro): 0.8907
Iteration 6 Test F1 Score (macro): 0.8761
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_5.pt

Query 7: Using the exact images and labels from the CSV for this iteration.

Query 7: Using images from iteration=7 (random sampling).
Number of samples used for training in Query 7 is 704
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8629[0m        [32m0.3090[0m       [35m0.7615[0m      [31m0.8473[0m        [94m0.2913[0m     +  0.0000  9.5894
      2      [36m0.8972[0m        [32m0.2656[0m       [35m0.7691[0m      [31m0.8630[0m        [94m0.2836[0m     +  0.0000  9.4465
      3      [36m0.9089[0m        [32m0.2575[0m       0.7656      0.8562        [94m0.2758[0m     +  0.0000  9.4279
      4      [36m0.9152[0m        [32m0.2504[0m       0.7585      0.8469        [94m0.2720[0m     +  0.0000  9.4762
      5      [36m0.9160[0m        [32m0.2455[0m       0.7639      0.8515        [94m0.2686[0m     +  0.0000  9.4839
      6      [36m0.9192[0m        [32m0.2396[0m       0.7627      0.8561        [94m0.2673[0m     +  0.0000  9.4784
      7      [36m0.9232[0m        [32m0.2370[0m       0.7656      0.8585        [94m0.2665[0m     +  0.0000  9.4381
      8      [36m0.9280[0m        [32m0.2336[0m       0.7649      0.8590        [94m0.2660[0m     +  0.0000  9.4840
      9      [36m0.9339[0m        [32m0.2328[0m       0.7646      0.8569        [94m0.2651[0m     +  0.0000  9.4381
     10      0.9286        [32m0.2295[0m       0.7653      0.8581        [94m0.2645[0m     +  0.0000  9.4353
     11      0.9333        0.2297       0.7674      0.8611        [94m0.2642[0m     +  0.0000  9.4616
     12      [36m0.9347[0m        [32m0.2266[0m       0.7660      0.8579        [94m0.2639[0m     +  0.0000  9.4587
     13      0.9339        0.2283       0.7677      0.8603        [94m0.2635[0m     +  0.0000  9.4632
     14      0.9272        0.2325       0.7667      0.8583        [94m0.2633[0m     +  0.0000  9.4743
     15      0.9310        0.2282       0.7660      0.8576        [94m0.2631[0m     +  0.0000  9.4650
     16      [36m0.9421[0m        [32m0.2262[0m       0.7658      0.8575        [94m0.2630[0m     +  0.0000  9.4523
     17      0.9311        0.2295       0.7653      0.8573        0.2631        0.0000  9.5052
     18      0.9288        [32m0.2257[0m       0.7655      0.8573        [94m0.2630[0m     +  0.0000  9.4776
     19      0.9383        0.2263       0.7656      0.8572        [94m0.2628[0m     +  0.0000  9.4834
     20      0.9310        0.2275       0.7675      0.8593        [94m0.2626[0m     +  0.0000  9.4388
     21      0.9309        0.2293       0.7670      0.8588        0.2626        0.0000  9.4372
     22      0.9329        0.2257       0.7665      0.8583        0.2626        0.0000  9.4918
     23      0.9390        0.2275       0.7655      0.8577        0.2626        0.0000  9.5091
     24      0.9345        0.2259       0.7656      0.8581        [94m0.2626[0m     +  0.0000  9.5208
     25      0.9305        0.2268       0.7655      0.8577        [94m0.2625[0m     +  0.0000  9.4225
     26      0.9334        0.2288       0.7655      0.8579        [94m0.2625[0m     +  0.0000  9.4836
     27      0.9368        0.2279       0.7658      0.8581        [94m0.2625[0m     +  0.0000  9.3918
     28      0.9310        0.2262       0.7660      0.8581        [94m0.2625[0m     +  0.0000  9.4832
     29      0.9354        0.2276       0.7661      0.8580        [94m0.2625[0m     +  0.0000  9.4841
     30      0.9363        0.2267       0.7663      0.8579        [94m0.2625[0m     +  0.0000  9.4742
     31      0.9378        0.2265       0.7660      0.8577        0.2625        0.0000  9.4695
     32      0.9339        0.2286       0.7661      0.8578        [94m0.2625[0m     +  0.0000  9.5227
     33      0.9365        0.2263       0.7660      0.8578        [94m0.2624[0m     +  0.0000  9.4735
     34      0.9337        0.2265       0.7661      0.8579        [94m0.2624[0m     +  0.0000  9.5136
     35      0.9381        0.2259       0.7665      0.8581        [94m0.2624[0m     +  0.0000  9.4533
     36      0.9354        0.2274       0.7665      0.8581        [94m0.2624[0m     +  0.0000  9.4271
     37      0.9357        0.2285       0.7665      0.8581        [94m0.2624[0m     +  0.0000  9.5287
     38      0.9385        0.2260       0.7665      0.8581        [94m0.2624[0m     +  0.0000  9.4826
     39      0.9350        0.2266       0.7663      0.8581        [94m0.2624[0m     +  0.0000  9.5289
     40      0.9310        [32m0.2244[0m       0.7667      0.8582        [94m0.2624[0m     +  0.0000  9.4327
     41      0.9354        0.2247       0.7665      0.8581        [94m0.2624[0m     +  0.0000  9.4619
     42      0.9339        0.2284       0.7665      0.8581        [94m0.2624[0m     +  0.0000  9.4136
     43      0.9329        0.2258       0.7667      0.8582        0.2624        0.0000  9.4295
     44      0.9331        0.2288       0.7667      0.8582        0.2624        0.0000  9.4629
     45      0.9377        0.2260       0.7667      0.8582        [94m0.2624[0m     +  0.0000  9.4701
     46      0.9334        0.2251       0.7667      0.8582        [94m0.2624[0m     +  0.0000  9.4759
     47      0.9346        0.2289       0.7667      0.8582        [94m0.2624[0m     +  0.0000  9.4298
     48      0.9383        0.2254       0.7667      0.8582        [94m0.2624[0m     +  0.0000  9.4629
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 7 Test Accuracy: 0.7833
Iteration 7 Test F1 Score (micro): 0.8937
Iteration 7 Test F1 Score (macro): 0.8785
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_6.pt

Query 8: Using the exact images and labels from the CSV for this iteration.

Query 8: Using images from iteration=8 (random sampling).
Number of samples used for training in Query 8 is 1264
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8850[0m        [32m0.2691[0m       [35m0.7804[0m      [31m0.8748[0m        [94m0.2564[0m     +  0.0000  11.0404
      2      [36m0.9202[0m        [32m0.2326[0m       [35m0.7852[0m      [31m0.8778[0m        [94m0.2528[0m     +  0.0000  10.8996
      3      [36m0.9283[0m        [32m0.2301[0m       0.7790      0.8672        [94m0.2505[0m     +  0.0000  10.8700
      4      0.9254        [32m0.2236[0m       0.7726      0.8669        0.2507        0.0000  10.8825
      5      [36m0.9297[0m        [32m0.2210[0m       [35m0.7859[0m      [31m0.8783[0m        [94m0.2482[0m     +  0.0000  10.8825
      6      [36m0.9411[0m        [32m0.2114[0m       [35m0.7944[0m      0.8776        [94m0.2456[0m     +  0.0000  10.9157
      7      [36m0.9444[0m        [32m0.2113[0m       0.7936      0.8778        [94m0.2450[0m     +  0.0000  10.8999
      8      0.9403        [32m0.2110[0m       0.7944      [31m0.8793[0m        0.2453        0.0000  10.8692
      9      [36m0.9458[0m        [32m0.2070[0m       [35m0.7950[0m      0.8777        [94m0.2442[0m     +  0.0000  10.9318
     10      0.9449        0.2071       [35m0.7955[0m      0.8784        [94m0.2439[0m     +  0.0000  10.8835
     11      [36m0.9494[0m        [32m0.2052[0m       0.7918      0.8734        [94m0.2432[0m     +  0.0000  10.8693
     12      0.9488        [32m0.2050[0m       0.7905      0.8729        0.2433        0.0000  10.9142
     13      0.9481        0.2051       0.7927      0.8733        [94m0.2431[0m     +  0.0000  10.9154
     14      0.9490        0.2074       0.7936      0.8749        [94m0.2429[0m     +  0.0000  10.8989
     15      [36m0.9500[0m        0.2056       0.7951      0.8745        [94m0.2426[0m     +  0.0000  10.8835
     16      [36m0.9505[0m        [32m0.2032[0m       0.7941      0.8737        0.2426        0.0000  10.9140
     17      0.9504        0.2034       0.7941      0.8739        [94m0.2426[0m     +  0.0000  10.9179
     18      0.9465        0.2037       0.7934      0.8731        [94m0.2425[0m     +  0.0000  10.9140
     19      0.9485        [32m0.2022[0m       0.7950      0.8747        [94m0.2425[0m     +  0.0000  10.9303
     20      0.9464        0.2024       0.7931      0.8725        [94m0.2424[0m     +  0.0000  10.9159
     21      [36m0.9544[0m        [32m0.1998[0m       0.7929      0.8724        0.2424        0.0000  10.8687
     22      0.9510        0.2032       0.7929      0.8723        0.2424        0.0000  10.9460
     23      0.9518        [32m0.1996[0m       0.7931      0.8724        [94m0.2424[0m     +  0.0000  10.9296
     24      0.9492        0.2018       0.7937      0.8731        0.2424        0.0000  10.8852
     25      [36m0.9547[0m        0.2014       0.7936      0.8729        [94m0.2424[0m     +  0.0000  10.9160
     26      0.9513        0.2035       0.7936      0.8729        [94m0.2424[0m     +  0.0000  10.9295
     27      0.9504        0.2007       0.7931      0.8726        [94m0.2423[0m     +  0.0000  10.8543
     28      0.9526        0.1996       0.7932      0.8725        [94m0.2423[0m     +  0.0000  10.8989
     29      0.9521        0.2025       0.7931      0.8723        [94m0.2423[0m     +  0.0000  10.9469
     30      0.9494        0.2018       0.7934      0.8725        [94m0.2423[0m     +  0.0000  10.9001
     31      0.9519        0.2014       0.7932      0.8724        [94m0.2423[0m     +  0.0000  10.8980
     32      0.9519        0.2005       0.7937      0.8726        [94m0.2423[0m     +  0.0000  10.9486
     33      0.9538        [32m0.1995[0m       0.7937      0.8727        [94m0.2423[0m     +  0.0000  10.8524
     34      0.9474        0.2047       0.7936      0.8726        [94m0.2423[0m     +  0.0000  10.8845
     35      0.9502        [32m0.1988[0m       0.7932      0.8726        [94m0.2423[0m     +  0.0000  10.9631
     36      0.9532        0.2000       0.7932      0.8726        [94m0.2423[0m     +  0.0000  10.9147
     37      0.9507        0.2005       0.7932      0.8726        [94m0.2423[0m     +  0.0000  10.9503
     38      0.9520        0.2003       0.7934      0.8727        0.2423        0.0000  10.9349
     39      0.9503        0.2009       0.7934      0.8727        [94m0.2423[0m     +  0.0000  10.9491
     40      0.9539        0.2008       0.7934      0.8726        [94m0.2423[0m     +  0.0000  10.9472
     41      0.9516        0.2012       0.7934      0.8726        0.2423        0.0000  10.9631
     42      0.9498        0.1997       0.7932      0.8725        0.2423        0.0000  10.9315
     43      0.9511        0.2023       0.7932      0.8725        0.2423        0.0000  10.9501
     44      0.9538        0.2013       0.7932      0.8725        0.2423        0.0000  10.8702
     45      0.9507        0.2000       0.7932      0.8725        0.2423        0.0000  10.8830
     46      0.9523        0.2012       0.7932      0.8725        0.2423        0.0000  10.8834
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 8 Test Accuracy: 0.8083
Iteration 8 Test F1 Score (micro): 0.9105
Iteration 8 Test F1 Score (macro): 0.8996
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_7.pt

Query 9: Using the exact images and labels from the CSV for this iteration.

Query 9: Using images from iteration=9 (random sampling).
Number of samples used for training in Query 9 is 2264
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9184[0m        [32m0.2252[0m       [35m0.7988[0m      [31m0.8798[0m        [94m0.2426[0m     +  0.0000  13.7608
      2      [36m0.9384[0m        [32m0.2034[0m       0.7984      0.8788        [94m0.2400[0m     +  0.0000  13.4161
      3      [36m0.9466[0m        [32m0.1927[0m       [35m0.8054[0m      [31m0.8800[0m        [94m0.2350[0m     +  0.0000  13.5261
      4      [36m0.9496[0m        [32m0.1887[0m       [35m0.8125[0m      [31m0.8812[0m        [94m0.2319[0m     +  0.0000  13.4794
      5      [36m0.9548[0m        [32m0.1855[0m       0.8038      [31m0.8824[0m        [94m0.2318[0m     +  0.0000  13.4965
      6      [36m0.9584[0m        [32m0.1792[0m       [35m0.8132[0m      [31m0.8840[0m        [94m0.2274[0m     +  0.0000  13.4809
      7      [36m0.9609[0m        [32m0.1766[0m       0.8130      [31m0.8842[0m        0.2276        0.0000  13.5089
      8      [36m0.9624[0m        [32m0.1760[0m       0.8125      0.8840        [94m0.2270[0m     +  0.0000  13.5596
      9      [36m0.9641[0m        [32m0.1738[0m       0.8102      [31m0.8845[0m        0.2278        0.0000  13.5725
     10      0.9637        [32m0.1722[0m       0.8102      0.8842        [94m0.2270[0m     +  0.0000  13.6053
     11      0.9639        0.1738       [35m0.8208[0m      [31m0.8847[0m        [94m0.2238[0m     +  0.0000  13.5607
     12      [36m0.9652[0m        [32m0.1715[0m       0.8186      0.8840        [94m0.2237[0m     +  0.0000  13.5124
     13      0.9652        [32m0.1707[0m       0.8194      0.8841        [94m0.2235[0m     +  0.0000  13.5246
     14      [36m0.9683[0m        [32m0.1694[0m       [35m0.8212[0m      0.8845        [94m0.2233[0m     +  0.0000  13.4951
     15      0.9682        [32m0.1669[0m       [35m0.8217[0m      0.8846        [94m0.2231[0m     +  0.0000  13.5279
     16      0.9676        0.1681       0.8203      0.8843        [94m0.2229[0m     +  0.0000  13.5364
     17      0.9671        0.1675       0.8212      0.8844        [94m0.2226[0m     +  0.0000  13.5251
     18      [36m0.9695[0m        0.1674       0.8207      0.8844        [94m0.2226[0m     +  0.0000  13.5097
     19      0.9688        0.1675       0.8207      0.8843        0.2226        0.0000  13.5084
     20      0.9685        0.1676       0.8203      0.8842        0.2226        0.0000  13.5124
     21      0.9681        0.1675       0.8210      0.8842        [94m0.2225[0m     +  0.0000  13.5579
     22      0.9685        0.1670       0.8208      0.8838        [94m0.2224[0m     +  0.0000  13.5930
     23      0.9686        0.1669       0.8212      0.8842        [94m0.2224[0m     +  0.0000  13.5110
     24      0.9691        [32m0.1661[0m       0.8208      0.8838        [94m0.2224[0m     +  0.0000  13.5126
     25      0.9680        0.1689       0.8212      0.8840        [94m0.2224[0m     +  0.0000  13.4782
     26      [36m0.9697[0m        [32m0.1641[0m       0.8212      0.8838        [94m0.2223[0m     +  0.0000  13.5119
     27      0.9695        0.1667       0.8217      0.8841        [94m0.2223[0m     +  0.0000  13.4967
     28      0.9692        0.1669       0.8217      0.8842        [94m0.2223[0m     +  0.0000  13.4950
     29      [36m0.9698[0m        0.1659       [35m0.8226[0m      0.8846        [94m0.2223[0m     +  0.0000  13.4474
     30      0.9693        0.1663       0.8215      0.8841        [94m0.2223[0m     +  0.0000  13.4621
     31      0.9692        0.1670       0.8224      0.8844        [94m0.2223[0m     +  0.0000  13.4968
     32      0.9674        0.1665       0.8226      0.8846        [94m0.2223[0m     +  0.0000  13.5588
     33      0.9683        0.1667       0.8226      0.8846        0.2223        0.0000  13.5274
     34      0.9688        0.1667       0.8226      0.8846        [94m0.2222[0m     +  0.0000  13.5405
     35      [36m0.9706[0m        0.1654       0.8226      0.8845        [94m0.2222[0m     +  0.0000  13.4959
     36      0.9678        0.1667       0.8226      0.8845        [94m0.2222[0m     +  0.0000  13.5421
     37      0.9695        0.1664       0.8226      0.8845        [94m0.2222[0m     +  0.0000  13.5272
     38      0.9682        0.1665       0.8222      0.8843        0.2222        0.0000  13.5106
     39      0.9687        0.1675       0.8224      0.8844        0.2222        0.0000  13.5412
     40      0.9692        0.1658       0.8226      0.8845        [94m0.2222[0m     +  0.0000  13.5671
     41      0.9697        0.1679       [35m0.8227[0m      0.8846        [94m0.2222[0m     +  0.0000  14.1079
     42      0.9689        0.1655       0.8226      0.8845        [94m0.2222[0m     +  0.0000  13.5587
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 9 Test Accuracy: 0.8253
Iteration 9 Test F1 Score (micro): 0.9187
Iteration 9 Test F1 Score (macro): 0.9081
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_8.pt

Query 10: Using the exact images and labels from the CSV for this iteration.

Query 10: Using images from iteration=10 (random sampling).
Number of samples used for training in Query 10 is 4040
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9406[0m        [32m0.1898[0m       [35m0.8156[0m      [31m0.8793[0m        [94m0.2223[0m     +  0.0000  18.2816
      2      [36m0.9604[0m        [32m0.1667[0m       0.8094      [31m0.8804[0m        [94m0.2191[0m     +  0.0000  18.0765
      3      [36m0.9620[0m        [32m0.1620[0m       [35m0.8200[0m      [31m0.8808[0m        [94m0.2173[0m     +  0.0000  18.3123
      4      [36m0.9659[0m        [32m0.1562[0m       0.8135      0.8800        [94m0.2148[0m     +  0.0000  18.2328
      5      [36m0.9663[0m        [32m0.1550[0m       0.8172      0.8773        0.2176        0.0000  18.1868
      6      [36m0.9701[0m        [32m0.1516[0m       [35m0.8323[0m      [31m0.8854[0m        [94m0.2114[0m     +  0.0000  18.2027
      7      [36m0.9711[0m        [32m0.1479[0m       0.8293      0.8826        0.2123        0.0000  18.2194
      8      0.9710        [32m0.1475[0m       0.8299      0.8832        0.2122        0.0000  18.1847
      9      0.9711        [32m0.1462[0m       0.8269      0.8803        0.2129        0.0000  18.1886
     10      [36m0.9730[0m        [32m0.1450[0m       0.8281      0.8838        [94m0.2099[0m     +  0.0000  18.2293
     11      [36m0.9739[0m        [32m0.1438[0m       0.8311      [31m0.8856[0m        [94m0.2090[0m     +  0.0000  18.1717
     12      0.9735        [32m0.1421[0m       0.8306      0.8852        [94m0.2087[0m     +  0.0000  18.2187
     13      0.9736        0.1426       0.8314      0.8850        0.2092        0.0000  18.1746
     14      [36m0.9748[0m        [32m0.1418[0m       0.8306      0.8846        0.2090        0.0000  18.1723
     15      [36m0.9751[0m        0.1423       0.8299      0.8844        0.2090        0.0000  18.1701
     16      0.9749        [32m0.1403[0m       0.8283      0.8853        [94m0.2079[0m     +  0.0000  18.2342
     17      0.9750        [32m0.1402[0m       0.8290      [31m0.8857[0m        0.2081        0.0000  18.2337
     18      0.9743        [32m0.1394[0m       0.8283      0.8850        [94m0.2079[0m     +  0.0000  18.1882
     19      0.9749        0.1404       0.8295      0.8855        [94m0.2079[0m     +  0.0000  18.1592
     20      0.9749        0.1403       0.8280      0.8850        0.2079        0.0000  18.1530
     21      0.9740        0.1398       0.8280      [31m0.8869[0m        [94m0.2076[0m     +  0.0000  18.2033
     22      0.9736        0.1403       0.8273      0.8863        [94m0.2075[0m     +  0.0000  18.1569
     23      [36m0.9761[0m        [32m0.1385[0m       0.8276      0.8864        [94m0.2075[0m     +  0.0000  18.1586
     24      0.9752        [32m0.1382[0m       0.8278      0.8868        [94m0.2075[0m     +  0.0000  18.2483
     25      0.9754        0.1389       0.8276      0.8868        [94m0.2074[0m     +  0.0000  19.2185
     26      0.9751        0.1399       0.8280      [31m0.8873[0m        [94m0.2074[0m     +  0.0000  18.1732
     27      0.9754        0.1402       0.8281      [31m0.8876[0m        [94m0.2074[0m     +  0.0000  18.2497
     28      0.9747        0.1394       0.8271      0.8870        0.2074        0.0000  18.1406
     29      0.9742        0.1397       0.8274      0.8871        0.2074        0.0000  18.2203
     30      0.9757        0.1387       0.8273      0.8870        0.2075        0.0000  18.1698
     31      0.9746        0.1388       0.8273      0.8870        0.2075        0.0000  18.2339
     32      0.9750        0.1390       0.8274      0.8872        0.2074        0.0000  18.2019
     33      0.9744        0.1385       0.8271      0.8869        0.2074        0.0000  18.1577
     34      0.9741        0.1394       0.8274      0.8872        0.2074        0.0000  18.2002
     35      0.9750        0.1401       0.8274      0.8872        0.2074        0.0000  18.2806
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 10 Test Accuracy: 0.8252
Iteration 10 Test F1 Score (micro): 0.9185
Iteration 10 Test F1 Score (macro): 0.9066
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_9.pt

Query 11: Using the exact images and labels from the CSV for this iteration.

Query 11: Using images from iteration=11 (random sampling).
Number of samples used for training in Query 11 is 7200
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9530[0m        [32m0.1587[0m       [35m0.8337[0m      [31m0.8944[0m        [94m0.2045[0m     +  0.0000  26.5057
      2      [36m0.9637[0m        [32m0.1434[0m       0.8318      [31m0.8978[0m        [94m0.2032[0m     +  0.0000  26.5053
      3      [36m0.9675[0m        [32m0.1389[0m       0.8302      0.8975        0.2057        0.0000  26.6015
      4      [36m0.9687[0m        [32m0.1348[0m       [35m0.8410[0m      [31m0.8992[0m        [94m0.1983[0m     +  0.0000  26.5515
      5      [36m0.9690[0m        [32m0.1311[0m       0.8292      0.8992        0.2056        0.0000  26.5746
      6      [36m0.9714[0m        [32m0.1280[0m       0.8332      0.8936        [94m0.1951[0m     +  0.0000  26.5525
      7      [36m0.9717[0m        [32m0.1260[0m       0.8352      0.8949        0.1960        0.0000  26.5220
      8      [36m0.9724[0m        [32m0.1251[0m       0.8356      0.8956        0.1952        0.0000  26.5546
      9      0.9723        [32m0.1240[0m       0.8345      0.8940        0.1954        0.0000  26.5032
     10      [36m0.9729[0m        [32m0.1224[0m       0.8335      0.8933        0.1962        0.0000  26.4594
     11      [36m0.9742[0m        [32m0.1202[0m       0.8299      0.8917        0.1960        0.0000  26.5052
     12      [36m0.9747[0m        0.1207       0.8311      0.8925        0.1955        0.0000  26.5057
     13      0.9738        0.1205       0.8300      0.8925        0.1957        0.0000  26.5213
     14      0.9745        [32m0.1198[0m       0.8314      0.8926        0.1958        0.0000  26.5527
     15      [36m0.9747[0m        [32m0.1186[0m       0.8316      0.8923        0.1956        0.0000  26.5635
     16      0.9747        [32m0.1180[0m       0.8281      0.8904        0.1961        0.0000  26.4731
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 11 Test Accuracy: 0.8163
Iteration 11 Test F1 Score (micro): 0.9138
Iteration 11 Test F1 Score (macro): 0.9028
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_10.pt

Query 12: Using the exact images and labels from the CSV for this iteration.

Query 12: Using images from iteration=12 (random sampling).
Number of samples used for training in Query 12 is 12824
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9613[0m        [32m0.1357[0m       [35m0.8205[0m      [31m0.8678[0m        [94m0.2067[0m     +  0.0000  41.1105
      2      [36m0.9684[0m        [32m0.1242[0m       0.7964      0.8224        0.2253        0.0000  41.2967
      3      [36m0.9686[0m        [32m0.1199[0m       0.7806      0.7975        0.2348        0.0000  41.2825
      4      [36m0.9703[0m        [32m0.1158[0m       [35m0.8215[0m      [31m0.8822[0m        [94m0.1896[0m     +  0.0000  41.2857
      5      [36m0.9723[0m        [32m0.1123[0m       0.8104      0.8599        0.2062        0.0000  41.2844
      6      [36m0.9752[0m        [32m0.1080[0m       0.8170      0.8792        0.1919        0.0000  41.1724
      7      [36m0.9759[0m        [32m0.1062[0m       0.8186      0.8816        0.1927        0.0000  41.2060
      8      [36m0.9761[0m        [32m0.1045[0m       0.8193      0.8739        0.1960        0.0000  41.2325
      9      [36m0.9766[0m        [32m0.1034[0m       0.8153      0.8815        0.1952        0.0000  41.2174
     10      [36m0.9774[0m        [32m0.1010[0m       0.8161      0.8778        0.1936        0.0000  41.2460
     11      [36m0.9784[0m        [32m0.1003[0m       [35m0.8220[0m      0.8790        0.1914        0.0000  43.0398
     12      [36m0.9786[0m        [32m0.0992[0m       0.8196      0.8804        0.1928        0.0000  41.0465
     13      0.9784        0.0996       0.8194      0.8801        0.1929        0.0000  41.2405
     14      0.9785        [32m0.0985[0m       0.8208      0.8801        0.1926        0.0000  41.2366
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 12 Test Accuracy: 0.8153
Iteration 12 Test F1 Score (micro): 0.9139
Iteration 12 Test F1 Score (macro): 0.9009
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_11.pt

Query 13: Using the exact images and labels from the CSV for this iteration.

Query 13: Using images from iteration=13 (random sampling).
Number of samples used for training in Query 13 is 22824
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9684[0m        [32m0.1144[0m       [35m0.8276[0m      [31m0.8647[0m        [94m0.1995[0m     +  0.0000  67.1130
      2      [36m0.9734[0m        [32m0.1053[0m       0.8240      0.8605        0.2026        0.0000  67.6029
      3      [36m0.9744[0m        [32m0.0998[0m       0.8057      0.8370        0.2112        0.0000  67.6790
      4      [36m0.9759[0m        [32m0.0955[0m       0.8002      0.8327        0.2104        0.0000  67.5938
      5      [36m0.9766[0m        [32m0.0906[0m       0.8203      [31m0.8661[0m        [94m0.1916[0m     +  0.0000  67.5933
      6      [36m0.9783[0m        [32m0.0859[0m       0.8224      [31m0.8718[0m        [94m0.1887[0m     +  0.0000  70.3557
      7      [36m0.9801[0m        [32m0.0839[0m       0.8250      [31m0.8761[0m        [94m0.1853[0m     +  0.0000  68.5010
      8      0.9795        [32m0.0826[0m       0.8260      [31m0.8786[0m        [94m0.1844[0m     +  0.0000  67.5527
      9      [36m0.9806[0m        [32m0.0810[0m       0.8253      0.8768        0.1860        0.0000  67.5518
     10      [36m0.9815[0m        [32m0.0791[0m       0.8240      0.8762        0.1862        0.0000  67.5384
     11      [36m0.9816[0m        [32m0.0777[0m       0.8262      [31m0.8835[0m        [94m0.1815[0m     +  0.0000  67.5212
     12      [36m0.9822[0m        [32m0.0768[0m       0.8267      [31m0.8838[0m        0.1823        0.0000  67.4241
     13      [36m0.9827[0m        [32m0.0761[0m       0.8259      0.8832        0.1828        0.0000  67.5498
     14      0.9825        [32m0.0754[0m       0.8253      0.8822        0.1838        0.0000  67.4706
     15      [36m0.9828[0m        [32m0.0747[0m       0.8234      0.8821        0.1835        0.0000  67.5778
     16      [36m0.9833[0m        [32m0.0743[0m       0.8229      0.8824        0.1836        0.0000  67.5182
     17      [36m0.9836[0m        [32m0.0735[0m       0.8224      0.8823        0.1834        0.0000  67.5811
     18      0.9834        [32m0.0734[0m       0.8220      0.8818        0.1837        0.0000  67.5372
     19      [36m0.9837[0m        [32m0.0733[0m       0.8222      0.8820        0.1836        0.0000  67.5177
     20      [36m0.9837[0m        [32m0.0732[0m       0.8229      0.8827        0.1838        0.0000  67.4882
     21      0.9836        [32m0.0731[0m       0.8212      0.8816        0.1841        0.0000  67.5643
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 13 Test Accuracy: 0.8307
Iteration 13 Test F1 Score (micro): 0.9219
Iteration 13 Test F1 Score (macro): 0.9078
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_12.pt

Query 14: Using the exact images and labels from the CSV for this iteration.

Query 14: Using images from iteration=14 (random sampling).
Number of samples used for training in Query 14 is 26880
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9775[0m        [32m0.0800[0m       [35m0.8194[0m      [31m0.8802[0m        [94m0.1833[0m     +  0.0000  78.1069
      2      [36m0.9805[0m        [32m0.0739[0m       [35m0.8222[0m      [31m0.8817[0m        [94m0.1818[0m     +  0.0000  78.2485
      3      [36m0.9817[0m        [32m0.0699[0m       0.8220      [31m0.8818[0m        0.1828        0.0000  78.2656
      4      0.9815        [32m0.0674[0m       0.8207      0.8810        [94m0.1811[0m     +  0.0000  78.2007
      5      [36m0.9823[0m        [32m0.0645[0m       [35m0.8238[0m      [31m0.8823[0m        [94m0.1796[0m     +  0.0000  78.0730
      6      [36m0.9837[0m        [32m0.0607[0m       [35m0.8240[0m      0.8814        [94m0.1788[0m     +  0.0000  78.1859
      7      [36m0.9843[0m        [32m0.0592[0m       0.8236      0.8808        0.1798        0.0000  78.1637
      8      [36m0.9843[0m        [32m0.0580[0m       [35m0.8255[0m      0.8808        0.1806        0.0000  78.0582
      9      [36m0.9848[0m        [32m0.0567[0m       [35m0.8266[0m      0.8814        0.1813        0.0000  78.0960
     10      [36m0.9852[0m        [32m0.0557[0m       0.8259      0.8814        0.1826        0.0000  78.0882
     11      [36m0.9862[0m        [32m0.0544[0m       0.8252      0.8803        0.1834        0.0000  78.2135
     12      [36m0.9863[0m        [32m0.0538[0m       0.8240      0.8795        0.1845        0.0000  78.1384
     13      [36m0.9865[0m        [32m0.0532[0m       0.8255      0.8798        0.1845        0.0000  78.1705
     14      0.9862        [32m0.0530[0m       0.8245      0.8793        0.1844        0.0000  78.0791
     15      [36m0.9868[0m        [32m0.0524[0m       0.8252      0.8792        0.1848        0.0000  78.0577
     16      [36m0.9870[0m        [32m0.0520[0m       0.8231      0.8791        0.1861        0.0000  78.2027
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 14 Test Accuracy: 0.8427
Iteration 14 Test F1 Score (micro): 0.9258
Iteration 14 Test F1 Score (macro): 0.9122
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\model_checkpoint_iteration_13.pt

Best F1 score across all iterations: 0.9122
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed44_test\random_sampling_results_for_multilabel_classification_s44.pickle
