Train set shape: (26880, 5)
Val set shape:   (5760, 5)
Test set shape:  (5760, 5)
Selected images DataFrame (Random Sampling):
   Query_Iteration                                     Selected_Image
0                1  Spule035_Image0269.jpg,Spule020_Image0191.jpg,...
1                2  Spule021_Image0201.jpg,Spule022_Image0815.jpg,...
2                3  Spule003_Image0783.jpg,Spule028_Image0616.jpg,...
3                4  Spule008_Image0342.jpg,Spule013_Image0238.jpg,...
4                5  Spule021_Image0012.jpg,Spule036_Image0919.jpg,...

Query 1: Using the exact images and labels from the CSV for this iteration.

Query 1: Using images from iteration=1 (random sampling).
Number of samples used for training in Query 1 is 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.2000[0m        [32m0.7363[0m       [35m0.1616[0m      [31m0.1366[0m        [94m0.6922[0m     +  0.0000  7.9098
      2      [36m0.3619[0m        [32m0.6652[0m       [35m0.2080[0m      [31m0.2869[0m        [94m0.6915[0m     +  0.0000  7.4114
      3      [36m0.7222[0m        [32m0.6119[0m       [35m0.2630[0m      [31m0.3464[0m        [94m0.6886[0m     +  0.0000  7.4701
      4      0.6984        [32m0.5935[0m       0.2552      [31m0.3597[0m        0.6942        0.0000  7.5267
      5      0.5000        0.6108       0.2335      [31m0.3889[0m        [94m0.6856[0m     +  0.0000  7.5587
      6      [36m0.8333[0m        0.5954       [35m0.2726[0m      0.3817        0.6872        0.0000  7.5521
      7      0.7579        [32m0.5660[0m       0.2628      0.3870        0.6864        0.0000  7.5950
      8      [36m0.8796[0m        [32m0.5481[0m       [35m0.2894[0m      0.3715        0.6892        0.0000  7.6636
      9      0.8796        0.5523       0.2668      [31m0.4019[0m        0.6877        0.0000  7.6629
     10      [36m0.9153[0m        [32m0.5227[0m       0.2396      0.3979        0.6860        0.0000  7.6699
     11      0.8487        0.5490       0.2382      [31m0.4045[0m        0.6861        0.0000  7.6825
     12      [36m0.9167[0m        0.5303       0.2370      [31m0.4085[0m        0.6873        0.0000  7.6560
     13      0.9167        [32m0.5176[0m       0.2431      0.4072        0.6877        0.0000  7.6979
     14      0.9153        0.5316       0.2418      [31m0.4140[0m        0.6884        0.0000  7.7061
     15      0.9153        [32m0.5106[0m       0.2359      [31m0.4215[0m        0.6877        0.0000  7.6866
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 1 Test Accuracy: 0.3389
Iteration 1 Test F1 Score (micro): 0.4720
Iteration 1 Test F1 Score (macro): 0.4518
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_0.pt

Query 2: Using the exact images and labels from the CSV for this iteration.

Query 2: Using images from iteration=2 (random sampling).
Number of samples used for training in Query 2 is 24
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.5563[0m        [32m0.6641[0m       [35m0.1311[0m      [31m0.6929[0m        [94m0.6708[0m     +  0.0000  7.7542
      2      [36m0.6219[0m        [32m0.6281[0m       [35m0.2014[0m      0.3768        [94m0.6576[0m     +  0.0000  7.7104
      3      [36m0.7105[0m        [32m0.5944[0m       0.1677      0.4583        0.6597        0.0000  7.6709
      4      0.6886        [32m0.5902[0m       [35m0.2220[0m      0.4689        [94m0.6467[0m     +  0.0000  7.7889
      5      [36m0.7552[0m        [32m0.5802[0m       0.1943      0.5166        0.6575        0.0000  7.6832
      6      [36m0.7662[0m        0.5865       0.1793      0.5018        0.6511        0.0000  7.7794
      7      [36m0.7810[0m        [32m0.5469[0m       0.1585      0.4843        0.6475        0.0000  7.7696
      8      0.7396        0.5486       0.1413      0.4765        0.6472        0.0000  7.7254
      9      [36m0.7975[0m        [32m0.5332[0m       0.1576      0.4827        [94m0.6444[0m     +  0.0000  7.7073
     10      0.7789        0.5555       0.1597      0.4873        [94m0.6429[0m     +  0.0000  7.6806
     11      [36m0.8254[0m        0.5363       0.1630      0.4871        [94m0.6413[0m     +  0.0000  7.6920
     12      0.7646        0.5360       0.1649      0.4878        [94m0.6405[0m     +  0.0000  7.6642
     13      0.7965        [32m0.5331[0m       0.1641      0.4874        [94m0.6400[0m     +  0.0000  7.6614
     14      0.8047        [32m0.5259[0m       0.1672      0.4910        [94m0.6399[0m     +  0.0000  7.6769
     15      [36m0.8383[0m        [32m0.5166[0m       0.1734      0.4909        [94m0.6380[0m     +  0.0000  7.6326
     16      0.7801        0.5357       0.1733      0.4923        [94m0.6380[0m     +  0.0000  7.6630
     17      [36m0.8476[0m        0.5234       0.1755      0.4922        [94m0.6375[0m     +  0.0000  7.6771
     18      0.8289        0.5197       0.1759      0.4918        [94m0.6372[0m     +  0.0000  7.6311
     19      0.7963        0.5273       0.1764      0.4919        [94m0.6369[0m     +  0.0000  7.6296
     20      0.8289        [32m0.5098[0m       0.1762      0.4928        [94m0.6368[0m     +  0.0000  7.6461
     21      0.8060        0.5124       0.1760      0.4929        [94m0.6368[0m     +  0.0000  7.5998
     22      0.8043        0.5195       0.1762      0.4926        [94m0.6366[0m     +  0.0000  7.6148
     23      0.8379        0.5148       0.1759      0.4929        [94m0.6366[0m     +  0.0000  7.6793
     24      0.8214        0.5343       0.1760      0.4929        0.6366        0.0000  7.6632
     25      0.7816        0.5304       0.1757      0.4926        [94m0.6366[0m     +  0.0000  7.6943
     26      [36m0.8675[0m        0.5234       0.1759      0.4927        [94m0.6365[0m     +  0.0000  7.6463
     27      0.8274        [32m0.5091[0m       0.1760      0.4928        [94m0.6365[0m     +  0.0000  7.7396
     28      [36m0.9120[0m        0.5136       0.1760      0.4928        [94m0.6365[0m     +  0.0000  7.6634
     29      0.7816        0.5291       0.1757      0.4926        [94m0.6365[0m     +  0.0000  7.6159
     30      0.7974        0.5203       0.1762      0.4928        [94m0.6364[0m     +  0.0000  7.7262
     31      0.7835        0.5200       0.1760      0.4928        [94m0.6364[0m     +  0.0000  7.6787
     32      0.8264        [32m0.4950[0m       0.1762      0.4927        [94m0.6364[0m     +  0.0000  7.6464
     33      0.8332        [32m0.4940[0m       0.1762      0.4928        0.6364        0.0000  7.6152
     34      0.8475        0.5210       0.1760      0.4927        [94m0.6364[0m     +  0.0000  7.6312
     35      0.8172        0.5216       0.1762      0.4930        [94m0.6364[0m     +  0.0000  7.6461
     36      0.8208        0.5113       0.1762      0.4930        [94m0.6364[0m     +  0.0000  7.6003
     37      0.8047        0.5265       0.1762      0.4930        [94m0.6364[0m     +  0.0000  7.6779
     38      0.8401        0.5268       0.1762      0.4930        [94m0.6363[0m     +  0.0000  7.6312
     39      0.7656        0.5380       0.1762      0.4930        [94m0.6363[0m     +  0.0000  7.6317
     40      0.8900        0.5025       0.1762      0.4930        [94m0.6363[0m     +  0.0000  7.6156
     41      0.8330        0.5266       0.1762      0.4930        [94m0.6363[0m     +  0.0000  7.6482
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 2 Test Accuracy: 0.2363
Iteration 2 Test F1 Score (micro): 0.5800
Iteration 2 Test F1 Score (macro): 0.5156
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_1.pt

Query 3: Using the exact images and labels from the CSV for this iteration.

Query 3: Using images from iteration=3 (random sampling).
Number of samples used for training in Query 3 is 56
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.6889[0m        [32m0.5898[0m       [35m0.4132[0m      [31m0.2792[0m        [94m0.6168[0m     +  0.0000  7.8174
      2      0.3206        0.5959       0.3116      [31m0.4949[0m        [94m0.5997[0m     +  0.0000  7.6932
      3      0.6478        [32m0.5660[0m       0.3731      0.4785        [94m0.5837[0m     +  0.0000  7.7260
      4      0.6322        [32m0.5327[0m       0.3773      [31m0.5613[0m        [94m0.5651[0m     +  0.0000  7.6492
      5      [36m0.7289[0m        [32m0.5143[0m       [35m0.5071[0m      [31m0.5653[0m        [94m0.5513[0m     +  0.0000  7.7417
      6      [36m0.7540[0m        [32m0.4934[0m       [35m0.5417[0m      [31m0.6265[0m        [94m0.5412[0m     +  0.0000  7.7239
      7      [36m0.8179[0m        [32m0.4865[0m       [35m0.5453[0m      [31m0.6331[0m        [94m0.5369[0m     +  0.0000  7.7245
      8      0.7968        [32m0.4625[0m       [35m0.5571[0m      [31m0.6527[0m        [94m0.5303[0m     +  0.0000  7.7082
      9      0.7956        0.4638       0.5503      0.6433        [94m0.5278[0m     +  0.0000  7.6949
     10      [36m0.8827[0m        [32m0.4585[0m       [35m0.5677[0m      [31m0.6758[0m        [94m0.5199[0m     +  0.0000  7.7247
     11      [36m0.9277[0m        [32m0.4397[0m       0.5634      0.6636        [94m0.5185[0m     +  0.0000  7.6931
     12      0.8933        [32m0.4374[0m       0.5656      0.6677        [94m0.5166[0m     +  0.0000  7.7095
     13      0.8938        0.4394       0.5646      0.6663        [94m0.5152[0m     +  0.0000  7.6790
     14      0.8326        0.4486       [35m0.5701[0m      [31m0.6799[0m        [94m0.5133[0m     +  0.0000  7.6799
     15      0.8966        [32m0.4360[0m       0.5674      0.6718        [94m0.5110[0m     +  0.0000  7.7406
     16      0.8465        0.4390       0.5681      0.6726        [94m0.5105[0m     +  0.0000  7.7094
     17      0.8544        [32m0.4358[0m       0.5696      0.6783        [94m0.5099[0m     +  0.0000  7.7238
     18      0.8382        [32m0.4344[0m       [35m0.5712[0m      [31m0.6803[0m        [94m0.5093[0m     +  0.0000  7.7253
     19      0.8382        0.4483       0.5708      0.6795        [94m0.5088[0m     +  0.0000  7.7245
     20      0.8975        [32m0.4300[0m       [35m0.5714[0m      0.6803        [94m0.5083[0m     +  0.0000  7.6944
     21      0.8592        [32m0.4272[0m       [35m0.5715[0m      [31m0.6806[0m        [94m0.5080[0m     +  0.0000  7.7085
     22      0.8585        0.4339       0.5715      [31m0.6809[0m        [94m0.5078[0m     +  0.0000  7.7420
     23      0.8789        0.4379       [35m0.5717[0m      [31m0.6811[0m        [94m0.5077[0m     +  0.0000  7.6948
     24      0.8338        0.4364       0.5717      [31m0.6815[0m        [94m0.5074[0m     +  0.0000  7.7422
     25      0.8698        0.4331       [35m0.5724[0m      [31m0.6832[0m        [94m0.5073[0m     +  0.0000  7.6649
     26      0.8623        0.4388       0.5724      0.6832        [94m0.5072[0m     +  0.0000  7.7554
     27      0.8823        [32m0.4256[0m       0.5720      0.6827        [94m0.5072[0m     +  0.0000  7.6959
     28      0.8909        0.4304       0.5724      [31m0.6833[0m        [94m0.5071[0m     +  0.0000  7.7100
     29      0.8816        0.4525       0.5724      0.6832        [94m0.5070[0m     +  0.0000  7.7107
     30      0.8868        0.4284       0.5724      0.6832        [94m0.5070[0m     +  0.0000  7.6930
     31      0.8598        0.4315       0.5724      0.6833        [94m0.5069[0m     +  0.0000  7.7431
     32      0.8745        0.4319       0.5722      0.6832        [94m0.5069[0m     +  0.0000  7.6788
     33      0.8887        [32m0.4256[0m       0.5724      0.6833        [94m0.5069[0m     +  0.0000  7.7255
     34      0.8715        [32m0.4242[0m       0.5724      0.6833        [94m0.5069[0m     +  0.0000  7.6946
     35      0.9018        0.4311       0.5722      0.6832        [94m0.5068[0m     +  0.0000  7.7090
     36      0.8580        0.4375       0.5722      0.6833        [94m0.5068[0m     +  0.0000  7.6937
     37      0.8685        [32m0.4210[0m       0.5724      [31m0.6834[0m        [94m0.5068[0m     +  0.0000  7.7255
     38      0.8891        0.4356       0.5724      0.6834        [94m0.5068[0m     +  0.0000  7.7562
     39      0.8942        0.4224       0.5724      0.6834        [94m0.5068[0m     +  0.0000  7.6801
     40      0.8664        0.4357       0.5724      0.6833        [94m0.5068[0m     +  0.0000  7.6927
     41      0.8385        0.4387       0.5724      0.6833        [94m0.5068[0m     +  0.0000  7.6636
     42      0.9118        0.4379       0.5724      0.6833        [94m0.5068[0m     +  0.0000  7.6913
     43      0.8641        0.4414       0.5724      0.6833        [94m0.5068[0m     +  0.0000  7.6929
     44      0.8488        0.4431       0.5724      [31m0.6835[0m        [94m0.5068[0m     +  0.0000  7.6757
     45      0.8424        0.4388       0.5724      0.6835        [94m0.5067[0m     +  0.0000  7.6931
     46      0.8803        0.4450       0.5724      0.6835        [94m0.5067[0m     +  0.0000  7.6923
     47      0.8874        0.4408       0.5724      0.6835        [94m0.5067[0m     +  0.0000  7.7080
     48      0.8481        0.4465       0.5724      0.6835        [94m0.5067[0m     +  0.0000  7.7259
     49      0.9037        0.4329       0.5724      0.6835        [94m0.5067[0m     +  0.0000  7.6938
     50      0.8975        0.4225       0.5724      0.6835        [94m0.5067[0m     +  0.0000  7.7089
     51      0.8444        0.4384       0.5724      0.6835        [94m0.5067[0m     +  0.0000  7.7090
     52      0.8499        0.4375       0.5724      0.6835        [94m0.5067[0m     +  0.0000  7.7079
     53      0.8633        0.4322       0.5724      0.6835        [94m0.5067[0m     +  0.0000  7.7584
     54      0.8450        0.4392       0.5724      0.6835        [94m0.5067[0m     +  0.0000  7.6929
     55      0.8633        0.4430       0.5724      0.6835        [94m0.5067[0m     +  0.0000  7.7252
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 3 Test Accuracy: 0.6116
Iteration 3 Test F1 Score (micro): 0.7531
Iteration 3 Test F1 Score (macro): 0.7072
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_2.pt

Query 4: Using the exact images and labels from the CSV for this iteration.

Query 4: Using images from iteration=4 (random sampling).
Number of samples used for training in Query 4 is 112
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.7670[0m        [32m0.4715[0m       [35m0.3573[0m      [31m0.6845[0m        [94m0.5874[0m     +  0.0000  7.9742
      2      [36m0.7744[0m        0.5715       [35m0.4750[0m      0.1804        [94m0.5555[0m     +  0.0000  7.8975
      3      0.2363        0.5470       [35m0.5252[0m      [31m0.7681[0m        [94m0.4834[0m     +  0.0000  7.8799
      4      [36m0.8326[0m        [32m0.4520[0m       [35m0.6191[0m      0.7125        [94m0.4493[0m     +  0.0000  7.8814
      5      0.7498        [32m0.4293[0m       [35m0.6385[0m      [31m0.8001[0m        [94m0.4403[0m     +  0.0000  7.8965
      6      [36m0.8756[0m        [32m0.4046[0m       [35m0.6417[0m      0.7945        [94m0.4280[0m     +  0.0000  7.8959
      7      0.8731        [32m0.3958[0m       [35m0.6443[0m      0.7941        [94m0.4242[0m     +  0.0000  7.9100
      8      0.8741        [32m0.3817[0m       [35m0.6498[0m      0.7960        [94m0.4212[0m     +  0.0000  7.9108
      9      0.8753        0.3878       [35m0.6535[0m      0.7984        [94m0.4185[0m     +  0.0000  8.1772
     10      0.8750        0.3823       [35m0.6573[0m      [31m0.8004[0m        [94m0.4159[0m     +  0.0000  7.8661
     11      [36m0.8782[0m        [32m0.3791[0m       [35m0.6590[0m      [31m0.8009[0m        [94m0.4149[0m     +  0.0000  7.8501
     12      0.8595        [32m0.3756[0m       0.6590      [31m0.8011[0m        [94m0.4138[0m     +  0.0000  7.8064
     13      [36m0.9216[0m        0.3760       [35m0.6597[0m      [31m0.8012[0m        [94m0.4129[0m     +  0.0000  7.8330
     14      0.8808        0.3794       [35m0.6604[0m      [31m0.8015[0m        [94m0.4120[0m     +  0.0000  7.8663
     15      0.8820        0.3791       [35m0.6608[0m      0.8012        [94m0.4112[0m     +  0.0000  7.9119
     16      0.8722        0.3771       [35m0.6622[0m      [31m0.8019[0m        [94m0.4109[0m     +  0.0000  7.9603
     17      0.8874        [32m0.3715[0m       [35m0.6625[0m      [31m0.8020[0m        [94m0.4105[0m     +  0.0000  7.8660
     18      0.8888        [32m0.3698[0m       0.6625      0.8020        [94m0.4102[0m     +  0.0000  7.9268
     19      0.8794        0.3785       0.6625      [31m0.8022[0m        [94m0.4098[0m     +  0.0000  7.8357
     20      0.8828        0.3804       [35m0.6634[0m      [31m0.8029[0m        [94m0.4095[0m     +  0.0000  7.8806
     21      0.8576        0.3756       0.6634      0.8029        [94m0.4094[0m     +  0.0000  7.9437
     22      0.8519        0.3762       [35m0.6637[0m      0.8028        [94m0.4093[0m     +  0.0000  7.8820
     23      0.9216        0.3714       [35m0.6641[0m      [31m0.8029[0m        [94m0.4092[0m     +  0.0000  7.8815
     24      0.8930        0.3743       0.6641      0.8029        [94m0.4090[0m     +  0.0000  7.8342
     25      0.8778        [32m0.3648[0m       [35m0.6644[0m      [31m0.8033[0m        [94m0.4089[0m     +  0.0000  7.9912
     26      0.8663        0.3674       0.6644      0.8033        [94m0.4088[0m     +  0.0000  7.8018
     27      0.8993        0.3774       [35m0.6646[0m      [31m0.8033[0m        [94m0.4088[0m     +  0.0000  7.9437
     28      0.8837        0.3724       0.6646      0.8033        [94m0.4087[0m     +  0.0000  7.8667
     29      0.9070        0.3684       0.6646      [31m0.8034[0m        [94m0.4087[0m     +  0.0000  7.8959
     30      0.8972        0.3676       0.6646      0.8034        [94m0.4087[0m     +  0.0000  7.8656
     31      0.8693        0.3807       0.6646      0.8034        [94m0.4086[0m     +  0.0000  7.8662
     32      0.9004        0.3708       0.6646      [31m0.8035[0m        [94m0.4086[0m     +  0.0000  7.8654
     33      0.8882        0.3703       0.6646      0.8035        [94m0.4086[0m     +  0.0000  7.8659
     34      0.8889        0.3682       0.6646      0.8035        [94m0.4086[0m     +  0.0000  7.8804
     35      0.9063        0.3676       0.6646      0.8035        [94m0.4086[0m     +  0.0000  7.8491
     36      0.9082        0.3653       0.6646      0.8035        [94m0.4086[0m     +  0.0000  7.9272
     37      0.8722        0.3823       0.6646      0.8035        [94m0.4086[0m     +  0.0000  7.8353
     38      0.9117        0.3707       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.9298
     39      0.8873        0.3743       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.8486
     40      0.8929        0.3700       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.8337
     41      0.8757        0.3714       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.8653
     42      0.8722        0.3738       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.8189
     43      0.8950        0.3730       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.8800
     44      0.8602        0.3718       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.8339
     45      0.8597        0.3725       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.8806
     46      0.9094        0.3781       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.8970
     47      0.8831        0.3672       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.8640
     48      0.8903        0.3716       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.8953
     49      0.9008        0.3767       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.8339
     50      0.9057        0.3729       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.9281
     51      0.9129        0.3677       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.8344
     52      0.8961        0.3717       0.6646      0.8035        [94m0.4085[0m     +  0.0000  7.8972
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 4 Test Accuracy: 0.7108
Iteration 4 Test F1 Score (micro): 0.8389
Iteration 4 Test F1 Score (macro): 0.8054
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_3.pt

Query 5: Using the exact images and labels from the CSV for this iteration.

Query 5: Using images from iteration=5 (random sampling).
Number of samples used for training in Query 5 is 208
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8388[0m        [32m0.3853[0m       [35m0.4089[0m      [31m0.6844[0m        [94m0.5882[0m     +  0.0000  8.1944
      2      0.7536        0.4837       [35m0.7021[0m      [31m0.8328[0m        [94m0.3693[0m     +  0.0000  8.1473
      3      [36m0.8931[0m        [32m0.3351[0m       0.6845      0.8047        [94m0.3627[0m     +  0.0000  8.0836
      4      [36m0.9036[0m        [32m0.3188[0m       0.6924      0.8121        [94m0.3557[0m     +  0.0000  8.0833
      5      0.9005        0.3209       0.6974      0.8175        [94m0.3501[0m     +  0.0000  8.1638
      6      [36m0.9038[0m        [32m0.3102[0m       [35m0.7189[0m      [31m0.8383[0m        [94m0.3456[0m     +  0.0000  8.1629
      7      0.8960        [32m0.3054[0m       [35m0.7212[0m      [31m0.8410[0m        [94m0.3439[0m     +  0.0000  8.1315
      8      0.8993        0.3104       [35m0.7236[0m      [31m0.8445[0m        [94m0.3423[0m     +  0.0000  8.1468
      9      0.8946        [32m0.3018[0m       0.7188      0.8392        [94m0.3413[0m     +  0.0000  8.1314
     10      0.9008        [32m0.2990[0m       0.7229      0.8435        [94m0.3397[0m     +  0.0000  8.1163
     11      0.8924        0.3001       0.7231      0.8431        [94m0.3390[0m     +  0.0000  8.1144
     12      0.8921        0.2993       0.7233      0.8435        [94m0.3385[0m     +  0.0000  8.0862
     13      [36m0.9077[0m        0.3004       0.7231      0.8435        [94m0.3382[0m     +  0.0000  8.1003
     14      0.9028        0.3030       0.7226      0.8431        [94m0.3377[0m     +  0.0000  8.1019
     15      0.8989        [32m0.2898[0m       [35m0.7238[0m      0.8444        [94m0.3372[0m     +  0.0000  8.1308
     16      0.8981        0.2977       [35m0.7243[0m      [31m0.8448[0m        [94m0.3370[0m     +  0.0000  8.1637
     17      [36m0.9295[0m        0.2930       0.7234      0.8441        [94m0.3369[0m     +  0.0000  8.1308
     18      0.8963        0.2947       0.7238      0.8440        [94m0.3367[0m     +  0.0000  8.1499
     19      0.9199        0.2962       0.7241      0.8443        [94m0.3366[0m     +  0.0000  8.1465
     20      0.8873        0.2931       0.7229      0.8442        [94m0.3363[0m     +  0.0000  8.1327
     21      0.8959        0.2934       0.7240      0.8447        [94m0.3363[0m     +  0.0000  8.0844
     22      0.8946        0.2999       [35m0.7245[0m      [31m0.8451[0m        [94m0.3362[0m     +  0.0000  8.1159
     23      0.9123        0.2907       0.7245      [31m0.8451[0m        [94m0.3361[0m     +  0.0000  8.0524
     24      0.9135        0.2923       [35m0.7248[0m      [31m0.8452[0m        [94m0.3360[0m     +  0.0000  8.1311
     25      0.8921        [32m0.2894[0m       0.7243      0.8450        [94m0.3359[0m     +  0.0000  8.1474
     26      0.9089        0.2935       0.7245      0.8451        [94m0.3359[0m     +  0.0000  8.1774
     27      0.8995        0.2994       0.7243      0.8450        [94m0.3358[0m     +  0.0000  8.1469
     28      0.8897        0.2963       0.7243      0.8450        [94m0.3358[0m     +  0.0000  8.1454
     29      0.8868        0.2955       0.7245      0.8450        [94m0.3358[0m     +  0.0000  8.1642
     30      0.8894        0.2981       0.7245      0.8450        [94m0.3358[0m     +  0.0000  8.1158
     31      0.8877        0.2951       0.7245      0.8450        [94m0.3357[0m     +  0.0000  8.0994
     32      0.9135        [32m0.2883[0m       0.7245      0.8450        [94m0.3357[0m     +  0.0000  8.1791
     33      0.9188        [32m0.2840[0m       0.7245      0.8450        [94m0.3357[0m     +  0.0000  8.1332
     34      0.9058        0.2940       0.7245      0.8450        [94m0.3357[0m     +  0.0000  8.1530
     35      0.8941        0.2933       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.1530
     36      0.9000        0.2945       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.2627
     37      0.9107        0.2937       0.7247      0.8452        [94m0.3357[0m     +  0.0000  9.1976
     38      0.8970        0.2976       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.1159
     39      0.9088        0.2907       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.0686
     40      0.8829        0.3045       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.1469
     41      0.9000        0.2896       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.1175
     42      0.8968        0.2959       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.0532
     43      0.9028        0.2912       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.1007
     44      0.9109        0.2914       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.1160
     45      0.9092        0.2926       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.0546
     46      0.8921        0.2847       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.0994
     47      0.8924        0.2971       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.1925
     48      0.9068        0.2934       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.1160
     49      0.8985        0.2929       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.0834
     50      0.8957        0.2944       0.7247      0.8452        [94m0.3357[0m     +  0.0000  8.1300
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 5 Test Accuracy: 0.7443
Iteration 5 Test F1 Score (micro): 0.8585
Iteration 5 Test F1 Score (macro): 0.8312
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_4.pt

Query 6: Using the exact images and labels from the CSV for this iteration.

Query 6: Using images from iteration=6 (random sampling).
Number of samples used for training in Query 6 is 384
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8577[0m        [32m0.3261[0m       [35m0.4988[0m      [31m0.7426[0m        [94m0.4951[0m     +  0.0000  8.6779
      2      0.8104        0.3622       [35m0.7328[0m      [31m0.8567[0m        [94m0.3162[0m     +  0.0000  8.5701
      3      [36m0.8827[0m        [32m0.2880[0m       [35m0.7561[0m      [31m0.8709[0m        [94m0.3128[0m     +  0.0000  8.5996
      4      [36m0.8891[0m        [32m0.2802[0m       0.7550      0.8695        [94m0.3068[0m     +  0.0000  8.5987
      5      [36m0.8991[0m        [32m0.2763[0m       0.7556      0.8686        [94m0.3030[0m     +  0.0000  8.5853
      6      0.8880        [32m0.2677[0m       0.7524      0.8669        [94m0.3018[0m     +  0.0000  8.5843
      7      [36m0.8998[0m        [32m0.2672[0m       0.7536      0.8665        [94m0.3002[0m     +  0.0000  8.5870
      8      0.8991        [32m0.2629[0m       [35m0.7562[0m      0.8672        [94m0.2988[0m     +  0.0000  8.5849
      9      0.8894        0.2680       [35m0.7568[0m      0.8671        [94m0.2980[0m     +  0.0000  8.6166
     10      [36m0.9030[0m        0.2653       [35m0.7582[0m      0.8685        [94m0.2973[0m     +  0.0000  8.5691
     11      [36m0.9099[0m        [32m0.2624[0m       0.7571      0.8674        [94m0.2970[0m     +  0.0000  8.5848
     12      0.8953        0.2669       0.7571      0.8673        [94m0.2967[0m     +  0.0000  8.5998
     13      0.9020        0.2649       0.7573      0.8668        [94m0.2961[0m     +  0.0000  8.6001
     14      0.8981        [32m0.2600[0m       0.7571      0.8667        [94m0.2959[0m     +  0.0000  8.5536
     15      0.9049        [32m0.2588[0m       0.7571      0.8667        [94m0.2957[0m     +  0.0000  8.5842
     16      0.9041        0.2602       0.7576      0.8669        [94m0.2955[0m     +  0.0000  8.5686
     17      0.9060        0.2641       0.7580      0.8671        [94m0.2953[0m     +  0.0000  8.5997
     18      0.9055        0.2598       [35m0.7583[0m      0.8674        [94m0.2953[0m     +  0.0000  8.5699
     19      0.9077        0.2619       0.7575      0.8667        [94m0.2951[0m     +  0.0000  8.5540
     20      [36m0.9149[0m        0.2592       0.7573      0.8664        [94m0.2950[0m     +  0.0000  8.5537
     21      0.9124        0.2614       0.7575      0.8665        [94m0.2949[0m     +  0.0000  8.6153
     22      [36m0.9203[0m        [32m0.2552[0m       0.7575      0.8664        [94m0.2949[0m     +  0.0000  8.5840
     23      0.8966        0.2591       0.7575      0.8664        [94m0.2948[0m     +  0.0000  8.5696
     24      0.9171        0.2585       0.7575      0.8664        [94m0.2947[0m     +  0.0000  8.6152
     25      0.9058        0.2606       0.7576      0.8666        [94m0.2947[0m     +  0.0000  8.5865
     26      0.8963        0.2582       0.7578      0.8667        [94m0.2947[0m     +  0.0000  8.5690
     27      0.9048        0.2618       0.7580      0.8667        [94m0.2947[0m     +  0.0000  8.5692
     28      0.9044        0.2636       0.7576      0.8666        [94m0.2947[0m     +  0.0000  8.6016
     29      0.9056        0.2615       0.7576      0.8666        [94m0.2946[0m     +  0.0000  8.5854
     30      0.9200        0.2594       0.7578      0.8667        [94m0.2946[0m     +  0.0000  8.5701
     31      0.8947        0.2639       0.7578      0.8667        [94m0.2946[0m     +  0.0000  8.5694
     32      0.9070        0.2600       0.7578      0.8667        [94m0.2946[0m     +  0.0000  8.5849
     33      0.9161        0.2584       0.7578      0.8667        [94m0.2946[0m     +  0.0000  8.5696
     34      0.9027        0.2610       0.7576      0.8667        [94m0.2946[0m     +  0.0000  8.5844
     35      0.9153        0.2580       0.7578      0.8667        [94m0.2945[0m     +  0.0000  8.5848
     36      0.8917        0.2607       0.7578      0.8667        [94m0.2945[0m     +  0.0000  8.5858
     37      0.9067        0.2583       0.7578      0.8667        [94m0.2945[0m     +  0.0000  8.5851
     38      0.9036        0.2620       0.7576      0.8667        [94m0.2945[0m     +  0.0000  8.5520
     39      0.9170        0.2581       0.7578      0.8667        [94m0.2945[0m     +  0.0000  8.5523
     40      0.9001        0.2594       0.7578      0.8667        [94m0.2945[0m     +  0.0000  8.6187
     41      0.9099        0.2561       0.7578      0.8667        [94m0.2945[0m     +  0.0000  8.6009
     42      0.9039        0.2630       0.7578      0.8667        [94m0.2945[0m     +  0.0000  8.5705
     43      0.9078        0.2616       0.7578      0.8667        [94m0.2945[0m     +  0.0000  8.6318
     44      0.9097        0.2589       0.7578      0.8667        [94m0.2945[0m     +  0.0000  8.5397
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 6 Test Accuracy: 0.7688
Iteration 6 Test F1 Score (micro): 0.8793
Iteration 6 Test F1 Score (macro): 0.8579
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_5.pt

Query 7: Using the exact images and labels from the CSV for this iteration.

Query 7: Using images from iteration=7 (random sampling).
Number of samples used for training in Query 7 is 704
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8311[0m        [32m0.3249[0m       [35m0.7517[0m      [31m0.8664[0m        [94m0.2905[0m     +  0.0000  9.5877
      2      [36m0.8937[0m        [32m0.2672[0m       [35m0.7573[0m      0.8658        [94m0.2824[0m     +  0.0000  9.3820
      3      [36m0.9060[0m        [32m0.2580[0m       [35m0.7580[0m      [31m0.8683[0m        [94m0.2803[0m     +  0.0000  9.4782
      4      [36m0.9067[0m        [32m0.2563[0m       [35m0.7637[0m      [31m0.8707[0m        [94m0.2766[0m     +  0.0000  9.4300
      5      [36m0.9259[0m        [32m0.2498[0m       [35m0.7646[0m      0.8704        [94m0.2749[0m     +  0.0000  9.4152
      6      0.9224        [32m0.2438[0m       0.7639      0.8706        [94m0.2732[0m     +  0.0000  9.4607
      7      0.9209        0.2469       0.7641      [31m0.8707[0m        [94m0.2723[0m     +  0.0000  9.4445
      8      0.9151        0.2455       [35m0.7667[0m      [31m0.8711[0m        [94m0.2711[0m     +  0.0000  9.4456
      9      0.9206        [32m0.2411[0m       0.7653      [31m0.8720[0m        [94m0.2708[0m     +  0.0000  9.4467
     10      0.9169        0.2428       [35m0.7679[0m      [31m0.8730[0m        [94m0.2699[0m     +  0.0000  9.4440
     11      0.9211        [32m0.2387[0m       0.7670      0.8728        [94m0.2696[0m     +  0.0000  9.3830
     12      [36m0.9300[0m        [32m0.2360[0m       0.7675      [31m0.8732[0m        [94m0.2696[0m     +  0.0000  9.4296
     13      0.9228        0.2414       0.7663      0.8718        [94m0.2690[0m     +  0.0000  9.4448
     14      0.9267        [32m0.2325[0m       0.7668      0.8729        [94m0.2690[0m     +  0.0000  9.4123
     15      0.9267        [32m0.2322[0m       0.7677      0.8727        [94m0.2685[0m     +  0.0000  9.4279
     16      0.9294        0.2339       0.7668      0.8722        [94m0.2685[0m     +  0.0000  9.3991
     17      0.9237        0.2364       0.7675      0.8726        [94m0.2684[0m     +  0.0000  9.3983
     18      0.9240        0.2357       0.7679      0.8727        [94m0.2682[0m     +  0.0000  9.4442
     19      0.9279        0.2355       0.7679      0.8727        [94m0.2681[0m     +  0.0000  9.4452
     20      0.9257        0.2364       0.7677      0.8726        [94m0.2680[0m     +  0.0000  9.4329
     21      0.9269        0.2336       0.7679      0.8727        [94m0.2679[0m     +  0.0000  9.4462
     22      0.9290        0.2362       [35m0.7682[0m      0.8727        [94m0.2679[0m     +  0.0000  9.4134
     23      0.9268        0.2345       0.7679      0.8724        [94m0.2679[0m     +  0.0000  9.4134
     24      0.9300        0.2334       [35m0.7684[0m      0.8730        [94m0.2678[0m     +  0.0000  9.3975
     25      0.9236        0.2378       0.7681      0.8726        [94m0.2678[0m     +  0.0000  9.3677
     26      [36m0.9315[0m        0.2326       0.7684      0.8729        [94m0.2678[0m     +  0.0000  9.4285
     27      [36m0.9355[0m        0.2340       [35m0.7686[0m      0.8730        [94m0.2678[0m     +  0.0000  9.3983
     28      0.9291        0.2344       0.7686      0.8730        [94m0.2677[0m     +  0.0000  9.4136
     29      0.9238        [32m0.2315[0m       0.7681      0.8728        [94m0.2677[0m     +  0.0000  9.4316
     30      0.9218        0.2370       0.7682      0.8729        0.2678        0.0000  9.3977
     31      0.9278        0.2370       0.7681      0.8729        0.2677        0.0000  9.3981
     32      0.9297        [32m0.2307[0m       0.7681      0.8729        [94m0.2677[0m     +  0.0000  9.4802
     33      0.9311        0.2341       0.7684      0.8730        [94m0.2677[0m     +  0.0000  9.3989
     34      0.9309        0.2345       0.7681      0.8729        0.2677        0.0000  9.3510
     35      0.9285        0.2348       0.7682      0.8730        [94m0.2677[0m     +  0.0000  9.4619
     36      0.9274        0.2347       0.7682      0.8730        [94m0.2677[0m     +  0.0000  9.3685
     37      [36m0.9373[0m        0.2359       0.7681      0.8728        [94m0.2677[0m     +  0.0000  9.4300
     38      0.9236        0.2351       0.7681      0.8728        [94m0.2677[0m     +  0.0000  9.4146
     39      0.9258        0.2344       0.7681      0.8728        [94m0.2677[0m     +  0.0000  9.3831
     40      0.9242        0.2328       0.7684      0.8730        [94m0.2677[0m     +  0.0000  9.4295
     41      0.9239        0.2318       0.7684      0.8730        [94m0.2677[0m     +  0.0000  9.3997
     42      0.9284        0.2342       0.7684      0.8730        [94m0.2677[0m     +  0.0000  9.4137
     43      0.9310        0.2325       0.7684      0.8730        [94m0.2677[0m     +  0.0000  9.4135
     44      0.9325        0.2331       0.7684      0.8730        [94m0.2677[0m     +  0.0000  9.4288
     45      0.9315        0.2336       0.7684      0.8730        [94m0.2677[0m     +  0.0000  9.3673
     46      0.9212        0.2389       0.7684      0.8730        [94m0.2677[0m     +  0.0000  9.4286
     47      0.9264        0.2310       0.7684      0.8730        [94m0.2677[0m     +  0.0000  9.3997
     48      0.9334        0.2329       0.7684      0.8730        [94m0.2677[0m     +  0.0000  9.4136
     49      0.9262        0.2345       0.7684      0.8730        [94m0.2677[0m     +  0.0000  9.4440
     50      0.9263        0.2333       0.7684      0.8730        [94m0.2677[0m     +  0.0000  9.3982
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 7 Test Accuracy: 0.7944
Iteration 7 Test F1 Score (micro): 0.8953
Iteration 7 Test F1 Score (macro): 0.8735
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_6.pt

Query 8: Using the exact images and labels from the CSV for this iteration.

Query 8: Using images from iteration=8 (random sampling).
Number of samples used for training in Query 8 is 1264
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8704[0m        [32m0.2814[0m       [35m0.7651[0m      [31m0.8767[0m        [94m0.2630[0m     +  0.0000  11.1944
      2      [36m0.9110[0m        [32m0.2370[0m       [35m0.7682[0m      [31m0.8784[0m        [94m0.2584[0m     +  0.0000  10.8377
      3      [36m0.9197[0m        [32m0.2283[0m       [35m0.7816[0m      [31m0.8831[0m        [94m0.2517[0m     +  0.0000  10.8682
      4      [36m0.9263[0m        [32m0.2244[0m       [35m0.7901[0m      [31m0.8857[0m        [94m0.2468[0m     +  0.0000  10.9613
      5      [36m0.9302[0m        [32m0.2226[0m       [35m0.7974[0m      [31m0.8877[0m        [94m0.2438[0m     +  0.0000  10.9036
      6      [36m0.9337[0m        [32m0.2149[0m       [35m0.8012[0m      [31m0.8897[0m        [94m0.2433[0m     +  0.0000  10.9533
      7      0.9301        0.2160       0.8010      [31m0.8900[0m        [94m0.2421[0m     +  0.0000  10.9557
      8      0.9322        [32m0.2114[0m       [35m0.8075[0m      [31m0.8923[0m        [94m0.2411[0m     +  0.0000  11.0766
      9      0.9316        0.2146       0.8071      [31m0.8928[0m        [94m0.2407[0m     +  0.0000  11.7022
     10      [36m0.9410[0m        [32m0.2087[0m       [35m0.8118[0m      [31m0.8938[0m        [94m0.2394[0m     +  0.0000  11.6259
     11      [36m0.9421[0m        0.2096       0.8078      0.8936        [94m0.2391[0m     +  0.0000  11.5537
     12      0.9391        0.2092       0.8078      0.8936        [94m0.2390[0m     +  0.0000  10.8187
     13      [36m0.9438[0m        [32m0.2073[0m       0.8075      0.8936        0.2391        0.0000  10.8511
     14      0.9318        0.2094       0.8095      [31m0.8939[0m        [94m0.2381[0m     +  0.0000  10.8519
     15      0.9438        [32m0.2045[0m       0.8111      [31m0.8953[0m        [94m0.2380[0m     +  0.0000  10.8533
     16      0.9435        0.2058       0.8115      [31m0.8954[0m        [94m0.2379[0m     +  0.0000  10.8835
     17      0.9434        [32m0.2026[0m       0.8104      0.8948        [94m0.2378[0m     +  0.0000  10.8524
     18      0.9425        0.2050       0.8099      0.8947        0.2379        0.0000  10.8825
     19      0.9403        0.2056       0.8102      0.8947        [94m0.2377[0m     +  0.0000  10.9134
     20      0.9407        0.2061       0.8118      [31m0.8955[0m        [94m0.2375[0m     +  0.0000  10.8702
     21      0.9428        0.2063       [35m0.8122[0m      [31m0.8957[0m        [94m0.2374[0m     +  0.0000  10.8671
     22      0.9377        0.2063       0.8111      0.8951        0.2375        0.0000  10.9146
     23      [36m0.9440[0m        [32m0.2026[0m       0.8115      0.8956        0.2375        0.0000  10.9298
     24      [36m0.9461[0m        0.2042       0.8109      0.8954        [94m0.2374[0m     +  0.0000  10.9430
     25      0.9425        0.2049       0.8115      0.8955        [94m0.2373[0m     +  0.0000  10.9619
     26      0.9426        0.2038       0.8116      0.8956        0.2373        0.0000  10.9148
     27      0.9415        0.2062       [35m0.8123[0m      [31m0.8959[0m        [94m0.2373[0m     +  0.0000  10.9169
     28      [36m0.9486[0m        0.2031       [35m0.8125[0m      0.8959        [94m0.2372[0m     +  0.0000  10.9008
     29      0.9417        0.2050       0.8125      0.8958        [94m0.2372[0m     +  0.0000  10.8991
     30      0.9437        0.2044       0.8125      0.8957        [94m0.2372[0m     +  0.0000  10.9158
     31      0.9416        0.2050       [35m0.8127[0m      0.8958        [94m0.2371[0m     +  0.0000  10.8367
     32      0.9435        0.2049       0.8127      0.8958        0.2371        0.0000  10.8855
     33      0.9424        0.2053       [35m0.8128[0m      [31m0.8959[0m        [94m0.2371[0m     +  0.0000  10.8986
     34      0.9425        [32m0.2025[0m       [35m0.8130[0m      [31m0.8961[0m        [94m0.2371[0m     +  0.0000  10.9011
     35      0.9481        0.2046       0.8130      0.8961        [94m0.2371[0m     +  0.0000  10.8688
     36      0.9468        0.2033       [35m0.8132[0m      [31m0.8962[0m        [94m0.2371[0m     +  0.0000  10.9000
     37      0.9430        0.2050       0.8130      0.8961        [94m0.2371[0m     +  0.0000  10.8975
     38      0.9413        0.2041       0.8132      0.8962        [94m0.2371[0m     +  0.0000  10.9156
     39      0.9406        0.2033       0.8132      0.8962        [94m0.2371[0m     +  0.0000  10.8994
     40      0.9417        0.2052       0.8132      0.8962        [94m0.2371[0m     +  0.0000  10.9609
     41      0.9419        0.2070       0.8132      0.8962        [94m0.2371[0m     +  0.0000  10.9482
     42      0.9422        0.2037       0.8130      0.8961        0.2371        0.0000  10.9314
     43      0.9419        0.2038       0.8130      0.8961        0.2371        0.0000  10.8836
     44      0.9431        0.2035       0.8130      0.8961        [94m0.2371[0m     +  0.0000  10.8650
     45      0.9426        0.2026       0.8130      0.8961        [94m0.2371[0m     +  0.0000  10.8688
     46      0.9410        0.2038       0.8130      0.8961        0.2371        0.0000  10.8669
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 8 Test Accuracy: 0.8181
Iteration 8 Test F1 Score (micro): 0.9093
Iteration 8 Test F1 Score (macro): 0.8917
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_7.pt

Query 9: Using the exact images and labels from the CSV for this iteration.

Query 9: Using images from iteration=9 (random sampling).
Number of samples used for training in Query 9 is 2264
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8996[0m        [32m0.2359[0m       [35m0.8158[0m      [31m0.8944[0m        [94m0.2321[0m     +  0.0000  13.5868
      2      [36m0.9329[0m        [32m0.2080[0m       [35m0.8274[0m      [31m0.8992[0m        [94m0.2284[0m     +  0.0000  13.4472
      3      0.9329        [32m0.2053[0m       [35m0.8297[0m      [31m0.8999[0m        [94m0.2258[0m     +  0.0000  13.5097
      4      [36m0.9383[0m        [32m0.1962[0m       0.8295      [31m0.9017[0m        [94m0.2241[0m     +  0.0000  13.5407
      5      [36m0.9463[0m        [32m0.1929[0m       0.8238      0.8989        0.2261        0.0000  13.5546
      6      [36m0.9463[0m        [32m0.1893[0m       [35m0.8314[0m      [31m0.9029[0m        [94m0.2208[0m     +  0.0000  13.5579
      7      [36m0.9498[0m        [32m0.1868[0m       0.8311      0.9025        [94m0.2205[0m     +  0.0000  13.5575
      8      [36m0.9526[0m        [32m0.1845[0m       [35m0.8330[0m      0.9026        [94m0.2198[0m     +  0.0000  13.5422
      9      [36m0.9543[0m        [32m0.1830[0m       [35m0.8368[0m      [31m0.9033[0m        [94m0.2190[0m     +  0.0000  13.7219
     10      0.9534        [32m0.1810[0m       [35m0.8370[0m      [31m0.9046[0m        [94m0.2185[0m     +  0.0000  13.4002
     11      [36m0.9568[0m        [32m0.1788[0m       [35m0.8387[0m      0.9045        [94m0.2179[0m     +  0.0000  13.5419
     12      [36m0.9621[0m        0.1796       0.8380      [31m0.9052[0m        0.2179        0.0000  13.4936
     13      0.9573        0.1797       0.8378      0.9052        [94m0.2178[0m     +  0.0000  13.5265
     14      0.9568        0.1810       0.8380      0.9050        [94m0.2176[0m     +  0.0000  13.5250
     15      0.9583        [32m0.1773[0m       [35m0.8392[0m      0.9049        [94m0.2172[0m     +  0.0000  13.5433
     16      0.9598        0.1774       [35m0.8422[0m      [31m0.9063[0m        [94m0.2171[0m     +  0.0000  13.4950
     17      0.9568        0.1798       0.8405      0.9056        0.2171        0.0000  13.4931
     18      0.9596        0.1793       0.8417      0.9061        [94m0.2171[0m     +  0.0000  13.4801
     19      0.9591        0.1776       0.8413      0.9060        [94m0.2170[0m     +  0.0000  13.5243
     20      0.9571        0.1794       0.8417      0.9062        [94m0.2170[0m     +  0.0000  13.5254
     21      0.9573        [32m0.1768[0m       0.8413      0.9060        [94m0.2170[0m     +  0.0000  13.5590
     22      0.9592        [32m0.1763[0m       0.8417      0.9063        [94m0.2169[0m     +  0.0000  13.4183
     23      0.9598        [32m0.1754[0m       0.8413      0.9062        [94m0.2169[0m     +  0.0000  13.5567
     24      0.9603        0.1772       0.8408      0.9060        0.2169        0.0000  13.5091
     25      0.9601        0.1780       0.8408      0.9061        0.2169        0.0000  13.4401
     26      [36m0.9627[0m        0.1769       0.8408      0.9060        [94m0.2169[0m     +  0.0000  13.4933
     27      0.9605        0.1756       0.8413      0.9062        [94m0.2169[0m     +  0.0000  13.4171
     28      [36m0.9627[0m        0.1761       0.8410      0.9060        [94m0.2169[0m     +  0.0000  13.5718
     29      0.9582        0.1774       0.8413      0.9062        [94m0.2169[0m     +  0.0000  13.5145
     30      0.9608        0.1768       0.8413      0.9062        [94m0.2168[0m     +  0.0000  13.4474
     31      0.9616        0.1773       0.8413      0.9062        [94m0.2168[0m     +  0.0000  13.4162
     32      0.9601        0.1762       0.8410      0.9060        [94m0.2168[0m     +  0.0000  13.4780
     33      0.9588        0.1762       0.8415      [31m0.9065[0m        0.2168        0.0000  13.5012
     34      0.9612        [32m0.1741[0m       0.8415      0.9065        0.2168        0.0000  13.6087
     35      0.9592        0.1765       0.8411      0.9061        0.2168        0.0000  13.4756
     36      0.9599        0.1777       0.8411      0.9061        [94m0.2168[0m     +  0.0000  13.6022
     37      0.9615        0.1753       0.8411      0.9061        0.2168        0.0000  13.4640
     38      0.9620        0.1762       0.8410      0.9060        [94m0.2168[0m     +  0.0000  13.5081
     39      0.9618        0.1758       0.8408      0.9060        0.2168        0.0000  13.5742
     40      0.9571        0.1775       0.8405      0.9058        0.2168        0.0000  13.4937
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 9 Test Accuracy: 0.8165
Iteration 9 Test F1 Score (micro): 0.9111
Iteration 9 Test F1 Score (macro): 0.8930
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_8.pt

Query 10: Using the exact images and labels from the CSV for this iteration.

Query 10: Using images from iteration=10 (random sampling).
Number of samples used for training in Query 10 is 4040
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9237[0m        [32m0.2068[0m       [35m0.8220[0m      [31m0.8691[0m        [94m0.2218[0m     +  0.0000  18.2634
      2      [36m0.9458[0m        [32m0.1841[0m       [35m0.8255[0m      0.8681        [94m0.2196[0m     +  0.0000  18.0457
      3      [36m0.9529[0m        [32m0.1786[0m       [35m0.8373[0m      [31m0.8863[0m        [94m0.2141[0m     +  0.0000  18.2348
      4      [36m0.9532[0m        [32m0.1748[0m       [35m0.8398[0m      [31m0.8883[0m        [94m0.2111[0m     +  0.0000  18.1558
      5      [36m0.9564[0m        [32m0.1717[0m       0.8392      [31m0.8890[0m        [94m0.2095[0m     +  0.0000  18.2633
      6      [36m0.9623[0m        [32m0.1649[0m       [35m0.8535[0m      [31m0.9046[0m        [94m0.2053[0m     +  0.0000  18.3308
      7      0.9620        [32m0.1637[0m       0.8509      0.9019        0.2056        0.0000  18.2991
      8      [36m0.9634[0m        [32m0.1632[0m       0.8477      0.9013        0.2066        0.0000  19.0657
      9      [36m0.9641[0m        [32m0.1607[0m       0.8512      0.9031        [94m0.2049[0m     +  0.0000  19.7552
     10      [36m0.9643[0m        [32m0.1600[0m       0.8486      0.9004        [94m0.2048[0m     +  0.0000  19.4902
     11      [36m0.9684[0m        [32m0.1583[0m       0.8526      0.9046        [94m0.2029[0m     +  0.0000  19.7056
     12      0.9673        [32m0.1576[0m       0.8533      0.9043        [94m0.2028[0m     +  0.0000  18.9690
     13      0.9669        0.1583       [35m0.8547[0m      [31m0.9058[0m        [94m0.2026[0m     +  0.0000  17.9670
     14      0.9676        [32m0.1564[0m       0.8540      [31m0.9065[0m        [94m0.2025[0m     +  0.0000  17.9800
     15      0.9679        0.1567       0.8533      0.9055        [94m0.2023[0m     +  0.0000  18.0765
     16      [36m0.9688[0m        0.1564       [35m0.8580[0m      [31m0.9104[0m        [94m0.2012[0m     +  0.0000  18.0931
     17      [36m0.9701[0m        [32m0.1553[0m       0.8580      [31m0.9112[0m        [94m0.2011[0m     +  0.0000  18.1388
     18      0.9686        [32m0.1551[0m       0.8571      0.9110        [94m0.2010[0m     +  0.0000  18.1236
     19      0.9686        0.1553       0.8571      0.9096        0.2011        0.0000  18.1720
     20      0.9678        [32m0.1546[0m       0.8578      0.9107        0.2010        0.0000  18.1073
     21      0.9694        [32m0.1543[0m       0.8573      [31m0.9116[0m        [94m0.2005[0m     +  0.0000  18.1383
     22      0.9673        [32m0.1541[0m       0.8571      [31m0.9118[0m        [94m0.2004[0m     +  0.0000  18.2694
     23      0.9686        [32m0.1536[0m       0.8580      [31m0.9123[0m        [94m0.2003[0m     +  0.0000  18.2513
     24      0.9694        0.1543       0.8576      0.9122        [94m0.2003[0m     +  0.0000  18.1532
     25      0.9688        0.1549       0.8578      0.9120        0.2003        0.0000  18.2019
     26      0.9674        0.1543       0.8576      0.9122        [94m0.2002[0m     +  0.0000  18.2635
     27      0.9692        0.1547       [35m0.8585[0m      [31m0.9132[0m        [94m0.2002[0m     +  0.0000  18.2162
     28      0.9699        0.1539       0.8583      0.9127        0.2002        0.0000  18.1398
     29      0.9687        0.1539       0.8578      0.9123        0.2002        0.0000  18.1699
     30      0.9697        0.1543       0.8580      0.9129        0.2002        0.0000  18.1534
     31      0.9682        [32m0.1527[0m       0.8578      0.9130        [94m0.2002[0m     +  0.0000  18.2786
     32      [36m0.9702[0m        0.1534       0.8576      0.9129        [94m0.2002[0m     +  0.0000  18.1564
     33      0.9685        0.1537       0.8578      0.9130        [94m0.2002[0m     +  0.0000  18.0943
     34      0.9693        0.1538       0.8576      0.9130        [94m0.2001[0m     +  0.0000  18.2343
     35      0.9695        0.1534       0.8575      0.9129        [94m0.2001[0m     +  0.0000  18.2976
     36      0.9693        0.1530       0.8575      0.9129        [94m0.2001[0m     +  0.0000  18.1686
     37      0.9682        0.1542       0.8575      0.9129        [94m0.2001[0m     +  0.0000  18.1076
     38      0.9698        0.1537       0.8575      0.9129        [94m0.2001[0m     +  0.0000  18.2332
     39      0.9694        0.1533       0.8575      0.9129        0.2001        0.0000  18.0452
     40      0.9685        0.1538       0.8575      0.9129        0.2001        0.0000  18.1243
     41      0.9687        0.1538       0.8575      0.9129        0.2001        0.0000  18.1663
     42      0.9697        0.1533       0.8575      0.9129        0.2001        0.0000  18.2323
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 10 Test Accuracy: 0.8253
Iteration 10 Test F1 Score (micro): 0.9161
Iteration 10 Test F1 Score (macro): 0.8987
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_9.pt

Query 11: Using the exact images and labels from the CSV for this iteration.

Query 11: Using images from iteration=11 (random sampling).
Number of samples used for training in Query 11 is 7200
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9444[0m        [32m0.1694[0m       [35m0.8345[0m      [31m0.9082[0m        [94m0.2039[0m     +  0.0000  26.4578
      2      [36m0.9607[0m        [32m0.1517[0m       [35m0.8509[0m      [31m0.9120[0m        [94m0.1958[0m     +  0.0000  26.4298
      3      [36m0.9616[0m        [32m0.1488[0m       [35m0.8517[0m      [31m0.9135[0m        [94m0.1945[0m     +  0.0000  26.4404
      4      [36m0.9659[0m        [32m0.1439[0m       0.8484      0.9120        [94m0.1943[0m     +  0.0000  26.4555
      5      0.9649        [32m0.1417[0m       0.8309      0.8993        0.1998        0.0000  26.5338
      6      [36m0.9690[0m        [32m0.1361[0m       [35m0.8521[0m      0.9111        [94m0.1899[0m     +  0.0000  26.5694
      7      [36m0.9708[0m        [32m0.1351[0m       0.8497      0.9101        0.1908        0.0000  26.4418
      8      0.9700        [32m0.1340[0m       0.8521      [31m0.9136[0m        0.1909        0.0000  26.4748
      9      [36m0.9711[0m        [32m0.1322[0m       0.8460      0.9070        0.1900        0.0000  26.5197
     10      0.9705        0.1323       0.8495      0.9102        0.1901        0.0000  26.5364
     11      [36m0.9717[0m        [32m0.1297[0m       0.8491      0.9068        [94m0.1876[0m     +  0.0000  26.5025
     12      [36m0.9722[0m        [32m0.1294[0m       0.8509      0.9088        0.1878        0.0000  26.4901
     13      [36m0.9736[0m        0.1301       0.8495      0.9083        0.1880        0.0000  26.4727
     14      0.9720        [32m0.1285[0m       0.8503      0.9102        0.1883        0.0000  26.4735
     15      0.9722        [32m0.1281[0m       0.8498      0.9088        0.1879        0.0000  26.5800
     16      [36m0.9739[0m        [32m0.1275[0m       0.8510      0.9082        [94m0.1873[0m     +  0.0000  26.5355
     17      [36m0.9741[0m        [32m0.1265[0m       0.8519      0.9082        [94m0.1872[0m     +  0.0000  26.3798
     18      [36m0.9746[0m        0.1273       0.8500      0.9068        0.1875        0.0000  26.5223
     19      0.9740        0.1272       0.8498      0.9068        0.1875        0.0000  26.5040
     20      [36m0.9748[0m        [32m0.1262[0m       0.8505      0.9074        0.1873        0.0000  26.5974
     21      0.9741        [32m0.1258[0m       0.8505      0.9071        [94m0.1872[0m     +  0.0000  26.4272
     22      0.9735        0.1267       0.8505      0.9067        [94m0.1871[0m     +  0.0000  26.3473
     23      0.9733        0.1261       0.8505      0.9070        [94m0.1871[0m     +  0.0000  26.4261
     24      0.9748        [32m0.1253[0m       0.8502      0.9067        0.1871        0.0000  26.3769
     25      0.9742        [32m0.1247[0m       0.8510      0.9075        [94m0.1871[0m     +  0.0000  26.5781
     26      0.9745        0.1256       0.8507      0.9073        [94m0.1870[0m     +  0.0000  26.4112
     27      0.9742        0.1258       0.8507      0.9073        [94m0.1869[0m     +  0.0000  26.3956
     28      [36m0.9751[0m        0.1255       0.8510      0.9075        [94m0.1869[0m     +  0.0000  26.3785
     29      [36m0.9755[0m        0.1253       0.8512      0.9077        [94m0.1869[0m     +  0.0000  26.4741
     30      0.9747        0.1259       0.8510      0.9075        0.1869        0.0000  26.3963
     31      0.9743        0.1257       0.8512      0.9076        0.1869        0.0000  26.4591
     32      0.9750        0.1258       0.8510      0.9075        0.1869        0.0000  26.5022
     33      0.9741        0.1257       0.8510      0.9077        0.1869        0.0000  26.5311
     34      0.9740        0.1258       0.8512      0.9078        0.1869        0.0000  26.4263
     35      0.9745        0.1252       0.8505      0.9074        0.1869        0.0000  26.4892
     36      0.9745        0.1260       0.8505      0.9075        0.1869        0.0000  26.5333
     37      0.9750        0.1257       0.8505      0.9074        [94m0.1869[0m     +  0.0000  26.5379
     38      0.9735        0.1258       0.8507      0.9076        0.1869        0.0000  26.3805
     39      0.9750        0.1255       0.8507      0.9076        0.1869        0.0000  26.4999
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 11 Test Accuracy: 0.8300
Iteration 11 Test F1 Score (micro): 0.9187
Iteration 11 Test F1 Score (macro): 0.9005
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_10.pt

Query 12: Using the exact images and labels from the CSV for this iteration.

Query 12: Using images from iteration=12 (random sampling).
Number of samples used for training in Query 12 is 12824
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9614[0m        [32m0.1372[0m       [35m0.8201[0m      [31m0.8996[0m        [94m0.2041[0m     +  0.0000  41.0783
      2      [36m0.9724[0m        [32m0.1235[0m       [35m0.8476[0m      [31m0.9138[0m        [94m0.1890[0m     +  0.0000  41.2206
      3      [36m0.9735[0m        [32m0.1199[0m       0.8266      0.9025        0.1978        0.0000  41.3780
      4      [36m0.9749[0m        [32m0.1165[0m       0.8313      0.9057        0.1948        0.0000  41.3297
      5      [36m0.9758[0m        [32m0.1125[0m       0.8266      0.9015        0.1954        0.0000  41.3453
      6      [36m0.9789[0m        [32m0.1079[0m       [35m0.8547[0m      [31m0.9150[0m        [94m0.1784[0m     +  0.0000  41.9413
      7      [36m0.9800[0m        [32m0.1072[0m       0.8510      0.9145        0.1817        0.0000  41.6466
      8      [36m0.9805[0m        [32m0.1052[0m       0.8536      [31m0.9155[0m        0.1790        0.0000  41.8436
      9      0.9802        [32m0.1033[0m       0.8510      0.9145        0.1796        0.0000  41.2558
     10      [36m0.9814[0m        [32m0.1016[0m       0.8498      0.9137        0.1786        0.0000  41.2544
     11      [36m0.9819[0m        [32m0.1004[0m       0.8512      0.9118        [94m0.1755[0m     +  0.0000  41.2677
     12      [36m0.9821[0m        [32m0.0998[0m       0.8521      0.9104        [94m0.1734[0m     +  0.0000  41.2208
     13      0.9818        [32m0.0992[0m       0.8524      0.9106        [94m0.1731[0m     +  0.0000  41.2382
     14      [36m0.9822[0m        [32m0.0985[0m       0.8514      0.9105        0.1734        0.0000  41.2496
     15      [36m0.9825[0m        [32m0.0979[0m       0.8500      0.9102        0.1741        0.0000  41.3001
     16      0.9823        [32m0.0974[0m       0.8514      0.9092        [94m0.1724[0m     +  0.0000  41.2690
     17      [36m0.9827[0m        [32m0.0970[0m       0.8536      0.9102        [94m0.1720[0m     +  0.0000  41.1731
     18      [36m0.9831[0m        0.0972       0.8540      0.9101        [94m0.1719[0m     +  0.0000  41.1903
     19      0.9829        [32m0.0965[0m       0.8523      0.9095        0.1723        0.0000  41.1605
     20      0.9828        0.0966       0.8517      0.9096        0.1725        0.0000  41.2827
     21      0.9827        [32m0.0965[0m       0.8540      0.9087        [94m0.1715[0m     +  0.0000  41.2264
     22      [36m0.9833[0m        [32m0.0955[0m       0.8545      0.9087        0.1716        0.0000  41.2536
     23      0.9829        0.0962       0.8536      0.9088        0.1717        0.0000  41.2328
     24      0.9823        0.0967       0.8531      0.9085        0.1718        0.0000  41.1561
     25      0.9823        0.0962       0.8528      0.9082        0.1717        0.0000  41.2047
     26      0.9825        0.0957       0.8543      0.9085        0.1716        0.0000  41.1711
     27      0.9829        0.0959       0.8536      0.9080        0.1717        0.0000  41.2047
     28      0.9824        0.0959       0.8530      0.9076        0.1717        0.0000  41.2505
     29      0.9828        0.0961       0.8535      0.9080        0.1717        0.0000  41.2962
     30      0.9830        0.0957       0.8531      0.9076        0.1717        0.0000  41.2547
     31      0.9830        0.0959       0.8531      0.9078        0.1718        0.0000  41.2384
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 12 Test Accuracy: 0.8436
Iteration 12 Test F1 Score (micro): 0.9243
Iteration 12 Test F1 Score (macro): 0.9075
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_11.pt

Query 13: Using the exact images and labels from the CSV for this iteration.

Query 13: Using images from iteration=13 (random sampling).
Number of samples used for training in Query 13 is 22824
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9734[0m        [32m0.1053[0m       [35m0.8283[0m      [31m0.8841[0m        [94m0.1756[0m     +  0.0000  67.0819
      2      [36m0.9787[0m        [32m0.0957[0m       [35m0.8333[0m      [31m0.8893[0m        [94m0.1720[0m     +  0.0000  67.8028
      3      0.9785        [32m0.0916[0m       0.8187      0.8795        0.1777        0.0000  68.2551
      4      [36m0.9796[0m        [32m0.0879[0m       0.8155      0.8781        0.1778        0.0000  67.4437
      5      [36m0.9801[0m        [32m0.0844[0m       0.8328      0.8891        [94m0.1665[0m     +  0.0000  67.4877
      6      [36m0.9818[0m        [32m0.0808[0m       [35m0.8344[0m      0.8834        [94m0.1665[0m     +  0.0000  67.4757
      7      [36m0.9825[0m        [32m0.0790[0m       0.8333      0.8804        0.1684        0.0000  67.5230
      8      [36m0.9834[0m        [32m0.0776[0m       [35m0.8451[0m      0.8892        [94m0.1618[0m     +  0.0000  67.5364
      9      [36m0.9834[0m        [32m0.0765[0m       0.8441      [31m0.8898[0m        0.1625        0.0000  67.4465
     10      [36m0.9840[0m        [32m0.0746[0m       0.8377      0.8819        0.1669        0.0000  67.5188
     11      [36m0.9841[0m        [32m0.0734[0m       [35m0.8552[0m      [31m0.9052[0m        [94m0.1580[0m     +  0.0000  67.5469
     12      [36m0.9842[0m        [32m0.0727[0m       [35m0.8556[0m      0.9051        0.1581        0.0000  67.4946
     13      [36m0.9850[0m        [32m0.0724[0m       0.8531      0.9026        0.1590        0.0000  67.5514
     14      [36m0.9852[0m        [32m0.0715[0m       [35m0.8566[0m      [31m0.9059[0m        [94m0.1575[0m     +  0.0000  67.5331
     15      [36m0.9854[0m        [32m0.0706[0m       0.8528      0.9025        0.1588        0.0000  67.4119
     16      [36m0.9855[0m        0.0709       [35m0.8601[0m      [31m0.9106[0m        [94m0.1573[0m     +  0.0000  67.5242
     17      [36m0.9856[0m        [32m0.0704[0m       [35m0.8613[0m      [31m0.9109[0m        [94m0.1572[0m     +  0.0000  67.4430
     18      0.9852        [32m0.0702[0m       0.8594      0.9096        0.1575        0.0000  67.5007
     19      [36m0.9858[0m        [32m0.0695[0m       0.8602      0.9104        [94m0.1572[0m     +  0.0000  66.8452
     20      0.9855        [32m0.0694[0m       0.8585      0.9089        0.1577        0.0000  66.7042
     21      [36m0.9858[0m        [32m0.0694[0m       [35m0.8620[0m      [31m0.9129[0m        [94m0.1567[0m     +  0.0000  66.7475
     22      [36m0.9860[0m        [32m0.0693[0m       [35m0.8632[0m      [31m0.9134[0m        [94m0.1565[0m     +  0.0000  66.6560
     23      0.9857        [32m0.0692[0m       0.8627      0.9131        0.1567        0.0000  66.6874
     24      0.9857        0.0693       0.8632      [31m0.9134[0m        0.1566        0.0000  66.6881
     25      [36m0.9861[0m        [32m0.0690[0m       0.8623      0.9131        0.1566        0.0000  66.6819
     26      0.9860        [32m0.0687[0m       0.8630      [31m0.9145[0m        [94m0.1564[0m     +  0.0000  66.6352
     27      0.9858        0.0687       0.8630      0.9145        0.1565        0.0000  66.6747
     28      0.9859        0.0687       [35m0.8634[0m      [31m0.9148[0m        0.1564        0.0000  66.7158
     29      0.9858        [32m0.0685[0m       [35m0.8635[0m      [31m0.9148[0m        0.1564        0.0000  66.6908
     30      0.9860        0.0689       0.8632      0.9147        0.1564        0.0000  66.6513
     31      [36m0.9864[0m        [32m0.0684[0m       0.8630      0.9147        [94m0.1564[0m     +  0.0000  66.6241
     32      0.9862        0.0686       0.8628      0.9147        0.1564        0.0000  66.6257
     33      0.9855        0.0686       0.8630      0.9147        0.1564        0.0000  66.6379
     34      0.9859        0.0685       0.8628      0.9146        0.1564        0.0000  66.6525
     35      0.9863        0.0688       0.8630      0.9147        0.1564        0.0000  66.6537
     36      0.9857        0.0685       0.8627      0.9146        0.1564        0.0000  66.7809
     37      0.9862        0.0686       0.8627      0.9146        0.1564        0.0000  66.6397
     38      0.9863        0.0685       0.8625      0.9145        0.1564        0.0000  66.6706
     39      0.9862        0.0686       0.8625      0.9145        0.1565        0.0000  66.6593
     40      0.9861        0.0689       0.8630      [31m0.9149[0m        0.1564        0.0000  66.6241
     41      0.9861        0.0687       0.8628      0.9147        0.1564        0.0000  66.6422
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 13 Test Accuracy: 0.8524
Iteration 13 Test F1 Score (micro): 0.9299
Iteration 13 Test F1 Score (macro): 0.9150
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_12.pt

Query 14: Using the exact images and labels from the CSV for this iteration.

Query 14: Using images from iteration=14 (random sampling).
Number of samples used for training in Query 14 is 26880
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9794[0m        [32m0.0749[0m       [35m0.8719[0m      [31m0.9225[0m        [94m0.1533[0m     +  0.0000  76.8794
      2      [36m0.9824[0m        [32m0.0681[0m       0.8632      0.9191        0.1552        0.0000  77.2070
      3      [36m0.9831[0m        [32m0.0654[0m       0.8688      0.9208        [94m0.1529[0m     +  0.0000  77.2058
      4      [36m0.9842[0m        [32m0.0625[0m       0.8536      0.9152        0.1616        0.0000  77.1611
      5      0.9839        [32m0.0604[0m       0.8653      0.9187        [94m0.1513[0m     +  0.0000  77.1263
      6      [36m0.9855[0m        [32m0.0573[0m       0.8641      0.9088        [94m0.1512[0m     +  0.0000  77.1341
      7      [36m0.9861[0m        [32m0.0557[0m       0.8602      0.9081        0.1514        0.0000  77.1022
      8      [36m0.9865[0m        [32m0.0547[0m       0.8642      0.9107        0.1516        0.0000  77.1430
      9      [36m0.9872[0m        [32m0.0532[0m       0.8656      0.9138        0.1512        0.0000  77.1541
     10      0.9867        [32m0.0528[0m       0.8635      0.9136        0.1515        0.0000  77.1180
     11      [36m0.9879[0m        [32m0.0513[0m       0.8608      0.9116        0.1531        0.0000  77.1163
     12      0.9879        [32m0.0509[0m       0.8611      0.9118        0.1537        0.0000  77.0991
     13      [36m0.9885[0m        [32m0.0502[0m       0.8611      0.9119        0.1539        0.0000  77.1159
     14      0.9884        [32m0.0497[0m       0.8604      0.9120        0.1544        0.0000  77.1759
     15      [36m0.9885[0m        [32m0.0496[0m       0.8608      0.9130        0.1540        0.0000  77.1459
     16      [36m0.9890[0m        [32m0.0489[0m       0.8602      0.9133        0.1561        0.0000  77.1417
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 14 Test Accuracy: 0.8523
Iteration 14 Test F1 Score (micro): 0.9300
Iteration 14 Test F1 Score (macro): 0.9145
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\model_checkpoint_iteration_13.pt

Best F1 score across all iterations: 0.9150
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed45_test\random_sampling_results_for_multilabel_classification_s45.pickle
