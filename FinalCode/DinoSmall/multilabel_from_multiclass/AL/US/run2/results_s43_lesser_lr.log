Train set shape: (26880, 5)
Val set shape:   (5760, 5)
Test set shape:  (5760, 5)
Selected images DataFrame (Uncertainty Sampling):
   Iteration                                       Sample_Names
0          1  Spule035_Image0269.jpg,Spule020_Image0191.jpg,...
1          2  Spule040_Image0935.jpg,Spule009_Image0591.jpg,...
2          3  Spule036_Image0051.jpg,Spule028_Image0814.jpg,...
3          4  Spule012_Image0431.jpg,Spule027_Image0667.jpg,...
4          5  Spule036_Image0814.jpg,Spule015_Image0268.jpg,...
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.4889[0m        [32m0.7147[0m       [35m0.0043[0m      [31m0.3553[0m        [94m0.7135[0m     +  0.0000  7.8448
      2      [36m0.5407[0m        [32m0.6860[0m       [35m0.0611[0m      0.3443        [94m0.7031[0m     +  0.0000  7.3410
      3      [36m0.6869[0m        [32m0.6747[0m       [35m0.0757[0m      [31m0.3881[0m        0.7088        0.0000  7.3644
      4      0.6571        [32m0.6566[0m       [35m0.0868[0m      [31m0.4815[0m        [94m0.6940[0m     +  0.0000  7.3901
      5      0.6556        0.6593       [35m0.1030[0m      0.4437        0.7014        0.0000  7.4232
      6      [36m0.7833[0m        [32m0.6286[0m       [35m0.1050[0m      0.4355        0.7012        0.0000  7.4832
      7      0.7685        [32m0.6054[0m       [35m0.1090[0m      0.4444        0.6967        0.0000  7.5310
      8      [36m0.8487[0m        [32m0.5847[0m       [35m0.1099[0m      0.4448        [94m0.6934[0m     +  0.0000  7.5372
      9      0.8320        0.5978       0.1026      0.4512        [94m0.6907[0m     +  0.0000  7.5329
     10      0.6944        0.6178       0.1080      0.4482        [94m0.6904[0m     +  0.0000  7.5770
     11      [36m0.8796[0m        [32m0.5755[0m       0.1075      0.4491        [94m0.6903[0m     +  0.0000  7.6106
     12      0.8024        [32m0.5614[0m       0.1083      0.4495        [94m0.6894[0m     +  0.0000  7.6035
     13      0.8258        0.5746       0.1059      0.4511        [94m0.6884[0m     +  0.0000  7.6097
     14      0.7685        0.5952       0.1073      0.4558        [94m0.6879[0m     +  0.0000  7.5994
     15      0.7857        0.5727       0.1082      0.4546        0.6879        0.0000  7.6276
     16      [36m0.8889[0m        [32m0.5465[0m       0.1083      0.4533        0.6883        0.0000  7.6720
     17      0.7857        0.5623       0.1082      0.4545        0.6880        0.0000  7.6672
     18      0.8320        0.5548       0.1080      0.4544        0.6884        0.0000  7.6616
     19      [36m0.9153[0m        0.5681       0.1076      0.4553        0.6883        0.0000  7.6571
     20      0.8796        [32m0.5455[0m       0.1078      0.4566        0.6880        0.0000  7.6579
     21      0.7833        0.5698       0.1076      0.4561        0.6881        0.0000  7.7129
     22      0.8381        0.5664       0.1082      0.4567        0.6880        0.0000  7.6688
     23      0.8500        0.5522       0.1082      0.4567        0.6880        0.0000  7.6589
     24      0.8783        0.5501       0.1083      0.4573        0.6880        0.0000  7.6527
Stopping since valid_loss has not improved in the last 11 epochs.
Pre-training scores with initial data:
  F1 (macro) = 0.4798
  F1 (micro) = 0.4832
  Accuracy   = 0.1594

Query 1: Using images from iteration=2 (uncertainty sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.5741[0m        [32m0.6381[0m       [35m0.4465[0m      [31m0.1783[0m        [94m0.6399[0m     +  0.0000  7.7158
      2      [36m0.6629[0m        [32m0.6069[0m       [35m0.4786[0m      [31m0.2076[0m        [94m0.6348[0m     +  0.0000  7.7030
      3      0.4412        [32m0.5446[0m       [35m0.5120[0m      [31m0.2890[0m        [94m0.6251[0m     +  0.0000  7.6605
      4      0.6210        [32m0.5410[0m       0.5045      [31m0.2890[0m        [94m0.6225[0m     +  0.0000  7.6534
      5      0.4630        [32m0.5308[0m       0.4976      [31m0.3251[0m        [94m0.6138[0m     +  0.0000  7.6836
      6      0.6296        [32m0.5248[0m       0.5014      0.2811        [94m0.6129[0m     +  0.0000  7.6563
      7      [36m0.6872[0m        [32m0.4967[0m       0.4941      0.2933        [94m0.6088[0m     +  0.0000  7.7074
      8      [36m0.6919[0m        [32m0.4878[0m       0.4988      0.2940        [94m0.6074[0m     +  0.0000  7.6601
      9      0.6686        0.4959       0.5043      0.2882        [94m0.6052[0m     +  0.0000  7.6526
     10      [36m0.7762[0m        [32m0.4812[0m       0.4979      0.2844        [94m0.6028[0m     +  0.0000  7.6431
     11      0.6919        [32m0.4726[0m       0.4953      0.2862        [94m0.6015[0m     +  0.0000  7.6457
     12      0.6078        [32m0.4645[0m       0.4934      0.2878        [94m0.6004[0m     +  0.0000  7.6522
     13      0.6919        0.4676       0.4917      0.2883        [94m0.5994[0m     +  0.0000  7.6671
     14      0.7249        0.4709       0.4910      0.2871        [94m0.5988[0m     +  0.0000  7.6474
     15      0.5608        0.4896       0.4839      0.2876        [94m0.5975[0m     +  0.0000  7.6449
     16      0.7285        [32m0.4439[0m       0.4844      0.2880        [94m0.5973[0m     +  0.0000  7.6355
     17      0.6491        0.4672       0.4840      0.2910        [94m0.5967[0m     +  0.0000  7.6342
     18      0.6881        0.4721       0.4845      0.2901        0.5968        0.0000  7.6251
     19      0.6701        0.4769       0.4837      0.2918        [94m0.5962[0m     +  0.0000  7.6715
     20      0.6729        0.4623       0.4839      0.2922        [94m0.5958[0m     +  0.0000  7.6732
     21      0.6881        0.4576       0.4842      0.2926        [94m0.5956[0m     +  0.0000  7.6374
     22      0.7286        0.4632       0.4844      0.2925        [94m0.5955[0m     +  0.0000  7.6918
     23      0.6919        0.4689       0.4840      0.2924        [94m0.5954[0m     +  0.0000  7.6254
     24      0.7432        0.4594       0.4823      0.2925        [94m0.5952[0m     +  0.0000  7.6469
     25      0.7114        0.4682       0.4833      0.2925        [94m0.5951[0m     +  0.0000  7.6745
     26      0.6934        0.4667       0.4825      0.2925        [94m0.5951[0m     +  0.0000  7.6251
     27      0.7627        0.4543       0.4828      0.2926        [94m0.5950[0m     +  0.0000  7.6276
     28      0.7090        0.4576       0.4825      0.2926        [94m0.5949[0m     +  0.0000  7.6487
     29      0.7627        0.4696       0.4818      0.2925        [94m0.5949[0m     +  0.0000  7.6529
     30      0.7762        0.4487       0.4823      0.2926        [94m0.5949[0m     +  0.0000  7.6606
     31      0.6140        0.4657       0.4823      0.2925        [94m0.5948[0m     +  0.0000  7.6999
     32      0.6881        0.4704       0.4823      0.2925        [94m0.5948[0m     +  0.0000  7.6368
     33      0.7725        0.4498       0.4825      0.2926        [94m0.5948[0m     +  0.0000  7.6113
     34      0.7285        0.4593       0.4823      0.2925        0.5948        0.0000  7.6559
     35      0.7281        0.4636       0.4823      0.2925        [94m0.5948[0m     +  0.0000  7.6720
     36      0.6881        0.4568       0.4823      0.2925        [94m0.5948[0m     +  0.0000  7.6252
     37      0.6833        0.4476       0.4823      0.2925        [94m0.5948[0m     +  0.0000  7.6389
     38      0.7090        0.4696       0.4823      0.2925        [94m0.5948[0m     +  0.0000  7.6403
     39      0.7432        0.4647       0.4823      0.2925        [94m0.5948[0m     +  0.0000  7.6394
     40      0.5674        0.4687       0.4825      0.2926        [94m0.5948[0m     +  0.0000  7.6935
     41      0.6968        0.4549       0.4825      0.2926        [94m0.5948[0m     +  0.0000  7.6543
     42      0.7090        0.4642       0.4825      0.2926        [94m0.5948[0m     +  0.0000  7.6398
     43      0.7285        0.4610       0.4825      0.2926        [94m0.5948[0m     +  0.0000  7.6249
     44      0.7090        0.4541       0.4823      0.2925        [94m0.5948[0m     +  0.0000  7.6148
     45      0.6881        0.4674       0.4823      0.2925        [94m0.5948[0m     +  0.0000  7.6396
     46      0.7249        0.4648       0.4823      0.2925        [94m0.5948[0m     +  0.0000  7.6411
     47      0.7432        0.4523       0.4823      0.2925        [94m0.5948[0m     +  0.0000  7.6479
     48      0.7090        0.4674       0.4823      0.2925        [94m0.5948[0m     +  0.0000  7.6063
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 1 Test Accuracy: 0.5406
Iteration 1 Test F1 Score (micro): 0.4677
Iteration 1 Test F1 Score (macro): 0.3431
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\model_checkpoint_iteration_0.pt

Query 2: Using images from iteration=3 (uncertainty sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.4705[0m        [32m0.5485[0m       [35m0.3160[0m      [31m0.4122[0m        [94m0.5781[0m     +  0.0000  7.8176
      2      [36m0.5588[0m        [32m0.5315[0m       [35m0.4913[0m      0.2149        0.5866        0.0000  7.7227
      3      0.3450        [32m0.5220[0m       0.3922      [31m0.6697[0m        [94m0.5532[0m     +  0.0000  7.7163
      4      [36m0.8010[0m        [32m0.5099[0m       0.4823      0.1810        0.5669        0.0000  7.7131
      5      0.5664        [32m0.4839[0m       [35m0.5276[0m      0.4392        [94m0.5155[0m     +  0.0000  7.7087
      6      [36m0.8063[0m        [32m0.4432[0m       [35m0.5347[0m      0.4317        [94m0.5078[0m     +  0.0000  7.7241
      7      [36m0.8449[0m        [32m0.4261[0m       [35m0.5458[0m      0.4591        [94m0.5021[0m     +  0.0000  7.7018
      8      0.7944        0.4326       [35m0.5470[0m      0.4678        [94m0.4999[0m     +  0.0000  7.7220
      9      0.7125        0.4300       [35m0.5517[0m      0.4878        [94m0.4956[0m     +  0.0000  7.6822
     10      0.7811        [32m0.4217[0m       [35m0.5595[0m      0.5167        [94m0.4919[0m     +  0.0000  7.7041
     11      0.8313        [32m0.4076[0m       [35m0.5599[0m      0.5174        [94m0.4911[0m     +  0.0000  7.6894
     12      0.7979        0.4123       [35m0.5604[0m      0.5190        [94m0.4898[0m     +  0.0000  7.7082
     13      0.7500        0.4151       [35m0.5635[0m      0.5226        [94m0.4883[0m     +  0.0000  7.7485
     14      0.8379        0.4089       0.5625      0.5219        [94m0.4873[0m     +  0.0000  7.7072
     15      0.8031        0.4095       [35m0.5639[0m      0.5242        [94m0.4859[0m     +  0.0000  7.6970
     16      [36m0.8483[0m        0.4117       [35m0.5642[0m      0.5260        [94m0.4855[0m     +  0.0000  7.7172
     17      [36m0.8483[0m        [32m0.3977[0m       [35m0.5651[0m      0.5261        [94m0.4851[0m     +  0.0000  7.7168
     18      0.8178        0.4093       0.5651      0.5274        [94m0.4847[0m     +  0.0000  7.7626
     19      0.8413        0.4163       0.5632      0.5233        [94m0.4845[0m     +  0.0000  7.6895
     20      0.8206        0.4005       0.5648      0.5262        [94m0.4839[0m     +  0.0000  7.7396
     21      0.8468        0.3993       0.5646      0.5258        [94m0.4838[0m     +  0.0000  7.7066
     22      0.8013        0.4110       [35m0.5655[0m      0.5265        [94m0.4837[0m     +  0.0000  7.7501
     23      0.7938        0.3999       [35m0.5661[0m      0.5290        [94m0.4835[0m     +  0.0000  7.7448
     24      0.8338        0.4044       [35m0.5665[0m      0.5312        [94m0.4834[0m     +  0.0000  7.6911
     25      0.8456        0.3988       0.5665      0.5314        [94m0.4832[0m     +  0.0000  7.7134
     26      0.7752        0.4016       0.5663      0.5308        [94m0.4832[0m     +  0.0000  7.7501
     27      0.8086        0.4074       0.5665      0.5309        [94m0.4832[0m     +  0.0000  7.7192
     28      [36m0.8643[0m        0.3986       [35m0.5667[0m      0.5310        [94m0.4831[0m     +  0.0000  7.7180
     29      [36m0.9014[0m        [32m0.3940[0m       0.5665      0.5310        [94m0.4830[0m     +  0.0000  7.7201
     30      0.8309        [32m0.3916[0m       0.5665      0.5317        [94m0.4830[0m     +  0.0000  7.7535
     31      0.8573        0.4073       0.5665      0.5317        [94m0.4830[0m     +  0.0000  7.7033
     32      0.7869        0.4100       0.5667      0.5318        [94m0.4829[0m     +  0.0000  7.7194
     33      0.8265        0.4021       0.5665      0.5317        [94m0.4829[0m     +  0.0000  7.7028
     34      0.8161        0.3984       0.5667      0.5318        [94m0.4829[0m     +  0.0000  7.6898
     35      0.7731        0.4094       [35m0.5670[0m      0.5324        [94m0.4829[0m     +  0.0000  7.7455
     36      0.8171        0.4069       0.5670      0.5324        [94m0.4829[0m     +  0.0000  7.7036
     37      0.7690        0.4035       0.5670      0.5324        [94m0.4829[0m     +  0.0000  7.7156
     38      0.8659        0.4016       0.5670      0.5324        [94m0.4828[0m     +  0.0000  7.7400
     39      0.8187        0.4136       0.5670      0.5324        [94m0.4828[0m     +  0.0000  7.6878
     40      0.8440        0.3986       0.5670      0.5324        [94m0.4828[0m     +  0.0000  7.7478
     41      0.8716        0.4094       0.5670      0.5324        [94m0.4828[0m     +  0.0000  7.7188
     42      0.8446        0.4144       0.5670      0.5324        [94m0.4828[0m     +  0.0000  7.7226
     43      0.7789        0.4014       0.5670      0.5324        [94m0.4828[0m     +  0.0000  7.7334
     44      0.8551        0.3963       0.5670      0.5324        0.4828        0.0000  7.7156
     45      0.8365        0.4008       0.5670      0.5324        [94m0.4828[0m     +  0.0000  7.7375
     46      0.8519        0.4055       0.5670      0.5324        [94m0.4828[0m     +  0.0000  7.6874
     47      0.8067        0.4099       0.5670      0.5324        [94m0.4828[0m     +  0.0000  7.7341
     48      0.8315        0.4106       0.5670      0.5324        [94m0.4828[0m     +  0.0000  7.7287
     49      0.8769        0.4001       0.5670      0.5324        [94m0.4828[0m     +  0.0000  7.7654
     50      0.8717        0.3921       0.5670      0.5324        [94m0.4828[0m     +  0.0000  7.7111
     51      0.8612        [32m0.3886[0m       0.5670      0.5324        [94m0.4828[0m     +  0.0000  7.7182
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 2 Test Accuracy: 0.6186
Iteration 2 Test F1 Score (micro): 0.7194
Iteration 2 Test F1 Score (macro): 0.6269
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\model_checkpoint_iteration_1.pt

Query 3: Using images from iteration=4 (uncertainty sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.7455[0m        [32m0.4457[0m       [35m0.4656[0m      [31m0.4754[0m        [94m0.5425[0m     +  0.0000  8.0205
      2      0.4954        0.4748       [35m0.6559[0m      [31m0.8298[0m        [94m0.4765[0m     +  0.0000  7.9019
      3      [36m0.7934[0m        0.4740       0.5269      0.7393        0.4795        0.0000  7.8595
      4      0.6632        [32m0.4169[0m       0.6349      0.7547        [94m0.4178[0m     +  0.0000  7.8509
      5      [36m0.8730[0m        [32m0.3950[0m       0.6141      0.6682        [94m0.4162[0m     +  0.0000  7.8581
      6      0.8178        [32m0.3740[0m       0.6326      0.7107        [94m0.4077[0m     +  0.0000  7.8742
      7      0.8609        [32m0.3685[0m       0.6269      0.7147        [94m0.4040[0m     +  0.0000  7.9196
      8      0.8547        [32m0.3604[0m       0.6316      0.7254        [94m0.4011[0m     +  0.0000  7.8565
      9      0.8689        [32m0.3562[0m       0.6304      0.7288        [94m0.3993[0m     +  0.0000  7.9104
     10      0.8415        0.3615       0.6288      0.7305        [94m0.3961[0m     +  0.0000  7.8904
     11      [36m0.8875[0m        [32m0.3537[0m       0.6311      0.7354        [94m0.3952[0m     +  0.0000  7.8744
     12      0.8821        [32m0.3512[0m       0.6326      0.7377        [94m0.3945[0m     +  0.0000  7.8427
     13      0.8525        [32m0.3451[0m       0.6319      0.7388        [94m0.3936[0m     +  0.0000  7.9211
     14      0.8635        0.3485       0.6314      0.7405        [94m0.3927[0m     +  0.0000  7.8585
     15      [36m0.8988[0m        [32m0.3420[0m       0.6326      0.7405        [94m0.3922[0m     +  0.0000  7.8957
     16      0.8740        0.3528       0.6330      0.7404        [94m0.3919[0m     +  0.0000  7.8923
     17      0.8626        0.3430       0.6323      0.7397        [94m0.3916[0m     +  0.0000  7.8736
     18      [36m0.9023[0m        [32m0.3417[0m       0.6323      0.7397        [94m0.3915[0m     +  0.0000  7.8787
     19      0.8530        0.3521       0.6323      0.7396        [94m0.3912[0m     +  0.0000  7.8741
     20      0.8744        0.3576       0.6321      0.7400        [94m0.3908[0m     +  0.0000  7.8892
     21      0.8490        0.3471       0.6321      0.7399        [94m0.3907[0m     +  0.0000  7.8910
     22      0.8810        0.3432       0.6325      0.7406        [94m0.3906[0m     +  0.0000  7.9091
     23      0.8699        0.3418       0.6330      0.7415        [94m0.3905[0m     +  0.0000  7.8896
     24      0.8588        0.3425       0.6330      0.7417        [94m0.3904[0m     +  0.0000  7.8853
     25      0.8627        0.3495       0.6330      0.7422        [94m0.3903[0m     +  0.0000  7.8907
     26      0.8393        0.3434       0.6330      0.7426        [94m0.3902[0m     +  0.0000  7.9054
     27      0.8786        0.3435       0.6332      0.7428        [94m0.3902[0m     +  0.0000  7.8900
     28      0.8679        0.3465       0.6335      0.7434        [94m0.3902[0m     +  0.0000  7.8798
     29      0.8833        [32m0.3363[0m       0.6333      0.7433        [94m0.3901[0m     +  0.0000  7.9210
     30      0.8723        0.3414       0.6332      0.7432        [94m0.3901[0m     +  0.0000  7.8855
     31      0.8847        0.3456       0.6332      0.7432        [94m0.3901[0m     +  0.0000  7.8753
     32      0.8702        0.3449       0.6332      0.7432        [94m0.3901[0m     +  0.0000  7.9103
     33      0.8772        0.3476       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.8849
     34      0.8818        0.3407       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.8807
     35      0.8786        0.3473       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.8961
     36      0.8866        0.3408       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.8751
     37      0.8839        0.3437       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.8785
     38      0.8846        0.3462       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.8278
     39      0.8673        0.3468       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.8749
     40      0.8538        0.3521       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.8791
     41      0.8551        0.3543       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.9199
     42      0.8969        0.3401       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.8933
     43      0.8790        0.3413       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.9001
     44      0.8982        0.3397       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.9269
     45      0.8671        0.3420       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.8922
     46      0.8393        0.3487       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.8894
     47      0.8774        0.3481       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.8744
     48      0.8837        0.3449       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.9061
     49      0.8753        0.3458       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.8486
     50      0.8608        0.3422       0.6330      0.7432        [94m0.3900[0m     +  0.0000  7.9507
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 3 Test Accuracy: 0.7241
Iteration 3 Test F1 Score (micro): 0.8442
Iteration 3 Test F1 Score (macro): 0.8192
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\model_checkpoint_iteration_2.pt

Query 4: Using images from iteration=5 (uncertainty sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8686[0m        [32m0.3557[0m       [35m0.6771[0m      [31m0.8278[0m        [94m0.4188[0m     +  0.0000  8.2524
      2      0.7990        0.4047       [35m0.7042[0m      [31m0.8461[0m        [94m0.3655[0m     +  0.0000  8.1429
      3      [36m0.8816[0m        [32m0.3314[0m       0.6552      0.7733        [94m0.3423[0m     +  0.0000  8.1421
      4      [36m0.8868[0m        [32m0.3058[0m       0.6550      0.7704        [94m0.3389[0m     +  0.0000  8.1114
      5      [36m0.8949[0m        [32m0.3020[0m       0.6608      0.7753        [94m0.3354[0m     +  0.0000  8.1841
      6      0.8808        [32m0.2966[0m       0.6639      0.7756        [94m0.3338[0m     +  0.0000  8.1209
      7      [36m0.9108[0m        [32m0.2919[0m       0.6663      0.7829        [94m0.3326[0m     +  0.0000  8.1116
      8      0.8991        0.2964       0.6681      0.7868        [94m0.3316[0m     +  0.0000  8.1589
      9      0.8972        0.2931       0.6705      0.7910        [94m0.3305[0m     +  0.0000  8.1303
     10      0.8940        [32m0.2916[0m       0.6696      0.7883        [94m0.3300[0m     +  0.0000  8.1407
     11      0.9058        [32m0.2891[0m       0.6720      0.7918        [94m0.3291[0m     +  0.0000  8.1616
     12      0.9076        [32m0.2805[0m       0.6722      0.7922        [94m0.3287[0m     +  0.0000  8.1254
     13      [36m0.9206[0m        0.2839       0.6714      0.7920        [94m0.3285[0m     +  0.0000  8.1927
     14      0.8858        0.2873       0.6712      0.7917        [94m0.3282[0m     +  0.0000  8.1288
     15      0.9024        0.2899       0.6698      0.7908        [94m0.3280[0m     +  0.0000  8.1371
     16      0.8995        0.2872       0.6694      0.7901        [94m0.3280[0m     +  0.0000  8.1837
     17      0.9106        0.2856       0.6694      0.7904        [94m0.3279[0m     +  0.0000  8.1549
     18      0.9063        0.2827       0.6700      0.7906        [94m0.3278[0m     +  0.0000  8.1588
     19      0.8797        0.2841       0.6693      0.7902        [94m0.3276[0m     +  0.0000  8.1365
     20      0.9095        0.2820       0.6696      0.7904        [94m0.3274[0m     +  0.0000  8.1258
     21      0.9056        0.2821       0.6701      0.7910        [94m0.3274[0m     +  0.0000  8.2011
     22      0.9107        0.2905       0.6700      0.7906        [94m0.3274[0m     +  0.0000  8.1499
     23      0.9020        0.2831       0.6700      0.7906        [94m0.3273[0m     +  0.0000  8.1433
     24      0.9062        0.2863       0.6703      0.7908        [94m0.3273[0m     +  0.0000  8.1124
     25      0.9033        0.2849       0.6703      0.7911        [94m0.3272[0m     +  0.0000  8.1329
     26      0.9012        [32m0.2783[0m       0.6703      0.7911        [94m0.3272[0m     +  0.0000  8.1694
     27      0.9012        0.2818       0.6703      0.7911        [94m0.3271[0m     +  0.0000  8.1271
     28      [36m0.9229[0m        [32m0.2771[0m       0.6703      0.7910        [94m0.3271[0m     +  0.0000  8.1669
     29      0.9060        0.2797       0.6703      0.7910        [94m0.3271[0m     +  0.0000  8.1146
     30      0.8990        0.2817       0.6703      0.7910        [94m0.3271[0m     +  0.0000  8.1432
     31      0.9164        0.2821       0.6703      0.7910        [94m0.3271[0m     +  0.0000  8.1105
     32      0.9054        0.2809       0.6701      0.7910        [94m0.3271[0m     +  0.0000  8.1106
     33      0.9076        0.2775       0.6705      0.7912        [94m0.3271[0m     +  0.0000  8.1426
     34      0.9059        0.2890       0.6703      0.7910        [94m0.3271[0m     +  0.0000  8.1183
     35      0.9054        0.2811       0.6705      0.7912        [94m0.3271[0m     +  0.0000  8.0991
     36      0.8932        0.2797       0.6703      0.7912        [94m0.3271[0m     +  0.0000  8.1170
     37      0.8922        0.2809       0.6703      0.7912        [94m0.3271[0m     +  0.0000  8.1500
     38      0.9024        0.2850       0.6703      0.7912        [94m0.3271[0m     +  0.0000  8.1457
     39      0.9092        0.2848       0.6703      0.7912        [94m0.3271[0m     +  0.0000  8.1398
     40      0.9218        0.2791       0.6705      0.7912        [94m0.3271[0m     +  0.0000  8.1409
     41      0.8994        0.2872       0.6705      0.7912        [94m0.3271[0m     +  0.0000  8.1375
     42      0.9209        0.2811       0.6703      0.7912        [94m0.3270[0m     +  0.0000  8.1608
     43      0.9195        0.2806       0.6703      0.7912        [94m0.3270[0m     +  0.0000  8.1364
     44      0.9007        0.2859       0.6703      0.7912        [94m0.3270[0m     +  0.0000  8.1429
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 4 Test Accuracy: 0.7401
Iteration 4 Test F1 Score (micro): 0.8623
Iteration 4 Test F1 Score (macro): 0.8435
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\model_checkpoint_iteration_3.pt

Query 5: Using images from iteration=6 (uncertainty sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8281[0m        [32m0.3254[0m       [35m0.6710[0m      [31m0.8326[0m        [94m0.3684[0m     +  0.0000  8.7782
      2      [36m0.8660[0m        [32m0.3140[0m       [35m0.6887[0m      0.8147        [94m0.3113[0m     +  0.0000  8.6380
      3      [36m0.8955[0m        [32m0.2773[0m       [35m0.6917[0m      0.8126        [94m0.3066[0m     +  0.0000  8.6351
      4      0.8828        [32m0.2725[0m       0.6908      0.8113        [94m0.3039[0m     +  0.0000  8.5781
      5      [36m0.9025[0m        [32m0.2653[0m       0.6899      0.8101        [94m0.3011[0m     +  0.0000  8.6228
      6      0.8969        [32m0.2592[0m       [35m0.7078[0m      0.8279        [94m0.2976[0m     +  0.0000  8.5980
      7      0.8959        0.2606       [35m0.7090[0m      0.8307        [94m0.2969[0m     +  0.0000  8.5962
      8      [36m0.9168[0m        [32m0.2589[0m       [35m0.7095[0m      0.8279        [94m0.2956[0m     +  0.0000  8.5781
      9      0.9056        [32m0.2550[0m       [35m0.7115[0m      0.8318        [94m0.2951[0m     +  0.0000  8.5649
     10      0.9088        [32m0.2545[0m       [35m0.7128[0m      [31m0.8334[0m        [94m0.2943[0m     +  0.0000  8.6057
     11      0.9077        [32m0.2533[0m       0.7109      0.8314        [94m0.2940[0m     +  0.0000  8.5967
     12      [36m0.9232[0m        [32m0.2488[0m       0.7122      0.8332        [94m0.2937[0m     +  0.0000  8.5949
     13      0.8975        0.2531       0.7115      0.8324        0.2938        0.0000  8.7238
     14      0.9113        0.2495       0.7115      0.8330        [94m0.2934[0m     +  0.0000  8.6630
     15      0.9070        0.2498       0.7106      0.8315        [94m0.2934[0m     +  0.0000  8.5950
     16      0.9112        0.2515       0.7115      0.8330        [94m0.2931[0m     +  0.0000  8.6059
     17      0.9090        0.2545       0.7116      0.8330        [94m0.2931[0m     +  0.0000  8.6369
     18      0.9071        0.2512       0.7125      0.8334        [94m0.2928[0m     +  0.0000  8.5638
     19      0.9173        0.2489       0.7128      [31m0.8335[0m        [94m0.2927[0m     +  0.0000  8.6048
     20      0.8992        0.2509       [35m0.7132[0m      [31m0.8340[0m        [94m0.2926[0m     +  0.0000  8.6233
     21      0.9146        [32m0.2442[0m       0.7130      0.8340        [94m0.2925[0m     +  0.0000  8.6157
     22      0.9080        0.2506       0.7132      0.8340        [94m0.2925[0m     +  0.0000  8.6251
     23      0.9078        0.2510       0.7130      [31m0.8341[0m        [94m0.2924[0m     +  0.0000  8.5883
     24      0.9180        0.2473       0.7130      0.8341        [94m0.2924[0m     +  0.0000  8.6062
     25      0.9101        0.2491       0.7125      0.8336        [94m0.2923[0m     +  0.0000  8.5785
     26      0.9150        0.2503       0.7125      0.8336        0.2923        0.0000  8.6120
     27      0.9209        0.2497       0.7130      0.8341        [94m0.2923[0m     +  0.0000  8.5931
     28      0.9066        0.2456       0.7127      0.8337        [94m0.2923[0m     +  0.0000  8.5638
     29      0.9169        0.2488       0.7130      [31m0.8342[0m        [94m0.2923[0m     +  0.0000  8.5807
     30      0.9116        0.2497       0.7130      0.8342        0.2923        0.0000  8.5796
     31      0.9215        0.2483       0.7130      0.8341        0.2923        0.0000  8.6252
     32      0.9155        0.2535       0.7128      0.8340        [94m0.2923[0m     +  0.0000  8.5636
     33      0.9196        0.2519       0.7127      0.8338        [94m0.2923[0m     +  0.0000  8.5675
     34      0.9230        0.2473       0.7127      0.8338        [94m0.2923[0m     +  0.0000  8.5626
     35      0.9091        0.2474       0.7127      0.8338        [94m0.2922[0m     +  0.0000  8.6143
     36      0.9185        [32m0.2440[0m       0.7127      0.8338        [94m0.2922[0m     +  0.0000  8.5650
     37      0.9142        0.2481       0.7127      0.8338        [94m0.2922[0m     +  0.0000  8.5911
     38      0.9101        0.2506       0.7127      0.8338        [94m0.2922[0m     +  0.0000  8.6099
     39      0.9136        0.2491       0.7127      0.8338        [94m0.2922[0m     +  0.0000  8.5957
     40      0.9134        0.2464       0.7127      0.8338        [94m0.2922[0m     +  0.0000  8.5822
     41      0.9079        0.2468       0.7127      0.8338        [94m0.2922[0m     +  0.0000  8.6110
     42      0.9126        0.2492       0.7127      0.8338        [94m0.2922[0m     +  0.0000  8.5915
     43      0.9170        0.2512       0.7127      0.8338        [94m0.2922[0m     +  0.0000  8.6274
     44      0.9155        0.2485       0.7127      0.8338        [94m0.2922[0m     +  0.0000  8.5624
     45      0.8993        0.2557       0.7127      0.8338        [94m0.2922[0m     +  0.0000  8.6058
     46      0.9130        0.2495       0.7127      0.8338        [94m0.2922[0m     +  0.0000  8.5788
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 5 Test Accuracy: 0.7436
Iteration 5 Test F1 Score (micro): 0.8704
Iteration 5 Test F1 Score (macro): 0.8527
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\model_checkpoint_iteration_4.pt

Query 6: Using images from iteration=7 (uncertainty sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8648[0m        [32m0.3037[0m       [35m0.7325[0m      [31m0.8470[0m        [94m0.2887[0m     +  0.0000  9.5488
      2      [36m0.9132[0m        [32m0.2543[0m       [35m0.7438[0m      [31m0.8550[0m        [94m0.2829[0m     +  0.0000  9.3905
      3      [36m0.9164[0m        [32m0.2480[0m       0.7425      0.8484        [94m0.2820[0m     +  0.0000  9.4532
      4      [36m0.9165[0m        [32m0.2406[0m       [35m0.7592[0m      [31m0.8653[0m        [94m0.2754[0m     +  0.0000  9.4107
      5      [36m0.9186[0m        0.2411       0.7406      0.8419        0.2788        0.0000  9.4526
      6      [36m0.9295[0m        [32m0.2321[0m       [35m0.7609[0m      [31m0.8672[0m        [94m0.2720[0m     +  0.0000  9.4472
      7      0.9258        0.2335       [35m0.7611[0m      0.8660        [94m0.2714[0m     +  0.0000  9.4061
      8      [36m0.9306[0m        [32m0.2301[0m       0.7599      0.8635        [94m0.2711[0m     +  0.0000  9.4117
      9      0.9281        [32m0.2300[0m       [35m0.7623[0m      0.8651        [94m0.2705[0m     +  0.0000  9.4789
     10      0.9270        [32m0.2291[0m       [35m0.7628[0m      0.8661        [94m0.2695[0m     +  0.0000  9.4053
     11      0.9283        [32m0.2268[0m       [35m0.7646[0m      [31m0.8676[0m        [94m0.2685[0m     +  0.0000  9.4338
     12      0.9271        0.2290       0.7639      0.8669        [94m0.2685[0m     +  0.0000  9.4363
     13      0.9268        0.2272       [35m0.7648[0m      [31m0.8682[0m        [94m0.2680[0m     +  0.0000  9.4364
     14      0.9300        0.2293       0.7646      [31m0.8682[0m        [94m0.2679[0m     +  0.0000  9.3882
     15      [36m0.9344[0m        [32m0.2240[0m       0.7648      [31m0.8687[0m        [94m0.2677[0m     +  0.0000  9.4885
     16      [36m0.9424[0m        [32m0.2220[0m       0.7646      0.8686        [94m0.2676[0m     +  0.0000  9.4379
     17      0.9320        0.2236       0.7648      0.8682        [94m0.2675[0m     +  0.0000  9.4104
     18      0.9377        0.2242       [35m0.7649[0m      0.8685        [94m0.2674[0m     +  0.0000  9.4205
     19      0.9293        0.2255       [35m0.7653[0m      0.8687        [94m0.2672[0m     +  0.0000  9.4391
     20      0.9392        [32m0.2218[0m       0.7648      0.8685        0.2673        0.0000  9.3881
     21      0.9374        0.2237       0.7644      0.8682        0.2673        0.0000  9.4377
     22      0.9330        0.2247       0.7642      0.8682        [94m0.2672[0m     +  0.0000  9.4422
     23      0.9353        0.2232       0.7641      0.8683        [94m0.2672[0m     +  0.0000  9.3885
     24      0.9314        [32m0.2215[0m       0.7644      0.8686        [94m0.2671[0m     +  0.0000  9.3959
     25      0.9291        0.2244       0.7642      0.8684        0.2671        0.0000  9.4152
     26      0.9396        [32m0.2205[0m       0.7642      0.8684        [94m0.2671[0m     +  0.0000  9.4731
     27      0.9319        0.2225       0.7642      0.8684        [94m0.2671[0m     +  0.0000  9.4700
     28      0.9347        0.2225       0.7642      0.8684        0.2671        0.0000  9.4520
     29      0.9330        0.2240       0.7644      0.8684        [94m0.2670[0m     +  0.0000  9.4676
     30      0.9378        0.2218       0.7646      0.8687        [94m0.2670[0m     +  0.0000  9.4997
     31      0.9349        0.2226       0.7646      0.8687        [94m0.2670[0m     +  0.0000  9.4851
     32      0.9382        0.2221       0.7646      0.8686        [94m0.2670[0m     +  0.0000  9.4598
     33      0.9396        0.2215       0.7646      0.8686        [94m0.2670[0m     +  0.0000  9.4016
     34      0.9335        0.2230       0.7644      0.8685        [94m0.2669[0m     +  0.0000  9.4313
     35      0.9323        0.2233       0.7646      0.8686        [94m0.2669[0m     +  0.0000  9.4198
     36      0.9371        0.2215       0.7644      0.8685        [94m0.2669[0m     +  0.0000  9.3679
     37      0.9383        0.2254       0.7644      0.8685        [94m0.2669[0m     +  0.0000  9.4137
     38      0.9337        0.2242       0.7644      0.8685        0.2669        0.0000  9.4146
     39      0.9347        0.2255       0.7644      0.8685        [94m0.2669[0m     +  0.0000  9.4310
     40      0.9380        0.2247       0.7644      0.8685        [94m0.2669[0m     +  0.0000  9.4923
     41      0.9358        0.2229       0.7644      0.8685        [94m0.2669[0m     +  0.0000  9.3987
     42      0.9372        0.2221       0.7644      0.8685        [94m0.2669[0m     +  0.0000  9.4126
     43      0.9381        0.2226       0.7644      0.8685        0.2669        0.0000  9.4143
     44      0.9324        0.2234       0.7644      0.8685        [94m0.2669[0m     +  0.0000  9.4619
     45      0.9306        0.2252       0.7644      0.8685        [94m0.2669[0m     +  0.0000  9.4606
     46      0.9386        [32m0.2204[0m       0.7644      0.8685        [94m0.2669[0m     +  0.0000  9.4308
     47      0.9347        0.2235       0.7644      0.8685        0.2669        0.0000  9.4621
     48      0.9340        0.2215       0.7644      0.8685        0.2669        0.0000  9.4534
     49      0.9314        0.2227       0.7644      0.8685        0.2669        0.0000  9.4440
     50      0.9409        0.2242       0.7644      0.8685        [94m0.2669[0m     +  0.0000  9.4785
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 6 Test Accuracy: 0.7856
Iteration 6 Test F1 Score (micro): 0.8997
Iteration 6 Test F1 Score (macro): 0.8865
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\model_checkpoint_iteration_5.pt

Query 7: Using images from iteration=8 (uncertainty sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8882[0m        [32m0.2683[0m       [35m0.7243[0m      [31m0.8292[0m        [94m0.2661[0m     +  0.0000  10.9942
      2      [36m0.9252[0m        [32m0.2295[0m       [35m0.7370[0m      [31m0.8415[0m        [94m0.2603[0m     +  0.0000  10.8525
      3      [36m0.9307[0m        [32m0.2229[0m       [35m0.7377[0m      [31m0.8425[0m        [94m0.2584[0m     +  0.0000  10.8689
      4      [36m0.9330[0m        [32m0.2194[0m       [35m0.7479[0m      [31m0.8556[0m        [94m0.2541[0m     +  0.0000  10.8679
      5      [36m0.9355[0m        [32m0.2157[0m       [35m0.7505[0m      0.8547        [94m0.2509[0m     +  0.0000  10.8393
      6      [36m0.9398[0m        [32m0.2106[0m       [35m0.7569[0m      [31m0.8587[0m        [94m0.2500[0m     +  0.0000  10.8985
      7      0.9379        0.2131       0.7545      0.8571        [94m0.2498[0m     +  0.0000  10.8832
      8      [36m0.9432[0m        0.2106       0.7509      0.8521        [94m0.2495[0m     +  0.0000  10.8539
      9      [36m0.9434[0m        [32m0.2068[0m       0.7566      0.8583        [94m0.2485[0m     +  0.0000  10.8986
     10      [36m0.9445[0m        [32m0.2064[0m       [35m0.7595[0m      [31m0.8603[0m        [94m0.2476[0m     +  0.0000  10.8705
     11      [36m0.9461[0m        [32m0.2052[0m       [35m0.7635[0m      [31m0.8634[0m        [94m0.2471[0m     +  0.0000  10.8997
     12      [36m0.9485[0m        [32m0.2030[0m       [35m0.7684[0m      [31m0.8663[0m        [94m0.2462[0m     +  0.0000  10.9136
     13      [36m0.9490[0m        0.2031       0.7677      0.8655        [94m0.2459[0m     +  0.0000  10.8828
     14      0.9471        0.2043       0.7672      0.8654        0.2463        0.0000  10.8837
     15      0.9482        0.2034       0.7670      0.8649        0.2462        0.0000  10.8698
     16      0.9457        [32m0.2022[0m       [35m0.7689[0m      [31m0.8669[0m        [94m0.2456[0m     +  0.0000  10.9151
     17      0.9451        0.2035       0.7689      [31m0.8671[0m        [94m0.2454[0m     +  0.0000  10.8982
     18      [36m0.9519[0m        0.2037       [35m0.7694[0m      [31m0.8673[0m        [94m0.2453[0m     +  0.0000  10.8989
     19      0.9498        [32m0.2011[0m       [35m0.7698[0m      [31m0.8677[0m        [94m0.2452[0m     +  0.0000  10.8841
     20      0.9474        0.2017       0.7698      0.8675        [94m0.2452[0m     +  0.0000  10.8683
     21      0.9460        0.2029       0.7696      0.8674        [94m0.2451[0m     +  0.0000  10.8827
     22      0.9504        0.2016       [35m0.7700[0m      [31m0.8678[0m        [94m0.2450[0m     +  0.0000  10.8984
     23      0.9490        0.2021       0.7698      0.8677        [94m0.2449[0m     +  0.0000  10.8834
     24      0.9482        0.2019       0.7700      [31m0.8680[0m        [94m0.2449[0m     +  0.0000  10.8690
     25      0.9510        [32m0.2004[0m       [35m0.7705[0m      [31m0.8683[0m        [94m0.2448[0m     +  0.0000  10.8681
     26      0.9495        0.2010       0.7705      [31m0.8683[0m        [94m0.2447[0m     +  0.0000  10.8841
     27      0.9490        [32m0.2004[0m       0.7705      0.8683        [94m0.2447[0m     +  0.0000  10.8852
     28      0.9479        [32m0.1977[0m       0.7705      [31m0.8684[0m        [94m0.2447[0m     +  0.0000  10.9303
     29      0.9505        0.2012       0.7705      0.8684        0.2447        0.0000  10.8532
     30      0.9489        0.2011       0.7701      0.8681        0.2447        0.0000  10.9002
     31      0.9479        0.2018       0.7701      0.8681        0.2448        0.0000  10.8804
     32      0.9484        0.2015       0.7703      0.8681        0.2448        0.0000  10.9134
     33      0.9481        0.2017       0.7701      0.8682        0.2448        0.0000  10.9107
     34      0.9492        0.1994       0.7701      0.8683        0.2447        0.0000  10.8830
     35      0.9492        0.2019       0.7701      0.8683        0.2447        0.0000  10.8995
     36      [36m0.9525[0m        0.2004       0.7701      0.8683        0.2447        0.0000  10.9160
     37      0.9510        0.2009       0.7701      0.8683        0.2447        0.0000  10.8847
     38      0.9516        0.1997       0.7701      0.8683        0.2447        0.0000  10.8997
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 7 Test Accuracy: 0.8036
Iteration 7 Test F1 Score (micro): 0.9097
Iteration 7 Test F1 Score (macro): 0.8967
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\model_checkpoint_iteration_6.pt

Query 8: Using images from iteration=9 (uncertainty sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9143[0m        [32m0.2264[0m       [35m0.7920[0m      [31m0.8809[0m        [94m0.2362[0m     +  0.0000  13.7301
      2      [36m0.9385[0m        [32m0.2014[0m       [35m0.7925[0m      [31m0.8821[0m        [94m0.2340[0m     +  0.0000  13.3706
      3      [36m0.9414[0m        [32m0.1962[0m       [35m0.7943[0m      [31m0.8821[0m        [94m0.2322[0m     +  0.0000  13.4648
      4      [36m0.9471[0m        [32m0.1911[0m       0.7931      0.8787        [94m0.2303[0m     +  0.0000  13.4644
      5      [36m0.9497[0m        [32m0.1871[0m       [35m0.7950[0m      0.8788        [94m0.2294[0m     +  0.0000  13.5270
      6      [36m0.9522[0m        [32m0.1810[0m       0.7915      0.8751        0.2307        0.0000  13.4797
      7      0.9518        0.1824       0.7913      0.8766        0.2304        0.0000  13.5575
      8      [36m0.9544[0m        [32m0.1806[0m       0.7910      0.8742        0.2303        0.0000  13.5417
      9      0.9543        [32m0.1778[0m       0.7925      0.8764        0.2298        0.0000  13.5276
     10      [36m0.9546[0m        [32m0.1748[0m       0.7913      0.8751        0.2298        0.0000  13.6065
     11      [36m0.9563[0m        0.1752       0.7943      0.8765        0.2296        0.0000  13.5276
     12      [36m0.9573[0m        [32m0.1745[0m       0.7936      0.8763        0.2295        0.0000  13.5262
     13      [36m0.9573[0m        [32m0.1731[0m       0.7937      0.8764        0.2295        0.0000  13.5255
     14      [36m0.9584[0m        [32m0.1727[0m       0.7913      0.8747        0.2299        0.0000  13.4979
     15      0.9578        0.1729       0.7931      0.8760        [94m0.2293[0m     +  0.0000  13.5118
     16      0.9576        0.1739       0.7925      0.8761        0.2296        0.0000  13.5112
     17      0.9573        0.1740       0.7929      0.8759        [94m0.2293[0m     +  0.0000  13.5127
     18      0.9575        [32m0.1723[0m       0.7924      0.8760        0.2294        0.0000  13.4802
     19      [36m0.9599[0m        [32m0.1711[0m       0.7925      0.8761        0.2294        0.0000  13.4819
     20      [36m0.9610[0m        [32m0.1706[0m       0.7927      0.8763        [94m0.2293[0m     +  0.0000  13.5111
     21      0.9606        [32m0.1705[0m       0.7936      0.8771        [94m0.2291[0m     +  0.0000  13.4819
     22      0.9606        0.1711       0.7936      0.8772        [94m0.2291[0m     +  0.0000  13.5284
     23      0.9591        [32m0.1699[0m       0.7934      0.8770        0.2292        0.0000  13.5293
     24      0.9609        0.1703       0.7936      0.8769        0.2292        0.0000  13.4788
     25      [36m0.9620[0m        0.1706       0.7934      0.8766        0.2292        0.0000  13.4502
     26      0.9588        [32m0.1699[0m       0.7934      0.8766        0.2292        0.0000  13.4795
     27      0.9582        [32m0.1692[0m       0.7936      0.8768        0.2292        0.0000  13.4975
     28      0.9600        0.1709       0.7934      0.8767        0.2292        0.0000  13.4808
     29      0.9584        0.1698       0.7939      0.8771        0.2291        0.0000  13.4974
     30      0.9576        0.1708       0.7939      0.8772        0.2291        0.0000  13.4481
     31      0.9613        0.1708       0.7939      0.8772        0.2291        0.0000  13.4502
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 8 Test Accuracy: 0.8259
Iteration 8 Test F1 Score (micro): 0.9215
Iteration 8 Test F1 Score (macro): 0.9106
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\model_checkpoint_iteration_7.pt

Query 9: Using images from iteration=10 (uncertainty sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9375[0m        [32m0.1905[0m       [35m0.8007[0m      [31m0.8874[0m        [94m0.2231[0m     +  0.0000  18.3269
      2      [36m0.9536[0m        [32m0.1707[0m       0.7953      0.8848        [94m0.2224[0m     +  0.0000  18.1085
      3      [36m0.9598[0m        [32m0.1639[0m       0.7981      0.8861        [94m0.2202[0m     +  0.0000  18.1891
      4      [36m0.9613[0m        [32m0.1613[0m       [35m0.8024[0m      0.8873        [94m0.2181[0m     +  0.0000  18.2668
      5      [36m0.9641[0m        [32m0.1563[0m       0.8010      0.8857        [94m0.2179[0m     +  0.0000  18.2035
      6      [36m0.9665[0m        [32m0.1517[0m       [35m0.8092[0m      [31m0.8884[0m        [94m0.2147[0m     +  0.0000  18.1872
      7      [36m0.9677[0m        [32m0.1500[0m       [35m0.8094[0m      [31m0.8886[0m        [94m0.2143[0m     +  0.0000  18.1868
      8      [36m0.9686[0m        [32m0.1489[0m       0.8071      0.8876        [94m0.2140[0m     +  0.0000  18.1885
      9      [36m0.9694[0m        0.1491       0.8075      0.8875        0.2140        0.0000  18.1277
     10      [36m0.9711[0m        [32m0.1457[0m       0.8063      0.8869        [94m0.2136[0m     +  0.0000  18.1399
     11      [36m0.9718[0m        [32m0.1451[0m       [35m0.8113[0m      0.8884        [94m0.2126[0m     +  0.0000  18.1541
     12      0.9716        [32m0.1447[0m       [35m0.8120[0m      0.8883        0.2127        0.0000  18.0965
     13      0.9700        [32m0.1447[0m       [35m0.8123[0m      0.8881        [94m0.2125[0m     +  0.0000  18.1543
     14      0.9702        [32m0.1438[0m       0.8116      0.8882        0.2128        0.0000  18.2095
     15      [36m0.9719[0m        [32m0.1427[0m       [35m0.8146[0m      [31m0.8891[0m        [94m0.2120[0m     +  0.0000  18.1896
     16      0.9718        [32m0.1414[0m       0.8139      0.8879        0.2121        0.0000  18.1869
     17      [36m0.9740[0m        [32m0.1412[0m       0.8142      0.8879        0.2121        0.0000  18.0924
     18      0.9727        0.1421       0.8146      0.8884        0.2121        0.0000  18.0935
     19      0.9723        0.1425       0.8135      0.8875        0.2122        0.0000  18.1695
     20      0.9724        0.1416       0.8141      0.8880        0.2121        0.0000  18.1723
     21      0.9735        0.1423       0.8128      0.8870        0.2121        0.0000  18.1085
     22      0.9727        0.1418       0.8127      0.8867        0.2121        0.0000  18.1575
     23      0.9723        0.1416       0.8132      0.8869        0.2121        0.0000  18.1266
     24      0.9733        [32m0.1410[0m       0.8130      0.8869        0.2121        0.0000  18.1700
     25      0.9732        0.1410       0.8130      0.8870        0.2121        0.0000  18.1393
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 9 Test Accuracy: 0.8292
Iteration 9 Test F1 Score (micro): 0.9230
Iteration 9 Test F1 Score (macro): 0.9122
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\model_checkpoint_iteration_8.pt

Query 10: Using images from iteration=11 (uncertainty sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9550[0m        [32m0.1606[0m       [35m0.8210[0m      [31m0.8927[0m        [94m0.2041[0m     +  0.0000  26.5238
      2      [36m0.9676[0m        [32m0.1442[0m       [35m0.8281[0m      [31m0.8960[0m        [94m0.2019[0m     +  0.0000  26.3630
      3      [36m0.9712[0m        [32m0.1396[0m       0.8250      0.8940        0.2022        0.0000  26.4598
      4      [36m0.9737[0m        [32m0.1349[0m       0.8241      0.8948        [94m0.2016[0m     +  0.0000  26.5188
      5      0.9737        [32m0.1329[0m       0.8241      0.8929        [94m0.2012[0m     +  0.0000  26.4466
      6      [36m0.9761[0m        [32m0.1277[0m       0.8252      0.8933        [94m0.2007[0m     +  0.0000  26.4594
      7      [36m0.9782[0m        [32m0.1264[0m       0.8264      0.8935        [94m0.2001[0m     +  0.0000  26.4601
      8      [36m0.9788[0m        [32m0.1248[0m       0.8248      0.8922        [94m0.2000[0m     +  0.0000  26.3808
      9      [36m0.9793[0m        [32m0.1241[0m       0.8278      0.8937        [94m0.1982[0m     +  0.0000  26.4603
     10      [36m0.9795[0m        [32m0.1222[0m       [35m0.8307[0m      0.8947        [94m0.1981[0m     +  0.0000  26.3959
     11      [36m0.9811[0m        [32m0.1208[0m       0.8266      0.8931        0.1982        0.0000  26.5224
     12      [36m0.9817[0m        [32m0.1199[0m       0.8259      0.8932        0.1985        0.0000  26.3155
     13      0.9815        [32m0.1191[0m       0.8262      0.8926        0.1986        0.0000  26.4268
     14      0.9813        [32m0.1188[0m       0.8260      0.8928        0.1984        0.0000  26.3930
     15      [36m0.9820[0m        [32m0.1177[0m       0.8259      0.8928        0.1984        0.0000  26.4553
     16      [36m0.9824[0m        0.1181       0.8245      0.8923        0.1982        0.0000  26.3680
     17      0.9823        0.1179       0.8243      0.8926        0.1982        0.0000  26.3942
     18      0.9818        [32m0.1173[0m       0.8250      0.8928        0.1982        0.0000  26.4892
     19      [36m0.9830[0m        0.1175       0.8241      0.8922        0.1984        0.0000  26.4632
     20      0.9825        [32m0.1162[0m       0.8245      0.8921        0.1984        0.0000  26.4105
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 10 Test Accuracy: 0.8396
Iteration 10 Test F1 Score (micro): 0.9277
Iteration 10 Test F1 Score (macro): 0.9163
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\model_checkpoint_iteration_9.pt

Query 11: Using images from iteration=12 (uncertainty sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9696[0m        [32m0.1355[0m       [35m0.8097[0m      [31m0.8902[0m        [94m0.2059[0m     +  0.0000  41.1126
      2      [36m0.9776[0m        [32m0.1224[0m       [35m0.8109[0m      [31m0.8903[0m        [94m0.2036[0m     +  0.0000  41.1949
      3      [36m0.9787[0m        [32m0.1183[0m       [35m0.8137[0m      [31m0.8921[0m        [94m0.2002[0m     +  0.0000  41.2244
      4      [36m0.9795[0m        [32m0.1144[0m       [35m0.8144[0m      [31m0.8925[0m        [94m0.2001[0m     +  0.0000  41.2874
      5      [36m0.9811[0m        [32m0.1106[0m       0.8097      0.8907        0.2025        0.0000  41.1631
      6      [36m0.9831[0m        [32m0.1064[0m       0.8134      0.8908        [94m0.1974[0m     +  0.0000  41.2037
      7      [36m0.9833[0m        [32m0.1054[0m       [35m0.8179[0m      [31m0.8928[0m        [94m0.1952[0m     +  0.0000  41.2059
      8      [36m0.9841[0m        [32m0.1036[0m       0.8168      0.8923        0.1957        0.0000  41.2093
      9      [36m0.9844[0m        [32m0.1025[0m       [35m0.8182[0m      0.8923        0.1960        0.0000  41.1777
     10      0.9842        [32m0.1011[0m       0.8142      0.8907        0.1979        0.0000  41.1265
     11      [36m0.9845[0m        [32m0.0995[0m       [35m0.8214[0m      0.8918        [94m0.1935[0m     +  0.0000  41.1585
     12      [36m0.9852[0m        [32m0.0986[0m       0.8194      0.8905        0.1951        0.0000  41.1924
     13      [36m0.9857[0m        [32m0.0983[0m       0.8214      0.8916        0.1945        0.0000  41.0497
     14      [36m0.9860[0m        0.0986       0.8214      0.8917        0.1940        0.0000  41.1601
     15      0.9855        [32m0.0973[0m       0.8201      0.8911        0.1953        0.0000  41.1591
     16      0.9856        [32m0.0966[0m       0.8200      0.8894        0.1938        0.0000  41.1428
     17      [36m0.9860[0m        [32m0.0962[0m       0.8201      0.8897        0.1941        0.0000  41.1281
     18      [36m0.9864[0m        [32m0.0961[0m       0.8207      0.8895        0.1940        0.0000  41.0961
     19      0.9862        [32m0.0959[0m       0.8196      0.8891        0.1938        0.0000  41.1788
     20      [36m0.9865[0m        [32m0.0955[0m       0.8212      0.8899        0.1938        0.0000  41.1631
     21      0.9861        0.0959       0.8205      0.8894        0.1937        0.0000  41.1914
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 11 Test Accuracy: 0.8420
Iteration 11 Test F1 Score (micro): 0.9283
Iteration 11 Test F1 Score (macro): 0.9162
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\model_checkpoint_iteration_10.pt

Query 12: Using images from iteration=13 (uncertainty sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9782[0m        [32m0.1065[0m       [35m0.8194[0m      [31m0.8885[0m        [94m0.1889[0m     +  0.0000  67.1649
      2      [36m0.9829[0m        [32m0.0967[0m       0.8151      0.8860        0.1912        0.0000  67.4712
      3      [36m0.9838[0m        [32m0.0924[0m       0.8111      0.8843        0.1929        0.0000  67.3022
      4      [36m0.9843[0m        [32m0.0888[0m       0.8127      0.8850        0.1904        0.0000  67.4091
      5      [36m0.9847[0m        [32m0.0856[0m       0.8101      0.8832        0.1916        0.0000  67.4440
      6      [36m0.9865[0m        [32m0.0813[0m       0.8141      0.8848        0.1900        0.0000  67.4596
      7      [36m0.9872[0m        [32m0.0795[0m       0.8128      0.8843        0.1908        0.0000  67.3668
      8      0.9871        [32m0.0779[0m       0.8127      0.8856        0.1903        0.0000  67.3468
      9      [36m0.9880[0m        [32m0.0764[0m       0.8151      0.8851        0.1895        0.0000  67.3698
     10      0.9879        [32m0.0754[0m       0.8130      0.8851        0.1902        0.0000  67.2579
     11      [36m0.9888[0m        [32m0.0734[0m       0.8151      0.8859        0.1905        0.0000  67.3491
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 12 Test Accuracy: 0.8486
Iteration 12 Test F1 Score (micro): 0.9308
Iteration 12 Test F1 Score (macro): 0.9182
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\model_checkpoint_iteration_11.pt

Query 13: Using images from iteration=14 (uncertainty sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9795[0m        [32m0.0990[0m       [35m0.7948[0m      [31m0.8843[0m        [94m0.2121[0m     +  0.0000  78.0381
      2      [36m0.9829[0m        [32m0.0919[0m       [35m0.8005[0m      [31m0.8879[0m        [94m0.2065[0m     +  0.0000  78.6558
      3      [36m0.9836[0m        [32m0.0870[0m       [35m0.8052[0m      0.8866        [94m0.2040[0m     +  0.0000  78.5917
      4      [36m0.9842[0m        [32m0.0837[0m       [35m0.8057[0m      0.8876        [94m0.1942[0m     +  0.0000  77.9860
      5      [36m0.9849[0m        [32m0.0802[0m       0.8024      0.8856        0.2057        0.0000  78.0158
      6      [36m0.9866[0m        [32m0.0764[0m       [35m0.8137[0m      0.8863        [94m0.1899[0m     +  0.0000  77.9843
      7      [36m0.9869[0m        [32m0.0743[0m       0.8127      0.8866        0.1942        0.0000  78.0784
      8      [36m0.9877[0m        [32m0.0728[0m       0.8132      0.8874        0.1942        0.0000  77.9543
      9      [36m0.9884[0m        [32m0.0708[0m       [35m0.8160[0m      0.8867        [94m0.1890[0m     +  0.0000  78.0297
     10      [36m0.9885[0m        [32m0.0697[0m       [35m0.8194[0m      0.8873        [94m0.1861[0m     +  0.0000  78.0796
     11      [36m0.9889[0m        [32m0.0683[0m       [35m0.8201[0m      [31m0.8880[0m        0.1878        0.0000  78.0189
     12      [36m0.9897[0m        [32m0.0677[0m       0.8198      0.8875        0.1886        0.0000  77.9691
     13      [36m0.9898[0m        [32m0.0671[0m       [35m0.8208[0m      [31m0.8882[0m        0.1871        0.0000  78.1283
     14      0.9897        [32m0.0666[0m       [35m0.8212[0m      [31m0.8889[0m        0.1880        0.0000  77.9393
     15      [36m0.9902[0m        [32m0.0655[0m       0.8191      0.8871        0.1901        0.0000  77.8949
     16      [36m0.9903[0m        [32m0.0648[0m       0.8186      0.8868        0.1890        0.0000  78.0553
     17      0.9902        [32m0.0647[0m       0.8189      0.8872        0.1898        0.0000  78.0780
     18      0.9901        [32m0.0646[0m       0.8200      0.8877        0.1895        0.0000  78.0214
     19      [36m0.9910[0m        [32m0.0640[0m       0.8196      0.8875        0.1898        0.0000  78.0659
     20      0.9905        0.0641       0.8189      0.8872        0.1900        0.0000  77.9188
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 13 Test Accuracy: 0.8557
Iteration 13 Test F1 Score (micro): 0.9329
Iteration 13 Test F1 Score (macro): 0.9199
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\model_checkpoint_iteration_12.pt

Best F1 score across all iterations: 0.9199
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/uncertainty_sampling_seed43_test\AL_uncertainty_sampling_results_for_multilabel_classification_s43_test.pickle
