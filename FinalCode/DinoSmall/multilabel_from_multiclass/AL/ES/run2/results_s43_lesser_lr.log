Train set shape: (26880, 5)
Val set shape:   (5760, 5)
Test set shape:  (5760, 5)
Selected images DataFrame (Entropy Sampling):
   Iteration                                       Sample_Names
0          1  Spule035_Image0269.jpg,Spule020_Image0191.jpg,...
1          2  Spule011_Image0263.jpg,Spule021_Image0051.jpg,...
2          3  Spule030_Image0176.jpg,Spule010_Image0148.jpg,...
3          4  Spule009_Image0177.jpg,Spule021_Image0914.jpg,...
4          5  Spule015_Image0668.jpg,Spule026_Image0300.jpg,...
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.4889[0m        [32m0.7147[0m       [35m0.0043[0m      [31m0.3553[0m        [94m0.7135[0m     +  0.0000  7.7448
      2      [36m0.5407[0m        [32m0.6860[0m       [35m0.0611[0m      0.3443        [94m0.7031[0m     +  0.0000  7.4530
      3      [36m0.6869[0m        [32m0.6747[0m       [35m0.0757[0m      [31m0.3881[0m        0.7088        0.0000  7.4731
      4      0.6571        [32m0.6566[0m       [35m0.0868[0m      [31m0.4815[0m        [94m0.6940[0m     +  0.0000  7.5935
      5      0.6556        0.6593       [35m0.1030[0m      0.4437        0.7014        0.0000  8.0171
      6      [36m0.7833[0m        [32m0.6286[0m       [35m0.1050[0m      0.4355        0.7012        0.0000  7.6185
      7      0.7685        [32m0.6054[0m       [35m0.1090[0m      0.4444        0.6967        0.0000  7.6566
      8      [36m0.8487[0m        [32m0.5847[0m       [35m0.1099[0m      0.4448        [94m0.6934[0m     +  0.0000  7.6635
      9      0.8320        0.5978       0.1026      0.4512        [94m0.6907[0m     +  0.0000  7.6530
     10      0.6944        0.6178       0.1080      0.4482        [94m0.6904[0m     +  0.0000  7.6583
     11      [36m0.8796[0m        [32m0.5755[0m       0.1075      0.4491        [94m0.6903[0m     +  0.0000  7.6609
     12      0.8024        [32m0.5614[0m       0.1083      0.4495        [94m0.6894[0m     +  0.0000  7.7191
     13      0.8258        0.5746       0.1059      0.4511        [94m0.6884[0m     +  0.0000  7.6816
     14      0.7685        0.5952       0.1073      0.4558        [94m0.6879[0m     +  0.0000  7.7192
     15      0.7857        0.5727       0.1082      0.4546        0.6879        0.0000  7.6563
     16      [36m0.8889[0m        [32m0.5465[0m       0.1083      0.4533        0.6883        0.0000  7.7526
     17      0.7857        0.5623       0.1082      0.4545        0.6880        0.0000  7.7548
     18      0.8320        0.5548       0.1080      0.4544        0.6884        0.0000  7.7305
     19      [36m0.9153[0m        0.5681       0.1076      0.4553        0.6883        0.0000  7.8108
     20      0.8796        [32m0.5455[0m       0.1078      0.4566        0.6880        0.0000  7.7302
     21      0.7833        0.5698       0.1076      0.4561        0.6881        0.0000  7.7621
     22      0.8381        0.5664       0.1082      0.4567        0.6880        0.0000  7.7731
     23      0.8500        0.5522       0.1082      0.4567        0.6880        0.0000  7.7340
     24      0.8783        0.5501       0.1083      0.4573        0.6880        0.0000  7.7549
Stopping since valid_loss has not improved in the last 11 epochs.
Pre-training scores with initial data:
  F1 (macro) = 0.4798
  F1 (micro) = 0.4832
  Accuracy   = 0.1594

Query 1: Using images from iteration=2 (entropy sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.5742[0m        [32m0.6567[0m       [35m0.2587[0m      [31m0.3466[0m        [94m0.6432[0m     +  0.0000  7.8017
      2      0.3143        [32m0.6406[0m       [35m0.3375[0m      0.3006        [94m0.6264[0m     +  0.0000  7.8231
      3      0.5256        [32m0.6008[0m       [35m0.3470[0m      0.3353        [94m0.6190[0m     +  0.0000  7.7442
      4      0.5263        [32m0.5652[0m       0.3378      0.3248        [94m0.6093[0m     +  0.0000  7.7339
      5      [36m0.7659[0m        [32m0.5434[0m       [35m0.4431[0m      0.3189        [94m0.6029[0m     +  0.0000  7.7350
      6      0.4426        0.5509       0.4175      [31m0.3674[0m        [94m0.5930[0m     +  0.0000  7.7796
      7      0.6836        [32m0.5249[0m       0.4300      0.3628        [94m0.5878[0m     +  0.0000  7.6715
      8      [36m0.8238[0m        [32m0.5053[0m       0.4304      [31m0.3772[0m        [94m0.5836[0m     +  0.0000  7.6998
      9      [36m0.8596[0m        [32m0.5001[0m       0.4361      [31m0.3795[0m        [94m0.5789[0m     +  0.0000  7.7612
     10      0.7723        [32m0.4940[0m       [35m0.4616[0m      [31m0.3820[0m        [94m0.5744[0m     +  0.0000  7.7984
     11      0.8078        0.5003       0.4517      [31m0.3939[0m        [94m0.5728[0m     +  0.0000  7.6850
     12      0.7672        [32m0.4861[0m       0.4533      [31m0.3969[0m        [94m0.5711[0m     +  0.0000  7.7049
     13      0.7845        [32m0.4779[0m       0.4493      [31m0.4001[0m        [94m0.5702[0m     +  0.0000  7.7136
     14      [36m0.8600[0m        [32m0.4749[0m       0.4519      [31m0.4061[0m        [94m0.5687[0m     +  0.0000  7.7499
     15      [36m0.8674[0m        0.4800       0.4549      [31m0.4113[0m        [94m0.5671[0m     +  0.0000  7.7016
     16      [36m0.9219[0m        [32m0.4687[0m       0.4549      [31m0.4127[0m        [94m0.5669[0m     +  0.0000  7.6592
     17      0.8290        [32m0.4560[0m       0.4550      [31m0.4137[0m        [94m0.5665[0m     +  0.0000  7.6748
     18      0.9182        0.4632       0.4542      [31m0.4137[0m        [94m0.5662[0m     +  0.0000  7.6992
     19      0.8660        0.4627       0.4545      [31m0.4143[0m        [94m0.5659[0m     +  0.0000  7.7433
     20      0.8771        0.4696       0.4559      [31m0.4156[0m        [94m0.5653[0m     +  0.0000  7.7695
     21      0.8722        0.4730       0.4566      [31m0.4165[0m        [94m0.5650[0m     +  0.0000  7.7964
     22      0.6728        0.4728       0.4568      [31m0.4167[0m        [94m0.5649[0m     +  0.0000  7.7216
     23      [36m0.9327[0m        [32m0.4464[0m       0.4568      [31m0.4171[0m        [94m0.5647[0m     +  0.0000  7.6872
     24      0.7487        0.4665       0.4569      [31m0.4173[0m        [94m0.5645[0m     +  0.0000  7.6890
     25      0.9024        [32m0.4441[0m       0.4573      0.4171        [94m0.5644[0m     +  0.0000  7.7071
     26      0.7633        0.4536       0.4573      0.4172        [94m0.5643[0m     +  0.0000  7.6718
     27      0.8855        0.4655       0.4576      0.4172        [94m0.5642[0m     +  0.0000  7.7947
     28      0.8850        0.4746       0.4575      [31m0.4175[0m        [94m0.5642[0m     +  0.0000  7.6843
     29      0.8218        0.4773       0.4576      [31m0.4175[0m        [94m0.5641[0m     +  0.0000  7.6859
     30      0.8736        0.4711       0.4575      [31m0.4175[0m        [94m0.5640[0m     +  0.0000  7.6895
     31      0.7357        0.4744       0.4576      [31m0.4176[0m        [94m0.5640[0m     +  0.0000  7.7641
     32      0.8019        0.4583       0.4578      0.4176        [94m0.5640[0m     +  0.0000  7.7522
     33      0.8561        0.4613       0.4578      0.4176        [94m0.5639[0m     +  0.0000  7.6859
     34      0.8308        0.4805       0.4578      0.4176        [94m0.5639[0m     +  0.0000  7.7474
     35      0.9171        0.4615       0.4578      0.4175        [94m0.5639[0m     +  0.0000  7.7273
     36      0.8487        0.4706       0.4578      0.4175        [94m0.5639[0m     +  0.0000  7.6736
     37      0.7866        0.4728       0.4578      0.4175        [94m0.5639[0m     +  0.0000  7.6959
     38      0.8232        0.4708       0.4578      0.4175        [94m0.5639[0m     +  0.0000  7.7206
     39      0.8042        0.4644       0.4578      0.4175        [94m0.5639[0m     +  0.0000  7.7559
     40      0.7315        0.4668       0.4578      0.4176        [94m0.5638[0m     +  0.0000  7.7011
     41      0.8360        0.4780       0.4578      0.4176        [94m0.5638[0m     +  0.0000  7.6736
     42      0.8612        0.4799       0.4578      0.4176        [94m0.5638[0m     +  0.0000  7.7345
     43      0.8528        0.4601       0.4578      0.4176        [94m0.5638[0m     +  0.0000  7.7338
     44      0.8269        0.4677       0.4578      0.4176        [94m0.5638[0m     +  0.0000  7.7170
     45      0.8156        0.4614       0.4578      0.4175        [94m0.5638[0m     +  0.0000  7.6629
     46      0.8407        0.4698       0.4578      0.4175        [94m0.5638[0m     +  0.0000  7.7058
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 1 Test Accuracy: 0.4646
Iteration 1 Test F1 Score (micro): 0.5969
Iteration 1 Test F1 Score (macro): 0.5016
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\model_checkpoint_iteration_0.pt

Query 2: Using images from iteration=3 (entropy sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.7009[0m        [32m0.5025[0m       [35m0.4693[0m      [31m0.1994[0m        [94m0.5827[0m     +  0.0000  7.9141
      2      0.4632        0.5063       0.4417      [31m0.6560[0m        [94m0.5427[0m     +  0.0000  7.7853
      3      [36m0.7847[0m        0.5128       0.4550      0.1510        0.5803        0.0000  7.7813
      4      0.3834        [32m0.4811[0m       [35m0.5740[0m      0.5495        [94m0.5079[0m     +  0.0000  7.7982
      5      [36m0.8321[0m        [32m0.4385[0m       0.5448      0.4626        [94m0.5007[0m     +  0.0000  7.8401
      6      [36m0.8708[0m        [32m0.4048[0m       0.5582      0.5079        [94m0.4933[0m     +  0.0000  7.7827
      7      0.7998        0.4106       0.5651      0.5213        [94m0.4924[0m     +  0.0000  7.7638
      8      0.8322        0.4092       [35m0.5750[0m      0.5522        [94m0.4863[0m     +  0.0000  7.7671
      9      [36m0.9087[0m        [32m0.3906[0m       0.5681      0.5326        0.4880        0.0000  7.7791
     10      0.8755        0.3953       0.5734      0.5484        [94m0.4834[0m     +  0.0000  7.8294
     11      0.8867        [32m0.3851[0m       0.5750      0.5522        [94m0.4824[0m     +  0.0000  7.8124
     12      0.8763        0.3930       [35m0.5760[0m      0.5523        [94m0.4815[0m     +  0.0000  7.7972
     13      [36m0.9503[0m        [32m0.3845[0m       0.5740      0.5464        [94m0.4812[0m     +  0.0000  7.8421
     14      0.8764        0.3943       [35m0.5762[0m      0.5510        [94m0.4805[0m     +  0.0000  7.8904
     15      0.8608        0.3887       0.5753      0.5532        [94m0.4796[0m     +  0.0000  7.8283
     16      0.8700        [32m0.3769[0m       0.5762      0.5528        0.4797        0.0000  7.8328
     17      0.8550        0.3966       [35m0.5767[0m      0.5540        [94m0.4792[0m     +  0.0000  7.7607
     18      0.9256        [32m0.3763[0m       [35m0.5776[0m      0.5544        [94m0.4790[0m     +  0.0000  7.7915
     19      0.8733        0.3822       0.5774      0.5531        [94m0.4789[0m     +  0.0000  7.8125
     20      0.8762        0.3838       0.5776      0.5532        0.4789        0.0000  7.7944
     21      0.8905        0.3866       0.5776      0.5529        0.4789        0.0000  7.7645
     22      0.8999        0.3836       0.5776      0.5525        [94m0.4787[0m     +  0.0000  7.7924
     23      0.8900        0.3789       [35m0.5780[0m      0.5530        0.4787        0.0000  7.7979
     24      0.8344        0.3871       0.5778      0.5529        [94m0.4785[0m     +  0.0000  7.7558
     25      0.8767        [32m0.3725[0m       0.5774      0.5531        0.4785        0.0000  7.8121
     26      0.8709        0.3860       0.5774      0.5531        [94m0.4785[0m     +  0.0000  7.7846
     27      0.9071        0.3761       0.5774      0.5531        [94m0.4785[0m     +  0.0000  7.7646
     28      0.8747        0.3758       0.5780      0.5539        [94m0.4785[0m     +  0.0000  7.8024
     29      0.9053        0.3811       0.5778      0.5534        0.4785        0.0000  7.8151
     30      [36m0.9534[0m        0.3732       0.5776      0.5531        0.4785        0.0000  7.7941
     31      0.9011        0.3868       0.5776      0.5531        0.4785        0.0000  7.7810
     32      0.8946        0.3841       0.5780      0.5537        [94m0.4785[0m     +  0.0000  7.8265
     33      0.8807        0.3767       0.5776      0.5531        [94m0.4784[0m     +  0.0000  7.7810
     34      0.8897        0.3736       0.5776      0.5531        [94m0.4784[0m     +  0.0000  7.7521
     35      0.8720        0.3862       0.5776      0.5532        [94m0.4784[0m     +  0.0000  7.7827
     36      0.8946        0.3761       0.5776      0.5531        [94m0.4784[0m     +  0.0000  7.7786
     37      0.8603        0.3768       0.5778      0.5534        [94m0.4784[0m     +  0.0000  7.7536
     38      0.8835        0.3945       0.5776      0.5532        [94m0.4784[0m     +  0.0000  7.8021
     39      0.8322        0.3902       0.5778      0.5534        [94m0.4784[0m     +  0.0000  7.8447
     40      0.8062        0.3821       0.5776      0.5531        [94m0.4784[0m     +  0.0000  7.7482
     41      0.8463        0.3873       0.5778      0.5534        [94m0.4784[0m     +  0.0000  7.7963
     42      0.9009        0.3810       0.5776      0.5531        [94m0.4784[0m     +  0.0000  7.8296
     43      0.9063        0.3833       0.5778      0.5534        [94m0.4784[0m     +  0.0000  7.7517
     44      0.8307        0.3982       0.5778      0.5536        [94m0.4784[0m     +  0.0000  7.7868
     45      0.8727        0.3748       0.5778      0.5536        [94m0.4784[0m     +  0.0000  7.7861
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 2 Test Accuracy: 0.6330
Iteration 2 Test F1 Score (micro): 0.7113
Iteration 2 Test F1 Score (macro): 0.6266
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\model_checkpoint_iteration_1.pt

Query 3: Using images from iteration=4 (entropy sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8018[0m        [32m0.4263[0m       [35m0.5318[0m      [31m0.7364[0m        [94m0.4867[0m     +  0.0000  8.0314
      2      0.7561        0.4818       0.4674      0.2816        0.5227        0.0000  7.9372
      3      0.4628        0.4546       [35m0.6396[0m      [31m0.7417[0m        [94m0.4272[0m     +  0.0000  7.9730
      4      [36m0.8073[0m        [32m0.4023[0m       0.6146      0.6266        [94m0.4228[0m     +  0.0000  8.0313
      5      0.7920        [32m0.3632[0m       [35m0.6632[0m      0.7312        [94m0.3970[0m     +  0.0000  7.9697
      6      [36m0.8467[0m        [32m0.3536[0m       0.6606      0.7131        0.3977        0.0000  7.9330
      7      [36m0.8679[0m        0.3552       0.6569      0.7076        0.3972        0.0000  7.9764
      8      0.8548        0.3541       0.6547      0.7073        [94m0.3958[0m     +  0.0000  7.9366
      9      [36m0.8717[0m        [32m0.3464[0m       0.6542      0.7063        [94m0.3946[0m     +  0.0000  7.9265
     10      [36m0.8732[0m        [32m0.3397[0m       0.6564      0.7121        [94m0.3929[0m     +  0.0000  7.9364
     11      [36m0.8748[0m        0.3422       0.6556      0.7111        [94m0.3926[0m     +  0.0000  8.0312
     12      0.8229        [32m0.3351[0m       0.6566      0.7131        [94m0.3914[0m     +  0.0000  7.9640
     13      0.8356        0.3537       0.6569      0.7139        [94m0.3906[0m     +  0.0000  7.9544
     14      0.8588        0.3405       0.6576      0.7180        [94m0.3892[0m     +  0.0000  7.9483
     15      0.8677        0.3408       0.6573      0.7170        0.3892        0.0000  7.9064
     16      0.8722        0.3412       0.6573      0.7165        0.3892        0.0000  8.0479
     17      [36m0.8792[0m        0.3386       0.6569      0.7160        [94m0.3890[0m     +  0.0000  7.9361
     18      0.8418        0.3480       0.6566      0.7167        [94m0.3887[0m     +  0.0000  7.9521
     19      0.8146        0.3461       0.6571      0.7179        [94m0.3884[0m     +  0.0000  7.9544
     20      [36m0.8922[0m        0.3387       0.6569      0.7172        [94m0.3883[0m     +  0.0000  8.0159
     21      0.8273        [32m0.3341[0m       0.6568      0.7171        [94m0.3882[0m     +  0.0000  8.0505
     22      0.8537        [32m0.3274[0m       0.6566      0.7172        [94m0.3882[0m     +  0.0000  7.9446
     23      0.8648        0.3382       0.6569      0.7173        [94m0.3881[0m     +  0.0000  7.9687
     24      0.8638        0.3341       0.6569      0.7173        [94m0.3880[0m     +  0.0000  7.9372
     25      0.8878        0.3394       0.6569      0.7173        [94m0.3879[0m     +  0.0000  7.9376
     26      0.8758        0.3339       0.6568      0.7172        [94m0.3879[0m     +  0.0000  7.9705
     27      0.8755        0.3384       0.6568      0.7172        [94m0.3879[0m     +  0.0000  7.9565
     28      0.8908        0.3331       0.6566      0.7172        [94m0.3878[0m     +  0.0000  7.9680
     29      0.8831        0.3458       0.6568      0.7172        [94m0.3878[0m     +  0.0000  7.9397
     30      0.8645        0.3304       0.6566      0.7172        [94m0.3878[0m     +  0.0000  7.9049
     31      0.8618        0.3331       0.6568      0.7172        [94m0.3878[0m     +  0.0000  7.9323
     32      0.8598        0.3340       0.6568      0.7172        [94m0.3878[0m     +  0.0000  8.0158
     33      0.8568        0.3340       0.6571      0.7174        [94m0.3878[0m     +  0.0000  7.9278
     34      0.8697        0.3389       0.6568      0.7173        [94m0.3878[0m     +  0.0000  7.9544
     35      0.8585        0.3345       0.6573      0.7175        0.3878        0.0000  7.9508
     36      0.8345        0.3324       0.6571      0.7174        [94m0.3878[0m     +  0.0000  7.9376
     37      [36m0.8970[0m        0.3283       0.6571      0.7174        [94m0.3877[0m     +  0.0000  7.9264
     38      0.8770        [32m0.3270[0m       0.6571      0.7174        [94m0.3877[0m     +  0.0000  7.9555
     39      0.8662        0.3369       0.6571      0.7174        [94m0.3877[0m     +  0.0000  7.9374
     40      0.8291        0.3326       0.6571      0.7174        [94m0.3877[0m     +  0.0000  7.9834
     41      0.8485        0.3436       0.6571      0.7174        [94m0.3877[0m     +  0.0000  7.9389
     42      0.8472        0.3314       0.6571      0.7174        [94m0.3877[0m     +  0.0000  7.9683
     43      0.8538        0.3425       0.6571      0.7174        [94m0.3877[0m     +  0.0000  7.9847
     44      0.8770        0.3399       0.6571      0.7174        [94m0.3877[0m     +  0.0000  8.0956
     45      0.8691        0.3311       0.6571      0.7174        [94m0.3877[0m     +  0.0000  7.9386
     46      0.8815        0.3339       0.6571      0.7174        [94m0.3877[0m     +  0.0000  7.9343
     47      0.8812        0.3362       0.6571      0.7174        [94m0.3877[0m     +  0.0000  7.9221
     48      0.8706        0.3375       0.6571      0.7174        [94m0.3877[0m     +  0.0000  8.0446
     49      0.8799        0.3351       0.6571      0.7174        [94m0.3877[0m     +  0.0000  7.9375
     50      0.8466        0.3374       0.6571      0.7174        0.3877        0.0000  7.9576
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 3 Test Accuracy: 0.6892
Iteration 3 Test F1 Score (micro): 0.8177
Iteration 3 Test F1 Score (macro): 0.7644
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\model_checkpoint_iteration_2.pt

Query 4: Using images from iteration=5 (entropy sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.7719[0m        [32m0.3614[0m       [35m0.5856[0m      [31m0.7950[0m        [94m0.4547[0m     +  0.0000  8.2786
      2      0.7657        0.4229       [35m0.6637[0m      0.7433        [94m0.3526[0m     +  0.0000  8.2359
      3      [36m0.8591[0m        [32m0.3138[0m       [35m0.6781[0m      0.7764        [94m0.3441[0m     +  0.0000  8.2790
      4      [36m0.8696[0m        [32m0.3074[0m       0.6781      0.7854        [94m0.3391[0m     +  0.0000  8.2189
      5      0.8292        0.3094       0.6781      0.7901        [94m0.3355[0m     +  0.0000  8.2039
      6      0.8574        [32m0.2961[0m       0.6722      0.7714        0.3388        0.0000  8.2041
      7      [36m0.9140[0m        [32m0.2877[0m       0.6766      0.7770        0.3355        0.0000  8.1837
      8      0.8926        0.2906       0.6757      0.7752        [94m0.3345[0m     +  0.0000  8.1744
      9      0.8763        0.2918       0.6727      0.7693        0.3355        0.0000  8.2377
     10      0.8860        0.2944       0.6764      0.7716        0.3346        0.0000  8.2766
     11      0.8815        0.2944       0.6750      0.7720        [94m0.3336[0m     +  0.0000  8.1875
     12      0.8942        [32m0.2876[0m       0.6760      0.7726        [94m0.3334[0m     +  0.0000  8.2342
     13      0.8993        [32m0.2872[0m       0.6759      0.7727        [94m0.3331[0m     +  0.0000  8.2340
     14      [36m0.9161[0m        [32m0.2862[0m       0.6748      0.7731        [94m0.3327[0m     +  0.0000  8.2946
     15      0.9058        [32m0.2832[0m       0.6755      0.7745        [94m0.3319[0m     +  0.0000  8.2462
     16      0.9019        0.2842       0.6759      0.7745        [94m0.3319[0m     +  0.0000  8.1715
     17      0.8952        0.2839       0.6759      0.7743        0.3319        0.0000  8.2645
     18      0.8883        0.2901       0.6762      0.7746        [94m0.3316[0m     +  0.0000  8.2192
     19      0.9002        [32m0.2826[0m       0.6755      0.7731        0.3319        0.0000  8.2319
     20      0.8767        0.2862       0.6760      0.7738        [94m0.3316[0m     +  0.0000  8.2270
     21      0.9005        0.2835       0.6760      0.7738        [94m0.3315[0m     +  0.0000  8.3533
     22      0.9012        0.2882       0.6759      0.7733        [94m0.3315[0m     +  0.0000  8.2383
     23      0.8950        [32m0.2765[0m       0.6764      0.7735        [94m0.3314[0m     +  0.0000  8.3053
     24      0.8708        0.2820       0.6766      0.7741        [94m0.3313[0m     +  0.0000  8.1941
     25      0.8907        0.2835       0.6764      0.7741        [94m0.3312[0m     +  0.0000  8.2288
     26      0.8948        0.2844       0.6764      0.7742        [94m0.3312[0m     +  0.0000  8.2032
     27      0.8851        0.2853       0.6762      0.7741        [94m0.3311[0m     +  0.0000  8.2027
     28      [36m0.9191[0m        0.2867       0.6762      0.7741        [94m0.3311[0m     +  0.0000  8.2886
     29      [36m0.9205[0m        0.2799       0.6762      0.7741        [94m0.3310[0m     +  0.0000  8.2223
     30      0.9165        0.2791       0.6762      0.7741        0.3310        0.0000  8.1875
     31      0.8879        0.2831       0.6762      0.7741        [94m0.3310[0m     +  0.0000  8.2653
     32      0.9108        0.2794       0.6762      0.7741        [94m0.3310[0m     +  0.0000  8.1934
     33      0.9012        0.2771       0.6762      0.7741        [94m0.3310[0m     +  0.0000  8.2781
     34      0.8855        0.2774       0.6762      0.7741        [94m0.3309[0m     +  0.0000  8.2308
     35      0.8910        0.2793       0.6762      0.7741        [94m0.3309[0m     +  0.0000  8.2385
     36      0.9020        0.2812       0.6762      0.7741        [94m0.3309[0m     +  0.0000  8.2582
     37      0.8991        0.2811       0.6762      0.7741        [94m0.3309[0m     +  0.0000  8.2813
     38      0.8968        0.2806       0.6762      0.7741        [94m0.3309[0m     +  0.0000  8.2346
     39      0.8963        0.2818       0.6762      0.7741        [94m0.3309[0m     +  0.0000  8.2501
     40      0.9103        0.2827       0.6760      0.7740        [94m0.3309[0m     +  0.0000  8.1958
     41      0.8855        0.2808       0.6760      0.7740        [94m0.3309[0m     +  0.0000  8.2240
     42      0.8999        0.2788       0.6760      0.7740        [94m0.3309[0m     +  0.0000  8.2089
     43      0.9004        0.2790       0.6760      0.7740        [94m0.3309[0m     +  0.0000  8.2003
     44      0.8952        0.2812       0.6760      0.7740        [94m0.3309[0m     +  0.0000  8.2027
     45      0.9201        0.2823       0.6760      0.7740        [94m0.3309[0m     +  0.0000  8.2592
     46      0.9163        0.2839       0.6760      0.7740        [94m0.3309[0m     +  0.0000  8.2684
     47      0.8897        0.2895       0.6760      0.7740        [94m0.3309[0m     +  0.0000  8.2555
     48      0.8998        0.2903       0.6760      0.7740        [94m0.3309[0m     +  0.0000  8.2093
     49      0.9105        [32m0.2761[0m       0.6760      0.7740        [94m0.3309[0m     +  0.0000  8.1982
     50      0.8860        0.2803       0.6760      0.7740        [94m0.3309[0m     +  0.0000  8.2349
     51      0.8788        0.2859       0.6760      0.7740        [94m0.3309[0m     +  0.0000  8.2237
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 4 Test Accuracy: 0.7306
Iteration 4 Test F1 Score (micro): 0.8524
Iteration 4 Test F1 Score (macro): 0.8230
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\model_checkpoint_iteration_3.pt

Query 5: Using images from iteration=6 (entropy sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8372[0m        [32m0.3221[0m       [35m0.6530[0m      [31m0.8061[0m        [94m0.3899[0m     +  0.0000  8.8368
      2      0.8328        0.3349       [35m0.6720[0m      0.7827        [94m0.3137[0m     +  0.0000  8.6836
      3      [36m0.8904[0m        [32m0.2821[0m       [35m0.6743[0m      0.7861        [94m0.3104[0m     +  0.0000  8.6718
      4      [36m0.8987[0m        [32m0.2714[0m       [35m0.6844[0m      0.7960        [94m0.3050[0m     +  0.0000  8.5941
      5      0.8890        0.2724       0.6802      0.7927        [94m0.3045[0m     +  0.0000  8.6398
      6      [36m0.9112[0m        [32m0.2603[0m       [35m0.7285[0m      [31m0.8467[0m        [94m0.2955[0m     +  0.0000  8.7034
      7      0.9052        [32m0.2582[0m       [35m0.7354[0m      [31m0.8532[0m        [94m0.2945[0m     +  0.0000  8.6338
      8      0.8941        [32m0.2558[0m       0.7276      0.8421        [94m0.2940[0m     +  0.0000  8.7203
      9      [36m0.9146[0m        0.2584       0.7342      0.8500        [94m0.2925[0m     +  0.0000  8.6213
     10      0.9057        0.2610       [35m0.7373[0m      0.8523        [94m0.2918[0m     +  0.0000  8.6977
     11      0.9116        0.2604       0.7330      0.8474        0.2919        0.0000  8.7616
     12      0.9080        0.2567       0.7325      0.8467        [94m0.2917[0m     +  0.0000  8.8132
     13      [36m0.9347[0m        [32m0.2474[0m       0.7319      0.8458        [94m0.2916[0m     +  0.0000  8.7340
     14      0.9173        0.2524       0.7326      0.8463        [94m0.2911[0m     +  0.0000  8.6559
     15      0.9232        0.2559       0.7311      0.8448        [94m0.2910[0m     +  0.0000  8.6526
     16      0.9093        0.2526       0.7304      0.8442        [94m0.2910[0m     +  0.0000  8.6820
     17      0.9110        0.2576       0.7293      0.8434        0.2910        0.0000  8.7229
     18      0.9120        0.2519       0.7306      0.8445        [94m0.2907[0m     +  0.0000  8.6527
     19      0.9264        0.2505       0.7299      0.8437        [94m0.2907[0m     +  0.0000  8.6586
     20      0.9203        0.2560       0.7297      0.8434        [94m0.2906[0m     +  0.0000  8.7218
     21      0.9134        0.2513       0.7293      0.8431        [94m0.2906[0m     +  0.0000  8.7348
     22      0.9230        [32m0.2459[0m       0.7299      0.8435        [94m0.2905[0m     +  0.0000  8.7188
     23      0.9191        0.2503       0.7300      0.8437        [94m0.2905[0m     +  0.0000  8.6982
     24      0.9220        0.2511       0.7307      0.8444        [94m0.2904[0m     +  0.0000  8.7287
     25      0.9227        0.2542       0.7302      0.8439        0.2904        0.0000  8.6349
     26      0.9181        0.2469       0.7307      0.8444        [94m0.2903[0m     +  0.0000  8.6448
     27      0.9091        0.2521       0.7309      0.8445        [94m0.2903[0m     +  0.0000  8.7541
     28      0.9229        0.2528       0.7306      0.8442        [94m0.2903[0m     +  0.0000  8.6927
     29      0.9213        0.2523       0.7304      0.8440        [94m0.2903[0m     +  0.0000  8.6887
     30      0.9216        0.2538       0.7304      0.8440        0.2903        0.0000  8.6803
     31      0.9077        0.2540       0.7302      0.8439        0.2903        0.0000  8.7079
     32      0.9103        0.2552       0.7306      0.8442        [94m0.2903[0m     +  0.0000  8.6365
     33      0.9142        0.2502       0.7307      0.8444        [94m0.2902[0m     +  0.0000  8.6427
     34      0.9131        0.2502       0.7302      0.8439        0.2903        0.0000  8.7397
     35      0.9174        0.2514       0.7304      0.8441        0.2903        0.0000  8.6383
     36      0.9143        0.2508       0.7304      0.8441        0.2903        0.0000  8.6533
     37      0.9224        0.2524       0.7302      0.8439        0.2903        0.0000  8.6148
     38      0.9199        0.2494       0.7302      0.8439        0.2903        0.0000  8.7405
     39      0.9215        0.2503       0.7302      0.8439        0.2903        0.0000  8.7285
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 5 Test Accuracy: 0.7595
Iteration 5 Test F1 Score (micro): 0.8810
Iteration 5 Test F1 Score (macro): 0.8672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\model_checkpoint_iteration_4.pt

Query 6: Using images from iteration=7 (entropy sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8030[0m        [32m0.3261[0m       [35m0.7427[0m      [31m0.8685[0m        [94m0.2895[0m     +  0.0000  9.7103
      2      [36m0.9088[0m        [32m0.2512[0m       [35m0.7446[0m      [31m0.8713[0m        [94m0.2829[0m     +  0.0000  9.4645
      3      0.9064        [32m0.2447[0m       [35m0.7502[0m      [31m0.8728[0m        [94m0.2789[0m     +  0.0000  9.4839
      4      [36m0.9107[0m        [32m0.2388[0m       [35m0.7503[0m      0.8720        [94m0.2769[0m     +  0.0000  9.4864
      5      [36m0.9161[0m        [32m0.2372[0m       [35m0.7519[0m      [31m0.8735[0m        [94m0.2728[0m     +  0.0000  9.5226
      6      [36m0.9245[0m        [32m0.2292[0m       [35m0.7521[0m      0.8725        [94m0.2702[0m     +  0.0000  9.4891
      7      0.9228        [32m0.2268[0m       [35m0.7536[0m      0.8729        [94m0.2692[0m     +  0.0000  9.5310
      8      0.9215        0.2296       0.7526      0.8726        [94m0.2689[0m     +  0.0000  9.4947
      9      0.9206        0.2280       [35m0.7571[0m      [31m0.8747[0m        [94m0.2682[0m     +  0.0000  9.5317
     10      [36m0.9252[0m        [32m0.2244[0m       0.7571      0.8745        [94m0.2673[0m     +  0.0000  9.5032
     11      [36m0.9266[0m        0.2250       0.7536      0.8724        [94m0.2665[0m     +  0.0000  9.5246
     12      [36m0.9271[0m        [32m0.2220[0m       0.7523      0.8717        [94m0.2664[0m     +  0.0000  9.5135
     13      [36m0.9317[0m        0.2231       0.7523      0.8716        [94m0.2660[0m     +  0.0000  9.4992
     14      0.9303        0.2240       0.7545      0.8719        [94m0.2655[0m     +  0.0000  9.5744
     15      0.9279        [32m0.2218[0m       0.7524      0.8713        0.2656        0.0000  9.4770
     16      0.9273        [32m0.2214[0m       0.7547      0.8722        [94m0.2655[0m     +  0.0000  9.5648
     17      [36m0.9342[0m        0.2217       0.7535      0.8714        [94m0.2653[0m     +  0.0000  9.5315
     18      [36m0.9377[0m        0.2221       0.7540      0.8711        [94m0.2652[0m     +  0.0000  9.6411
     19      0.9330        [32m0.2210[0m       0.7545      0.8716        [94m0.2650[0m     +  0.0000  9.5305
     20      0.9333        0.2236       0.7545      0.8717        [94m0.2649[0m     +  0.0000  9.5877
     21      [36m0.9380[0m        [32m0.2189[0m       0.7545      0.8713        [94m0.2648[0m     +  0.0000  9.5163
     22      0.9302        0.2213       0.7543      0.8713        0.2648        0.0000  9.5656
     23      0.9328        0.2217       0.7542      0.8711        [94m0.2648[0m     +  0.0000  9.5612
     24      [36m0.9381[0m        [32m0.2179[0m       0.7543      0.8711        [94m0.2647[0m     +  0.0000  9.6040
     25      0.9362        0.2191       0.7550      0.8714        [94m0.2647[0m     +  0.0000  9.5269
     26      0.9317        0.2208       0.7545      0.8712        [94m0.2647[0m     +  0.0000  9.5372
     27      [36m0.9397[0m        0.2211       0.7543      0.8710        0.2647        0.0000  9.5776
     28      0.9297        0.2243       0.7542      0.8709        0.2647        0.0000  9.5111
     29      0.9369        [32m0.2172[0m       0.7542      0.8709        [94m0.2647[0m     +  0.0000  9.5204
     30      0.9305        0.2202       0.7540      0.8707        [94m0.2646[0m     +  0.0000  9.6060
     31      0.9258        0.2216       0.7540      0.8707        [94m0.2646[0m     +  0.0000  9.5163
     32      0.9383        0.2197       0.7540      0.8707        [94m0.2646[0m     +  0.0000  9.5038
     33      0.9385        0.2225       0.7540      0.8707        [94m0.2646[0m     +  0.0000  9.6098
     34      0.9377        0.2186       0.7540      0.8707        [94m0.2646[0m     +  0.0000  9.5315
     35      0.9361        0.2187       0.7542      0.8707        [94m0.2646[0m     +  0.0000  9.5119
     36      0.9350        [32m0.2156[0m       0.7542      0.8707        [94m0.2646[0m     +  0.0000  9.5565
     37      0.9343        0.2186       0.7542      0.8707        0.2646        0.0000  9.5562
     38      0.9330        0.2220       0.7543      0.8708        [94m0.2646[0m     +  0.0000  9.5314
     39      0.9308        0.2212       0.7542      0.8707        [94m0.2646[0m     +  0.0000  9.5936
     40      0.9320        0.2214       0.7542      0.8707        [94m0.2646[0m     +  0.0000  9.5467
     41      0.9312        0.2196       0.7542      0.8707        0.2646        0.0000  9.4843
     42      [36m0.9408[0m        0.2205       0.7542      0.8707        0.2646        0.0000  9.5200
     43      0.9335        0.2193       0.7542      0.8707        [94m0.2646[0m     +  0.0000  9.5117
     44      0.9326        0.2235       0.7542      0.8707        [94m0.2646[0m     +  0.0000  9.5749
     45      0.9323        0.2193       0.7542      0.8707        [94m0.2646[0m     +  0.0000  9.5453
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 6 Test Accuracy: 0.7759
Iteration 6 Test F1 Score (micro): 0.8928
Iteration 6 Test F1 Score (macro): 0.8806
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\model_checkpoint_iteration_5.pt

Query 7: Using images from iteration=8 (entropy sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8720[0m        [32m0.2729[0m       [35m0.7701[0m      [31m0.8673[0m        [94m0.2598[0m     +  0.0000  11.2297
      2      [36m0.9218[0m        [32m0.2219[0m       [35m0.7726[0m      0.8636        [94m0.2595[0m     +  0.0000  10.9726
      3      [36m0.9244[0m        [32m0.2211[0m       [35m0.7764[0m      0.8659        [94m0.2552[0m     +  0.0000  10.9482
      4      [36m0.9313[0m        [32m0.2160[0m       0.7722      0.8641        [94m0.2547[0m     +  0.0000  10.9062
      5      [36m0.9344[0m        [32m0.2108[0m       [35m0.7804[0m      [31m0.8697[0m        [94m0.2495[0m     +  0.0000  10.9248
      6      0.9339        [32m0.2090[0m       0.7707      [31m0.8706[0m        [94m0.2475[0m     +  0.0000  10.9425
      7      0.9337        [32m0.2074[0m       0.7741      [31m0.8722[0m        [94m0.2463[0m     +  0.0000  10.9697
      8      [36m0.9414[0m        [32m0.2056[0m       0.7714      0.8707        0.2465        0.0000  11.0032
      9      0.9391        [32m0.2042[0m       0.7745      0.8710        [94m0.2455[0m     +  0.0000  10.9743
     10      0.9413        [32m0.2036[0m       0.7724      0.8712        [94m0.2453[0m     +  0.0000  11.0572
     11      [36m0.9415[0m        [32m0.2026[0m       0.7740      [31m0.8737[0m        [94m0.2446[0m     +  0.0000  10.9953
     12      [36m0.9421[0m        [32m0.2024[0m       0.7736      [31m0.8738[0m        [94m0.2444[0m     +  0.0000  11.0028
     13      0.9409        [32m0.2015[0m       0.7740      0.8729        [94m0.2443[0m     +  0.0000  11.0261
     14      [36m0.9452[0m        [32m0.2010[0m       0.7743      [31m0.8741[0m        [94m0.2441[0m     +  0.0000  11.0161
     15      0.9432        [32m0.2003[0m       0.7747      [31m0.8742[0m        [94m0.2438[0m     +  0.0000  10.9790
     16      0.9420        0.2017       0.7743      [31m0.8743[0m        [94m0.2438[0m     +  0.0000  11.0001
     17      [36m0.9462[0m        [32m0.1976[0m       0.7747      0.8742        [94m0.2437[0m     +  0.0000  11.0468
     18      0.9448        [32m0.1975[0m       0.7743      0.8740        0.2438        0.0000  11.0204
     19      0.9440        0.2002       0.7743      0.8740        0.2437        0.0000  11.0883
     20      [36m0.9516[0m        0.1990       0.7745      0.8742        [94m0.2437[0m     +  0.0000  10.9832
     21      0.9478        [32m0.1964[0m       0.7748      [31m0.8744[0m        [94m0.2436[0m     +  0.0000  11.0433
     22      0.9488        0.1974       0.7743      0.8742        [94m0.2435[0m     +  0.0000  10.9878
     23      0.9459        0.1973       0.7750      [31m0.8745[0m        [94m0.2434[0m     +  0.0000  11.0383
     24      0.9431        0.1969       0.7748      [31m0.8745[0m        [94m0.2434[0m     +  0.0000  10.9683
     25      0.9460        0.1975       0.7747      0.8744        [94m0.2433[0m     +  0.0000  11.0546
     26      0.9452        0.2001       0.7747      0.8743        0.2434        0.0000  10.9939
     27      0.9437        0.1972       0.7748      0.8744        0.2434        0.0000  10.9698
     28      0.9441        0.1986       0.7747      0.8743        0.2434        0.0000  11.0040
     29      0.9424        0.1968       0.7748      0.8743        0.2434        0.0000  10.9486
     30      0.9488        0.1976       0.7745      0.8742        0.2434        0.0000  10.9994
     31      0.9492        0.1976       0.7743      0.8741        [94m0.2433[0m     +  0.0000  11.0007
     32      0.9457        [32m0.1958[0m       0.7747      0.8743        0.2434        0.0000  11.0262
     33      0.9471        0.1968       0.7748      0.8744        0.2433        0.0000  10.9718
     34      0.9462        0.1961       0.7748      0.8743        0.2434        0.0000  11.0282
     35      0.9444        0.1981       0.7747      0.8742        0.2433        0.0000  10.9810
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 7 Test Accuracy: 0.7939
Iteration 7 Test F1 Score (micro): 0.9035
Iteration 7 Test F1 Score (macro): 0.8912
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\model_checkpoint_iteration_6.pt

Query 8: Using images from iteration=9 (entropy sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8995[0m        [32m0.2399[0m       [35m0.7601[0m      [31m0.8535[0m        [94m0.2419[0m     +  0.0000  13.9000
      2      [36m0.9301[0m        [32m0.2100[0m       0.7592      0.8489        [94m0.2418[0m     +  0.0000  13.5691
      3      [36m0.9337[0m        [32m0.2038[0m       0.7535      0.8384        0.2446        0.0000  13.6023
      4      [36m0.9360[0m        [32m0.1998[0m       [35m0.7606[0m      0.8473        [94m0.2413[0m     +  0.0000  13.6261
      5      [36m0.9404[0m        [32m0.1950[0m       [35m0.7634[0m      0.8472        0.2415        0.0000  13.6225
      6      [36m0.9450[0m        [32m0.1899[0m       [35m0.7937[0m      [31m0.8746[0m        [94m0.2317[0m     +  0.0000  13.6141
      7      [36m0.9475[0m        [32m0.1898[0m       0.7887      0.8737        0.2323        0.0000  13.6819
      8      [36m0.9522[0m        [32m0.1866[0m       0.7861      0.8710        0.2325        0.0000  13.7214
      9      0.9519        [32m0.1855[0m       0.7922      0.8740        [94m0.2309[0m     +  0.0000  13.6680
     10      [36m0.9531[0m        [32m0.1823[0m       0.7927      0.8715        0.2316        0.0000  13.8867
     11      [36m0.9540[0m        0.1823       [35m0.8003[0m      [31m0.8803[0m        [94m0.2299[0m     +  0.0000  13.6452
     12      0.9533        0.1830       0.7988      0.8796        [94m0.2297[0m     +  0.0000  13.6922
     13      0.9513        [32m0.1823[0m       0.7967      0.8785        0.2300        0.0000  13.6198
     14      [36m0.9541[0m        [32m0.1798[0m       0.7972      0.8788        [94m0.2297[0m     +  0.0000  13.6642
     15      [36m0.9543[0m        0.1805       0.7972      0.8785        [94m0.2295[0m     +  0.0000  13.6720
     16      [36m0.9545[0m        [32m0.1792[0m       0.7965      0.8792        0.2295        0.0000  13.6509
     17      [36m0.9571[0m        [32m0.1780[0m       0.7937      0.8783        0.2301        0.0000  13.7121
     18      0.9571        [32m0.1777[0m       0.7950      0.8788        0.2298        0.0000  13.5784
     19      0.9566        0.1782       0.7943      0.8784        0.2299        0.0000  13.7182
     20      0.9550        0.1786       0.7946      0.8787        0.2297        0.0000  13.6397
     21      [36m0.9583[0m        0.1787       0.7937      0.8785        0.2299        0.0000  13.6230
     22      0.9551        0.1791       0.7939      0.8785        0.2299        0.0000  13.7095
     23      [36m0.9584[0m        [32m0.1770[0m       0.7937      0.8784        0.2299        0.0000  13.5815
     24      [36m0.9603[0m        [32m0.1759[0m       0.7931      0.8781        0.2299        0.0000  13.5896
     25      0.9591        0.1771       0.7936      0.8784        0.2300        0.0000  13.5899
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 8 Test Accuracy: 0.8168
Iteration 8 Test F1 Score (micro): 0.9178
Iteration 8 Test F1 Score (macro): 0.9078
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\model_checkpoint_iteration_7.pt

Query 9: Using images from iteration=10 (entropy sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9312[0m        [32m0.2011[0m       [35m0.7917[0m      [31m0.8818[0m        [94m0.2284[0m     +  0.0000  18.3602
      2      [36m0.9522[0m        [32m0.1775[0m       [35m0.7934[0m      0.8815        0.2303        0.0000  18.1911
      3      [36m0.9571[0m        [32m0.1713[0m       [35m0.8005[0m      [31m0.8825[0m        [94m0.2250[0m     +  0.0000  18.2487
      4      [36m0.9613[0m        [32m0.1655[0m       0.7983      0.8803        [94m0.2225[0m     +  0.0000  18.4202
      5      [36m0.9642[0m        [32m0.1608[0m       0.7977      0.8811        0.2239        0.0000  18.3770
      6      [36m0.9654[0m        [32m0.1567[0m       0.7976      0.8781        [94m0.2188[0m     +  0.0000  18.4015
      7      [36m0.9672[0m        [32m0.1545[0m       0.7984      0.8788        0.2194        0.0000  18.3444
      8      [36m0.9696[0m        [32m0.1529[0m       [35m0.8014[0m      0.8793        [94m0.2181[0m     +  0.0000  18.4066
      9      0.9681        [32m0.1499[0m       0.7995      0.8785        [94m0.2179[0m     +  0.0000  18.3631
     10      0.9692        0.1508       0.7934      0.8771        0.2199        0.0000  18.3587
     11      [36m0.9707[0m        [32m0.1488[0m       [35m0.8045[0m      0.8797        [94m0.2156[0m     +  0.0000  18.3916
     12      [36m0.9717[0m        [32m0.1470[0m       0.8038      0.8792        0.2158        0.0000  18.3004
     13      0.9717        [32m0.1464[0m       0.8036      0.8797        0.2159        0.0000  18.3124
     14      [36m0.9729[0m        0.1469       0.8009      0.8787        0.2162        0.0000  18.2649
     15      [36m0.9734[0m        [32m0.1454[0m       0.8033      0.8794        [94m0.2156[0m     +  0.0000  18.3116
     16      [36m0.9737[0m        0.1456       [35m0.8089[0m      0.8823        [94m0.2147[0m     +  0.0000  18.2769
     17      0.9734        [32m0.1453[0m       [35m0.8099[0m      0.8824        [94m0.2146[0m     +  0.0000  18.3131
     18      [36m0.9739[0m        [32m0.1439[0m       0.8066      0.8810        0.2151        0.0000  18.2850
     19      0.9721        0.1446       0.8082      0.8820        0.2149        0.0000  18.3268
     20      0.9719        [32m0.1433[0m       0.8090      0.8823        0.2148        0.0000  18.4057
     21      0.9731        [32m0.1428[0m       0.8089      0.8823        0.2147        0.0000  18.5012
     22      0.9726        0.1441       0.8090      0.8824        0.2147        0.0000  18.2496
     23      0.9725        0.1447       0.8089      0.8824        0.2147        0.0000  18.3121
     24      0.9732        0.1440       0.8090      0.8824        0.2146        0.0000  18.3151
     25      0.9730        0.1443       [35m0.8101[0m      [31m0.8829[0m        [94m0.2145[0m     +  0.0000  18.3129
     26      0.9720        0.1437       0.8089      0.8824        0.2146        0.0000  18.2354
     27      0.9734        0.1433       0.8087      0.8822        0.2147        0.0000  18.2822
     28      0.9727        0.1430       0.8089      0.8823        0.2147        0.0000  18.3039
     29      [36m0.9747[0m        0.1434       0.8087      0.8822        0.2147        0.0000  18.2818
     30      0.9744        0.1439       0.8087      0.8822        0.2147        0.0000  18.3119
     31      0.9738        0.1429       0.8082      0.8819        0.2147        0.0000  18.2812
     32      0.9723        0.1441       0.8082      0.8819        0.2147        0.0000  18.2659
     33      0.9743        [32m0.1423[0m       0.8082      0.8820        0.2147        0.0000  18.2792
     34      [36m0.9748[0m        0.1431       0.8083      0.8820        0.2147        0.0000  18.2349
     35      0.9731        0.1426       0.8080      0.8818        0.2147        0.0000  18.2657
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 9 Test Accuracy: 0.8236
Iteration 9 Test F1 Score (micro): 0.9202
Iteration 9 Test F1 Score (macro): 0.9100
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\model_checkpoint_iteration_8.pt

Query 10: Using images from iteration=11 (entropy sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9553[0m        [32m0.1623[0m       [35m0.8380[0m      [31m0.8939[0m        [94m0.2041[0m     +  0.0000  26.5391
      2      [36m0.9669[0m        [32m0.1457[0m       0.8108      0.8841        0.2067        0.0000  26.5232
      3      [36m0.9715[0m        [32m0.1400[0m       0.8156      0.8866        0.2055        0.0000  26.5853
      4      [36m0.9722[0m        [32m0.1362[0m       0.8160      0.8869        0.2046        0.0000  26.7726
      5      [36m0.9728[0m        [32m0.1326[0m       0.8165      0.8878        [94m0.2027[0m     +  0.0000  26.7098
      6      [36m0.9764[0m        [32m0.1283[0m       0.8087      0.8836        0.2041        0.0000  26.6642
      7      [36m0.9768[0m        [32m0.1266[0m       0.8113      0.8851        0.2032        0.0000  26.7090
      8      0.9766        [32m0.1262[0m       0.8108      0.8844        0.2039        0.0000  26.6660
      9      [36m0.9771[0m        [32m0.1243[0m       0.8153      0.8860        [94m0.2024[0m     +  0.0000  26.6970
     10      [36m0.9782[0m        [32m0.1234[0m       0.8090      0.8829        0.2046        0.0000  26.6328
     11      [36m0.9785[0m        [32m0.1214[0m       0.8148      0.8857        [94m0.2019[0m     +  0.0000  26.6793
     12      [36m0.9786[0m        0.1220       0.8122      0.8840        0.2025        0.0000  26.6637
     13      0.9785        [32m0.1206[0m       0.8118      0.8832        0.2030        0.0000  26.6627
     14      [36m0.9793[0m        [32m0.1206[0m       0.8108      0.8830        0.2033        0.0000  26.6921
     15      0.9790        [32m0.1205[0m       0.8149      0.8847        0.2022        0.0000  26.6936
     16      [36m0.9796[0m        [32m0.1193[0m       0.8160      0.8853        [94m0.2019[0m     +  0.0000  26.7573
     17      [36m0.9799[0m        [32m0.1186[0m       0.8170      0.8857        0.2022        0.0000  26.6137
     18      0.9785        0.1191       0.8177      0.8859        0.2021        0.0000  26.6785
     19      0.9793        0.1189       0.8170      0.8857        0.2020        0.0000  26.6637
     20      0.9794        [32m0.1185[0m       0.8156      0.8849        0.2025        0.0000  26.6804
     21      0.9793        [32m0.1184[0m       0.8184      0.8859        0.2021        0.0000  26.5996
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 10 Test Accuracy: 0.8306
Iteration 10 Test F1 Score (micro): 0.9238
Iteration 10 Test F1 Score (macro): 0.9126
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\model_checkpoint_iteration_9.pt

Query 11: Using images from iteration=12 (entropy sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9675[0m        [32m0.1360[0m       [35m0.7882[0m      [31m0.8761[0m        [94m0.2115[0m     +  0.0000  41.2694
      2      [36m0.9748[0m        [32m0.1230[0m       [35m0.8066[0m      [31m0.8812[0m        [94m0.2021[0m     +  0.0000  41.3803
      3      [36m0.9763[0m        [32m0.1187[0m       0.8026      0.8798        0.2055        0.0000  41.5525
      4      [36m0.9783[0m        [32m0.1143[0m       0.7981      0.8789        0.2051        0.0000  41.5030
      5      [36m0.9790[0m        [32m0.1109[0m       0.8036      0.8798        0.2027        0.0000  41.6113
      6      [36m0.9805[0m        [32m0.1067[0m       [35m0.8181[0m      [31m0.8855[0m        [94m0.1972[0m     +  0.0000  41.3902
      7      [36m0.9811[0m        [32m0.1048[0m       0.8163      0.8852        [94m0.1972[0m     +  0.0000  41.5013
      8      [36m0.9813[0m        [32m0.1036[0m       [35m0.8194[0m      [31m0.8858[0m        [94m0.1966[0m     +  0.0000  41.5683
      9      [36m0.9831[0m        [32m0.1020[0m       0.8163      0.8847        0.1977        0.0000  41.4918
     10      0.9826        [32m0.1009[0m       [35m0.8224[0m      [31m0.8862[0m        0.1972        0.0000  41.3473
     11      [36m0.9837[0m        [32m0.0991[0m       0.8186      0.8847        0.1982        0.0000  41.5810
     12      [36m0.9841[0m        [32m0.0990[0m       0.8144      0.8838        0.1994        0.0000  41.5201
     13      0.9837        [32m0.0984[0m       0.8168      0.8841        0.1993        0.0000  41.4538
     14      0.9838        [32m0.0974[0m       0.8182      0.8850        0.1982        0.0000  41.4878
     15      [36m0.9845[0m        [32m0.0974[0m       0.8198      0.8853        0.1995        0.0000  41.4081
     16      [36m0.9851[0m        [32m0.0972[0m       0.8179      0.8848        0.2000        0.0000  41.4981
     17      0.9850        [32m0.0962[0m       0.8175      0.8846        0.2003        0.0000  41.7175
     18      0.9849        0.0968       0.8175      0.8847        0.2003        0.0000  41.6432
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 11 Test Accuracy: 0.8333
Iteration 11 Test F1 Score (micro): 0.9243
Iteration 11 Test F1 Score (macro): 0.9124
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\model_checkpoint_iteration_10.pt

Query 12: Using images from iteration=13 (entropy sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9763[0m        [32m0.1083[0m       [35m0.8174[0m      [31m0.8851[0m        [94m0.1934[0m     +  0.0000  67.4731
      2      [36m0.9813[0m        [32m0.0980[0m       0.8127      0.8843        0.1937        0.0000  68.0500
      3      [36m0.9818[0m        [32m0.0942[0m       0.8137      0.8830        0.1939        0.0000  67.8673
      4      [36m0.9837[0m        [32m0.0894[0m       0.8090      0.8817        0.1977        0.0000  67.8948
      5      0.9833        [32m0.0867[0m       0.8144      0.8818        0.1970        0.0000  67.9479
      6      [36m0.9857[0m        [32m0.0818[0m       [35m0.8196[0m      0.8838        [94m0.1915[0m     +  0.0000  68.0077
      7      [36m0.9865[0m        [32m0.0798[0m       0.8186      0.8829        0.1927        0.0000  67.7874
      8      [36m0.9866[0m        [32m0.0782[0m       [35m0.8227[0m      0.8849        [94m0.1914[0m     +  0.0000  67.8943
      9      [36m0.9872[0m        [32m0.0769[0m       0.8203      0.8838        0.1922        0.0000  68.9712
     10      [36m0.9874[0m        [32m0.0758[0m       [35m0.8243[0m      [31m0.8852[0m        [94m0.1905[0m     +  0.0000  67.9514
     11      [36m0.9883[0m        [32m0.0738[0m       0.8215      0.8845        0.1925        0.0000  67.8331
     12      [36m0.9885[0m        [32m0.0727[0m       0.8215      0.8844        0.1929        0.0000  68.0099
     13      0.9883        0.0727       0.8208      0.8843        0.1940        0.0000  67.8205
     14      [36m0.9887[0m        [32m0.0719[0m       0.8217      0.8841        0.1936        0.0000  67.8671
     15      0.9885        [32m0.0712[0m       0.8212      0.8839        0.1937        0.0000  68.0713
     16      [36m0.9888[0m        [32m0.0706[0m       0.8189      0.8836        0.1957        0.0000  67.9770
     17      [36m0.9892[0m        [32m0.0704[0m       0.8207      0.8837        0.1955        0.0000  67.7090
     18      [36m0.9893[0m        [32m0.0700[0m       0.8201      0.8837        0.1957        0.0000  67.9087
     19      0.9893        0.0701       0.8191      0.8835        0.1963        0.0000  67.9613
     20      [36m0.9897[0m        [32m0.0697[0m       0.8201      0.8833        0.1956        0.0000  68.1614
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 12 Test Accuracy: 0.8427
Iteration 12 Test F1 Score (micro): 0.9269
Iteration 12 Test F1 Score (macro): 0.9149
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\model_checkpoint_iteration_11.pt

Query 13: Using images from iteration=14 (entropy sampling).
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9826[0m        [32m0.0794[0m       [35m0.7849[0m      [31m0.8754[0m        [94m0.2037[0m     +  0.0000  78.5169
      2      [36m0.9869[0m        [32m0.0722[0m       0.7670      0.8709        0.2390        0.0000  78.7190
      3      [36m0.9871[0m        [32m0.0695[0m       [35m0.7898[0m      0.8748        0.2042        0.0000  78.5190
      4      0.9868        [32m0.0674[0m       [35m0.8005[0m      [31m0.8757[0m        [94m0.2020[0m     +  0.0000  78.7970
      5      [36m0.9877[0m        [32m0.0645[0m       0.7625      0.8672        0.2476        0.0000  82.0614
      6      [36m0.9890[0m        [32m0.0607[0m       [35m0.8016[0m      [31m0.8762[0m        [94m0.1994[0m     +  0.0000  78.5822
      7      [36m0.9897[0m        [32m0.0588[0m       0.7981      0.8747        0.2031        0.0000  78.9082
      8      [36m0.9905[0m        [32m0.0579[0m       0.7986      0.8748        0.2041        0.0000  78.7161
      9      0.9904        [32m0.0565[0m       0.7936      0.8734        0.2066        0.0000  78.6430
     10      [36m0.9911[0m        [32m0.0554[0m       0.7950      0.8731        0.2071        0.0000  78.6508
     11      [36m0.9914[0m        [32m0.0539[0m       0.8002      0.8761        0.2072        0.0000  79.2476
     12      [36m0.9917[0m        [32m0.0534[0m       0.7983      0.8746        0.2085        0.0000  78.7518
     13      [36m0.9920[0m        [32m0.0530[0m       [35m0.8021[0m      0.8750        0.2040        0.0000  78.6899
     14      [36m0.9922[0m        [32m0.0524[0m       0.7995      0.8751        0.2086        0.0000  78.6277
     15      [36m0.9924[0m        [32m0.0519[0m       0.7997      0.8747        0.2073        0.0000  78.5576
     16      [36m0.9924[0m        [32m0.0513[0m       [35m0.8049[0m      [31m0.8764[0m        0.2059        0.0000  78.5947
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 13 Test Accuracy: 0.8391
Iteration 13 Test F1 Score (micro): 0.9241
Iteration 13 Test F1 Score (macro): 0.9107
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\model_checkpoint_iteration_12.pt

Best F1 score across all iterations: 0.9149
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel_from_multiclass/DinoS/entropy_sampling_seed43_test\AL_margin_sampling_results_for_multilabel_classification_s43.pickle
