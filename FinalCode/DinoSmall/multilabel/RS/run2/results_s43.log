Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)

Iteration 1: Using initial samples.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2434[0m        [32m0.6979[0m       [35m0.2356[0m      [31m0.4635[0m        [94m0.6879[0m     +  0.0000  12.1192
      2      [36m0.8320[0m        [32m0.6229[0m       0.1953      0.4493        0.6886        0.0000  10.5661
      3      0.7460        0.6306       0.2273      0.4454        0.6916        0.0000  10.6153
      4      0.7054        0.6251       0.1556      0.4449        0.6932        0.0000  10.6810
      5      [36m0.8426[0m        [32m0.5746[0m       0.2014      [31m0.4773[0m        [94m0.6830[0m     +  0.0000  10.8793
      6      0.8426        [32m0.5676[0m       0.2083      0.4599        0.6870        0.0000  10.6646
      7      0.7963        [32m0.5644[0m       0.2033      0.4602        0.6952        0.0000  10.7644
      8      0.8333        [32m0.5369[0m       0.2113      0.4646        0.6927        0.0000  10.8077
      9      0.8320        [32m0.5339[0m       0.2056      0.4598        0.6932        0.0000  10.8757
     10      0.7857        [32m0.5283[0m       0.2073      0.4740        0.6929        0.0000  10.9656
     11      0.8130        0.5537       0.2066      0.4687        0.6947        0.0000  11.0311
     12      [36m0.9630[0m        [32m0.4794[0m       0.2083      0.4677        0.6938        0.0000  10.8907
     13      0.8796        0.4997       0.2122      0.4698        0.6929        0.0000  10.8746
     14      0.8889        0.5241       0.2115      0.4708        0.6932        0.0000  10.9233
     15      0.9167        0.4934       0.2125      0.4701        0.6944        0.0000  10.8127
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 1: Test F1 Micro Score: 0.4810321856812286
Iteration 1: Test F1 Macro Score: 0.47859102784285196
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_0.pt

Iteration 2: Requesting 16 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5695[0m        [32m0.5843[0m       [35m0.3568[0m      [31m0.2915[0m        [94m0.6605[0m     +  0.0000  10.9365
      2      0.3077        [32m0.5190[0m       [35m0.3576[0m      0.2797        0.6659        0.0000  10.8751
      3      0.3993        [32m0.4934[0m       [35m0.3960[0m      [31m0.3005[0m        0.6665        0.0000  10.9511
      4      0.5607        [32m0.4623[0m       [35m0.4389[0m      0.2961        0.6720        0.0000  11.0467
      5      0.4127        0.4646       0.4201      0.2453        0.6727        0.0000  10.9164
      6      0.4603        [32m0.4243[0m       0.4259      0.2478        0.6711        0.0000  11.0009
      7      0.3889        0.4450       0.4191      0.2428        0.6702        0.0000  11.0744
      8      0.4786        [32m0.4148[0m       0.4271      0.2422        0.6690        0.0000  11.1677
      9      [36m0.6834[0m        [32m0.4069[0m       0.4233      0.2324        0.6685        0.0000  10.7702
     10      [36m0.7188[0m        [32m0.3861[0m       0.4271      0.2372        0.6662        0.0000  11.0585
     11      0.5281        0.3893       0.4290      0.2352        0.6667        0.0000  10.9211
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 2: Test F1 Micro Score: 0.3468333133036895
Iteration 2: Test F1 Macro Score: 0.26802999163247615
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_1.pt

Iteration 3: Requesting 32 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6597[0m        [32m0.6248[0m       [35m0.4024[0m      [31m0.2207[0m        [94m0.6210[0m     +  0.0000  11.0312
      2      0.3412        [32m0.5555[0m       0.4016      [31m0.3202[0m        [94m0.6019[0m     +  0.0000  10.9212
      3      0.3142        [32m0.5323[0m       [35m0.4210[0m      [31m0.3504[0m        [94m0.5679[0m     +  0.0000  10.9480
      4      0.4583        [32m0.4980[0m       [35m0.4264[0m      [31m0.4223[0m        [94m0.5341[0m     +  0.0000  11.0672
      5      0.4648        [32m0.4615[0m       [35m0.5255[0m      [31m0.5639[0m        [94m0.5092[0m     +  0.0000  10.9565
      6      0.6302        [32m0.4369[0m       [35m0.5557[0m      0.5372        [94m0.4996[0m     +  0.0000  10.8761
      7      [36m0.6636[0m        [32m0.4082[0m       [35m0.5589[0m      0.5408        [94m0.4944[0m     +  0.0000  10.8960
      8      [36m0.6869[0m        0.4094       [35m0.5637[0m      [31m0.5772[0m        [94m0.4883[0m     +  0.0000  11.2443
      9      0.5855        [32m0.4000[0m       [35m0.5781[0m      [31m0.6027[0m        [94m0.4804[0m     +  0.0000  11.1153
     10      [36m0.6937[0m        [32m0.3898[0m       0.5729      0.5907        [94m0.4773[0m     +  0.0000  10.9253
     11      [36m0.7534[0m        [32m0.3775[0m       0.5766      0.5976        [94m0.4745[0m     +  0.0000  10.9932
     12      [36m0.7560[0m        [32m0.3747[0m       [35m0.5806[0m      [31m0.6081[0m        [94m0.4724[0m     +  0.0000  11.0459
     13      0.7474        0.3785       0.5793      [31m0.6100[0m        [94m0.4709[0m     +  0.0000  10.9801
     14      [36m0.7565[0m        [32m0.3675[0m       0.5799      0.6088        [94m0.4694[0m     +  0.0000  10.8940
     15      [36m0.7634[0m        0.3736       [35m0.5849[0m      [31m0.6183[0m        [94m0.4674[0m     +  0.0000  10.9290
     16      0.7282        0.3821       0.5826      0.6163        [94m0.4672[0m     +  0.0000  11.0255
     17      0.6961        [32m0.3640[0m       0.5849      [31m0.6215[0m        [94m0.4664[0m     +  0.0000  10.9640
     18      [36m0.7975[0m        0.3721       [35m0.5863[0m      [31m0.6241[0m        [94m0.4656[0m     +  0.0000  11.0256
     19      0.7908        [32m0.3604[0m       [35m0.5866[0m      [31m0.6252[0m        [94m0.4650[0m     +  0.0000  11.0474
     20      0.7975        0.3608       0.5863      [31m0.6262[0m        [94m0.4643[0m     +  0.0000  10.9482
     21      0.7395        0.3755       0.5865      0.6258        [94m0.4642[0m     +  0.0000  11.1564
     22      0.7288        [32m0.3601[0m       0.5866      [31m0.6263[0m        [94m0.4640[0m     +  0.0000  10.9064
     23      0.6774        0.3814       0.5865      [31m0.6263[0m        [94m0.4637[0m     +  0.0000  11.0182
     24      0.7332        0.3681       0.5865      [31m0.6265[0m        [94m0.4634[0m     +  0.0000  10.9934
     25      0.7727        0.3634       [35m0.5868[0m      [31m0.6279[0m        [94m0.4629[0m     +  0.0000  10.8485
     26      0.6352        0.3702       [35m0.5870[0m      [31m0.6280[0m        [94m0.4629[0m     +  0.0000  10.9843
     27      0.7801        0.3662       [35m0.5872[0m      [31m0.6283[0m        [94m0.4627[0m     +  0.0000  10.8811
     28      0.7975        [32m0.3557[0m       0.5868      0.6280        [94m0.4626[0m     +  0.0000  10.9330
     29      0.7961        0.3652       0.5868      0.6282        [94m0.4625[0m     +  0.0000  11.0724
     30      0.7816        0.3629       [35m0.5873[0m      [31m0.6287[0m        [94m0.4624[0m     +  0.0000  11.1816
     31      0.7236        0.3698       [35m0.5877[0m      [31m0.6289[0m        [94m0.4623[0m     +  0.0000  11.0207
     32      0.7491        0.3700       [35m0.5878[0m      [31m0.6290[0m        [94m0.4623[0m     +  0.0000  10.9330
     33      0.7395        0.3684       0.5878      [31m0.6293[0m        [94m0.4622[0m     +  0.0000  10.9389
     34      [36m0.8342[0m        0.3622       0.5870      0.6286        0.4622        0.0000  10.9690
     35      0.6560        0.3667       0.5873      0.6291        [94m0.4622[0m     +  0.0000  11.0357
     36      0.7534        0.3706       0.5873      0.6291        [94m0.4622[0m     +  0.0000  10.9022
     37      0.8268        0.3687       0.5873      0.6291        [94m0.4622[0m     +  0.0000  10.9584
     38      0.7888        0.3614       0.5873      0.6291        [94m0.4622[0m     +  0.0000  11.0880
     39      [36m0.8413[0m        [32m0.3556[0m       0.5872      0.6290        [94m0.4622[0m     +  0.0000  10.7541
     40      0.7619        0.3688       0.5872      0.6290        [94m0.4622[0m     +  0.0000  10.9470
     41      0.7215        0.3665       0.5872      0.6290        [94m0.4621[0m     +  0.0000  10.9218
     42      0.8257        [32m0.3553[0m       0.5872      0.6290        [94m0.4621[0m     +  0.0000  10.9691
     43      0.8167        0.3671       0.5872      0.6290        [94m0.4621[0m     +  0.0000  10.9993
     44      0.7973        0.3648       0.5872      0.6290        [94m0.4621[0m     +  0.0000  10.9339
     45      0.7043        0.3670       0.5872      0.6290        [94m0.4621[0m     +  0.0000  10.9357
     46      0.7875        0.3624       0.5872      0.6290        0.4621        0.0000  10.9581
     47      0.7804        0.3612       0.5872      0.6290        [94m0.4621[0m     +  0.0000  10.9735
     48      0.7406        0.3698       0.5872      0.6290        [94m0.4621[0m     +  0.0000  11.0153
     49      0.6868        0.3635       0.5873      0.6291        [94m0.4621[0m     +  0.0000  10.9316
     50      0.8117        0.3754       0.5873      0.6291        [94m0.4621[0m     +  0.0000  11.0464
     51      0.7931        0.3719       0.5873      0.6291        [94m0.4621[0m     +  0.0000  10.9220
     52      0.7804        0.3612       0.5873      0.6291        [94m0.4621[0m     +  0.0000  10.9374
     53      [36m0.8556[0m        0.3592       0.5873      0.6291        [94m0.4621[0m     +  0.0000  10.9655
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 3: Test F1 Micro Score: 0.7234612807504547
Iteration 3: Test F1 Macro Score: 0.6169831310417511
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_2.pt

Iteration 4: Requesting 56 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7068[0m        [32m0.4198[0m       [35m0.6312[0m      [31m0.6213[0m        [94m0.4032[0m     +  0.0000  11.3328
      2      [36m0.7321[0m        [32m0.3704[0m       [35m0.6451[0m      [31m0.6910[0m        [94m0.3812[0m     +  0.0000  11.2240
      3      [36m0.8678[0m        [32m0.3304[0m       [35m0.6538[0m      [31m0.7110[0m        [94m0.3688[0m     +  0.0000  11.2690
      4      0.8340        [32m0.3245[0m       [35m0.6800[0m      [31m0.7781[0m        [94m0.3582[0m     +  0.0000  11.2756
      5      0.8625        [32m0.3083[0m       [35m0.6844[0m      [31m0.8037[0m        [94m0.3528[0m     +  0.0000  11.2151
      6      [36m0.9191[0m        [32m0.2927[0m       0.6826      0.7992        [94m0.3475[0m     +  0.0000  11.1888
      7      0.9024        [32m0.2883[0m       [35m0.6859[0m      0.8030        [94m0.3448[0m     +  0.0000  11.2508
      8      [36m0.9226[0m        [32m0.2865[0m       0.6854      [31m0.8046[0m        [94m0.3428[0m     +  0.0000  11.3248
      9      0.9078        [32m0.2821[0m       [35m0.6880[0m      [31m0.8086[0m        [94m0.3405[0m     +  0.0000  11.2511
     10      [36m0.9621[0m        [32m0.2776[0m       [35m0.6901[0m      0.8083        [94m0.3394[0m     +  0.0000  11.1568
     11      0.9318        [32m0.2736[0m       0.6825      0.8016        0.3399        0.0000  11.1370
     12      0.9536        [32m0.2722[0m       0.6816      0.8007        0.3396        0.0000  11.1737
     13      0.9295        [32m0.2708[0m       0.6823      0.8019        [94m0.3383[0m     +  0.0000  11.2055
     14      0.9012        0.2735       0.6776      0.7948        0.3390        0.0000  11.2554
     15      0.9120        0.2782       0.6830      0.8022        [94m0.3373[0m     +  0.0000  11.2209
     16      0.9540        [32m0.2625[0m       0.6776      0.7955        0.3386        0.0000  11.0881
     17      0.9414        0.2712       0.6764      0.7941        0.3386        0.0000  11.3450
     18      0.9379        0.2772       0.6766      0.7949        0.3382        0.0000  11.2486
     19      0.9340        0.2696       0.6781      0.7965        0.3378        0.0000  11.2112
     20      0.9485        0.2649       0.6738      0.7914        0.3384        0.0000  11.2143
     21      0.9495        0.2649       0.6734      0.7910        0.3385        0.0000  11.2227
     22      0.9107        0.2690       0.6733      0.7912        0.3383        0.0000  11.1920
     23      0.9409        0.2686       0.6736      0.7916        0.3381        0.0000  11.2165
     24      0.9360        0.2640       0.6734      0.7899        0.3387        0.0000  11.3136
     25      0.9510        0.2705       0.6729      0.7904        0.3384        0.0000  11.2168
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 4: Test F1 Micro Score: 0.8598657495649291
Iteration 4: Test F1 Macro Score: 0.8336513765249642
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_3.pt

Iteration 5: Requesting 96 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8275[0m        [32m0.3131[0m       [35m0.6809[0m      [31m0.7773[0m        [94m0.3317[0m     +  0.0000  11.5772
      2      [36m0.8695[0m        [32m0.2838[0m       0.6797      0.7700        [94m0.3224[0m     +  0.0000  11.4702
      3      [36m0.9162[0m        [32m0.2704[0m       [35m0.6927[0m      [31m0.7838[0m        [94m0.3166[0m     +  0.0000  11.5812
      4      0.8965        [32m0.2646[0m       0.6894      0.7805        [94m0.3142[0m     +  0.0000  11.4687
      5      0.9087        [32m0.2510[0m       0.6896      0.7832        [94m0.3114[0m     +  0.0000  11.5788
      6      0.9095        0.2514       0.6905      [31m0.7881[0m        [94m0.3068[0m     +  0.0000  11.8128
      7      [36m0.9162[0m        [32m0.2459[0m       [35m0.6967[0m      [31m0.7990[0m        [94m0.3049[0m     +  0.0000  11.5155
      8      [36m0.9452[0m        [32m0.2434[0m       [35m0.6969[0m      0.7936        0.3052        0.0000  11.5935
      9      0.9311        [32m0.2379[0m       0.6965      0.7943        [94m0.3042[0m     +  0.0000  11.4844
     10      0.9396        [32m0.2361[0m       [35m0.7050[0m      [31m0.8041[0m        [94m0.3006[0m     +  0.0000  11.5931
     11      [36m0.9460[0m        [32m0.2326[0m       0.7021      [31m0.8048[0m        [94m0.3004[0m     +  0.0000  11.4888
     12      [36m0.9536[0m        [32m0.2278[0m       0.6997      0.7968        0.3018        0.0000  11.4537
     13      0.9483        0.2307       0.7016      0.8000        0.3005        0.0000  11.5298
     14      0.9535        0.2279       0.7033      0.8045        [94m0.2994[0m     +  0.0000  11.6012
     15      0.9495        [32m0.2273[0m       0.6998      0.8007        0.3003        0.0000  11.3993
     16      0.9528        [32m0.2261[0m       0.7003      0.8023        0.2995        0.0000  11.4813
     17      0.9462        0.2293       0.6995      0.7992        0.3001        0.0000  11.4226
     18      0.9505        [32m0.2208[0m       0.7017      0.8032        [94m0.2989[0m     +  0.0000  11.5121
     19      0.9495        0.2301       0.7010      0.8018        0.2991        0.0000  11.5324
     20      [36m0.9558[0m        0.2224       0.7012      0.8007        [94m0.2989[0m     +  0.0000  11.5158
     21      [36m0.9577[0m        0.2229       0.7014      0.8015        [94m0.2987[0m     +  0.0000  11.4981
     22      0.9533        [32m0.2200[0m       0.7021      0.8025        [94m0.2985[0m     +  0.0000  11.5429
     23      0.9509        0.2251       0.7010      0.8015        0.2986        0.0000  11.7188
     24      0.9555        0.2229       0.7005      0.8009        0.2986        0.0000  11.4603
     25      0.9439        0.2243       0.7023      0.8033        [94m0.2982[0m     +  0.0000  11.3666
     26      0.9573        0.2217       0.7016      0.8025        0.2983        0.0000  11.6440
     27      0.9519        0.2201       0.7017      0.8022        0.2984        0.0000  11.4876
     28      0.9524        0.2252       0.7012      0.8021        0.2983        0.0000  11.5488
     29      0.9577        [32m0.2180[0m       0.7014      0.8021        0.2984        0.0000  11.4554
     30      0.9454        0.2246       0.7009      0.8016        0.2984        0.0000  11.5348
     31      0.9536        0.2226       0.7014      0.8021        0.2984        0.0000  11.5921
     32      [36m0.9582[0m        0.2211       0.7007      0.8013        0.2984        0.0000  11.6086
     33      [36m0.9603[0m        0.2217       0.6998      0.8003        0.2985        0.0000  11.7283
     34      0.9580        0.2231       0.7007      0.8012        0.2984        0.0000  11.7288
     35      0.9417        0.2260       0.6997      0.8001        0.2985        0.0000  11.3061
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 5: Test F1 Micro Score: 0.8713229252259654
Iteration 5: Test F1 Macro Score: 0.8404808835551373
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_4.pt

Iteration 6: Requesting 176 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8997[0m        [32m0.2516[0m       [35m0.7156[0m      [31m0.8307[0m        [94m0.2774[0m     +  0.0000  12.3012
      2      [36m0.9222[0m        [32m0.2277[0m       [35m0.7276[0m      [31m0.8313[0m        [94m0.2686[0m     +  0.0000  12.2349
      3      [36m0.9346[0m        [32m0.2177[0m       [35m0.7332[0m      [31m0.8364[0m        [94m0.2635[0m     +  0.0000  12.2504
      4      [36m0.9417[0m        [32m0.2076[0m       [35m0.7413[0m      0.8319        [94m0.2630[0m     +  0.0000  12.2557
      5      [36m0.9496[0m        [32m0.2005[0m       [35m0.7420[0m      0.8362        [94m0.2593[0m     +  0.0000  12.2711
      6      [36m0.9564[0m        [32m0.1886[0m       [35m0.7634[0m      [31m0.8613[0m        [94m0.2514[0m     +  0.0000  12.5640
      7      [36m0.9577[0m        0.1908       [35m0.7644[0m      0.8588        0.2520        0.0000  12.3256
      8      0.9533        0.1887       0.7642      0.8560        0.2516        0.0000  12.2842
      9      [36m0.9689[0m        [32m0.1807[0m       0.7625      0.8547        0.2523        0.0000  12.2951
     10      0.9647        [32m0.1799[0m       0.7635      0.8547        0.2517        0.0000  12.2786
     11      [36m0.9733[0m        [32m0.1790[0m       [35m0.7686[0m      [31m0.8649[0m        [94m0.2474[0m     +  0.0000  12.2344
     12      0.9677        [32m0.1732[0m       [35m0.7698[0m      0.8648        0.2477        0.0000  12.2705
     13      0.9678        0.1741       [35m0.7710[0m      [31m0.8657[0m        [94m0.2469[0m     +  0.0000  12.2532
     14      0.9720        0.1743       0.7708      [31m0.8664[0m        [94m0.2464[0m     +  0.0000  12.2322
     15      0.9729        0.1738       [35m0.7714[0m      [31m0.8675[0m        [94m0.2458[0m     +  0.0000  12.2854
     16      0.9727        [32m0.1698[0m       [35m0.7717[0m      [31m0.8683[0m        [94m0.2450[0m     +  0.0000  12.2185
     17      [36m0.9802[0m        [32m0.1684[0m       [35m0.7727[0m      0.8680        0.2454        0.0000  12.2039
     18      0.9792        0.1718       0.7720      0.8681        [94m0.2450[0m     +  0.0000  12.2519
     19      [36m0.9809[0m        [32m0.1682[0m       [35m0.7729[0m      [31m0.8691[0m        [94m0.2448[0m     +  0.0000  12.2054
     20      0.9760        0.1757       0.7729      0.8683        0.2449        0.0000  12.2318
     21      0.9807        [32m0.1680[0m       [35m0.7731[0m      0.8684        0.2448        0.0000  12.2668
     22      0.9778        0.1704       0.7727      0.8677        0.2449        0.0000  12.3909
     23      0.9802        [32m0.1669[0m       0.7731      0.8679        0.2450        0.0000  12.2160
     24      0.9783        0.1685       [35m0.7733[0m      0.8681        [94m0.2447[0m     +  0.0000  12.2812
     25      0.9779        [32m0.1660[0m       0.7733      0.8678        0.2447        0.0000  12.3456
     26      0.9720        0.1701       [35m0.7736[0m      0.8679        [94m0.2446[0m     +  0.0000  12.2963
     27      [36m0.9822[0m        0.1682       0.7734      0.8678        0.2447        0.0000  12.2778
     28      0.9782        0.1725       0.7734      0.8678        0.2447        0.0000  12.2407
     29      [36m0.9829[0m        0.1698       0.7731      0.8676        0.2447        0.0000  12.3415
     30      0.9811        0.1695       0.7734      0.8678        [94m0.2446[0m     +  0.0000  12.2504
     31      0.9799        0.1709       0.7733      0.8678        0.2447        0.0000  12.2049
     32      [36m0.9832[0m        0.1678       0.7731      0.8677        0.2447        0.0000  12.2104
     33      0.9832        [32m0.1658[0m       0.7733      0.8678        0.2446        0.0000  12.3643
     34      0.9770        0.1685       0.7733      0.8678        0.2447        0.0000  12.2385
     35      0.9824        0.1675       0.7731      0.8675        0.2447        0.0000  12.2485
     36      0.9790        0.1698       0.7731      0.8675        0.2447        0.0000  12.2372
     37      0.9801        0.1687       0.7731      0.8675        0.2447        0.0000  12.3024
     38      0.9772        0.1700       0.7731      0.8675        0.2447        0.0000  12.3279
     39      0.9749        0.1682       0.7729      0.8674        0.2447        0.0000  12.3312
     40      0.9790        0.1694       0.7729      0.8673        0.2447        0.0000  12.2820
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 6: Test F1 Micro Score: 0.8907082107940545
Iteration 6: Test F1 Macro Score: 0.8683028841935009
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_5.pt

Iteration 7: Requesting 320 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9297[0m        [32m0.2027[0m       [35m0.7740[0m      [31m0.8851[0m        [94m0.2458[0m     +  0.0000  13.5614
      2      [36m0.9411[0m        [32m0.1834[0m       [35m0.7785[0m      0.8833        [94m0.2366[0m     +  0.0000  13.5474
      3      [36m0.9577[0m        [32m0.1733[0m       0.7785      0.8790        [94m0.2315[0m     +  0.0000  13.4512
      4      [36m0.9641[0m        [32m0.1669[0m       0.7767      0.8794        [94m0.2310[0m     +  0.0000  13.4689
      5      [36m0.9744[0m        [32m0.1593[0m       0.7689      0.8738        [94m0.2287[0m     +  0.0000  13.4387
      6      [36m0.9760[0m        [32m0.1535[0m       0.7759      0.8683        [94m0.2275[0m     +  0.0000  13.4684
      7      [36m0.9800[0m        [32m0.1495[0m       0.7762      0.8680        0.2297        0.0000  13.4614
      8      [36m0.9807[0m        0.1500       0.7771      0.8663        [94m0.2272[0m     +  0.0000  13.7405
      9      [36m0.9832[0m        [32m0.1428[0m       0.7771      0.8664        [94m0.2265[0m     +  0.0000  13.4851
     10      0.9802        [32m0.1411[0m       0.7783      0.8663        [94m0.2263[0m     +  0.0000  13.5316
     11      0.9826        [32m0.1379[0m       [35m0.7837[0m      0.8723        [94m0.2248[0m     +  0.0000  13.6402
     12      [36m0.9846[0m        0.1386       0.7823      0.8704        0.2256        0.0000  13.5655
     13      [36m0.9856[0m        [32m0.1366[0m       [35m0.7842[0m      0.8723        [94m0.2238[0m     +  0.0000  13.4867
     14      0.9834        [32m0.1338[0m       0.7840      0.8714        0.2243        0.0000  13.4606
     15      0.9856        0.1354       0.7828      0.8714        0.2251        0.0000  13.4230
     16      0.9852        0.1377       [35m0.7872[0m      0.8759        [94m0.2231[0m     +  0.0000  13.6101
     17      [36m0.9866[0m        [32m0.1317[0m       [35m0.7875[0m      0.8758        [94m0.2225[0m     +  0.0000  13.3968
     18      0.9852        0.1338       [35m0.7892[0m      0.8770        [94m0.2223[0m     +  0.0000  13.4154
     19      0.9834        0.1317       0.7870      0.8734        0.2226        0.0000  13.5415
     20      0.9856        0.1320       0.7885      0.8779        [94m0.2221[0m     +  0.0000  13.4373
     21      0.9856        0.1329       [35m0.7903[0m      0.8784        [94m0.2219[0m     +  0.0000  13.6581
     22      0.9851        0.1330       [35m0.7905[0m      0.8784        0.2220        0.0000  13.4999
     23      0.9864        0.1324       0.7899      0.8780        [94m0.2219[0m     +  0.0000  13.6696
     24      0.9852        0.1356       0.7903      0.8782        0.2220        0.0000  13.5775
     25      [36m0.9872[0m        [32m0.1316[0m       0.7901      0.8781        [94m0.2219[0m     +  0.0000  13.6096
     26      [36m0.9873[0m        0.1330       0.7905      0.8780        [94m0.2218[0m     +  0.0000  13.4712
     27      0.9871        0.1328       [35m0.7908[0m      0.8780        [94m0.2217[0m     +  0.0000  13.4817
     28      0.9873        [32m0.1294[0m       0.7908      0.8780        [94m0.2216[0m     +  0.0000  13.5161
     29      0.9856        0.1297       [35m0.7911[0m      0.8786        [94m0.2215[0m     +  0.0000  13.4233
     30      0.9865        0.1303       0.7911      0.8787        [94m0.2215[0m     +  0.0000  13.4188
     31      [36m0.9884[0m        0.1310       0.7910      0.8786        [94m0.2215[0m     +  0.0000  13.6088
     32      0.9850        0.1328       0.7910      0.8786        [94m0.2214[0m     +  0.0000  13.5159
     33      0.9867        0.1321       0.7911      0.8787        [94m0.2214[0m     +  0.0000  13.6538
     34      0.9860        0.1330       0.7910      0.8784        [94m0.2214[0m     +  0.0000  13.6121
     35      0.9860        0.1311       0.7910      0.8784        [94m0.2214[0m     +  0.0000  13.4830
     36      0.9884        [32m0.1294[0m       0.7908      0.8783        0.2214        0.0000  13.5373
     37      0.9833        0.1334       0.7910      0.8783        0.2214        0.0000  13.4653
     38      0.9849        0.1331       0.7910      0.8784        0.2214        0.0000  13.6092
     39      0.9865        0.1317       0.7910      0.8783        0.2214        0.0000  13.5502
     40      0.9844        0.1327       0.7911      0.8784        0.2214        0.0000  13.5754
     41      0.9856        0.1305       0.7911      0.8784        0.2214        0.0000  13.6458
     42      0.9878        0.1311       0.7911      0.8785        0.2214        0.0000  13.4540
     43      0.9850        0.1315       0.7911      0.8784        0.2214        0.0000  13.4282
     44      0.9855        0.1334       0.7911      0.8785        0.2214        0.0000  13.5297
     45      0.9845        0.1321       0.7908      0.8783        0.2214        0.0000  13.5447
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 7: Test F1 Micro Score: 0.9028695855043161
Iteration 7: Test F1 Macro Score: 0.8865007062122903
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_6.pt

Iteration 8: Requesting 560 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9479[0m        [32m0.1651[0m       [35m0.7865[0m      [31m0.8653[0m        [94m0.2173[0m     +  0.0000  15.7358
      2      [36m0.9642[0m        [32m0.1516[0m       [35m0.7997[0m      [31m0.8697[0m        [94m0.2127[0m     +  0.0000  15.5957
      3      [36m0.9698[0m        [32m0.1416[0m       [35m0.8003[0m      0.8696        [94m0.2113[0m     +  0.0000  15.7174
      4      [36m0.9722[0m        [32m0.1341[0m       [35m0.8153[0m      [31m0.8734[0m        [94m0.2104[0m     +  0.0000  15.6699
      5      [36m0.9765[0m        [32m0.1286[0m       0.8026      0.8527        0.2209        0.0000  15.7760
      6      [36m0.9818[0m        [32m0.1211[0m       0.8094      [31m0.8815[0m        [94m0.2034[0m     +  0.0000  15.7272
      7      0.9818        [32m0.1156[0m       0.8106      0.8814        [94m0.2028[0m     +  0.0000  15.9218
      8      [36m0.9838[0m        [32m0.1141[0m       0.8134      [31m0.8834[0m        [94m0.2025[0m     +  0.0000  15.7969
      9      [36m0.9847[0m        [32m0.1109[0m       0.8125      0.8807        [94m0.2024[0m     +  0.0000  15.5949
     10      [36m0.9861[0m        [32m0.1093[0m       0.8106      [31m0.8843[0m        0.2026        0.0000  15.7122
     11      [36m0.9871[0m        [32m0.1059[0m       0.8135      [31m0.8873[0m        [94m0.2016[0m     +  0.0000  15.7796
     12      [36m0.9887[0m        [32m0.1048[0m       0.8132      [31m0.8887[0m        [94m0.2015[0m     +  0.0000  15.7225
     13      0.9877        0.1061       0.8135      [31m0.8888[0m        0.2015        0.0000  15.7966
     14      [36m0.9894[0m        0.1050       0.8125      0.8853        [94m0.2008[0m     +  0.0000  15.7500
     15      0.9879        [32m0.1026[0m       0.8130      0.8886        0.2014        0.0000  15.7030
     16      [36m0.9896[0m        [32m0.1014[0m       0.8125      0.8884        0.2009        0.0000  15.7179
     17      [36m0.9897[0m        [32m0.1003[0m       0.8127      0.8878        [94m0.2000[0m     +  0.0000  15.7189
     18      0.9887        0.1007       0.8134      0.8885        0.2000        0.0000  15.4503
     19      [36m0.9904[0m        0.1016       0.8130      [31m0.8891[0m        0.2004        0.0000  15.0677
     20      0.9889        0.1017       0.8127      0.8886        0.2002        0.0000  15.1723
     21      0.9896        0.1019       0.8115      0.8871        [94m0.1997[0m     +  0.0000  15.1120
     22      0.9902        0.1008       0.8118      0.8879        0.2000        0.0000  15.1237
     23      [36m0.9907[0m        0.1010       0.8134      [31m0.8891[0m        0.2001        0.0000  15.1077
     24      0.9907        0.1011       0.8128      0.8888        0.1997        0.0000  15.1228
     25      0.9900        [32m0.0994[0m       0.8132      0.8889        [94m0.1997[0m     +  0.0000  15.1392
     26      0.9897        0.1002       0.8115      0.8865        [94m0.1990[0m     +  0.0000  14.9839
     27      0.9903        [32m0.0989[0m       0.8115      0.8864        [94m0.1989[0m     +  0.0000  15.0302
     28      0.9907        [32m0.0985[0m       0.8115      0.8865        0.1990        0.0000  15.1221
     29      [36m0.9908[0m        0.1011       0.8111      0.8861        [94m0.1988[0m     +  0.0000  15.0462
     30      0.9901        0.0993       0.8113      0.8865        0.1989        0.0000  14.9841
     31      [36m0.9909[0m        0.1001       0.8120      0.8861        [94m0.1986[0m     +  0.0000  14.9729
     32      0.9904        0.1012       0.8123      0.8863        [94m0.1986[0m     +  0.0000  14.8897
     33      0.9904        0.0993       0.8123      0.8862        [94m0.1985[0m     +  0.0000  15.1093
     34      0.9898        0.1001       0.8120      0.8860        0.1986        0.0000  14.9902
     35      [36m0.9910[0m        0.0990       0.8118      0.8861        0.1986        0.0000  15.0938
     36      0.9906        0.0990       0.8125      0.8862        [94m0.1985[0m     +  0.0000  14.9519
     37      0.9898        0.1002       0.8125      0.8862        [94m0.1985[0m     +  0.0000  15.0682
     38      0.9904        0.0995       0.8125      0.8861        [94m0.1985[0m     +  0.0000  15.0593
     39      0.9894        0.0995       0.8123      0.8859        [94m0.1984[0m     +  0.0000  15.1341
     40      [36m0.9912[0m        [32m0.0983[0m       0.8120      0.8859        [94m0.1984[0m     +  0.0000  14.9288
     41      0.9912        [32m0.0979[0m       0.8122      0.8858        0.1984        0.0000  15.1634
     42      0.9901        0.1002       0.8123      0.8859        0.1984        0.0000  15.1185
     43      0.9912        0.0994       0.8123      0.8859        0.1984        0.0000  15.0781
     44      0.9903        0.1001       0.8123      0.8859        0.1984        0.0000  15.0598
     45      0.9897        0.0987       0.8123      0.8859        0.1984        0.0000  15.1055
     46      0.9909        0.0985       0.8123      0.8859        0.1984        0.0000  15.1268
     47      0.9904        0.0994       0.8123      0.8859        0.1984        0.0000  15.1683
     48      0.9905        0.0991       0.8123      0.8859        0.1984        0.0000  15.0901
     49      0.9912        0.0987       0.8123      0.8859        0.1984        0.0000  15.1364
     50      0.9909        0.1005       0.8125      0.8860        0.1984        0.0000  15.0157
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 8: Test F1 Micro Score: 0.9179822872545245
Iteration 8: Test F1 Macro Score: 0.9055186762394848
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_7.pt

Iteration 9: Requesting 1000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9592[0m        [32m0.1256[0m       [35m0.8149[0m      [31m0.8886[0m        [94m0.1891[0m     +  0.0000  18.9371
      2      [36m0.9734[0m        [32m0.1082[0m       [35m0.8212[0m      0.8884        [94m0.1844[0m     +  0.0000  18.8861
      3      [36m0.9808[0m        [32m0.1008[0m       0.8165      [31m0.8952[0m        0.1878        0.0000  18.7783
      4      [36m0.9824[0m        [32m0.0944[0m       0.8201      0.8944        [94m0.1833[0m     +  0.0000  18.8793
      5      [36m0.9846[0m        [32m0.0887[0m       0.8144      0.8928        0.1855        0.0000  19.0108
      6      [36m0.9899[0m        [32m0.0809[0m       0.8174      0.8916        0.1847        0.0000  19.2788
      7      [36m0.9904[0m        [32m0.0785[0m       0.8191      0.8912        0.1843        0.0000  19.3212
      8      [36m0.9921[0m        [32m0.0750[0m       [35m0.8224[0m      0.8917        0.1836        0.0000  19.2163
      9      [36m0.9933[0m        [32m0.0731[0m       0.8198      0.8894        0.1848        0.0000  19.2603
     10      [36m0.9945[0m        [32m0.0696[0m       0.8219      0.8863        0.1841        0.0000  19.3042
     11      [36m0.9948[0m        [32m0.0690[0m       [35m0.8243[0m      0.8870        [94m0.1808[0m     +  0.0000  19.4477
     12      [36m0.9948[0m        [32m0.0671[0m       0.8214      0.8873        0.1812        0.0000  19.2490
     13      [36m0.9952[0m        [32m0.0664[0m       0.8222      0.8871        [94m0.1805[0m     +  0.0000  19.2805
     14      [36m0.9956[0m        [32m0.0655[0m       0.8220      0.8870        0.1817        0.0000  19.2499
     15      0.9953        [32m0.0646[0m       [35m0.8247[0m      0.8875        0.1820        0.0000  19.2507
     16      [36m0.9962[0m        [32m0.0640[0m       [35m0.8283[0m      0.8890        [94m0.1799[0m     +  0.0000  19.2371
     17      [36m0.9967[0m        0.0643       0.8278      0.8900        0.1801        0.0000  19.1255
     18      0.9964        [32m0.0633[0m       0.8280      0.8881        0.1805        0.0000  19.2267
     19      0.9959        [32m0.0625[0m       0.8274      0.8896        0.1805        0.0000  19.0318
     20      0.9964        0.0626       0.8274      0.8891        0.1804        0.0000  19.0828
     21      [36m0.9968[0m        [32m0.0621[0m       0.8278      0.8903        0.1800        0.0000  19.2319
     22      0.9964        [32m0.0619[0m       0.8260      0.8902        0.1803        0.0000  19.0868
     23      0.9965        0.0624       0.8271      0.8908        0.1802        0.0000  19.0626
     24      0.9964        0.0624       0.8274      0.8906        0.1803        0.0000  19.1042
     25      0.9964        0.0623       0.8271      0.8906        0.1805        0.0000  19.1458
     26      [36m0.9969[0m        0.0622       0.8260      0.8909        0.1806        0.0000  19.1553
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 9: Test F1 Micro Score: 0.9153353399706722
Iteration 9: Test F1 Macro Score: 0.8988800674547089
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_8.pt

Iteration 10: Requesting 1776 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9720[0m        [32m0.0894[0m       [35m0.8358[0m      [31m0.8873[0m        [94m0.1734[0m     +  0.0000  26.3421
      2      [36m0.9792[0m        [32m0.0782[0m       [35m0.8378[0m      [31m0.8874[0m        [94m0.1701[0m     +  0.0000  26.3372
      3      [36m0.9823[0m        [32m0.0725[0m       [35m0.8464[0m      [31m0.8993[0m        [94m0.1622[0m     +  0.0000  26.4807
      4      [36m0.9829[0m        [32m0.0673[0m       0.8401      0.8900        0.1697        0.0000  26.5572
      5      [36m0.9869[0m        [32m0.0618[0m       0.8295      0.8840        0.1705        0.0000  26.6567
      6      [36m0.9900[0m        [32m0.0539[0m       0.8351      0.8895        0.1697        0.0000  26.6303
      7      [36m0.9920[0m        [32m0.0507[0m       0.8323      0.8863        0.1728        0.0000  26.4870
      8      [36m0.9926[0m        [32m0.0485[0m       0.8293      0.8829        0.1769        0.0000  26.5103
      9      [36m0.9938[0m        [32m0.0466[0m       0.8405      0.8933        0.1713        0.0000  26.4552
     10      0.9934        [32m0.0449[0m       0.8385      0.8902        0.1709        0.0000  26.5226
     11      [36m0.9948[0m        [32m0.0431[0m       0.8389      0.8917        0.1735        0.0000  26.3444
     12      [36m0.9955[0m        [32m0.0417[0m       0.8411      0.8926        0.1731        0.0000  26.5138
     13      [36m0.9960[0m        [32m0.0406[0m       0.8399      0.8934        0.1729        0.0000  26.4834
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 10: Test F1 Micro Score: 0.9209302325581394
Iteration 10: Test F1 Macro Score: 0.9058377148507125
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_9.pt

Iteration 11: Requesting 3160 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9729[0m        [32m0.0782[0m       [35m0.8207[0m      [31m0.9008[0m        [94m0.1715[0m     +  0.0000  38.7945
      2      [36m0.9772[0m        [32m0.0686[0m       [35m0.8434[0m      [31m0.9074[0m        [94m0.1561[0m     +  0.0000  38.8959
      3      [36m0.9789[0m        [32m0.0627[0m       0.8325      0.9037        0.1578        0.0000  38.8635
      4      [36m0.9833[0m        [32m0.0546[0m       0.8307      0.8935        0.1564        0.0000  38.7090
      5      [36m0.9843[0m        [32m0.0497[0m       0.8276      0.8992        0.1679        0.0000  38.7149
      6      [36m0.9872[0m        [32m0.0446[0m       0.8361      0.9032        0.1725        0.0000  39.0106
      7      [36m0.9900[0m        [32m0.0412[0m       0.8273      0.8993        0.1811        0.0000  38.9105
      8      [36m0.9916[0m        [32m0.0383[0m       0.8319      0.9008        0.1779        0.0000  38.5002
      9      [36m0.9921[0m        [32m0.0359[0m       0.8377      0.9040        0.1732        0.0000  38.7660
     10      [36m0.9923[0m        [32m0.0344[0m       0.8365      0.9009        0.1776        0.0000  38.7339
     11      [36m0.9940[0m        [32m0.0321[0m       0.8405      0.9032        0.1770        0.0000  38.9437
     12      [36m0.9948[0m        [32m0.0303[0m       [35m0.8464[0m      0.9054        0.1742        0.0000  38.7313
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 11: Test F1 Micro Score: 0.9223069223069222
Iteration 11: Test F1 Macro Score: 0.9114152507130605
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_10.pt

Iteration 12: Requesting 5624 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9733[0m        [32m0.0708[0m       [35m0.8556[0m      [31m0.9006[0m        [94m0.1480[0m     +  0.0000  60.1561
      2      [36m0.9774[0m        [32m0.0612[0m       0.8542      0.8976        0.1543        0.0000  60.4406
      3      [36m0.9801[0m        [32m0.0545[0m       0.8545      0.8964        0.1518        0.0000  60.4811
      4      [36m0.9825[0m        [32m0.0489[0m       0.8554      [31m0.9028[0m        0.1492        0.0000  60.3623
      5      [36m0.9843[0m        [32m0.0448[0m       [35m0.8575[0m      0.9027        0.1485        0.0000  60.6973
      6      [36m0.9861[0m        [32m0.0384[0m       0.8512      0.8948        0.1524        0.0000  60.7336
      7      [36m0.9895[0m        [32m0.0349[0m       0.8521      0.9005        0.1492        0.0000  60.8888
      8      [36m0.9903[0m        [32m0.0324[0m       0.8531      0.8998        [94m0.1479[0m     +  0.0000  60.5107
      9      [36m0.9907[0m        [32m0.0307[0m       0.8500      0.8995        0.1587        0.0000  60.8224
     10      [36m0.9924[0m        [32m0.0279[0m       [35m0.8592[0m      [31m0.9076[0m        0.1497        0.0000  60.4572
     11      [36m0.9935[0m        [32m0.0256[0m       0.8568      0.9063        0.1583        0.0000  60.6550
     12      [36m0.9944[0m        [32m0.0246[0m       0.8575      0.9062        0.1610        0.0000  60.6445
     13      [36m0.9949[0m        [32m0.0232[0m       0.8575      0.9071        0.1642        0.0000  60.7964
     14      [36m0.9953[0m        [32m0.0224[0m       0.8562      0.9072        0.1687        0.0000  60.6710
     15      [36m0.9958[0m        [32m0.0213[0m       0.8524      0.9036        0.1712        0.0000  60.5364
     16      0.9956        [32m0.0210[0m       0.8484      0.9037        0.1792        0.0000  60.3316
     17      [36m0.9958[0m        [32m0.0202[0m       0.8502      0.9051        0.1807        0.0000  60.5458
     18      [36m0.9964[0m        [32m0.0197[0m       0.8512      0.9053        0.1802        0.0000  60.6448
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 12: Test F1 Micro Score: 0.9287150146899645
Iteration 12: Test F1 Macro Score: 0.9168756255791667
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_11.pt

Iteration 13: Requesting 10000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9808[0m        [32m0.0448[0m       [35m0.8755[0m      [31m0.9200[0m        [94m0.1384[0m     +  0.0000  98.7021
      2      [36m0.9822[0m        [32m0.0400[0m       0.8656      0.9157        0.1525        0.0000  99.5575
      3      [36m0.9848[0m        [32m0.0350[0m       0.8682      0.9185        0.1439        0.0000  100.1091
      4      [36m0.9858[0m        [32m0.0322[0m       0.8698      0.9189        0.1522        0.0000  99.4175
      5      [36m0.9879[0m        [32m0.0287[0m       0.8661      0.9136        0.1679        0.0000  99.5341
      6      [36m0.9908[0m        [32m0.0231[0m       0.8592      0.9086        0.1745        0.0000  99.5341
      7      [36m0.9924[0m        [32m0.0205[0m       0.8592      0.9110        0.1778        0.0000  100.0797
      8      [36m0.9939[0m        [32m0.0184[0m       0.8543      0.9086        0.1896        0.0000  99.5556
      9      [36m0.9948[0m        [32m0.0163[0m       0.8528      0.9093        0.1930        0.0000  98.9845
     10      [36m0.9951[0m        [32m0.0154[0m       0.8644      0.9097        0.1947        0.0000  99.3292
     11      [36m0.9956[0m        [32m0.0140[0m       0.8557      0.9059        0.2051        0.0000  99.2657
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 13: Test F1 Micro Score: 0.9274844720496894
Iteration 13: Test F1 Macro Score: 0.9147072686596612
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_12.pt

Iteration 14: Requesting all remaining samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9807[0m        [32m0.0418[0m       [35m0.8670[0m      [31m0.9108[0m        [94m0.1516[0m     +  0.0000  114.7750
      2      [36m0.9831[0m        [32m0.0370[0m       0.8575      0.9037        0.1621        0.0000  115.7169
      3      [36m0.9846[0m        [32m0.0334[0m       0.8554      [31m0.9115[0m        0.1622        0.0000  114.8123
      4      [36m0.9860[0m        [32m0.0304[0m       0.8641      [31m0.9127[0m        0.1652        0.0000  115.4507
      5      [36m0.9870[0m        [32m0.0284[0m       0.8448      0.9048        0.1852        0.0000  115.4280
      6      [36m0.9907[0m        [32m0.0222[0m       0.8476      0.9061        0.1817        0.0000  115.9147
      7      [36m0.9926[0m        [32m0.0191[0m       0.8410      0.9033        0.2026        0.0000  115.2062
      8      [36m0.9937[0m        [32m0.0174[0m       0.8425      0.9057        0.2064        0.0000  115.1585
      9      [36m0.9945[0m        [32m0.0154[0m       0.8424      0.9017        0.2126        0.0000  115.6422
     10      [36m0.9952[0m        [32m0.0139[0m       0.8380      0.9031        0.2249        0.0000  114.7666
     11      [36m0.9961[0m        [32m0.0127[0m       0.8457      0.9048        0.2204        0.0000  115.2489
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 14: Test F1 Micro Score: 0.9287480680061824
Iteration 14: Test F1 Macro Score: 0.9183193299859886
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR/model_checkpoint_iteration_13.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_43_config2_lowLR\random_sampling_results_for_multilabel_classification_s43.pickle
