Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2434[0m        [32m0.6979[0m       [35m0.1743[0m      [31m0.4814[0m        [94m0.6974[0m     +  0.0001  12.0357
      2      [36m0.8320[0m        [32m0.6060[0m       0.1276      0.4306        0.7038        0.0001  10.1257
      3      0.7667        0.6264       0.1323      0.4351        0.7086        0.0001  10.4880
      4      0.5985        0.6300       [35m0.2733[0m      0.4432        [94m0.6808[0m     +  0.0001  10.3385
      5      0.7368        [32m0.5420[0m       0.2479      0.4483        0.6907        0.0001  10.4890
      6      0.7963        0.5478       0.2483      0.4404        0.6928        0.0000  10.2862
      7      0.6905        0.5752       0.2500      0.4425        0.6925        0.0000  10.5367
      8      0.7857        0.5549       0.2576      0.4437        0.6927        0.0000  10.3024
      9      0.7222        0.5526       0.2585      0.4446        0.6912        0.0000  10.5452
     10      0.7500        0.5567       0.2540      0.4484        0.6946        0.0000  10.5351
     11      0.6111        0.5854       0.2481      0.4463        0.6956        0.0000  10.5622
     12      [36m0.8690[0m        [32m0.4682[0m       0.2500      0.4457        0.6959        0.0000  10.4205
     13      0.8333        0.5104       0.2587      0.4473        0.6939        0.0000  10.4755
     14      0.6111        0.5341       0.2528      0.4475        0.6950        0.0000  10.4518
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4688
Pre F1 macro score = 0.4682
Pre Accuracy = 0.2630

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7316[0m        [32m0.5854[0m       [35m0.1023[0m      [31m0.4625[0m        [94m0.7240[0m     +  0.0001  10.6256
      2      0.6890        [32m0.5678[0m       [35m0.2778[0m      [31m0.4917[0m        [94m0.6818[0m     +  0.0001  10.8050
      3      0.7260        [32m0.4956[0m       0.2615      [31m0.4993[0m        0.6835        0.0001  10.5281
      4      0.7143        0.5341       0.2674      0.4933        0.6830        0.0001  10.5992
      5      [36m0.7616[0m        0.5011       0.2602      0.4936        0.6846        0.0001  10.9418
      6      [36m0.7688[0m        [32m0.4685[0m       0.2722      0.4875        [94m0.6749[0m     +  0.0000  10.8630
      7      [36m0.8258[0m        [32m0.4397[0m       0.2740      0.4867        [94m0.6717[0m     +  0.0000  10.6426
      8      [36m0.8513[0m        [32m0.4309[0m       0.2722      0.4900        [94m0.6716[0m     +  0.0000  10.6983
      9      0.8340        0.4315       0.2734      0.4871        [94m0.6657[0m     +  0.0000  10.4995
     10      0.8299        [32m0.4298[0m       0.2734      0.4937        [94m0.6650[0m     +  0.0000  10.6253
     11      [36m0.8934[0m        [32m0.3955[0m       0.2726      0.4965        0.6662        0.0000  10.6252
     12      0.8759        0.4053       0.2717      0.4970        0.6658        0.0000  10.7331
     13      [36m0.9107[0m        0.3995       0.2766      0.4957        [94m0.6641[0m     +  0.0000  10.8124
     14      0.8918        [32m0.3832[0m       0.2736      [31m0.4996[0m        0.6661        0.0000  10.7868
     15      [36m0.9148[0m        [32m0.3656[0m       0.2720      0.4983        0.6665        0.0000  10.5623
     16      [36m0.9341[0m        [32m0.3632[0m       0.2750      0.4989        0.6659        0.0000  10.6729
     17      0.8653        0.3886       0.2773      0.4991        0.6651        0.0000  10.6351
     18      0.9167        [32m0.3622[0m       [35m0.2785[0m      0.4983        0.6646        0.0000  10.8254
     19      [36m0.9363[0m        0.3855       [35m0.2790[0m      0.4982        0.6643        0.0000  10.5774
     20      0.9054        0.3875       [35m0.2811[0m      0.4981        [94m0.6635[0m     +  0.0000  10.6208
     21      0.9077        0.3817       [35m0.2812[0m      0.4982        [94m0.6635[0m     +  0.0000  10.7040
     22      0.9158        0.3776       [35m0.2814[0m      0.4987        [94m0.6634[0m     +  0.0000  10.6093
     23      [36m0.9516[0m        [32m0.3581[0m       0.2809      0.4985        0.6634        0.0000  10.5618
     24      0.9107        0.3784       [35m0.2818[0m      0.4988        [94m0.6630[0m     +  0.0000  10.5739
     25      0.9190        0.3728       [35m0.2825[0m      0.4989        0.6630        0.0000  10.6875
     26      0.9341        0.3876       [35m0.2826[0m      0.4991        0.6630        0.0000  10.6315
     27      0.9453        0.3774       0.2826      0.4991        0.6630        0.0000  10.6527
     28      0.8934        0.3728       0.2825      0.4992        [94m0.6630[0m     +  0.0000  10.6577
     29      0.9198        [32m0.3506[0m       0.2825      0.4989        [94m0.6629[0m     +  0.0000  10.6086
     30      0.9024        0.3802       [35m0.2828[0m      0.4990        [94m0.6628[0m     +  0.0000  10.6030
     31      0.9426        0.3628       [35m0.2830[0m      0.4991        [94m0.6628[0m     +  0.0000  10.6587
     32      0.8581        0.3975       [35m0.2832[0m      0.4990        [94m0.6628[0m     +  0.0000  10.9064
     33      0.9024        0.3774       0.2832      0.4991        [94m0.6628[0m     +  0.0000  10.7830
     34      0.8914        0.3830       [35m0.2833[0m      0.4990        [94m0.6627[0m     +  0.0000  10.4469
     35      0.9197        0.3696       0.2832      0.4989        0.6627        0.0000  10.5796
     36      0.8884        0.3720       0.2832      0.4991        0.6627        0.0000  10.7772
     37      [36m0.9597[0m        0.3712       0.2833      0.4992        0.6627        0.0000  10.7029
     38      0.8918        0.3893       0.2832      0.4991        0.6627        0.0000  10.7955
     39      0.9219        0.3605       0.2833      0.4992        [94m0.6627[0m     +  0.0000  10.6565
     40      0.9167        0.3733       0.2832      0.4991        0.6627        0.0000  10.7808
     41      0.9507        [32m0.3501[0m       0.2832      0.4991        0.6627        0.0000  10.6625
     42      0.9107        0.3779       0.2832      0.4991        0.6627        0.0000  10.5934
     43      0.9252        0.3725       0.2832      0.4991        0.6627        0.0000  10.7927
     44      0.9252        [32m0.3475[0m       0.2832      0.4992        [94m0.6627[0m     +  0.0000  10.6574
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.5065162716256383
F1 Macro Score after query 1: 0.4977607419504613
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8765[0m        [32m0.3788[0m       [35m0.2467[0m      [31m0.5793[0m        [94m0.8629[0m     +  0.0001  10.6983
      2      [36m0.9007[0m        [32m0.3780[0m       [35m0.3165[0m      0.5531        [94m0.7145[0m     +  0.0001  10.6731
      3      [36m0.9132[0m        [32m0.3320[0m       0.2953      0.5109        [94m0.6771[0m     +  0.0001  10.5782
      4      [36m0.9461[0m        [32m0.2717[0m       0.2861      0.5156        [94m0.6459[0m     +  0.0001  10.7457
      5      0.9442        [32m0.2592[0m       0.2983      0.5185        [94m0.6339[0m     +  0.0001  10.5573
      6      [36m0.9476[0m        [32m0.2204[0m       [35m0.3427[0m      0.5187        [94m0.6088[0m     +  0.0000  10.7943
      7      0.9446        [32m0.2170[0m       0.3394      0.5240        [94m0.6035[0m     +  0.0000  10.7547
      8      0.9446        [32m0.2076[0m       [35m0.3455[0m      0.5269        [94m0.6008[0m     +  0.0000  10.7382
      9      [36m0.9641[0m        [32m0.2029[0m       0.3333      0.5292        0.6010        0.0000  10.7327
     10      0.9641        [32m0.1956[0m       0.3304      0.5317        [94m0.5996[0m     +  0.0000  10.7800
     11      0.9520        0.1959       0.3286      0.5318        0.5998        0.0000  10.6379
     12      0.9531        0.2030       0.3295      0.5338        [94m0.5995[0m     +  0.0000  10.7998
     13      0.9625        [32m0.1918[0m       0.3285      0.5334        0.6000        0.0000  10.7070
     14      [36m0.9720[0m        [32m0.1729[0m       0.3276      0.5330        0.5996        0.0000  10.6238
     15      [36m0.9786[0m        0.1800       0.3273      0.5335        0.5997        0.0000  10.6109
     16      0.9688        0.1749       0.3278      0.5335        0.5999        0.0000  10.7874
     17      0.9634        [32m0.1700[0m       0.3276      0.5337        0.6008        0.0000  10.6663
     18      0.9786        0.1757       0.3288      0.5339        0.6009        0.0000  10.6577
     19      0.9726        0.1853       0.3269      0.5347        0.6018        0.0000  10.7930
     20      [36m0.9824[0m        0.1822       0.3273      0.5345        0.6021        0.0000  10.7203
     21      0.9736        [32m0.1674[0m       0.3269      0.5349        0.6022        0.0000  10.7948
     22      0.9688        0.1898       0.3281      0.5345        0.6020        0.0000  10.6888
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.5763211798443261
F1 Macro Score after query 2: 0.5633463280698687
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9109[0m        [32m0.2827[0m       [35m0.2441[0m      [31m0.4919[0m        [94m0.6827[0m     +  0.0001  11.0476
      2      [36m0.9318[0m        [32m0.2235[0m       [35m0.3092[0m      [31m0.5365[0m        [94m0.6249[0m     +  0.0001  10.9588
      3      [36m0.9338[0m        [32m0.1980[0m       0.3045      [31m0.5367[0m        [94m0.6223[0m     +  0.0001  10.6251
      4      [36m0.9453[0m        [32m0.1794[0m       [35m0.3446[0m      0.5163        [94m0.6071[0m     +  0.0001  10.6424
      5      [36m0.9592[0m        [32m0.1737[0m       [35m0.3552[0m      0.5298        [94m0.6050[0m     +  0.0001  11.0200
      6      0.9586        [32m0.1549[0m       [35m0.3556[0m      [31m0.5423[0m        0.6081        0.0000  10.9411
      7      [36m0.9696[0m        [32m0.1381[0m       [35m0.3573[0m      0.5392        0.6084        0.0000  10.9118
      8      0.9696        0.1382       [35m0.3582[0m      0.5394        [94m0.6042[0m     +  0.0000  10.8743
      9      [36m0.9700[0m        [32m0.1311[0m       0.3569      [31m0.5440[0m        [94m0.6024[0m     +  0.0000  10.7519
     10      [36m0.9719[0m        [32m0.1268[0m       0.3392      [31m0.5499[0m        0.6057        0.0000  10.7189
     11      0.9647        0.1310       0.3458      0.5473        0.6068        0.0000  10.9358
     12      [36m0.9745[0m        0.1279       0.3500      0.5434        0.6066        0.0000  10.9265
     13      0.9722        [32m0.1258[0m       0.3497      0.5448        0.6076        0.0000  10.6878
     14      0.9669        [32m0.1196[0m       0.3530      0.5422        0.6069        0.0000  10.8242
     15      [36m0.9789[0m        0.1228       0.3507      0.5482        0.6055        0.0000  10.9558
     16      0.9722        [32m0.1176[0m       0.3507      0.5456        0.6058        0.0000  11.0575
     17      0.9692        0.1215       0.3500      0.5467        0.6067        0.0000  10.6415
     18      [36m0.9792[0m        [32m0.1012[0m       0.3497      0.5456        0.6064        0.0000  10.7355
     19      0.9719        0.1131       0.3507      0.5462        0.6063        0.0000  10.8330
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.6359579215811284
F1 Macro Score after query 3: 0.6184279443420304
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9696[0m        [32m0.1247[0m       [35m0.2910[0m      [31m0.6269[0m        [94m0.7439[0m     +  0.0001  11.0605
      2      [36m0.9762[0m        [32m0.1029[0m       [35m0.3094[0m      0.5920        [94m0.6529[0m     +  0.0001  11.0776
      3      [36m0.9808[0m        [32m0.0980[0m       [35m0.3606[0m      0.5846        [94m0.6241[0m     +  0.0001  11.0369
      4      [36m0.9838[0m        [32m0.0856[0m       0.3589      0.5655        [94m0.6191[0m     +  0.0001  10.9990
      5      0.9820        [32m0.0852[0m       [35m0.3840[0m      0.5876        [94m0.6104[0m     +  0.0001  10.9042
      6      [36m0.9842[0m        [32m0.0749[0m       0.3660      0.5680        [94m0.6067[0m     +  0.0000  11.0828
      7      [36m0.9861[0m        [32m0.0712[0m       0.3616      0.5618        0.6122        0.0000  11.1094
      8      [36m0.9881[0m        [32m0.0705[0m       0.3632      0.5514        0.6168        0.0000  10.9572
      9      0.9870        [32m0.0654[0m       0.3628      0.5536        0.6169        0.0000  10.9064
     10      [36m0.9891[0m        0.0657       0.3658      0.5488        0.6204        0.0000  10.8477
     11      0.9890        [32m0.0610[0m       0.3606      0.5506        0.6196        0.0000  10.9357
     12      0.9880        [32m0.0601[0m       0.3538      0.5516        0.6204        0.0000  11.0465
     13      0.9861        0.0606       0.3623      0.5493        0.6207        0.0000  10.9355
     14      [36m0.9901[0m        [32m0.0569[0m       0.3505      0.5509        0.6224        0.0000  11.0129
     15      0.9870        0.0625       0.3561      0.5484        0.6242        0.0000  11.0298
     16      0.9899        [32m0.0550[0m       0.3512      0.5485        0.6247        0.0000  11.0887
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.6445445208185194
F1 Macro Score after query 4: 0.6271479075339972
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9576[0m        [32m0.1442[0m       [35m0.3033[0m      [31m0.5883[0m        [94m0.6508[0m     +  0.0001  11.5302
      2      [36m0.9656[0m        [32m0.1175[0m       [35m0.3146[0m      0.5426        [94m0.6430[0m     +  0.0001  11.1874
      3      [36m0.9682[0m        [32m0.1056[0m       [35m0.3472[0m      0.5435        0.6480        0.0001  11.4835
      4      [36m0.9770[0m        [32m0.0916[0m       0.3460      0.5195        0.6526        0.0001  11.6135
      5      [36m0.9786[0m        [32m0.0915[0m       [35m0.3530[0m      0.5122        0.6449        0.0001  11.5942
      6      [36m0.9812[0m        [32m0.0701[0m       0.3512      0.5253        [94m0.6384[0m     +  0.0000  11.2986
      7      [36m0.9821[0m        [32m0.0697[0m       [35m0.3536[0m      0.5172        0.6389        0.0000  11.4875
      8      [36m0.9851[0m        [32m0.0665[0m       0.3535      0.5232        [94m0.6358[0m     +  0.0000  11.3786
      9      0.9817        [32m0.0665[0m       0.3519      0.5205        0.6366        0.0000  11.4854
     10      0.9827        [32m0.0627[0m       0.3479      0.5336        [94m0.6329[0m     +  0.0000  11.2621
     11      [36m0.9864[0m        [32m0.0591[0m       0.3427      0.5398        [94m0.6317[0m     +  0.0000  11.2557
     12      0.9847        [32m0.0573[0m       0.3448      0.5461        [94m0.6281[0m     +  0.0000  11.3612
     13      [36m0.9874[0m        [32m0.0542[0m       0.3476      0.5511        [94m0.6247[0m     +  0.0000  11.4688
     14      0.9852        0.0543       0.3481      0.5499        0.6259        0.0000  11.3461
     15      [36m0.9882[0m        0.0551       0.3460      0.5462        0.6269        0.0000  11.3289
     16      0.9876        0.0550       0.3444      0.5496        0.6255        0.0000  11.2989
     17      0.9875        [32m0.0542[0m       0.3460      0.5543        [94m0.6246[0m     +  0.0000  11.2229
     18      0.9876        [32m0.0538[0m       0.3472      0.5552        [94m0.6244[0m     +  0.0000  11.4726
     19      [36m0.9894[0m        [32m0.0507[0m       0.3455      0.5563        [94m0.6238[0m     +  0.0000  11.3853
     20      0.9888        0.0507       0.3458      0.5561        0.6244        0.0000  11.3594
     21      0.9869        0.0526       0.3434      0.5570        0.6240        0.0000  11.2770
     22      0.9873        [32m0.0501[0m       0.3425      0.5580        0.6240        0.0000  11.3156
     23      0.9869        0.0525       0.3436      0.5590        0.6246        0.0000  11.2981
     24      0.9876        0.0535       0.3431      0.5591        0.6241        0.0000  11.2952
     25      0.9857        0.0540       0.3438      0.5595        0.6239        0.0000  11.1924
     26      0.9877        0.0539       0.3436      0.5589        [94m0.6238[0m     +  0.0000  11.3753
     27      0.9888        0.0504       0.3438      0.5599        [94m0.6236[0m     +  0.0000  11.4031
     28      0.9870        0.0503       0.3434      0.5602        [94m0.6235[0m     +  0.0000  11.5753
     29      0.9875        [32m0.0487[0m       0.3436      0.5600        0.6236        0.0000  11.4835
     30      0.9855        0.0506       0.3438      0.5609        [94m0.6235[0m     +  0.0000  11.2358
     31      0.9858        0.0525       0.3439      0.5610        0.6235        0.0000  11.3577
     32      [36m0.9907[0m        [32m0.0481[0m       0.3436      0.5609        [94m0.6234[0m     +  0.0000  11.2357
     33      0.9888        0.0495       0.3439      0.5613        [94m0.6234[0m     +  0.0000  11.3466
     34      0.9875        0.0483       0.3441      0.5614        [94m0.6234[0m     +  0.0000  11.3335
     35      0.9900        0.0498       0.3438      0.5613        [94m0.6233[0m     +  0.0000  11.2923
     36      0.9888        0.0511       0.3438      0.5613        [94m0.6233[0m     +  0.0000  11.3174
     37      0.9851        0.0535       0.3439      0.5614        [94m0.6233[0m     +  0.0000  11.2694
     38      0.9876        0.0501       0.3439      0.5614        [94m0.6233[0m     +  0.0000  11.4668
     39      0.9870        0.0508       0.3438      0.5615        0.6233        0.0000  11.2391
     40      0.9870        0.0491       0.3438      0.5615        0.6233        0.0000  11.4134
     41      0.9876        0.0514       0.3438      0.5615        0.6233        0.0000  11.4167
     42      0.9858        0.0519       0.3438      0.5615        0.6233        0.0000  11.4008
     43      0.9870        0.0510       0.3438      0.5615        0.6233        0.0000  11.4059
     44      0.9882        0.0500       0.3438      0.5615        0.6233        0.0000  11.2330
     45      0.9876        [32m0.0480[0m       0.3438      0.5615        0.6233        0.0000  11.3334
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.6382117113468858
F1 Macro Score after query 5: 0.6241655233347908
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9641[0m        [32m0.1252[0m       [35m0.2819[0m      [31m0.6477[0m        [94m0.6747[0m     +  0.0001  12.2557
      2      [36m0.9750[0m        [32m0.0913[0m       [35m0.3243[0m      0.6369        [94m0.5942[0m     +  0.0001  11.9182
      3      [36m0.9773[0m        [32m0.0821[0m       [35m0.3283[0m      0.6250        0.6201        0.0001  12.0174
      4      [36m0.9784[0m        [32m0.0746[0m       [35m0.3465[0m      0.6321        0.6087        0.0001  11.9506
      5      [36m0.9806[0m        [32m0.0719[0m       [35m0.3542[0m      0.6157        0.6164        0.0001  12.1068
      6      [36m0.9845[0m        [32m0.0645[0m       0.3326      0.5891        0.6225        0.0000  11.9645
      7      [36m0.9856[0m        [32m0.0616[0m       0.3477      0.5988        0.6162        0.0000  11.9348
      8      [36m0.9859[0m        0.0650       0.3510      0.5896        0.6196        0.0000  11.9363
      9      [36m0.9860[0m        0.0618       0.3497      0.5972        0.6261        0.0000  12.3870
     10      0.9848        [32m0.0605[0m       0.3434      0.5821        0.6314        0.0000  12.2786
     11      [36m0.9862[0m        [32m0.0566[0m       0.3446      0.5813        0.6333        0.0000  11.9016
     12      0.9859        [32m0.0552[0m       0.3479      0.5887        0.6336        0.0000  11.7930
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6522716326858244
F1 Macro Score after query 6: 0.6414304510722768
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9674[0m        [32m0.0993[0m       [35m0.2991[0m      [31m0.6655[0m        [94m0.6898[0m     +  0.0001  13.0913
      2      [36m0.9776[0m        [32m0.0792[0m       [35m0.3785[0m      [31m0.6909[0m        [94m0.5859[0m     +  0.0001  13.3245
      3      [36m0.9785[0m        [32m0.0722[0m       [35m0.4181[0m      [31m0.6960[0m        [94m0.5398[0m     +  0.0001  12.9511
      4      [36m0.9813[0m        [32m0.0679[0m       [35m0.4311[0m      [31m0.7054[0m        [94m0.5275[0m     +  0.0001  12.9895
      5      0.9808        0.0683       [35m0.4391[0m      [31m0.7095[0m        [94m0.5246[0m     +  0.0001  13.1692
      6      [36m0.9837[0m        [32m0.0595[0m       0.4292      0.6890        [94m0.5202[0m     +  0.0000  13.2314
      7      [36m0.9844[0m        [32m0.0582[0m       0.4304      0.6943        0.5235        0.0000  13.1850
      8      0.9839        [32m0.0566[0m       0.4255      0.6823        0.5249        0.0000  13.1825
      9      0.9843        [32m0.0559[0m       0.4222      0.6837        0.5299        0.0000  12.9664
     10      [36m0.9849[0m        [32m0.0551[0m       0.4231      0.6889        0.5311        0.0000  13.2117
     11      [36m0.9864[0m        [32m0.0518[0m       0.4128      0.6764        0.5285        0.0000  13.0295
     12      0.9858        [32m0.0509[0m       0.4135      0.6798        0.5263        0.0000  12.9819
     13      0.9857        0.0518       0.4125      0.6785        0.5281        0.0000  13.3111
     14      0.9858        0.0519       0.4120      0.6789        0.5306        0.0000  13.0581
     15      0.9861        0.0514       0.4118      0.6758        0.5289        0.0000  13.1537
     16      0.9856        0.0510       0.4102      0.6811        0.5311        0.0000  12.7930
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.7267177845604109
F1 Macro Score after query 7: 0.7177887172969286
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9771[0m        [32m0.0771[0m       [35m0.3599[0m      [31m0.6851[0m        [94m0.7062[0m     +  0.0001  15.0947
      2      [36m0.9808[0m        [32m0.0654[0m       [35m0.3785[0m      [31m0.6970[0m        [94m0.6036[0m     +  0.0001  15.2193
      3      [36m0.9842[0m        [32m0.0592[0m       0.3753      0.6901        0.6077        0.0001  15.1867
      4      [36m0.9843[0m        [32m0.0557[0m       0.3684      0.6837        0.6138        0.0001  15.4196
      5      [36m0.9856[0m        [32m0.0531[0m       0.3778      0.6872        0.6158        0.0001  15.0775
      6      [36m0.9868[0m        [32m0.0462[0m       [35m0.4111[0m      0.6863        [94m0.5445[0m     +  0.0000  15.1240
      7      [36m0.9883[0m        [32m0.0443[0m       0.3991      0.6803        0.5510        0.0000  15.0025
      8      [36m0.9890[0m        [32m0.0421[0m       0.4087      0.6829        0.5492        0.0000  15.1078
      9      0.9882        0.0422       [35m0.4165[0m      0.6814        0.5448        0.0000  14.8411
     10      0.9890        [32m0.0418[0m       [35m0.4172[0m      0.6940        0.5620        0.0000  15.0762
     11      [36m0.9891[0m        [32m0.0401[0m       [35m0.4179[0m      0.6879        0.5474        0.0000  15.1382
     12      [36m0.9904[0m        [32m0.0377[0m       0.4175      0.6853        0.5482        0.0000  14.6956
     13      0.9899        0.0383       [35m0.4207[0m      0.6869        0.5464        0.0000  14.9986
     14      0.9897        [32m0.0370[0m       0.4200      0.6839        [94m0.5432[0m     +  0.0000  15.2334
     15      [36m0.9904[0m        [32m0.0367[0m       [35m0.4229[0m      0.6834        [94m0.5430[0m     +  0.0000  15.1066
     16      0.9897        [32m0.0360[0m       [35m0.4269[0m      0.6884        0.5465        0.0000  15.3612
     17      [36m0.9910[0m        [32m0.0348[0m       0.4208      0.6875        0.5500        0.0000  15.2987
     18      0.9903        0.0354       0.4186      0.6858        0.5531        0.0000  15.2141
     19      0.9907        0.0354       0.4170      0.6831        0.5510        0.0000  15.2494
     20      0.9903        [32m0.0341[0m       0.4149      0.6824        0.5535        0.0000  15.1967
     21      0.9902        0.0349       0.4153      0.6843        0.5570        0.0000  15.2944
     22      0.9902        0.0344       0.4137      0.6831        0.5562        0.0000  15.4852
     23      0.9905        0.0346       0.4137      0.6840        0.5576        0.0000  15.5332
     24      0.9903        0.0353       0.4153      0.6837        0.5555        0.0000  15.2799
     25      0.9906        0.0350       0.4139      0.6814        0.5552        0.0000  15.3728
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.6909938953288978
F1 Macro Score after query 8: 0.6932053210361504
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9808[0m        [32m0.0828[0m       [35m0.4050[0m      [31m0.7222[0m        [94m0.5190[0m     +  0.0001  18.6264
      2      [36m0.9829[0m        [32m0.0680[0m       0.3873      0.7146        0.5688        0.0001  18.8694
      3      [36m0.9838[0m        [32m0.0635[0m       0.3863      0.7153        0.5943        0.0001  18.6585
      4      [36m0.9845[0m        [32m0.0620[0m       [35m0.4238[0m      [31m0.7283[0m        0.5271        0.0001  18.3611
      5      0.9844        [32m0.0608[0m       [35m0.4503[0m      [31m0.7359[0m        0.5296        0.0001  18.5412
      6      [36m0.9872[0m        [32m0.0536[0m       [35m0.4571[0m      [31m0.7386[0m        0.5266        0.0000  18.5181
      7      [36m0.9874[0m        [32m0.0524[0m       [35m0.4780[0m      [31m0.7446[0m        [94m0.5013[0m     +  0.0000  18.5756
      8      [36m0.9875[0m        [32m0.0503[0m       [35m0.4866[0m      [31m0.7450[0m        [94m0.4811[0m     +  0.0000  18.6423
      9      0.9875        [32m0.0499[0m       0.4847      [31m0.7456[0m        0.4964        0.0000  18.7694
     10      [36m0.9876[0m        [32m0.0487[0m       [35m0.4898[0m      [31m0.7482[0m        0.4942        0.0000  18.6411
     11      [36m0.9882[0m        [32m0.0468[0m       [35m0.4991[0m      [31m0.7505[0m        0.4888        0.0000  18.7993
     12      0.9881        [32m0.0464[0m       [35m0.5042[0m      0.7499        [94m0.4809[0m     +  0.0000  18.9667
     13      [36m0.9889[0m        0.0465       [35m0.5068[0m      [31m0.7515[0m        [94m0.4793[0m     +  0.0000  18.7235
     14      0.9887        [32m0.0463[0m       0.5056      [31m0.7530[0m        0.4821        0.0000  18.8938
     15      0.9886        [32m0.0462[0m       [35m0.5085[0m      [31m0.7555[0m        [94m0.4758[0m     +  0.0000  18.9545
     16      [36m0.9896[0m        [32m0.0445[0m       [35m0.5092[0m      0.7532        [94m0.4717[0m     +  0.0000  18.8155
     17      0.9893        0.0452       0.5090      0.7528        0.4726        0.0000  18.9091
     18      0.9891        [32m0.0443[0m       [35m0.5111[0m      0.7527        [94m0.4705[0m     +  0.0000  18.6921
     19      0.9891        [32m0.0434[0m       [35m0.5156[0m      0.7555        [94m0.4696[0m     +  0.0000  18.6942
     20      0.9891        [32m0.0429[0m       [35m0.5175[0m      0.7541        [94m0.4668[0m     +  0.0000  18.4701
     21      0.9892        0.0431       0.5170      [31m0.7556[0m        0.4681        0.0000  18.3390
     22      0.9888        0.0430       [35m0.5182[0m      0.7550        [94m0.4662[0m     +  0.0000  18.7198
     23      0.9894        0.0435       0.5174      0.7548        [94m0.4659[0m     +  0.0000  19.1266
     24      0.9888        0.0435       0.5175      0.7539        0.4662        0.0000  18.8939
     25      [36m0.9899[0m        [32m0.0426[0m       0.5172      0.7533        0.4672        0.0000  18.5000
     26      0.9895        0.0431       0.5174      0.7546        0.4678        0.0000  18.7785
     27      0.9895        0.0430       0.5175      0.7546        0.4671        0.0000  19.1742
     28      0.9891        0.0441       0.5175      0.7543        0.4672        0.0000  18.9196
     29      0.9898        0.0429       0.5174      0.7542        0.4667        0.0000  18.4874
     30      0.9897        [32m0.0420[0m       0.5181      0.7547        0.4677        0.0000  19.0324
     31      0.9895        [32m0.0416[0m       0.5174      0.7546        0.4681        0.0000  19.0312
     32      0.9895        0.0427       0.5170      0.7547        0.4685        0.0000  18.5934
     33      0.9894        0.0423       0.5170      0.7550        0.4679        0.0000  18.5613
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.746653158694551
F1 Macro Score after query 9: 0.749395264358062
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9763[0m        [32m0.1063[0m       [35m0.5837[0m      [31m0.7783[0m        [94m0.3970[0m     +  0.0001  24.9435
      2      [36m0.9772[0m        [32m0.0961[0m       [35m0.5920[0m      [31m0.7813[0m        0.4091        0.0001  25.3200
      3      [36m0.9791[0m        [32m0.0899[0m       0.5917      0.7756        0.4101        0.0001  25.5843
      4      [36m0.9801[0m        [32m0.0853[0m       [35m0.5967[0m      [31m0.7952[0m        0.3993        0.0001  25.1205
      5      [36m0.9804[0m        [32m0.0827[0m       [35m0.6297[0m      [31m0.8072[0m        [94m0.3640[0m     +  0.0001  25.2094
      6      [36m0.9832[0m        [32m0.0725[0m       0.6269      0.8032        0.3942        0.0000  25.6160
      7      [36m0.9833[0m        [32m0.0702[0m       [35m0.6307[0m      [31m0.8100[0m        0.3912        0.0000  25.2381
      8      [36m0.9843[0m        [32m0.0682[0m       0.6292      0.8094        0.4007        0.0000  25.1284
      9      [36m0.9843[0m        [32m0.0677[0m       [35m0.6316[0m      [31m0.8124[0m        0.3985        0.0000  25.7874
     10      [36m0.9845[0m        [32m0.0667[0m       [35m0.6418[0m      [31m0.8156[0m        0.3858        0.0000  25.3515
     11      [36m0.9847[0m        [32m0.0638[0m       [35m0.6497[0m      [31m0.8208[0m        0.3861        0.0000  24.7262
     12      [36m0.9855[0m        [32m0.0622[0m       [35m0.6509[0m      0.8205        0.3878        0.0000  25.7279
     13      0.9853        [32m0.0618[0m       [35m0.6517[0m      [31m0.8215[0m        0.3886        0.0000  25.4872
     14      0.9855        [32m0.0608[0m       0.6512      0.8207        0.3925        0.0000  24.8765
     15      0.9853        0.0611       0.6446      0.8190        0.3998        0.0000  25.6755
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8352432268346363
F1 Macro Score after query 10: 0.8302410153093995
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9427[0m        [32m0.1718[0m       [35m0.7151[0m      [31m0.8351[0m        [94m0.2756[0m     +  0.0001  37.0478
      2      [36m0.9523[0m        [32m0.1457[0m       [35m0.7403[0m      [31m0.8535[0m        [94m0.2673[0m     +  0.0001  36.8442
      3      [36m0.9575[0m        [32m0.1308[0m       [35m0.7450[0m      0.8479        0.2787        0.0001  37.5833
      4      [36m0.9599[0m        [32m0.1228[0m       [35m0.7495[0m      [31m0.8591[0m        0.2678        0.0001  36.5804
      5      [36m0.9620[0m        [32m0.1164[0m       0.7457      0.8548        0.2795        0.0001  37.0762
      6      [36m0.9672[0m        [32m0.1026[0m       0.7477      [31m0.8604[0m        0.2914        0.0000  37.4853
      7      [36m0.9678[0m        [32m0.0998[0m       0.7438      0.8581        0.3019        0.0000  36.8745
      8      [36m0.9692[0m        [32m0.0955[0m       0.7464      0.8594        0.2876        0.0000  37.7797
      9      0.9689        [32m0.0947[0m       [35m0.7502[0m      [31m0.8613[0m        0.2969        0.0000  38.3072
     10      [36m0.9704[0m        [32m0.0933[0m       0.7464      0.8603        0.2974        0.0000  36.9439
     11      [36m0.9715[0m        [32m0.0887[0m       [35m0.7533[0m      [31m0.8625[0m        0.3041        0.0000  37.4057
     12      [36m0.9718[0m        [32m0.0876[0m       0.7497      0.8606        0.3054        0.0000  37.3564
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8986068111455108
F1 Macro Score after query 11: 0.8885040544411019
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9415[0m        [32m0.1206[0m       [35m0.7755[0m      [31m0.8661[0m        [94m0.2737[0m     +  0.0001  57.9840
      2      [36m0.9461[0m        [32m0.1062[0m       0.7719      0.8656        0.2820        0.0001  57.8886
      3      [36m0.9505[0m        [32m0.0979[0m       [35m0.7774[0m      [31m0.8729[0m        0.2845        0.0001  58.1588
      4      [36m0.9529[0m        [32m0.0918[0m       0.7653      0.8728        0.3159        0.0001  58.0736
      5      [36m0.9550[0m        [32m0.0875[0m       0.7733      0.8727        0.2906        0.0001  57.8764
      6      [36m0.9617[0m        [32m0.0749[0m       0.7682      0.8698        0.3320        0.0000  57.9750
      7      [36m0.9628[0m        [32m0.0727[0m       0.7674      0.8725        0.3319        0.0000  56.9853
      8      [36m0.9635[0m        [32m0.0705[0m       0.7649      0.8722        0.3662        0.0000  58.5314
      9      [36m0.9654[0m        [32m0.0688[0m       0.7714      [31m0.8741[0m        0.3441        0.0000  58.3282
     10      0.9649        [32m0.0681[0m       0.7700      0.8702        0.3179        0.0000  57.9406
     11      [36m0.9676[0m        [32m0.0644[0m       0.7660      0.8691        0.3432        0.0000  57.9853
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8947606142728094
F1 Macro Score after query 12: 0.8821542160163691
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9361[0m        [32m0.1136[0m       [35m0.7550[0m      [31m0.8640[0m        [94m0.3355[0m     +  0.0001  67.1889
      2      [36m0.9426[0m        [32m0.1003[0m       0.7438      0.8611        0.4030        0.0001  67.0152
      3      [36m0.9476[0m        [32m0.0937[0m       0.7477      0.8448        [94m0.3108[0m     +  0.0001  67.2352
      4      [36m0.9516[0m        [32m0.0867[0m       0.7503      0.8550        0.3181        0.0001  66.8464
      5      [36m0.9543[0m        [32m0.0818[0m       0.7549      0.8505        [94m0.2787[0m     +  0.0001  66.6530
      6      [36m0.9588[0m        [32m0.0711[0m       [35m0.7589[0m      [31m0.8645[0m        0.3429        0.0000  66.7974
      7      [36m0.9618[0m        [32m0.0680[0m       [35m0.7639[0m      [31m0.8651[0m        0.3305        0.0000  66.8249
      8      0.9615        [32m0.0671[0m       0.7549      0.8627        0.3679        0.0000  66.7973
      9      [36m0.9635[0m        [32m0.0643[0m       0.7595      [31m0.8668[0m        0.3675        0.0000  66.6879
     10      [36m0.9641[0m        [32m0.0634[0m       0.7587      0.8630        0.3368        0.0000  66.9231
     11      [36m0.9658[0m        [32m0.0592[0m       0.7634      [31m0.8690[0m        0.3359        0.0000  62.1406
     12      [36m0.9660[0m        0.0592       0.7623      0.8669        0.3299        0.0000  60.6617
     13      0.9657        [32m0.0590[0m       0.7618      0.8683        0.3283        0.0000  60.5048
     14      [36m0.9678[0m        [32m0.0571[0m       0.7590      0.8684        0.3558        0.0000  60.6712
     15      0.9669        0.0576       0.7618      0.8673        0.3313        0.0000  60.7101
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.900570559147965
F1 Macro Score after query 13: 0.8886135639401912
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_config2\AL_max_score_results_for_multilabel_classification.pickle
