Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6963[0m        [32m0.6694[0m       [35m0.0502[0m      [31m0.2983[0m        [94m0.7190[0m     +  0.0001  12.3085
      2      0.6498        [32m0.6421[0m       [35m0.1720[0m      [31m0.4558[0m        [94m0.6983[0m     +  0.0001  10.3628
      3      [36m0.7963[0m        [32m0.6193[0m       [35m0.2663[0m      0.4267        [94m0.6873[0m     +  0.0001  10.7263
      4      0.7368        [32m0.5757[0m       0.1826      0.4468        0.7050        0.0001  10.8024
      5      0.7222        0.5919       0.2655      0.4145        0.6883        0.0001  10.9362
      6      0.7222        [32m0.5485[0m       0.2269      0.4425        0.6966        0.0000  10.9153
      7      0.6627        0.5662       0.2170      0.4459        0.7001        0.0000  11.2200
      8      0.7963        [32m0.5172[0m       0.2314      0.4487        0.7015        0.0000  10.5610
      9      0.7963        0.5277       0.2486      0.4525        0.7004        0.0000  10.7475
     10      [36m0.8333[0m        [32m0.5022[0m       0.2611      0.4518        0.7003        0.0000  10.9259
     11      0.6333        0.5754       0.2531      0.4541        0.7040        0.0000  10.3592
     12      0.7963        0.5327       0.2524      0.4526        0.7032        0.0000  10.9989
     13      0.8333        0.5051       0.2481      0.4518        0.7033        0.0000  10.5784
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4573
Pre F1 macro score = 0.4548
Pre Accuracy = 0.2510

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8005[0m        [32m0.5511[0m       [35m0.1594[0m      [31m0.5053[0m        [94m0.8420[0m     +  0.0001  10.9374
      2      [36m0.8101[0m        0.5539       [35m0.1750[0m      0.4771        [94m0.7812[0m     +  0.0001  10.5332
      3      [36m0.8647[0m        [32m0.5083[0m       [35m0.1757[0m      0.4510        [94m0.7622[0m     +  0.0001  11.1039
      4      0.8521        [32m0.5074[0m       0.1708      0.4637        0.7854        0.0001  10.7995
      5      0.8311        [32m0.5004[0m       [35m0.2203[0m      0.4613        0.7641        0.0001  11.0366
      6      0.8331        [32m0.4572[0m       0.2054      0.4561        0.7713        0.0000  10.6600
      7      0.8600        [32m0.4546[0m       0.1997      0.4522        0.7778        0.0000  10.9160
      8      0.8486        [32m0.4492[0m       [35m0.2293[0m      0.4569        0.7629        0.0000  10.8849
      9      [36m0.8690[0m        0.4495       [35m0.2351[0m      0.4586        [94m0.7589[0m     +  0.0000  10.9373
     10      0.8632        [32m0.4244[0m       0.2278      0.4586        0.7634        0.0000  10.7223
     11      0.8632        0.4338       0.2260      0.4585        0.7651        0.0000  10.9778
     12      [36m0.8712[0m        0.4333       0.2247      0.4587        0.7644        0.0000  10.9998
     13      0.8557        [32m0.4170[0m       0.2278      0.4600        0.7615        0.0000  11.0468
     14      [36m0.9069[0m        [32m0.4155[0m       0.2269      0.4595        0.7605        0.0000  10.8604
     15      0.8738        0.4204       0.2307      0.4610        [94m0.7584[0m     +  0.0000  10.9829
     16      0.8712        [32m0.4106[0m       0.2302      0.4615        0.7592        0.0000  10.8786
     17      0.8771        [32m0.3961[0m       0.2300      0.4611        0.7592        0.0000  10.8216
     18      0.8632        0.3977       0.2309      0.4620        0.7585        0.0000  10.9204
     19      0.8712        0.4212       0.2318      0.4622        [94m0.7581[0m     +  0.0000  10.9998
     20      0.8647        0.4135       0.2319      0.4621        [94m0.7579[0m     +  0.0000  11.0051
     21      0.8681        0.4194       0.2319      0.4622        0.7581        0.0000  10.9886
     22      0.8436        0.4280       0.2318      0.4625        [94m0.7578[0m     +  0.0000  10.9989
     23      0.8632        0.4250       0.2318      0.4625        0.7580        0.0000  10.7771
     24      0.8968        0.4013       0.2321      0.4628        [94m0.7578[0m     +  0.0000  10.7942
     25      0.8721        0.3978       0.2319      0.4628        0.7580        0.0000  11.0817
     26      0.8690        0.4169       0.2319      0.4627        0.7582        0.0000  10.8717
     27      0.8738        0.4166       0.2319      0.4628        0.7581        0.0000  10.9663
     28      0.8600        [32m0.3916[0m       0.2319      0.4628        0.7581        0.0000  10.8721
     29      0.8712        0.4224       0.2319      0.4629        0.7581        0.0000  10.7196
     30      0.8796        0.4046       0.2319      0.4630        0.7582        0.0000  10.9257
     31      0.8712        0.4255       0.2319      0.4630        0.7581        0.0000  10.6570
     32      0.8663        0.4161       0.2318      0.4630        0.7580        0.0000  10.6396
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.45566376217324445
F1 Macro Score after query 1: 0.45061289472440885
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8143[0m        [32m0.3926[0m       [35m0.2101[0m      [31m0.4876[0m        [94m0.7878[0m     +  0.0001  10.6928
      2      [36m0.8157[0m        0.4041       [35m0.2752[0m      [31m0.5137[0m        [94m0.7529[0m     +  0.0001  11.0292
      3      0.7891        [32m0.3741[0m       [35m0.2870[0m      0.5094        [94m0.7520[0m     +  0.0001  11.1559
      4      0.7952        [32m0.3411[0m       0.2856      [31m0.5184[0m        [94m0.7484[0m     +  0.0001  11.0940
      5      [36m0.8283[0m        0.3426       0.2845      0.5169        0.7558        0.0001  11.2833
      6      0.8273        [32m0.3380[0m       0.2799      0.5143        0.7598        0.0000  11.0776
      7      [36m0.8526[0m        [32m0.3085[0m       0.2781      0.5062        0.7528        0.0000  10.9710
      8      [36m0.8609[0m        [32m0.2979[0m       0.2764      0.5016        0.7513        0.0000  11.3158
      9      [36m0.8675[0m        0.3048       0.2727      0.4955        [94m0.7467[0m     +  0.0000  11.1245
     10      [36m0.9033[0m        [32m0.2882[0m       0.2819      0.4990        [94m0.7374[0m     +  0.0000  10.9328
     11      0.8850        0.2970       0.2774      0.4958        0.7421        0.0000  11.1280
     12      0.8550        0.3069       0.2780      0.4960        0.7400        0.0000  11.1567
     13      0.9026        [32m0.2737[0m       0.2748      0.4941        0.7399        0.0000  11.2043
     14      0.8740        0.2982       0.2729      0.4919        0.7393        0.0000  10.9687
     15      0.9000        [32m0.2658[0m       0.2747      0.4915        [94m0.7368[0m     +  0.0000  10.8810
     16      0.8773        0.2731       0.2733      0.4903        0.7373        0.0000  11.1456
     17      0.9025        0.2757       0.2745      0.4911        [94m0.7357[0m     +  0.0000  11.3302
     18      [36m0.9255[0m        [32m0.2587[0m       0.2753      0.4911        [94m0.7348[0m     +  0.0000  11.2673
     19      0.8926        0.2621       0.2740      0.4896        [94m0.7342[0m     +  0.0000  11.3785
     20      0.9231        [32m0.2561[0m       0.2736      0.4889        0.7344        0.0000  11.2676
     21      0.9065        [32m0.2558[0m       0.2750      0.4897        [94m0.7335[0m     +  0.0000  10.9825
     22      0.9063        0.2655       0.2753      0.4896        [94m0.7328[0m     +  0.0000  11.1092
     23      0.9065        0.2748       0.2753      0.4890        0.7331        0.0000  11.1406
     24      0.9158        0.2783       0.2757      0.4891        [94m0.7327[0m     +  0.0000  11.0096
     25      0.8926        0.2768       0.2766      0.4895        [94m0.7319[0m     +  0.0000  11.0654
     26      0.9055        0.2688       0.2766      0.4896        [94m0.7318[0m     +  0.0000  11.0462
     27      0.8926        0.2731       0.2769      0.4898        [94m0.7317[0m     +  0.0000  10.8253
     28      0.9097        0.2618       0.2771      0.4896        [94m0.7316[0m     +  0.0000  11.2189
     29      0.8801        0.2744       0.2773      0.4898        [94m0.7313[0m     +  0.0000  10.9253
     30      0.9198        [32m0.2534[0m       0.2774      0.4897        [94m0.7313[0m     +  0.0000  10.7658
     31      [36m0.9310[0m        0.2592       0.2774      0.4898        [94m0.7312[0m     +  0.0000  10.7971
     32      0.8996        0.2628       0.2774      0.4898        [94m0.7311[0m     +  0.0000  10.7697
     33      0.9166        0.2617       0.2776      0.4898        0.7311        0.0000  11.0980
     34      0.9098        0.2553       0.2778      0.4901        [94m0.7310[0m     +  0.0000  10.9061
     35      0.8954        0.2705       0.2778      0.4900        [94m0.7310[0m     +  0.0000  11.1253
     36      [36m0.9377[0m        0.2574       0.2778      0.4900        [94m0.7310[0m     +  0.0000  11.0343
     37      0.8993        0.2745       0.2778      0.4901        [94m0.7310[0m     +  0.0000  11.1725
     38      0.9065        0.2743       0.2778      0.4901        [94m0.7309[0m     +  0.0000  11.0812
     39      0.9189        0.2702       0.2778      0.4901        [94m0.7309[0m     +  0.0000  10.9098
     40      0.9220        0.2746       0.2778      0.4901        [94m0.7309[0m     +  0.0000  10.9951
     41      0.9067        0.2630       0.2778      0.4901        [94m0.7308[0m     +  0.0000  10.8560
     42      0.8862        0.2761       0.2778      0.4901        0.7309        0.0000  11.2014
     43      0.9195        0.2639       0.2778      0.4901        [94m0.7308[0m     +  0.0000  10.8451
     44      0.9089        0.2767       0.2778      0.4901        [94m0.7308[0m     +  0.0000  11.1261
     45      0.9231        0.2616       0.2778      0.4901        [94m0.7308[0m     +  0.0000  10.9866
     46      0.9129        0.2578       0.2778      0.4901        0.7308        0.0000  11.0042
     47      0.9264        0.2717       0.2778      0.4901        [94m0.7308[0m     +  0.0000  11.0618
     48      0.9194        0.2619       0.2778      0.4901        [94m0.7308[0m     +  0.0000  11.1783
     49      0.8962        0.2658       0.2778      0.4901        0.7308        0.0000  11.0316
     50      0.8996        0.2667       0.2778      0.4901        [94m0.7308[0m     +  0.0000  10.9076
     51      0.9065        0.2712       0.2778      0.4901        [94m0.7308[0m     +  0.0000  10.9854
     52      0.9377        [32m0.2504[0m       0.2778      0.4901        [94m0.7308[0m     +  0.0000  11.1883
     53      0.8934        0.2623       0.2778      0.4901        [94m0.7308[0m     +  0.0000  11.1088
     54      0.8898        0.2681       0.2778      0.4901        0.7308        0.0000  10.9339
     55      0.9293        0.2530       0.2778      0.4901        [94m0.7308[0m     +  0.0000  11.1445
     56      0.8854        0.2791       0.2778      0.4901        [94m0.7308[0m     +  0.0000  10.8769
     57      0.9033        0.2653       0.2778      0.4901        [94m0.7308[0m     +  0.0000  11.1412
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.4827132519552664
F1 Macro Score after query 2: 0.48273460264913365
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8011[0m        [32m0.3036[0m       [35m0.2497[0m      [31m0.6118[0m        [94m0.8507[0m     +  0.0001  10.9177
      2      [36m0.8486[0m        [32m0.2728[0m       [35m0.3123[0m      0.5715        [94m0.7458[0m     +  0.0001  10.9670
      3      [36m0.8723[0m        [32m0.2400[0m       [35m0.3189[0m      0.5603        [94m0.7155[0m     +  0.0001  11.2804
      4      [36m0.9003[0m        [32m0.2209[0m       [35m0.3264[0m      0.5544        [94m0.6996[0m     +  0.0001  11.1864
      5      [36m0.9016[0m        [32m0.2173[0m       [35m0.3295[0m      0.5647        [94m0.6894[0m     +  0.0001  11.0315
      6      0.9012        [32m0.2028[0m       [35m0.3363[0m      0.5410        [94m0.6814[0m     +  0.0000  11.2855
      7      [36m0.9305[0m        [32m0.1884[0m       [35m0.3370[0m      0.5320        [94m0.6753[0m     +  0.0000  11.2484
      8      [36m0.9383[0m        [32m0.1814[0m       [35m0.3448[0m      0.5342        [94m0.6719[0m     +  0.0000  11.1170
      9      [36m0.9402[0m        [32m0.1771[0m       [35m0.3519[0m      0.5428        [94m0.6624[0m     +  0.0000  11.0001
     10      0.9395        [32m0.1654[0m       [35m0.3566[0m      0.5384        [94m0.6567[0m     +  0.0000  11.0051
     11      0.9287        0.1678       0.3481      0.5330        0.6601        0.0000  11.3472
     12      0.9337        [32m0.1588[0m       0.3443      0.5321        0.6629        0.0000  11.0652
     13      0.9334        0.1669       0.3484      0.5334        [94m0.6546[0m     +  0.0000  11.2517
     14      [36m0.9489[0m        0.1664       0.3474      0.5330        [94m0.6542[0m     +  0.0000  11.0460
     15      0.9478        [32m0.1572[0m       0.3516      0.5361        [94m0.6506[0m     +  0.0000  10.9529
     16      0.9432        [32m0.1547[0m       0.3497      0.5355        0.6514        0.0000  11.0013
     17      0.9383        0.1576       0.3498      0.5344        [94m0.6502[0m     +  0.0000  11.0043
     18      0.9432        0.1600       0.3497      0.5352        0.6505        0.0000  11.0782
     19      0.9455        [32m0.1529[0m       0.3495      0.5340        [94m0.6502[0m     +  0.0000  11.0009
     20      0.9428        [32m0.1498[0m       0.3493      0.5342        0.6504        0.0000  11.4255
     21      0.9351        0.1538       0.3495      0.5341        0.6505        0.0000  11.2160
     22      [36m0.9523[0m        0.1526       0.3491      0.5345        0.6503        0.0000  11.1661
     23      0.9460        0.1513       0.3498      0.5350        [94m0.6497[0m     +  0.0000  11.0804
     24      0.9412        0.1558       0.3498      0.5354        [94m0.6495[0m     +  0.0000  11.2185
     25      0.9478        [32m0.1477[0m       0.3498      0.5356        0.6498        0.0000  11.2042
     26      0.9432        [32m0.1466[0m       0.3500      0.5355        0.6498        0.0000  11.3404
     27      0.9489        0.1544       0.3498      0.5358        0.6497        0.0000  11.3459
     28      0.9417        0.1573       0.3498      0.5356        0.6497        0.0000  10.8262
     29      0.9452        0.1519       0.3500      0.5359        0.6495        0.0000  11.3355
     30      0.9385        0.1547       0.3502      0.5359        [94m0.6494[0m     +  0.0000  11.2448
     31      0.9385        0.1537       0.3502      0.5359        [94m0.6494[0m     +  0.0000  11.2204
     32      0.9321        0.1492       0.3502      0.5359        [94m0.6494[0m     +  0.0000  10.7778
     33      0.9432        0.1492       0.3502      0.5358        0.6495        0.0000  11.1075
     34      0.9497        0.1534       0.3500      0.5357        0.6495        0.0000  11.0310
     35      0.9432        0.1561       0.3498      0.5357        0.6495        0.0000  11.0523
     36      0.9353        0.1579       0.3500      0.5357        0.6494        0.0000  11.1708
     37      0.9508        0.1516       0.3498      0.5357        0.6494        0.0000  10.9373
     38      0.9432        0.1553       0.3498      0.5357        0.6494        0.0000  11.0665
     39      0.9498        0.1494       0.3498      0.5357        [94m0.6494[0m     +  0.0000  11.2156
     40      0.9417        0.1540       0.3498      0.5356        [94m0.6494[0m     +  0.0000  11.2185
     41      0.9489        0.1581       0.3498      0.5357        [94m0.6493[0m     +  0.0000  10.9814
     42      0.9439        0.1494       0.3498      0.5357        0.6493        0.0000  10.9545
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.5391633105942303
F1 Macro Score after query 3: 0.5347254830294309
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8496[0m        [32m0.2395[0m       [35m0.2757[0m      [31m0.6159[0m        [94m0.6990[0m     +  0.0001  11.3284
      2      [36m0.8732[0m        [32m0.1942[0m       [35m0.3080[0m      0.5994        [94m0.6457[0m     +  0.0001  11.2402
      3      [36m0.9196[0m        [32m0.1617[0m       0.3016      0.5785        0.6600        0.0001  11.2034
      4      [36m0.9327[0m        [32m0.1516[0m       [35m0.3219[0m      0.5735        [94m0.6436[0m     +  0.0001  11.1614
      5      [36m0.9378[0m        [32m0.1337[0m       0.3167      0.5685        0.6539        0.0001  11.3474
      6      [36m0.9521[0m        [32m0.1222[0m       0.3182      0.5634        0.6516        0.0000  11.3654
      7      0.9443        [32m0.1133[0m       [35m0.3257[0m      0.5673        0.6478        0.0000  11.1715
      8      [36m0.9559[0m        0.1212       0.3253      0.5623        0.6466        0.0000  11.2180
      9      0.9513        [32m0.1105[0m       [35m0.3274[0m      0.5618        0.6462        0.0000  11.1565
     10      0.9557        0.1147       0.3264      0.5657        0.6474        0.0000  11.2185
     11      0.9521        [32m0.1082[0m       [35m0.3278[0m      0.5675        0.6461        0.0000  11.3288
     12      0.9506        [32m0.1070[0m       [35m0.3302[0m      0.5690        0.6445        0.0000  11.0800
     13      0.9541        0.1098       [35m0.3326[0m      0.5696        0.6438        0.0000  11.4477
     14      0.9536        [32m0.1060[0m       0.3300      0.5708        0.6450        0.0000  11.1415
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.6040135436452226
F1 Macro Score after query 4: 0.5939685030025901
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8806[0m        [32m0.1739[0m       [35m0.2674[0m      [31m0.6182[0m        [94m0.7898[0m     +  0.0001  11.6453
      2      [36m0.9206[0m        [32m0.1319[0m       [35m0.2948[0m      0.6094        [94m0.7107[0m     +  0.0001  11.7175
      3      [36m0.9352[0m        [32m0.1131[0m       [35m0.3066[0m      0.5931        [94m0.6935[0m     +  0.0001  11.6304
      4      [36m0.9507[0m        [32m0.0999[0m       [35m0.3358[0m      0.5914        [94m0.6805[0m     +  0.0001  11.7986
      5      [36m0.9536[0m        [32m0.0913[0m       [35m0.3535[0m      0.6105        [94m0.6649[0m     +  0.0001  11.4392
      6      [36m0.9653[0m        [32m0.0775[0m       [35m0.3559[0m      0.5930        [94m0.6558[0m     +  0.0000  11.4170
      7      0.9620        [32m0.0747[0m       0.3536      0.5955        [94m0.6549[0m     +  0.0000  11.5201
      8      [36m0.9691[0m        [32m0.0722[0m       [35m0.3563[0m      0.6005        0.6601        0.0000  11.7221
      9      0.9685        [32m0.0680[0m       0.3554      0.6027        0.6576        0.0000  11.3697
     10      0.9685        0.0700       [35m0.3573[0m      0.5972        [94m0.6534[0m     +  0.0000  11.9074
     11      [36m0.9725[0m        [32m0.0643[0m       [35m0.3576[0m      0.6028        0.6574        0.0000  11.4929
     12      [36m0.9762[0m        [32m0.0624[0m       0.3569      0.6027        0.6580        0.0000  11.6439
     13      0.9761        [32m0.0609[0m       [35m0.3592[0m      0.6069        0.6586        0.0000  11.6391
     14      0.9732        [32m0.0591[0m       [35m0.3595[0m      0.6068        0.6571        0.0000  11.8317
     15      0.9757        [32m0.0573[0m       [35m0.3606[0m      0.6077        0.6563        0.0000  11.7531
     16      0.9734        0.0586       0.3604      0.6089        0.6568        0.0000  11.6645
     17      0.9759        0.0576       [35m0.3611[0m      0.6096        0.6600        0.0000  11.6621
     18      [36m0.9772[0m        0.0577       0.3608      0.6098        0.6602        0.0000  11.4846
     19      0.9764        [32m0.0567[0m       0.3608      0.6108        0.6608        0.0000  11.6873
     20      [36m0.9782[0m        [32m0.0555[0m       [35m0.3613[0m      0.6098        0.6585        0.0000  11.7678
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.6504688136975132
F1 Macro Score after query 5: 0.6499279191185864
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9176[0m        [32m0.1248[0m       [35m0.3198[0m      [31m0.6447[0m        [94m0.7355[0m     +  0.0001  12.5857
      2      [36m0.9493[0m        [32m0.0885[0m       [35m0.3311[0m      0.6404        0.7491        0.0001  12.9466
      3      [36m0.9543[0m        [32m0.0814[0m       [35m0.3474[0m      0.6377        [94m0.7254[0m     +  0.0001  12.8850
      4      [36m0.9599[0m        [32m0.0755[0m       0.3422      0.6320        0.7309        0.0001  12.5719
      5      [36m0.9618[0m        [32m0.0736[0m       [35m0.3608[0m      0.6316        [94m0.6823[0m     +  0.0001  12.6192
      6      [36m0.9685[0m        [32m0.0561[0m       [35m0.3637[0m      0.6326        0.6962        0.0000  12.0509
      7      [36m0.9709[0m        0.0572       [35m0.3663[0m      0.6319        0.6870        0.0000  12.5463
      8      0.9673        0.0561       0.3639      0.6296        0.6902        0.0000  12.2323
      9      0.9695        [32m0.0549[0m       [35m0.3672[0m      0.6373        0.6946        0.0000  12.1947
     10      [36m0.9712[0m        0.0561       [35m0.3705[0m      0.6390        0.6843        0.0000  12.7033
     11      [36m0.9751[0m        [32m0.0484[0m       0.3696      0.6406        0.6965        0.0000  12.4267
     12      0.9747        [32m0.0481[0m       0.3700      0.6369        0.6896        0.0000  12.6156
     13      0.9747        0.0485       0.3703      0.6343        0.6875        0.0000  12.3673
     14      0.9733        0.0485       [35m0.3729[0m      0.6380        0.6875        0.0000  12.3624
     15      [36m0.9759[0m        [32m0.0458[0m       0.3707      0.6362        0.6930        0.0000  12.2860
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6819626385551507
F1 Macro Score after query 6: 0.682050509509974
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9505[0m        [32m0.1060[0m       [35m0.4056[0m      [31m0.6733[0m        [94m0.5427[0m     +  0.0001  13.6313
      2      [36m0.9615[0m        [32m0.0873[0m       [35m0.4502[0m      [31m0.6917[0m        [94m0.5252[0m     +  0.0001  13.0833
      3      [36m0.9627[0m        [32m0.0749[0m       [35m0.4724[0m      0.6832        0.5334        0.0001  13.3274
      4      [36m0.9650[0m        [32m0.0722[0m       [35m0.5094[0m      [31m0.6974[0m        [94m0.5137[0m     +  0.0001  13.6079
      5      [36m0.9657[0m        [32m0.0680[0m       [35m0.5219[0m      [31m0.6994[0m        [94m0.4995[0m     +  0.0001  13.8455
      6      [36m0.9704[0m        [32m0.0603[0m       0.5120      [31m0.7045[0m        0.5090        0.0000  13.8371
      7      [36m0.9724[0m        [32m0.0545[0m       0.5038      0.6966        0.5180        0.0000  13.5538
      8      [36m0.9746[0m        [32m0.0533[0m       0.5101      0.6994        0.5227        0.0000  13.5829
      9      0.9724        0.0565       0.5038      0.6903        0.5167        0.0000  13.2396
     10      0.9723        [32m0.0519[0m       0.5080      0.6944        0.5253        0.0000  13.2660
     11      [36m0.9794[0m        [32m0.0478[0m       0.4944      0.6871        0.5382        0.0000  13.0691
     12      [36m0.9802[0m        [32m0.0467[0m       0.4932      0.6849        0.5400        0.0000  13.3573
     13      0.9774        0.0476       0.4960      0.6871        0.5350        0.0000  13.7578
     14      0.9767        [32m0.0441[0m       0.4990      0.6877        0.5317        0.0000  13.1806
     15      0.9779        0.0452       0.4946      0.6919        0.5425        0.0000  13.2468
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.7032949456174025
F1 Macro Score after query 7: 0.7018212367635535
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9795[0m        [32m0.0800[0m       [35m0.4658[0m      [31m0.7254[0m        [94m0.6177[0m     +  0.0001  15.9064
      2      [36m0.9800[0m        [32m0.0698[0m       [35m0.5646[0m      [31m0.7653[0m        [94m0.4937[0m     +  0.0001  15.5001
      3      [36m0.9812[0m        [32m0.0645[0m       [35m0.5818[0m      [31m0.7722[0m        [94m0.4738[0m     +  0.0001  15.2717
      4      [36m0.9814[0m        [32m0.0599[0m       [35m0.5845[0m      [31m0.7747[0m        0.4878        0.0001  15.0782
      5      [36m0.9834[0m        [32m0.0562[0m       [35m0.5974[0m      [31m0.7787[0m        [94m0.4659[0m     +  0.0001  15.6761
      6      [36m0.9862[0m        [32m0.0482[0m       0.5878      0.7628        [94m0.4395[0m     +  0.0000  15.5004
      7      [36m0.9864[0m        [32m0.0468[0m       0.5865      0.7645        0.4502        0.0000  14.7190
      8      0.9859        [32m0.0464[0m       0.5922      0.7690        0.4567        0.0000  15.4884
      9      [36m0.9866[0m        [32m0.0456[0m       0.5934      0.7676        0.4491        0.0000  15.7496
     10      0.9865        [32m0.0442[0m       [35m0.5998[0m      0.7721        0.4481        0.0000  15.4323
     11      [36m0.9881[0m        [32m0.0420[0m       0.5877      0.7527        0.4526        0.0000  15.4372
     12      0.9880        [32m0.0418[0m       0.5865      0.7501        0.4530        0.0000  15.6873
     13      [36m0.9882[0m        [32m0.0402[0m       0.5882      0.7531        0.4558        0.0000  14.9844
     14      [36m0.9884[0m        [32m0.0392[0m       0.5885      0.7514        0.4548        0.0000  15.7627
     15      [36m0.9887[0m        [32m0.0388[0m       0.5891      0.7521        0.4534        0.0000  15.2762
     16      0.9885        0.0398       0.5845      0.7456        0.4576        0.0000  15.1582
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7863532019314494
F1 Macro Score after query 8: 0.7878082495083847
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9754[0m        [32m0.0983[0m       [35m0.6106[0m      [31m0.7757[0m        [94m0.3959[0m     +  0.0001  19.5289
      2      [36m0.9793[0m        [32m0.0823[0m       [35m0.6267[0m      0.7749        0.3965        0.0001  19.2340
      3      [36m0.9798[0m        [32m0.0749[0m       [35m0.6278[0m      0.7750        [94m0.3928[0m     +  0.0001  18.9468
      4      [36m0.9816[0m        [32m0.0708[0m       [35m0.6479[0m      [31m0.7836[0m        [94m0.3698[0m     +  0.0001  18.5511
      5      [36m0.9829[0m        [32m0.0682[0m       0.6276      0.7755        [94m0.3672[0m     +  0.0001  19.2625
      6      [36m0.9858[0m        [32m0.0592[0m       [35m0.6514[0m      [31m0.7970[0m        [94m0.3665[0m     +  0.0000  18.4687
      7      0.9857        [32m0.0582[0m       0.6486      0.7884        [94m0.3610[0m     +  0.0000  19.2032
      8      [36m0.9863[0m        [32m0.0563[0m       0.6439      0.7880        [94m0.3579[0m     +  0.0000  18.5302
      9      [36m0.9864[0m        [32m0.0549[0m       [35m0.6540[0m      0.7913        0.3622        0.0000  19.3438
     10      [36m0.9865[0m        [32m0.0549[0m       [35m0.6601[0m      0.7944        [94m0.3516[0m     +  0.0000  18.7620
     11      [36m0.9874[0m        [32m0.0522[0m       0.6589      0.7950        0.3542        0.0000  19.3922
     12      [36m0.9876[0m        [32m0.0503[0m       0.6582      0.7947        0.3612        0.0000  18.7408
     13      [36m0.9880[0m        [32m0.0499[0m       0.6578      0.7929        0.3607        0.0000  19.5865
     14      0.9878        0.0505       [35m0.6611[0m      [31m0.7973[0m        0.3565        0.0000  19.1770
     15      0.9878        [32m0.0492[0m       0.6576      0.7901        0.3558        0.0000  19.8466
     16      [36m0.9889[0m        [32m0.0479[0m       0.6550      0.7925        0.3596        0.0000  18.9636
     17      0.9886        0.0480       0.6580      0.7929        0.3636        0.0000  19.3792
     18      0.9885        0.0482       0.6562      0.7917        0.3658        0.0000  18.9277
     19      0.9885        [32m0.0476[0m       0.6578      0.7934        0.3637        0.0000  18.6666
     20      [36m0.9891[0m        [32m0.0468[0m       0.6594      0.7932        0.3661        0.0000  18.9961
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8169613621480026
F1 Macro Score after query 9: 0.8143657274472472
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9693[0m        [32m0.1172[0m       [35m0.6767[0m      [31m0.7949[0m        [94m0.3135[0m     +  0.0001  25.6378
      2      [36m0.9729[0m        [32m0.1029[0m       0.6714      0.7782        0.3228        0.0001  24.9692
      3      [36m0.9757[0m        [32m0.0968[0m       0.6686      0.7710        0.3242        0.0001  24.9686
      4      [36m0.9772[0m        [32m0.0916[0m       0.6613      0.7599        0.3386        0.0001  25.4554
      5      [36m0.9783[0m        [32m0.0875[0m       0.6682      0.7650        0.3412        0.0001  25.0003
      6      [36m0.9809[0m        [32m0.0778[0m       [35m0.6783[0m      0.7881        0.3457        0.0000  25.6576
      7      [36m0.9815[0m        [32m0.0753[0m       [35m0.6852[0m      0.7946        0.3429        0.0000  25.4050
      8      [36m0.9819[0m        [32m0.0740[0m       [35m0.6861[0m      0.7935        0.3516        0.0000  25.5288
      9      0.9818        [32m0.0721[0m       0.6861      0.7910        0.3550        0.0000  26.0913
     10      [36m0.9820[0m        [32m0.0713[0m       [35m0.6875[0m      0.7930        0.3420        0.0000  25.5017
     11      [36m0.9828[0m        [32m0.0679[0m       [35m0.6898[0m      [31m0.8037[0m        0.3655        0.0000  25.8258
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8620742795500077
F1 Macro Score after query 10: 0.8516481531263401
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9404[0m        [32m0.1796[0m       [35m0.6984[0m      [31m0.8246[0m        [94m0.2948[0m     +  0.0001  37.4032
      2      [36m0.9524[0m        [32m0.1481[0m       [35m0.7194[0m      [31m0.8373[0m        [94m0.2897[0m     +  0.0001  36.8914
      3      [36m0.9576[0m        [32m0.1340[0m       [35m0.7267[0m      0.8368        0.3039        0.0001  37.2132
      4      [36m0.9599[0m        [32m0.1258[0m       [35m0.7399[0m      [31m0.8525[0m        [94m0.2871[0m     +  0.0001  37.7498
      5      [36m0.9620[0m        [32m0.1190[0m       0.7304      0.8426        [94m0.2748[0m     +  0.0001  36.8656
      6      [36m0.9673[0m        [32m0.1042[0m       0.7394      0.8495        0.2962        0.0000  37.2084
      7      [36m0.9681[0m        [32m0.1013[0m       [35m0.7417[0m      0.8465        0.2969        0.0000  37.5214
      8      [36m0.9697[0m        [32m0.0990[0m       0.7389      0.8465        0.2978        0.0000  36.7433
      9      0.9695        [32m0.0971[0m       0.7351      0.8438        0.2956        0.0000  37.8451
     10      [36m0.9697[0m        [32m0.0951[0m       0.7325      0.8347        0.3002        0.0000  35.7483
     11      [36m0.9718[0m        [32m0.0903[0m       0.7375      0.8477        0.3007        0.0000  37.5104
     12      [36m0.9721[0m        [32m0.0893[0m       0.7335      0.8445        0.3048        0.0000  36.6215
     13      [36m0.9721[0m        0.0894       0.7375      0.8477        0.3001        0.0000  37.4813
     14      [36m0.9728[0m        [32m0.0880[0m       0.7377      0.8468        0.3073        0.0000  37.0267
     15      0.9726        [32m0.0869[0m       0.7344      0.8428        0.3032        0.0000  37.0907
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8849148230941186
F1 Macro Score after query 11: 0.8763875718511679
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9480[0m        [32m0.1106[0m       [35m0.7752[0m      [31m0.8708[0m        [94m0.2611[0m     +  0.0001  58.2359
      2      [36m0.9518[0m        [32m0.1004[0m       0.7625      0.8611        [94m0.2474[0m     +  0.0001  58.1326
      3      [36m0.9536[0m        [32m0.0916[0m       0.7672      0.8641        0.2692        0.0001  58.0185
      4      [36m0.9562[0m        [32m0.0868[0m       0.7745      0.8695        0.2521        0.0001  57.8142
      5      [36m0.9568[0m        [32m0.0834[0m       0.7589      0.8619        0.2874        0.0001  57.8985
      6      [36m0.9627[0m        [32m0.0728[0m       0.7571      0.8607        0.3087        0.0000  57.8981
      7      [36m0.9643[0m        [32m0.0704[0m       0.7613      0.8640        0.2994        0.0000  58.9671
      8      [36m0.9649[0m        [32m0.0694[0m       0.7609      0.8620        0.2998        0.0000  59.0345
      9      [36m0.9651[0m        [32m0.0676[0m       0.7644      0.8637        0.3005        0.0000  54.0855
     10      [36m0.9654[0m        [32m0.0658[0m       0.7622      0.8653        0.3071        0.0000  53.0838
     11      [36m0.9682[0m        [32m0.0629[0m       0.7538      0.8561        0.3182        0.0000  52.8340
     12      [36m0.9687[0m        [32m0.0623[0m       0.7524      0.8602        0.3163        0.0000  52.7438
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8949056463041695
F1 Macro Score after query 12: 0.8837400341611669
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9452[0m        [32m0.0978[0m       [35m0.7566[0m      [31m0.8530[0m        [94m0.2867[0m     +  0.0001  60.3575
      2      [36m0.9496[0m        [32m0.0891[0m       [35m0.7597[0m      [31m0.8547[0m        0.2966        0.0001  60.4977
      3      [36m0.9537[0m        [32m0.0828[0m       [35m0.7646[0m      [31m0.8587[0m        0.2890        0.0001  60.4342
      4      [36m0.9551[0m        [32m0.0789[0m       [35m0.7649[0m      [31m0.8587[0m        0.3069        0.0001  61.0634
      5      [36m0.9564[0m        [32m0.0762[0m       0.7514      0.8546        0.3048        0.0001  60.5721
      6      [36m0.9626[0m        [32m0.0663[0m       0.7562      0.8545        0.3333        0.0000  60.2356
      7      [36m0.9643[0m        [32m0.0633[0m       0.7568      0.8573        0.3057        0.0000  60.3787
      8      0.9642        [32m0.0625[0m       0.7602      [31m0.8595[0m        0.3171        0.0000  60.4978
      9      [36m0.9650[0m        [32m0.0607[0m       0.7557      0.8565        0.3071        0.0000  60.5980
     10      [36m0.9651[0m        [32m0.0597[0m       0.7479      0.8569        0.3650        0.0000  60.4008
     11      [36m0.9679[0m        [32m0.0573[0m       0.7533      0.8572        0.3160        0.0000  60.5559
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8976666158304103
F1 Macro Score after query 13: 0.884451226767912
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed42_config2\AL_average_score_results_for_multilabel_classification.pickle
