Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5152[0m        [32m0.7299[0m       [35m0.0769[0m      [31m0.4301[0m        [94m0.7166[0m     +  0.0001  20.2020
      2      [36m0.6829[0m        [32m0.6723[0m       [35m0.3358[0m      0.2320        [94m0.6690[0m     +  0.0001  20.4218
      3      0.5167        [32m0.6271[0m       0.1760      [31m0.4389[0m        0.6979        0.0001  22.4735
      4      [36m0.7833[0m        [32m0.6164[0m       0.2965      0.3396        [94m0.6651[0m     +  0.0001  22.1880
      5      0.6468        [32m0.5992[0m       0.2790      0.4261        0.6822        0.0001  22.2810
      6      [36m0.8333[0m        [32m0.5498[0m       0.2927      0.4177        0.6779        0.0000  22.3350
      7      0.7857        0.5693       0.2922      0.4116        0.6781        0.0000  22.3074
      8      0.7963        0.5755       0.2918      0.4151        0.6789        0.0000  22.2440
      9      0.7857        0.5544       0.2905      0.4268        0.6807        0.0000  22.2105
     10      0.7857        0.5861       0.2632      [31m0.4415[0m        0.6878        0.0000  22.2500
     11      0.7500        [32m0.5226[0m       0.2738      [31m0.4420[0m        0.6866        0.0000  22.1561
     12      0.7368        0.5485       0.2773      0.4404        0.6857        0.0000  19.4953
     13      0.7857        [32m0.5152[0m       0.2734      [31m0.4424[0m        0.6863        0.0000  19.2809
     14      0.7500        0.5497       0.2745      [31m0.4427[0m        0.6867        0.0000  18.9528
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4625
Pre F1 macro score = 0.4614
Pre Accuracy = 0.3108

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8101[0m        [32m0.4693[0m       [35m0.1865[0m      [31m0.4162[0m        [94m0.7166[0m     +  0.0001  19.5309
      2      0.6275        [32m0.4239[0m       [35m0.2811[0m      [31m0.7236[0m        0.7223        0.0001  22.2090
      3      0.7175        [32m0.3774[0m       0.2557      0.3676        0.7331        0.0001  22.1280
      4      0.7286        [32m0.3428[0m       0.2545      0.4217        0.7516        0.0001  22.1215
      5      0.7286        [32m0.3128[0m       0.2382      0.4448        0.7588        0.0001  22.2192
      6      0.8000        [32m0.3020[0m       0.2220      0.4481        0.7598        0.0000  22.1689
      7      [36m0.9171[0m        [32m0.2651[0m       0.2208      0.4521        0.7648        0.0000  22.2084
      8      0.8085        0.2836       0.2102      0.4571        0.7690        0.0000  22.1860
      9      0.8000        0.2912       0.2019      0.4601        0.7754        0.0000  22.3111
     10      0.8641        0.2811       0.2069      0.4515        0.7691        0.0000  22.2955
     11      0.8556        [32m0.2633[0m       0.2045      0.4530        0.7695        0.0000  22.3039
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.49944702499447025
F1 Macro Score after query 1: 0.47053069137916587
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5821[0m        [32m0.5968[0m       [35m0.3260[0m      [31m0.3030[0m        [94m0.6336[0m     +  0.0001  22.4291
      2      0.5250        [32m0.5535[0m       0.3137      [31m0.3821[0m        [94m0.6281[0m     +  0.0001  22.3864
      3      [36m0.6616[0m        [32m0.4829[0m       0.3083      [31m0.4404[0m        [94m0.6222[0m     +  0.0001  22.3560
      4      [36m0.6730[0m        [32m0.4460[0m       [35m0.3762[0m      [31m0.4679[0m        [94m0.6186[0m     +  0.0001  22.3948
      5      [36m0.7138[0m        [32m0.3849[0m       [35m0.3877[0m      [31m0.5007[0m        [94m0.5925[0m     +  0.0001  22.4331
      6      [36m0.7583[0m        [32m0.3437[0m       [35m0.4269[0m      [31m0.5177[0m        [94m0.5887[0m     +  0.0000  22.3749
      7      [36m0.7586[0m        [32m0.3382[0m       [35m0.4420[0m      [31m0.5296[0m        [94m0.5842[0m     +  0.0000  22.3637
      8      [36m0.8144[0m        [32m0.2943[0m       [35m0.4616[0m      [31m0.5444[0m        [94m0.5793[0m     +  0.0000  22.4197
      9      [36m0.8159[0m        [32m0.2780[0m       [35m0.4740[0m      [31m0.5534[0m        [94m0.5699[0m     +  0.0000  22.3892
     10      [36m0.8873[0m        [32m0.2717[0m       [35m0.4873[0m      [31m0.5679[0m        [94m0.5597[0m     +  0.0000  22.3736
     11      0.8293        [32m0.2647[0m       [35m0.4944[0m      [31m0.5698[0m        [94m0.5556[0m     +  0.0000  22.4844
     12      0.8866        [32m0.2434[0m       [35m0.5000[0m      [31m0.5705[0m        [94m0.5547[0m     +  0.0000  22.4380
     13      0.8589        [32m0.2319[0m       [35m0.5036[0m      0.5684        [94m0.5520[0m     +  0.0000  22.4277
     14      [36m0.9059[0m        [32m0.2149[0m       [35m0.5078[0m      [31m0.5754[0m        [94m0.5498[0m     +  0.0000  22.4687
     15      0.8511        0.2331       [35m0.5127[0m      [31m0.5763[0m        [94m0.5486[0m     +  0.0000  20.5357
     16      0.8974        0.2303       [35m0.5137[0m      [31m0.5771[0m        [94m0.5469[0m     +  0.0000  19.7659
     17      [36m0.9116[0m        0.2294       [35m0.5142[0m      [31m0.5789[0m        [94m0.5462[0m     +  0.0000  18.5265
     18      [36m0.9434[0m        0.2190       [35m0.5165[0m      [31m0.5789[0m        [94m0.5452[0m     +  0.0000  22.4060
     19      0.8873        0.2259       0.5160      0.5776        [94m0.5441[0m     +  0.0000  22.3895
     20      0.9066        0.2178       [35m0.5181[0m      0.5786        [94m0.5436[0m     +  0.0000  22.4374
     21      0.8929        0.2218       [35m0.5182[0m      [31m0.5791[0m        [94m0.5431[0m     +  0.0000  22.4254
     22      0.9160        0.2196       [35m0.5184[0m      0.5784        [94m0.5426[0m     +  0.0000  22.4047
     23      0.9219        [32m0.2120[0m       [35m0.5198[0m      [31m0.5793[0m        [94m0.5422[0m     +  0.0000  22.3882
     24      0.8922        0.2173       [35m0.5208[0m      [31m0.5802[0m        [94m0.5417[0m     +  0.0000  22.4027
     25      0.9219        0.2343       [35m0.5214[0m      [31m0.5808[0m        [94m0.5416[0m     +  0.0000  22.4042
     26      0.8974        [32m0.2095[0m       [35m0.5215[0m      [31m0.5810[0m        [94m0.5415[0m     +  0.0000  22.4389
     27      0.9261        0.2153       [35m0.5219[0m      [31m0.5813[0m        [94m0.5413[0m     +  0.0000  22.4543
     28      0.8974        0.2122       0.5217      0.5810        [94m0.5413[0m     +  0.0000  22.4186
     29      0.8421        0.2230       [35m0.5226[0m      [31m0.5821[0m        [94m0.5411[0m     +  0.0000  22.4519
     30      0.8817        0.2246       0.5226      [31m0.5826[0m        [94m0.5411[0m     +  0.0000  22.4215
     31      0.9123        0.2177       [35m0.5229[0m      0.5826        [94m0.5411[0m     +  0.0000  22.4074
     32      [36m0.9717[0m        0.2134       [35m0.5231[0m      0.5824        [94m0.5410[0m     +  0.0000  22.4687
     33      0.9171        [32m0.2086[0m       0.5231      0.5824        [94m0.5409[0m     +  0.0000  22.4369
     34      0.9479        [32m0.1991[0m       0.5229      0.5824        [94m0.5408[0m     +  0.0000  20.4686
     35      0.9261        0.2169       [35m0.5233[0m      [31m0.5828[0m        [94m0.5407[0m     +  0.0000  19.5263
     36      0.9459        0.2156       0.5229      0.5826        [94m0.5407[0m     +  0.0000  19.9679
     37      0.9396        0.2175       0.5233      [31m0.5829[0m        [94m0.5407[0m     +  0.0000  22.4176
     38      0.9437        0.2099       0.5233      [31m0.5830[0m        [94m0.5406[0m     +  0.0000  22.3638
     39      0.9219        0.2046       0.5231      0.5829        [94m0.5406[0m     +  0.0000  22.4071
     40      0.8971        0.2036       0.5231      0.5829        [94m0.5406[0m     +  0.0000  22.4054
     41      0.8871        0.2267       0.5231      0.5829        [94m0.5406[0m     +  0.0000  22.4060
     42      0.9108        0.2078       0.5231      0.5829        [94m0.5406[0m     +  0.0000  22.4642
     43      0.8974        0.2114       0.5231      0.5829        [94m0.5406[0m     +  0.0000  22.4249
     44      0.9217        0.2146       0.5231      0.5829        [94m0.5406[0m     +  0.0000  22.4203
     45      0.9351        0.2115       0.5231      0.5829        [94m0.5406[0m     +  0.0000  22.4091
     46      0.8696        0.2196       0.5233      [31m0.5831[0m        [94m0.5406[0m     +  0.0000  22.3602
     47      0.8872        0.2115       0.5233      0.5831        0.5406        0.0000  22.4818
     48      0.8599        0.2115       0.5233      0.5831        [94m0.5406[0m     +  0.0000  22.4688
     49      0.9437        0.2044       0.5233      0.5831        [94m0.5406[0m     +  0.0000  22.4365
     50      0.9057        0.2196       0.5233      0.5831        [94m0.5405[0m     +  0.0000  22.4365
     51      0.9632        0.2124       0.5233      0.5831        [94m0.5405[0m     +  0.0000  22.4140
     52      0.9437        0.2107       0.5233      0.5831        [94m0.5405[0m     +  0.0000  22.4297
     53      0.8696        0.2174       0.5233      0.5831        [94m0.5405[0m     +  0.0000  19.6149
     54      0.9147        0.2131       0.5233      0.5831        0.5405        0.0000  19.3935
     55      0.9428        0.2143       0.5233      0.5831        [94m0.5405[0m     +  0.0000  19.3128
     56      0.9580        0.2095       0.5233      0.5831        [94m0.5405[0m     +  0.0000  22.4256
     57      0.8971        0.2131       0.5233      0.5831        [94m0.5405[0m     +  0.0000  22.3148
     58      0.8933        0.2129       0.5233      0.5831        [94m0.5405[0m     +  0.0000  22.3797
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.6281331836887392
F1 Macro Score after query 2: 0.6247004000141917
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8081[0m        [32m0.2824[0m       [35m0.5174[0m      [31m0.6356[0m        [94m0.4747[0m     +  0.0001  22.6131
      2      [36m0.8507[0m        [32m0.2017[0m       [35m0.5632[0m      [31m0.6744[0m        [94m0.4719[0m     +  0.0001  21.5345
      3      [36m0.9448[0m        [32m0.1390[0m       [35m0.5863[0m      0.6664        0.4838        0.0001  19.6454
      4      0.9429        [32m0.1234[0m       [35m0.5866[0m      [31m0.6913[0m        [94m0.4710[0m     +  0.0001  19.5655
      5      0.9425        [32m0.1120[0m       [35m0.6102[0m      [31m0.7055[0m        [94m0.4505[0m     +  0.0001  22.6434
      6      [36m0.9703[0m        [32m0.0929[0m       0.6087      0.6962        0.4579        0.0000  22.6601
      7      [36m0.9759[0m        [32m0.0846[0m       [35m0.6155[0m      0.6987        0.4532        0.0000  22.6141
      8      0.9703        [32m0.0821[0m       [35m0.6175[0m      [31m0.7062[0m        0.4518        0.0000  22.6436
      9      0.9703        [32m0.0783[0m       [35m0.6201[0m      [31m0.7067[0m        [94m0.4465[0m     +  0.0000  22.6279
     10      0.9626        0.0803       0.6174      0.7040        0.4516        0.0000  22.5696
     11      0.9703        0.0805       0.6200      [31m0.7089[0m        0.4467        0.0000  22.6109
     12      [36m0.9777[0m        [32m0.0713[0m       [35m0.6217[0m      [31m0.7098[0m        [94m0.4437[0m     +  0.0000  22.6570
     13      0.9758        0.0729       0.6208      0.7095        0.4445        0.0000  22.5960
     14      0.9722        [32m0.0693[0m       [35m0.6226[0m      [31m0.7132[0m        [94m0.4417[0m     +  0.0000  22.6300
     15      [36m0.9796[0m        0.0704       [35m0.6231[0m      [31m0.7182[0m        [94m0.4385[0m     +  0.0000  22.6421
     16      0.9778        0.0701       [35m0.6233[0m      0.7178        0.4387        0.0000  22.6617
     17      0.9777        [32m0.0642[0m       [35m0.6238[0m      [31m0.7187[0m        0.4390        0.0000  22.5808
     18      0.9740        0.0672       0.6233      0.7184        0.4393        0.0000  22.6115
     19      [36m0.9853[0m        0.0656       0.6217      0.7172        0.4399        0.0000  22.6110
     20      0.9777        0.0680       0.6227      0.7173        0.4403        0.0000  22.6768
     21      [36m0.9867[0m        0.0652       0.6224      0.7171        0.4400        0.0000  21.8175
     22      0.9777        [32m0.0638[0m       0.6224      0.7177        0.4395        0.0000  19.6263
     23      0.9848        [32m0.0598[0m       0.6224      0.7180        0.4393        0.0000  19.1286
     24      0.9867        0.0665       0.6222      0.7178        0.4393        0.0000  22.6602
     25      0.9796        0.0623       0.6224      0.7182        0.4393        0.0000  22.6105
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.733170134638923
F1 Macro Score after query 3: 0.7324376878495786
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9227[0m        [32m0.1838[0m       [35m0.5811[0m      [31m0.7612[0m        [94m0.4136[0m     +  0.0001  22.9420
      2      [36m0.9558[0m        [32m0.1133[0m       [35m0.6009[0m      0.7198        0.4346        0.0001  23.0000
      3      [36m0.9665[0m        [32m0.0877[0m       [35m0.6097[0m      0.7292        0.4328        0.0001  23.1152
      4      [36m0.9741[0m        [32m0.0778[0m       0.6007      0.7200        0.4365        0.0001  21.0821
      5      [36m0.9818[0m        [32m0.0558[0m       0.5837      0.7133        0.4493        0.0001  20.3049
      6      [36m0.9831[0m        [32m0.0551[0m       0.5997      0.7138        0.4413        0.0000  18.9857
      7      [36m0.9839[0m        [32m0.0513[0m       0.5948      0.7206        0.4358        0.0000  23.0212
      8      [36m0.9859[0m        [32m0.0472[0m       0.5920      0.7133        0.4406        0.0000  23.0065
      9      0.9802        [32m0.0470[0m       0.5870      0.7155        0.4389        0.0000  22.8483
     10      0.9820        0.0473       0.5872      0.7139        0.4404        0.0000  22.9571
     11      0.9820        [32m0.0462[0m       0.5776      0.6998        0.4487        0.0000  23.0175
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.7165114613180517
F1 Macro Score after query 4: 0.7076495455147512
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9429[0m        [32m0.1568[0m       [35m0.6050[0m      [31m0.7275[0m        [94m0.4285[0m     +  0.0001  20.7475
      2      [36m0.9631[0m        [32m0.0940[0m       0.6007      0.7180        0.4537        0.0001  20.8124
      3      [36m0.9729[0m        [32m0.0728[0m       0.5898      0.7109        0.4610        0.0001  22.5335
      4      [36m0.9757[0m        [32m0.0696[0m       0.5873      0.7044        0.4725        0.0001  23.9376
      5      [36m0.9785[0m        [32m0.0605[0m       0.5806      0.7001        0.4732        0.0001  24.0247
      6      [36m0.9896[0m        [32m0.0488[0m       0.5726      0.6866        0.4870        0.0000  24.0576
      7      0.9850        0.0512       0.5679      0.6844        0.4922        0.0000  23.9565
      8      [36m0.9897[0m        [32m0.0435[0m       0.5656      0.6826        0.4902        0.0000  23.8251
      9      0.9878        0.0472       0.5587      0.6814        0.4912        0.0000  23.8414
     10      0.9878        0.0446       0.5587      0.6872        0.4815        0.0000  23.8308
     11      0.9877        [32m0.0410[0m       0.5575      0.6828        0.4887        0.0000  23.9031
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.7089094405274242
F1 Macro Score after query 5: 0.6997509341247815
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9380[0m        [32m0.1506[0m       [35m0.6064[0m      [31m0.7431[0m        [94m0.4304[0m     +  0.0001  25.2023
      2      [36m0.9622[0m        [32m0.1037[0m       0.5998      0.7214        0.4811        0.0001  25.1762
      3      [36m0.9677[0m        [32m0.0885[0m       0.5783      0.6966        0.5035        0.0001  25.2797
      4      [36m0.9703[0m        [32m0.0825[0m       0.5708      0.7012        0.4960        0.0001  25.1669
      5      0.9677        [32m0.0819[0m       0.5507      0.6764        0.5329        0.0001  25.2049
      6      [36m0.9783[0m        [32m0.0673[0m       0.5618      0.6732        0.5159        0.0000  25.1737
      7      [36m0.9819[0m        [32m0.0656[0m       0.5557      0.6692        0.5122        0.0000  25.2689
      8      [36m0.9819[0m        [32m0.0630[0m       0.5580      0.6827        0.4960        0.0000  25.1222
      9      0.9808        [32m0.0601[0m       0.5505      0.6654        0.5051        0.0000  25.2830
     10      0.9805        0.0613       0.5450      0.6683        0.5058        0.0000  25.0808
     11      [36m0.9827[0m        [32m0.0589[0m       0.5443      0.6650        0.5105        0.0000  25.2031
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6996920847672523
F1 Macro Score after query 6: 0.6896831087366424
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9403[0m        [32m0.1351[0m       [35m0.5420[0m      [31m0.6961[0m        [94m0.5016[0m     +  0.0001  27.8234
      2      [36m0.9547[0m        [32m0.1035[0m       0.4627      0.6315        0.5589        0.0001  27.7318
      3      [36m0.9574[0m        [32m0.0961[0m       0.4564      0.6403        0.5527        0.0001  27.4736
      4      [36m0.9645[0m        [32m0.0847[0m       0.4611      0.6519        0.5379        0.0001  27.5002
      5      [36m0.9650[0m        [32m0.0825[0m       0.4542      0.6462        0.5473        0.0001  27.3280
      6      [36m0.9704[0m        [32m0.0706[0m       0.4470      0.6302        0.5678        0.0000  27.4844
      7      0.9693        [32m0.0688[0m       0.4429      0.6225        0.5767        0.0000  27.3186
      8      [36m0.9713[0m        [32m0.0655[0m       0.4443      0.6298        0.5713        0.0000  27.7514
      9      0.9708        [32m0.0654[0m       0.4384      0.6185        0.5706        0.0000  26.2630
     10      0.9710        [32m0.0632[0m       0.4415      0.6242        0.5735        0.0000  24.4059
     11      [36m0.9745[0m        [32m0.0595[0m       0.4372      0.6132        0.5798        0.0000  26.2974
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.6363069245165315
F1 Macro Score after query 7: 0.6315448046171055
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9307[0m        [32m0.1705[0m       [35m0.5660[0m      [31m0.7573[0m        [94m0.4366[0m     +  0.0001  32.4556
      2      [36m0.9426[0m        [32m0.1363[0m       0.5418      0.7340        0.4666        0.0001  32.6242
      3      [36m0.9526[0m        [32m0.1196[0m       0.5307      0.7228        0.4903        0.0001  32.5622
      4      [36m0.9564[0m        [32m0.1086[0m       0.5326      0.7237        0.4769        0.0001  28.4055
      5      [36m0.9602[0m        [32m0.1037[0m       0.5319      0.7204        0.4849        0.0001  28.7654
      6      [36m0.9677[0m        [32m0.0859[0m       0.5217      0.7025        0.4980        0.0000  32.6091
      7      [36m0.9693[0m        [32m0.0830[0m       0.5333      0.7138        0.4900        0.0000  32.1870
      8      [36m0.9700[0m        [32m0.0806[0m       0.5283      0.7055        0.4838        0.0000  32.3376
      9      [36m0.9719[0m        [32m0.0785[0m       0.5413      0.7226        0.4855        0.0000  32.3848
     10      [36m0.9733[0m        [32m0.0765[0m       0.5342      0.7126        0.4839        0.0000  31.5320
     11      [36m0.9738[0m        [32m0.0722[0m       0.5394      0.7208        0.4866        0.0000  31.8547
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7140495867768595
F1 Macro Score after query 8: 0.719252430000863
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9665[0m        [32m0.1250[0m       [35m0.6410[0m      [31m0.7967[0m        [94m0.3911[0m     +  0.0001  39.3910
      2      [36m0.9708[0m        [32m0.1044[0m       [35m0.6462[0m      [31m0.8028[0m        [94m0.3859[0m     +  0.0001  39.2781
      3      [36m0.9739[0m        [32m0.0944[0m       0.6340      0.8010        0.3873        0.0001  39.3437
      4      [36m0.9782[0m        [32m0.0861[0m       0.6288      0.7958        0.4185        0.0001  39.4748
      5      [36m0.9790[0m        [32m0.0818[0m       0.6229      0.7933        0.4107        0.0001  39.7507
      6      [36m0.9827[0m        [32m0.0687[0m       0.6269      0.7977        0.4113        0.0000  39.3902
      7      [36m0.9828[0m        [32m0.0657[0m       0.6234      0.7962        0.4149        0.0000  39.4840
      8      [36m0.9834[0m        [32m0.0647[0m       0.6236      0.7933        0.4223        0.0000  39.3449
      9      [36m0.9836[0m        [32m0.0633[0m       0.6260      0.7946        0.4213        0.0000  38.7979
     10      0.9835        [32m0.0622[0m       0.6257      0.7916        0.4302        0.0000  35.2541
     11      [36m0.9856[0m        [32m0.0574[0m       0.6349      0.7965        0.4096        0.0000  35.9244
     12      [36m0.9857[0m        [32m0.0554[0m       0.6356      0.7967        0.4179        0.0000  39.3638
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.788314606741573
F1 Macro Score after query 9: 0.7846467148964246
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9674[0m        [32m0.1377[0m       [35m0.6807[0m      [31m0.8355[0m        [94m0.3161[0m     +  0.0001  52.3881
      2      [36m0.9698[0m        [32m0.1202[0m       0.6455      0.8163        0.3424        0.0001  47.3278
      3      [36m0.9727[0m        [32m0.1082[0m       0.6134      0.8088        0.3867        0.0001  44.4440
      4      [36m0.9744[0m        [32m0.1021[0m       0.6068      0.7998        0.3934        0.0001  46.0936
      5      [36m0.9757[0m        [32m0.0980[0m       0.5934      0.8001        0.4260        0.0001  43.2490
      6      [36m0.9794[0m        [32m0.0850[0m       0.6109      0.7970        0.3961        0.0000  46.3897
      7      [36m0.9806[0m        [32m0.0818[0m       0.6153      0.7988        0.3927        0.0000  46.2342
      8      0.9805        [32m0.0795[0m       0.6104      0.7967        0.4016        0.0000  45.8784
      9      [36m0.9817[0m        [32m0.0778[0m       0.6026      0.7940        0.4163        0.0000  49.4376
     10      [36m0.9819[0m        [32m0.0764[0m       0.6083      0.7980        0.4041        0.0000  52.6876
     11      [36m0.9825[0m        [32m0.0729[0m       0.6127      0.8021        0.4007        0.0000  52.6877
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8292682926829268
F1 Macro Score after query 10: 0.8332180351659821
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9392[0m        [32m0.1800[0m       [35m0.7104[0m      [31m0.8411[0m        [94m0.2693[0m     +  0.0001  76.1408
      2      [36m0.9508[0m        [32m0.1486[0m       0.7024      [31m0.8422[0m        0.2984        0.0001  75.9694
      3      [36m0.9559[0m        [32m0.1348[0m       [35m0.7106[0m      [31m0.8449[0m        0.2965        0.0001  76.1092
      4      [36m0.9599[0m        [32m0.1240[0m       0.7014      0.8397        0.3100        0.0001  75.6244
      5      [36m0.9616[0m        [32m0.1182[0m       0.7036      0.8401        0.3103        0.0001  67.8280
      6      [36m0.9667[0m        [32m0.1036[0m       0.7078      0.8403        0.3267        0.0000  76.1873
      7      [36m0.9669[0m        [32m0.1010[0m       0.7045      0.8403        0.3254        0.0000  76.0466
      8      [36m0.9682[0m        [32m0.0978[0m       0.7083      0.8402        0.3361        0.0000  75.8746
      9      [36m0.9696[0m        [32m0.0953[0m       0.7066      0.8387        0.3348        0.0000  76.0469
     10      [36m0.9703[0m        [32m0.0929[0m       0.7054      0.8342        0.3243        0.0000  76.0465
     11      [36m0.9709[0m        [32m0.0895[0m       0.7071      0.8359        0.3319        0.0000  76.0325
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.867506916692284
F1 Macro Score after query 11: 0.8617023379412602
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9316[0m        [32m0.1351[0m       [35m0.7450[0m      [31m0.8622[0m        [94m0.2716[0m     +  0.0001  112.4530
      2      [36m0.9416[0m        [32m0.1148[0m       0.7443      0.8616        0.2847        0.0001  117.7490
      3      [36m0.9464[0m        [32m0.1035[0m       0.7370      0.8534        0.3086        0.0001  117.6254
      4      [36m0.9502[0m        [32m0.0956[0m       0.7358      0.8558        0.3343        0.0001  117.6737
      5      [36m0.9538[0m        [32m0.0905[0m       0.7328      0.8525        0.3256        0.0001  117.5932
      6      [36m0.9598[0m        [32m0.0787[0m       [35m0.7578[0m      [31m0.8633[0m        0.2891        0.0000  115.1717
      7      [36m0.9618[0m        [32m0.0744[0m       0.7448      0.8586        0.3261        0.0000  106.6923
      8      [36m0.9630[0m        [32m0.0736[0m       0.7422      0.8546        0.3176        0.0000  114.1873
      9      [36m0.9635[0m        [32m0.0718[0m       0.7453      0.8546        0.3214        0.0000  114.8909
     10      [36m0.9635[0m        [32m0.0708[0m       0.7425      0.8555        0.3141        0.0000  114.9061
     11      [36m0.9667[0m        [32m0.0650[0m       0.7467      0.8532        0.3044        0.0000  114.2873
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8936527311565455
F1 Macro Score after query 12: 0.8816538986515227
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9322[0m        [32m0.1188[0m       [35m0.7443[0m      [31m0.8561[0m        [94m0.3092[0m     +  0.0001  123.0904
      2      [36m0.9416[0m        [32m0.1031[0m       [35m0.7460[0m      0.8559        [94m0.2916[0m     +  0.0001  130.3801
      3      [36m0.9463[0m        [32m0.0947[0m       [35m0.7472[0m      0.8507        [94m0.2833[0m     +  0.0001  130.5399
      4      [36m0.9509[0m        [32m0.0874[0m       0.7415      0.8537        0.3084        0.0001  130.7427
      5      [36m0.9524[0m        [32m0.0824[0m       0.7427      0.8490        0.3073        0.0001  131.0424
      6      [36m0.9596[0m        [32m0.0715[0m       0.7424      0.8495        0.3188        0.0000  122.4484
      7      [36m0.9608[0m        [32m0.0686[0m       0.7443      0.8489        0.3120        0.0000  130.7965
      8      [36m0.9617[0m        [32m0.0662[0m       0.7368      0.8450        0.3218        0.0000  130.7529
      9      [36m0.9621[0m        0.0662       0.7339      0.8503        0.3702        0.0000  130.8597
     10      [36m0.9629[0m        [32m0.0640[0m       0.7290      0.8351        0.3254        0.0000  130.5791
     11      [36m0.9657[0m        [32m0.0601[0m       0.7340      0.8414        0.3259        0.0000  130.8285
     12      0.9657        [32m0.0595[0m       0.7372      0.8434        0.3199        0.0000  122.6011
     13      [36m0.9665[0m        [32m0.0584[0m       0.7378      0.8427        0.3079        0.0000  130.4350
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8930664434127407
F1 Macro Score after query 13: 0.8787354361220814
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_config2\AL_max_score_results_for_multilabel_classification.pickle
