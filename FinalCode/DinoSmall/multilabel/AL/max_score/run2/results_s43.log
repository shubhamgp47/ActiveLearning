Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2434[0m        [32m0.6979[0m       [35m0.2356[0m      [31m0.4635[0m        [94m0.6879[0m     +  0.0000  11.5288
      2      [36m0.8320[0m        [32m0.6229[0m       0.1953      0.4493        0.6886        0.0000  10.5315
      3      0.7460        0.6306       0.2273      0.4454        0.6916        0.0000  10.3476
      4      0.7054        0.6251       0.1556      0.4449        0.6932        0.0000  10.5463
      5      [36m0.8426[0m        [32m0.5746[0m       0.2014      [31m0.4773[0m        [94m0.6830[0m     +  0.0000  10.1825
      6      0.8426        [32m0.5676[0m       0.2083      0.4599        0.6870        0.0000  10.5660
      7      0.7963        [32m0.5644[0m       0.2033      0.4602        0.6952        0.0000  10.4992
      8      0.8333        [32m0.5369[0m       0.2113      0.4646        0.6927        0.0000  10.3849
      9      0.8320        [32m0.5339[0m       0.2056      0.4598        0.6932        0.0000  10.5648
     10      0.7857        [32m0.5283[0m       0.2073      0.4740        0.6929        0.0000  10.7713
     11      0.8130        0.5537       0.2066      0.4687        0.6947        0.0000  10.7325
     12      [36m0.9630[0m        [32m0.4794[0m       0.2083      0.4677        0.6938        0.0000  10.6624
     13      0.8796        0.4997       0.2122      0.4698        0.6929        0.0000  10.6918
     14      0.8889        0.5241       0.2115      0.4708        0.6932        0.0000  10.4677
     15      0.9167        0.4934       0.2125      0.4701        0.6944        0.0000  10.4519
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4810
Pre F1 macro score = 0.4786
Pre Accuracy = 0.2436

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6734[0m        [32m0.6354[0m       [35m0.3767[0m      [31m0.3335[0m        [94m0.6490[0m     +  0.0000  10.8750
      2      0.1587        [32m0.5374[0m       [35m0.4406[0m      0.2450        [94m0.6421[0m     +  0.0000  10.8265
      3      0.3556        [32m0.4835[0m       0.4200      0.2961        [94m0.6336[0m     +  0.0000  10.4905
      4      0.6012        [32m0.4531[0m       0.3882      0.3080        [94m0.6267[0m     +  0.0000  10.7137
      5      0.5825        [32m0.4221[0m       0.3856      0.3258        [94m0.6246[0m     +  0.0000  10.9560
      6      0.5185        0.4238       0.3649      0.3333        [94m0.6190[0m     +  0.0000  10.8464
      7      [36m0.8783[0m        [32m0.4049[0m       0.3486      [31m0.3380[0m        0.6191        0.0000  10.7990
      8      0.7153        [32m0.3916[0m       0.3467      [31m0.3463[0m        [94m0.6158[0m     +  0.0000  10.8113
      9      0.7389        [32m0.3899[0m       0.3427      [31m0.6771[0m        0.6182        0.0000  10.7475
     10      0.8067        [32m0.3691[0m       0.3462      0.3505        0.6176        0.0000  10.6102
     11      0.8237        [32m0.3628[0m       0.3457      0.3523        0.6173        0.0000  10.7202
     12      0.8042        0.3675       0.3439      0.3546        0.6167        0.0000  10.7058
     13      0.8730        [32m0.3599[0m       0.3394      0.3581        0.6169        0.0000  10.3881
     14      0.5825        0.3686       0.3380      0.3609        0.6169        0.0000  10.5938
     15      0.7153        [32m0.3570[0m       0.3352      0.3641        0.6170        0.0000  10.8743
     16      0.8745        0.3670       0.3366      0.3658        0.6171        0.0000  10.4196
     17      [36m0.8997[0m        [32m0.3494[0m       0.3370      0.3715        0.6170        0.0000  10.4859
     18      0.7524        [32m0.3399[0m       0.3366      0.3726        0.6168        0.0000  10.7501
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.46211302211302213
F1 Macro Score after query 1: 0.3769866265881108
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6923[0m        [32m0.4995[0m       [35m0.2611[0m      [31m0.5255[0m        [94m0.6040[0m     +  0.0000  10.7207
      2      [36m0.7693[0m        [32m0.3963[0m       [35m0.3363[0m      0.5117        0.6044        0.0000  10.7926
      3      0.7692        [32m0.3606[0m       0.3312      0.5096        0.6058        0.0000  10.8540
      4      0.7645        [32m0.3356[0m       [35m0.3457[0m      0.4990        0.6074        0.0000  10.9234
      5      [36m0.8120[0m        [32m0.3249[0m       0.3319      0.5143        0.6094        0.0000  10.7203
      6      0.7647        [32m0.3064[0m       [35m0.3554[0m      [31m0.5388[0m        0.6093        0.0000  10.6270
      7      [36m0.8796[0m        [32m0.2910[0m       [35m0.3594[0m      [31m0.5488[0m        0.6092        0.0000  10.8438
      8      [36m0.8804[0m        0.3019       0.3592      [31m0.5526[0m        0.6106        0.0000  10.8189
      9      0.8526        [32m0.2829[0m       0.3557      0.5506        0.6092        0.0000  11.0158
     10      0.8050        0.2849       [35m0.3609[0m      0.5491        0.6122        0.0000  10.8012
     11      [36m0.9327[0m        [32m0.2702[0m       [35m0.3618[0m      0.5497        0.6130        0.0000  10.9321
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.57523719909041
F1 Macro Score after query 2: 0.571356123546069
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6820[0m        [32m0.4066[0m       [35m0.2635[0m      [31m0.4965[0m        [94m0.6354[0m     +  0.0000  11.2493
      2      [36m0.7126[0m        [32m0.3352[0m       [35m0.3267[0m      0.4788        [94m0.6280[0m     +  0.0000  10.9106
      3      [36m0.7481[0m        [32m0.2971[0m       [35m0.3293[0m      0.4819        [94m0.6228[0m     +  0.0000  11.2632
      4      [36m0.8682[0m        [32m0.2721[0m       0.3224      [31m0.5051[0m        [94m0.6210[0m     +  0.0000  10.9960
      5      [36m0.9429[0m        [32m0.2577[0m       [35m0.3424[0m      [31m0.5169[0m        0.6217        0.0000  11.0470
      6      [36m0.9849[0m        [32m0.2477[0m       0.3245      [31m0.5227[0m        [94m0.6195[0m     +  0.0000  10.8352
      7      0.9610        [32m0.2385[0m       0.3139      [31m0.5260[0m        0.6207        0.0000  10.8572
      8      0.9761        [32m0.2359[0m       0.3144      0.5241        0.6211        0.0000  10.9829
      9      0.9704        [32m0.2327[0m       0.3120      [31m0.5275[0m        0.6223        0.0000  10.9693
     10      0.9778        [32m0.2286[0m       0.3135      [31m0.5282[0m        0.6218        0.0000  11.0008
     11      0.9761        [32m0.2266[0m       0.3153      [31m0.5282[0m        0.6226        0.0000  10.5902
     12      0.9778        [32m0.2228[0m       0.3172      0.5276        0.6216        0.0000  10.9463
     13      0.9687        0.2278       0.3168      [31m0.5286[0m        0.6224        0.0000  11.1682
     14      0.9849        0.2262       0.3187      [31m0.5292[0m        0.6229        0.0000  11.0313
     15      0.9849        [32m0.2176[0m       0.3160      [31m0.5311[0m        0.6223        0.0000  10.9684
     16      0.9832        0.2253       0.3161      [31m0.5316[0m        0.6226        0.0000  11.0468
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.5649621504711879
F1 Macro Score after query 3: 0.5534822070874139
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8420[0m        [32m0.2549[0m       [35m0.3248[0m      [31m0.5976[0m        [94m0.6269[0m     +  0.0000  11.4863
      2      [36m0.9251[0m        [32m0.2181[0m       [35m0.3531[0m      0.5783        0.6284        0.0000  11.3402
      3      [36m0.9570[0m        [32m0.2125[0m       0.3528      0.5754        [94m0.6259[0m     +  0.0000  11.4008
      4      [36m0.9750[0m        [32m0.2015[0m       [35m0.3540[0m      0.5715        0.6288        0.0000  11.2025
      5      [36m0.9759[0m        [32m0.1918[0m       0.3477      0.5718        0.6264        0.0000  11.6251
      6      0.9759        [32m0.1844[0m       0.3189      0.5698        0.6340        0.0000  11.3434
      7      [36m0.9815[0m        [32m0.1828[0m       0.3205      0.5692        0.6329        0.0000  11.5934
      8      [36m0.9861[0m        0.1863       0.3290      0.5672        0.6345        0.0000  11.2994
      9      0.9807        0.1877       0.3311      0.5679        0.6346        0.0000  11.4003
     10      0.9815        0.1846       0.3307      0.5689        0.6367        0.0000  11.3452
     11      [36m0.9870[0m        [32m0.1814[0m       0.3319      0.5697        0.6344        0.0000  11.3408
     12      0.9870        0.1819       0.3351      0.5690        0.6329        0.0000  11.3464
     13      [36m0.9923[0m        [32m0.1796[0m       0.3328      0.5668        0.6336        0.0000  11.2168
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.5996627813210175
F1 Macro Score after query 4: 0.5937801699698924
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8675[0m        [32m0.2478[0m       [35m0.3214[0m      [31m0.5610[0m        [94m0.6220[0m     +  0.0000  12.0063
      2      [36m0.9066[0m        [32m0.2154[0m       0.3134      [31m0.5678[0m        0.6230        0.0000  11.5358
      3      [36m0.9444[0m        [32m0.2005[0m       0.3031      0.5645        0.6286        0.0000  12.2416
      4      [36m0.9634[0m        [32m0.1921[0m       0.3094      [31m0.5695[0m        0.6280        0.0000  12.2105
      5      [36m0.9684[0m        [32m0.1840[0m       0.3127      [31m0.5700[0m        0.6314        0.0000  12.1331
      6      [36m0.9694[0m        [32m0.1736[0m       0.3151      0.5667        0.6316        0.0000  12.2886
      7      [36m0.9782[0m        [32m0.1717[0m       0.3151      0.5678        0.6305        0.0000  11.9366
      8      0.9751        [32m0.1686[0m       0.3116      [31m0.5711[0m        0.6339        0.0000  11.8351
      9      [36m0.9819[0m        0.1715       0.3181      [31m0.5725[0m        0.6319        0.0000  12.3668
     10      0.9783        [32m0.1655[0m       0.3122      0.5709        0.6318        0.0000  11.7732
     11      0.9752        0.1676       0.3130      0.5723        0.6333        0.0000  12.8049
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.6193870277975767
F1 Macro Score after query 5: 0.6146703096576699
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8891[0m        [32m0.2366[0m       [35m0.3431[0m      [31m0.5874[0m        [94m0.6247[0m     +  0.0000  13.2270
      2      [36m0.9460[0m        [32m0.2036[0m       0.3240      0.5838        0.6269        0.0000  13.4788
      3      [36m0.9579[0m        [32m0.1941[0m       0.3208      0.5842        0.6272        0.0000  13.1964
      4      0.9565        [32m0.1850[0m       0.3222      [31m0.5958[0m        0.6279        0.0000  13.2265
      5      [36m0.9585[0m        [32m0.1789[0m       0.3104      [31m0.5997[0m        0.6323        0.0000  13.4306
      6      [36m0.9714[0m        [32m0.1696[0m       0.3220      [31m0.6012[0m        0.6290        0.0000  13.2130
      7      [36m0.9721[0m        [32m0.1675[0m       0.3229      0.6003        0.6287        0.0000  13.4600
      8      0.9663        [32m0.1650[0m       0.3259      [31m0.6021[0m        0.6289        0.0000  13.2284
      9      [36m0.9725[0m        [32m0.1600[0m       0.3274      0.5997        0.6301        0.0000  13.2129
     10      0.9675        0.1605       0.3241      0.6000        0.6300        0.0000  13.6817
     11      [36m0.9738[0m        [32m0.1589[0m       0.3231      [31m0.6047[0m        0.6311        0.0000  13.1490
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6300340328984685
F1 Macro Score after query 6: 0.6313695481292194
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9256[0m        [32m0.2276[0m       [35m0.3542[0m      [31m0.6013[0m        [94m0.6025[0m     +  0.0000  15.6666
      2      [36m0.9581[0m        [32m0.1908[0m       0.3443      [31m0.6044[0m        [94m0.6003[0m     +  0.0000  15.3695
      3      [36m0.9643[0m        [32m0.1762[0m       0.3318      [31m0.6048[0m        [94m0.5955[0m     +  0.0000  15.3847
      4      0.9643        [32m0.1624[0m       0.3483      0.6046        [94m0.5890[0m     +  0.0000  15.1030
      5      [36m0.9695[0m        [32m0.1573[0m       0.3328      [31m0.6130[0m        [94m0.5873[0m     +  0.0000  15.6221
      6      [36m0.9737[0m        [32m0.1478[0m       0.3349      [31m0.6136[0m        [94m0.5791[0m     +  0.0000  15.2907
      7      [36m0.9769[0m        [32m0.1431[0m       0.3328      [31m0.6156[0m        0.5799        0.0000  15.3372
      8      0.9738        0.1437       0.3304      [31m0.6166[0m        [94m0.5791[0m     +  0.0000  15.5260
      9      0.9746        [32m0.1422[0m       0.3378      [31m0.6213[0m        [94m0.5763[0m     +  0.0000  15.3845
     10      [36m0.9795[0m        [32m0.1369[0m       0.3295      0.6166        0.5809        0.0000  15.4477
     11      0.9767        [32m0.1331[0m       0.3323      [31m0.6261[0m        0.5783        0.0000  15.3842
     12      0.9794        0.1331       0.3387      [31m0.6280[0m        [94m0.5760[0m     +  0.0000  15.5711
     13      0.9789        [32m0.1328[0m       0.3347      0.6251        0.5775        0.0000  15.4487
     14      [36m0.9810[0m        [32m0.1293[0m       0.3382      0.6278        0.5765        0.0000  15.4926
     15      [36m0.9814[0m        0.1296       0.3337      0.6258        0.5786        0.0000  15.3843
     16      0.9809        [32m0.1286[0m       0.3392      [31m0.6290[0m        [94m0.5756[0m     +  0.0000  15.4427
     17      [36m0.9820[0m        [32m0.1278[0m       0.3384      0.6282        0.5763        0.0000  15.4471
     18      0.9815        0.1291       0.3394      0.6277        0.5761        0.0000  15.3333
     19      0.9807        [32m0.1277[0m       0.3380      0.6273        0.5762        0.0000  15.2898
     20      0.9795        [32m0.1276[0m       0.3391      [31m0.6294[0m        0.5761        0.0000  15.5231
     21      0.9808        0.1283       0.3405      [31m0.6337[0m        [94m0.5754[0m     +  0.0000  15.4000
     22      [36m0.9840[0m        [32m0.1265[0m       0.3406      0.6335        [94m0.5753[0m     +  0.0000  15.5714
     23      0.9809        0.1288       0.3391      0.6311        0.5757        0.0000  14.8978
     24      0.9822        [32m0.1264[0m       0.3401      0.6330        0.5759        0.0000  15.3691
     25      0.9794        [32m0.1255[0m       0.3401      0.6330        0.5755        0.0000  15.4003
     26      0.9836        [32m0.1247[0m       0.3399      0.6331        0.5753        0.0000  15.4457
     27      0.9794        0.1271       0.3403      0.6335        [94m0.5753[0m     +  0.0000  15.2887
     28      0.9815        0.1258       0.3410      [31m0.6339[0m        [94m0.5752[0m     +  0.0000  15.4169
     29      0.9809        0.1268       0.3405      0.6335        0.5753        0.0000  15.6839
     30      0.9789        0.1274       0.3403      0.6336        0.5755        0.0000  15.8215
     31      0.9820        0.1264       0.3408      [31m0.6340[0m        0.5753        0.0000  15.4006
     32      0.9822        0.1271       0.3408      0.6338        0.5753        0.0000  15.1504
     33      0.9809        0.1256       0.3405      0.6337        0.5754        0.0000  15.3373
     34      0.9813        0.1248       0.3413      [31m0.6343[0m        0.5753        0.0000  15.7441
     35      0.9816        0.1250       0.3411      0.6339        0.5753        0.0000  15.7754
     36      0.9813        0.1258       0.3411      0.6340        0.5752        0.0000  15.7448
     37      0.9816        0.1256       0.3417      0.6341        0.5752        0.0000  15.6817
     38      0.9822        0.1284       0.3413      0.6339        0.5752        0.0000  15.5561
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.6524011988569038
F1 Macro Score after query 7: 0.6553794038136439
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9452[0m        [32m0.1631[0m       [35m0.5719[0m      [31m0.6772[0m        [94m0.4432[0m     +  0.0000  19.2789
      2      [36m0.9577[0m        [32m0.1388[0m       [35m0.6243[0m      [31m0.7627[0m        [94m0.3966[0m     +  0.0000  19.5372
      3      [36m0.9608[0m        [32m0.1261[0m       [35m0.6418[0m      [31m0.7958[0m        [94m0.3720[0m     +  0.0000  19.1855
      4      [36m0.9646[0m        [32m0.1174[0m       [35m0.6476[0m      [31m0.8037[0m        [94m0.3646[0m     +  0.0000  19.4059
      5      0.9629        [32m0.1105[0m       0.6413      0.7999        0.3665        0.0000  19.2343
      6      [36m0.9702[0m        [32m0.1033[0m       0.6193      0.7704        0.3894        0.0000  19.2618
      7      [36m0.9717[0m        [32m0.1013[0m       0.6241      0.7737        0.3868        0.0000  19.0669
      8      [36m0.9730[0m        [32m0.0989[0m       0.6276      0.7793        0.3815        0.0000  19.3181
      9      [36m0.9763[0m        [32m0.0952[0m       0.6290      0.7814        0.3800        0.0000  18.9248
     10      0.9740        [32m0.0948[0m       0.6326      0.7833        0.3810        0.0000  19.0788
     11      0.9746        [32m0.0908[0m       0.6266      0.7745        0.3829        0.0000  19.1348
     12      [36m0.9780[0m        [32m0.0898[0m       0.6267      0.7736        0.3852        0.0000  19.0149
     13      0.9766        [32m0.0878[0m       0.6262      0.7742        0.3844        0.0000  19.2450
     14      0.9768        [32m0.0876[0m       0.6253      0.7757        0.3833        0.0000  19.3504
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.81136689434185
F1 Macro Score after query 8: 0.8124655064526429
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9591[0m        [32m0.1516[0m       [35m0.6411[0m      [31m0.8245[0m        [94m0.3441[0m     +  0.0000  26.0683
      2      [36m0.9717[0m        [32m0.1261[0m       [35m0.6578[0m      [31m0.8404[0m        [94m0.3125[0m     +  0.0000  25.9737
      3      [36m0.9748[0m        [32m0.1151[0m       [35m0.6762[0m      [31m0.8475[0m        [94m0.3053[0m     +  0.0000  25.9688
      4      [36m0.9761[0m        [32m0.1081[0m       [35m0.6800[0m      [31m0.8479[0m        [94m0.3009[0m     +  0.0000  26.2311
      5      0.9758        [32m0.0997[0m       [35m0.7071[0m      [31m0.8592[0m        [94m0.2850[0m     +  0.0000  26.1022
      6      [36m0.9804[0m        [32m0.0915[0m       0.7068      0.8572        0.2902        0.0000  26.0310
      7      [36m0.9809[0m        [32m0.0886[0m       [35m0.7182[0m      [31m0.8598[0m        0.2870        0.0000  26.0469
      8      [36m0.9814[0m        [32m0.0870[0m       0.7132      0.8584        0.2914        0.0000  26.0002
      9      [36m0.9821[0m        [32m0.0830[0m       [35m0.7196[0m      [31m0.8598[0m        0.2877        0.0000  26.1423
     10      [36m0.9823[0m        [32m0.0808[0m       [35m0.7201[0m      0.8590        0.2888        0.0000  26.0164
     11      [36m0.9847[0m        [32m0.0779[0m       0.7135      0.8541        0.2945        0.0000  26.0278
     12      0.9832        [32m0.0764[0m       0.7196      0.8549        0.2917        0.0000  26.4999
     13      0.9846        [32m0.0756[0m       [35m0.7231[0m      0.8563        0.2909        0.0000  26.2587
     14      0.9846        [32m0.0745[0m       [35m0.7309[0m      0.8583        0.2874        0.0000  26.4406
     15      [36m0.9855[0m        [32m0.0725[0m       0.7266      0.8581        0.2906        0.0000  26.2218
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8718259683165315
F1 Macro Score after query 9: 0.8679852620313951
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9732[0m        [32m0.1260[0m       [35m0.5687[0m      [31m0.8117[0m        [94m0.3296[0m     +  0.0000  38.4559
      2      [36m0.9792[0m        [32m0.1054[0m       [35m0.6045[0m      [31m0.8206[0m        [94m0.3130[0m     +  0.0000  38.5908
      3      [36m0.9816[0m        [32m0.0964[0m       [35m0.6062[0m      [31m0.8250[0m        [94m0.3117[0m     +  0.0000  38.3652
      4      [36m0.9827[0m        [32m0.0882[0m       [35m0.6286[0m      [31m0.8280[0m        [94m0.2979[0m     +  0.0000  38.3407
      5      [36m0.9846[0m        [32m0.0800[0m       [35m0.6552[0m      [31m0.8363[0m        [94m0.2924[0m     +  0.0000  38.3312
      6      [36m0.9854[0m        [32m0.0712[0m       [35m0.7255[0m      [31m0.8587[0m        [94m0.2600[0m     +  0.0000  38.0203
      7      [36m0.9869[0m        [32m0.0684[0m       [35m0.7300[0m      [31m0.8593[0m        0.2681        0.0000  38.0502
      8      [36m0.9871[0m        [32m0.0650[0m       0.7226      0.8585        0.2692        0.0000  38.1812
      9      [36m0.9876[0m        [32m0.0632[0m       0.7260      0.8590        0.2728        0.0000  38.1778
     10      [36m0.9881[0m        [32m0.0616[0m       0.7290      0.8591        0.2775        0.0000  38.0485
     11      [36m0.9890[0m        [32m0.0580[0m       0.7210      0.8567        0.2888        0.0000  38.5160
     12      [36m0.9895[0m        [32m0.0562[0m       0.7201      0.8559        0.2923        0.0000  38.3280
     13      [36m0.9904[0m        [32m0.0552[0m       0.7196      0.8557        0.2921        0.0000  38.4840
     14      0.9902        [32m0.0541[0m       0.7172      0.8553        0.2970        0.0000  38.4399
     15      [36m0.9907[0m        [32m0.0523[0m       0.7217      0.8566        0.2964        0.0000  38.0448
     16      [36m0.9910[0m        [32m0.0504[0m       0.7257      0.8572        0.2969        0.0000  37.9145
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.875435863194599
F1 Macro Score after query 10: 0.8727609920299177
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9768[0m        [32m0.1041[0m       [35m0.7884[0m      [31m0.8698[0m        [94m0.2154[0m     +  0.0000  59.7819
      2      [36m0.9809[0m        [32m0.0866[0m       [35m0.8019[0m      [31m0.8778[0m        [94m0.2090[0m     +  0.0000  60.5789
      3      [36m0.9826[0m        [32m0.0772[0m       [35m0.8040[0m      [31m0.8806[0m        [94m0.2089[0m     +  0.0000  60.3453
      4      [36m0.9844[0m        [32m0.0699[0m       [35m0.8073[0m      [31m0.8811[0m        0.2131        0.0000  60.2358
      5      [36m0.9853[0m        [32m0.0648[0m       0.7894      0.8680        0.2221        0.0000  60.3690
      6      [36m0.9872[0m        [32m0.0561[0m       0.8021      0.8804        0.2231        0.0000  60.4212
      7      [36m0.9885[0m        [32m0.0534[0m       0.8003      0.8772        0.2252        0.0000  60.3278
      8      [36m0.9893[0m        [32m0.0503[0m       0.8038      0.8762        0.2265        0.0000  60.1339
      9      [36m0.9901[0m        [32m0.0478[0m       0.8049      0.8764        0.2194        0.0000  60.1902
     10      [36m0.9908[0m        [32m0.0450[0m       [35m0.8082[0m      [31m0.8833[0m        0.2241        0.0000  59.8242
     11      [36m0.9915[0m        [32m0.0420[0m       0.8057      [31m0.8889[0m        0.2291        0.0000  60.3110
     12      [36m0.9919[0m        [32m0.0404[0m       0.8033      0.8869        0.2289        0.0000  60.2217
     13      [36m0.9924[0m        [32m0.0389[0m       0.8016      0.8869        0.2352        0.0000  61.1125
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.9098692403486924
F1 Macro Score after query 11: 0.899897112482357
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9758[0m        [32m0.0742[0m       [35m0.7705[0m      [31m0.8639[0m        [94m0.2383[0m     +  0.0000  98.6263
      2      [36m0.9803[0m        [32m0.0594[0m       [35m0.8158[0m      [31m0.8825[0m        [94m0.2079[0m     +  0.0000  99.5541
      3      [36m0.9828[0m        [32m0.0512[0m       [35m0.8276[0m      [31m0.8852[0m        [94m0.2043[0m     +  0.0000  97.9984
      4      [36m0.9836[0m        [32m0.0458[0m       0.8210      0.8722        0.2106        0.0000  99.1742
      5      [36m0.9851[0m        [32m0.0410[0m       0.8028      0.8637        0.2362        0.0000  99.3595
      6      [36m0.9881[0m        [32m0.0342[0m       0.8149      0.8692        0.2307        0.0000  99.3013
      7      [36m0.9889[0m        [32m0.0314[0m       0.8097      0.8641        0.2404        0.0000  99.2380
      8      [36m0.9903[0m        [32m0.0292[0m       0.8146      0.8732        0.2403        0.0000  99.4848
      9      [36m0.9909[0m        [32m0.0269[0m       0.8073      0.8688        0.2497        0.0000  98.9500
     10      [36m0.9918[0m        [32m0.0248[0m       0.8215      0.8793        0.2446        0.0000  99.8489
     11      [36m0.9927[0m        [32m0.0231[0m       0.8149      0.8820        0.2493        0.0000  99.8123
     12      [36m0.9937[0m        [32m0.0216[0m       0.8115      0.8812        0.2582        0.0000  99.2857
     13      [36m0.9941[0m        [32m0.0204[0m       0.8181      0.8837        0.2556        0.0000  98.5025
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.918986160783704
F1 Macro Score after query 12: 0.9062339918823823
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9828[0m        [32m0.0428[0m       [35m0.8220[0m      [31m0.8653[0m        [94m0.2310[0m     +  0.0000  113.7594
      2      [36m0.9841[0m        [32m0.0379[0m       0.8092      0.8646        0.2457        0.0000  114.2916
      3      [36m0.9851[0m        [32m0.0340[0m       0.7884      0.8508        0.2712        0.0000  114.6953
      4      [36m0.9862[0m        [32m0.0313[0m       0.7981      0.8549        0.2671        0.0000  114.6588
      5      [36m0.9873[0m        [32m0.0281[0m       0.7872      0.8350        0.2909        0.0000  115.3648
      6      [36m0.9900[0m        [32m0.0234[0m       0.8155      [31m0.8745[0m        0.2405        0.0000  116.9584
      7      [36m0.9910[0m        [32m0.0209[0m       0.8118      0.8687        0.2675        0.0000  115.2073
      8      [36m0.9920[0m        [32m0.0192[0m       0.8210      [31m0.8777[0m        0.2630        0.0000  116.2801
      9      [36m0.9931[0m        [32m0.0174[0m       0.8181      0.8764        0.2765        0.0000  114.9985
     10      [36m0.9938[0m        [32m0.0161[0m       0.8172      0.8771        0.2769        0.0000  115.6075
     11      [36m0.9945[0m        [32m0.0145[0m       0.8179      [31m0.8844[0m        0.2841        0.0000  114.5655
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.9143883768161225
F1 Macro Score after query 13: 0.9037385037722188
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed43_lowLR\AL_max_score_results_for_multilabel_classification_s43.pickle
