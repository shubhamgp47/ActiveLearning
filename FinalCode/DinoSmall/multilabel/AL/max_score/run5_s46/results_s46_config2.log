Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5556[0m        [32m0.6869[0m       [35m0.2349[0m      [31m0.5648[0m        [94m0.6892[0m     +  0.0001  11.3871
      2      [36m0.6313[0m        0.6994       0.0997      0.3476        [94m0.6785[0m     +  0.0001  9.5326
      3      0.5945        [32m0.6623[0m       0.1566      0.4336        [94m0.6757[0m     +  0.0001  9.4823
      4      [36m0.7130[0m        [32m0.5900[0m       [35m0.2663[0m      0.3519        [94m0.6747[0m     +  0.0001  9.6281
      5      [36m0.8796[0m        0.6231       0.1536      0.5009        0.7018        0.0001  9.8024
      6      0.6985        0.6312       0.1727      0.4538        0.6888        0.0000  9.6741
      7      0.8130        0.6034       0.2568      0.4692        0.6791        0.0000  9.6571
      8      0.7857        [32m0.5544[0m       0.2562      0.4766        0.6772        0.0000  9.7065
      9      0.7424        [32m0.5443[0m       0.2564      0.4699        [94m0.6719[0m     +  0.0000  9.6966
     10      0.7857        [32m0.5361[0m       [35m0.2686[0m      0.4721        [94m0.6710[0m     +  0.0000  9.7678
     11      0.7500        0.5526       [35m0.2759[0m      0.4746        [94m0.6704[0m     +  0.0000  9.8610
     12      0.8333        [32m0.5334[0m       0.2747      0.4741        0.6718        0.0000  9.7939
     13      0.6905        0.5616       0.2738      0.4740        0.6723        0.0000  9.8530
     14      0.7500        0.5547       0.2736      0.4726        0.6712        0.0000  9.8812
     15      0.7857        [32m0.5206[0m       [35m0.2766[0m      0.4738        0.6714        0.0000  9.8713
     16      0.8426        [32m0.4995[0m       0.2759      0.4721        0.6707        0.0000  9.8494
     17      0.7857        0.5310       0.2759      0.4730        0.6708        0.0000  9.9378
     18      0.8333        0.5341       0.2760      0.4723        [94m0.6704[0m     +  0.0000  9.8991
     19      0.7857        0.5084       [35m0.2767[0m      0.4746        [94m0.6703[0m     +  0.0000  9.8689
     20      0.7963        [32m0.4736[0m       0.2767      0.4747        [94m0.6702[0m     +  0.0000  9.9525
     21      0.7857        0.5279       0.2753      0.4744        0.6703        0.0000  9.9751
     22      0.8796        0.5139       0.2759      0.4732        [94m0.6700[0m     +  0.0000  9.8376
     23      0.7685        0.5104       0.2757      0.4727        [94m0.6700[0m     +  0.0000  9.9746
     24      0.7222        0.5279       0.2752      0.4741        0.6703        0.0000  9.8753
     25      0.7857        0.5278       0.2755      0.4739        0.6702        0.0000  9.9939
     26      0.7857        0.5162       0.2753      0.4739        0.6701        0.0000  9.9072
     27      0.8333        0.5214       0.2752      0.4736        0.6701        0.0000  9.8983
     28      0.8333        0.4963       0.2752      0.4741        0.6701        0.0000  9.9283
     29      0.7667        0.5383       0.2748      0.4741        0.6701        0.0000  9.8610
     30      0.8426        0.5036       0.2748      0.4744        0.6701        0.0000  9.8817
     31      0.7857        0.4833       0.2748      0.4744        0.6701        0.0000  9.9222
     32      0.7963        0.5281       0.2750      0.4744        0.6701        0.0000  10.0078
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4928
Pre F1 macro score = 0.4914
Pre Accuracy = 0.3075

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.7647[0m        [32m0.4554[0m       [35m0.2085[0m      [31m0.4227[0m        [94m0.7478[0m     +  0.0001  9.9943
      2      0.7468        [32m0.4072[0m       [35m0.2580[0m      [31m0.5007[0m        [94m0.7399[0m     +  0.0001  9.9700
      3      [36m0.8238[0m        [32m0.3413[0m       0.2304      [31m0.5014[0m        0.7574        0.0001  9.9654
      4      0.8238        0.3456       [35m0.2589[0m      0.4946        0.7404        0.0001  9.9398
      5      [36m0.8641[0m        [32m0.2765[0m       0.2479      [31m0.5105[0m        [94m0.7393[0m     +  0.0001  9.9906
      6      [36m0.8800[0m        0.2821       0.2365      0.5045        0.7399        0.0000  9.9217
      7      [36m0.9085[0m        [32m0.2630[0m       0.2446      0.5010        [94m0.7324[0m     +  0.0000  9.9586
      8      0.9000        0.2713       0.2406      0.5020        [94m0.7314[0m     +  0.0000  9.9623
      9      [36m0.9392[0m        [32m0.2615[0m       0.2519      0.4879        [94m0.7206[0m     +  0.0000  9.9503
     10      0.9081        [32m0.2395[0m       0.2437      0.4920        0.7218        0.0000  9.9374
     11      [36m0.9471[0m        0.2402       0.2436      0.4926        0.7212        0.0000  9.8952
     12      0.9471        [32m0.2224[0m       0.2493      0.4936        [94m0.7168[0m     +  0.0000  10.0425
     13      [36m0.9556[0m        0.2422       0.2436      0.4923        [94m0.7164[0m     +  0.0000  9.9539
     14      [36m0.9667[0m        0.2253       0.2436      0.4912        [94m0.7135[0m     +  0.0000  9.9538
     15      0.9641        0.2288       0.2411      0.4894        [94m0.7122[0m     +  0.0000  9.9650
     16      0.9667        [32m0.2200[0m       0.2417      0.4890        [94m0.7116[0m     +  0.0000  9.8904
     17      0.9467        [32m0.2069[0m       0.2424      0.4894        [94m0.7109[0m     +  0.0000  9.9030
     18      0.9637        0.2075       0.2418      0.4902        0.7113        0.0000  9.9217
     19      [36m0.9723[0m        0.2115       0.2420      0.4893        [94m0.7100[0m     +  0.0000  9.8788
     20      0.9417        0.2210       0.2431      0.4898        [94m0.7095[0m     +  0.0000  9.9957
     21      0.9723        [32m0.1991[0m       0.2420      0.4888        [94m0.7093[0m     +  0.0000  9.9439
     22      0.9331        0.2127       0.2424      0.4893        [94m0.7092[0m     +  0.0000  9.9381
     23      [36m0.9833[0m        [32m0.1779[0m       0.2432      0.4896        [94m0.7091[0m     +  0.0000  9.9627
     24      0.9641        0.2056       0.2432      0.4894        [94m0.7088[0m     +  0.0000  9.9564
     25      0.9556        0.2218       0.2437      0.4893        [94m0.7084[0m     +  0.0000  9.9450
     26      0.9471        0.2210       0.2437      0.4893        [94m0.7084[0m     +  0.0000  9.9999
     27      0.9382        0.2175       0.2436      0.4892        [94m0.7083[0m     +  0.0000  10.2968
     28      0.9833        0.2198       0.2436      0.4892        [94m0.7081[0m     +  0.0000  10.2044
     29      0.9637        0.2232       0.2436      0.4892        [94m0.7079[0m     +  0.0000  10.0440
     30      0.9752        0.2064       0.2436      0.4890        [94m0.7077[0m     +  0.0000  10.0744
     31      [36m0.9837[0m        0.2067       0.2436      0.4890        [94m0.7076[0m     +  0.0000  9.9842
     32      0.9833        0.2196       0.2436      0.4890        0.7076        0.0000  9.9862
     33      0.9556        0.2309       0.2434      0.4890        [94m0.7076[0m     +  0.0000  10.0402
     34      0.9637        0.2184       0.2434      0.4890        [94m0.7076[0m     +  0.0000  10.0318
     35      0.9658        0.2080       0.2434      0.4890        [94m0.7076[0m     +  0.0000  10.0302
     36      0.9556        0.2078       0.2434      0.4890        [94m0.7076[0m     +  0.0000  10.0163
     37      0.9833        0.1980       0.2434      0.4890        [94m0.7076[0m     +  0.0000  10.0479
     38      0.9641        0.2084       0.2434      0.4890        [94m0.7075[0m     +  0.0000  9.9779
     39      0.9837        0.1994       0.2434      0.4890        [94m0.7075[0m     +  0.0000  9.9823
     40      0.9556        0.2196       0.2434      0.4890        [94m0.7075[0m     +  0.0000  10.0440
     41      0.9752        0.2162       0.2434      0.4890        [94m0.7075[0m     +  0.0000  10.0478
     42      0.9417        0.2136       0.2434      0.4890        [94m0.7075[0m     +  0.0000  10.0611
     43      0.9637        0.2131       0.2434      0.4890        0.7075        0.0000  10.0765
     44      [36m0.9919[0m        0.2082       0.2434      0.4890        [94m0.7075[0m     +  0.0000  9.9993
     45      0.9723        0.2088       0.2434      0.4890        [94m0.7075[0m     +  0.0000  10.0310
     46      0.9463        0.2241       0.2434      0.4890        0.7075        0.0000  9.9757
     47      0.9837        0.2007       0.2434      0.4891        [94m0.7075[0m     +  0.0000  10.1343
     48      0.9463        0.2056       0.2434      0.4891        [94m0.7075[0m     +  0.0000  10.0121
     49      0.9641        0.1959       0.2434      0.4891        0.7075        0.0000  10.0467
     50      0.9556        0.2090       0.2434      0.4891        [94m0.7075[0m     +  0.0000  10.0471
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.5286596119929453
F1 Macro Score after query 1: 0.5210713168676743
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9329[0m        [32m0.1934[0m       [35m0.2332[0m      [31m0.4429[0m        [94m0.7780[0m     +  0.0001  10.0745
      2      0.8737        0.1966       [35m0.2562[0m      [31m0.4830[0m        [94m0.7310[0m     +  0.0001  10.0952
      3      0.9329        [32m0.1602[0m       [35m0.2818[0m      [31m0.5048[0m        [94m0.7023[0m     +  0.0001  10.0952
      4      0.9164        [32m0.1492[0m       0.2658      [31m0.5130[0m        0.7106        0.0001  10.0388
      5      [36m0.9394[0m        [32m0.1310[0m       0.2601      [31m0.5253[0m        [94m0.6939[0m     +  0.0001  10.1403
      6      0.9199        0.1331       0.2554      [31m0.5358[0m        0.7111        0.0000  10.1576
      7      0.9302        [32m0.1137[0m       0.2681      [31m0.5367[0m        0.6989        0.0000  10.0718
      8      [36m0.9431[0m        [32m0.1111[0m       0.2679      [31m0.5415[0m        0.6975        0.0000  10.0631
      9      0.9431        [32m0.1018[0m       0.2792      0.5381        [94m0.6837[0m     +  0.0000  10.1089
     10      [36m0.9646[0m        [32m0.0920[0m       0.2743      [31m0.5427[0m        [94m0.6822[0m     +  0.0000  10.0765
     11      0.9524        [32m0.0889[0m       0.2689      [31m0.5451[0m        0.6872        0.0000  10.1116
     12      0.9646        [32m0.0878[0m       0.2703      0.5444        0.6856        0.0000  10.0572
     13      0.9552        0.0914       0.2745      0.5410        [94m0.6794[0m     +  0.0000  10.0961
     14      [36m0.9760[0m        [32m0.0821[0m       0.2741      0.5421        0.6799        0.0000  10.0516
     15      0.9760        0.0854       0.2743      0.5422        0.6798        0.0000  10.0609
     16      0.9552        0.0936       0.2745      0.5424        0.6797        0.0000  10.0837
     17      0.9746        0.0839       0.2743      0.5428        [94m0.6790[0m     +  0.0000  10.0397
     18      0.9646        [32m0.0757[0m       0.2750      0.5437        [94m0.6788[0m     +  0.0000  10.0148
     19      0.9760        0.0860       0.2757      0.5443        [94m0.6786[0m     +  0.0000  10.1032
     20      0.9697        0.0787       0.2767      0.5441        [94m0.6785[0m     +  0.0000  10.0462
     21      0.9556        0.0850       0.2774      0.5443        [94m0.6785[0m     +  0.0000  10.1276
     22      0.9760        0.0897       0.2767      0.5430        [94m0.6783[0m     +  0.0000  10.0836
     23      0.9760        [32m0.0723[0m       0.2764      0.5430        [94m0.6783[0m     +  0.0000  10.0963
     24      [36m0.9778[0m        0.0748       0.2760      0.5428        [94m0.6782[0m     +  0.0000  10.0940
     25      0.9760        0.0798       0.2767      0.5429        [94m0.6781[0m     +  0.0000  10.1338
     26      0.9760        0.0774       0.2766      0.5429        [94m0.6780[0m     +  0.0000  10.0242
     27      [36m0.9861[0m        0.0759       0.2769      0.5431        0.6781        0.0000  10.0730
     28      0.9861        [32m0.0718[0m       0.2773      0.5433        0.6781        0.0000  10.0718
     29      0.9646        0.0816       0.2773      0.5435        [94m0.6780[0m     +  0.0000  10.1433
     30      0.9760        [32m0.0715[0m       0.2773      0.5437        0.6780        0.0000  10.0942
     31      0.9665        0.0747       0.2773      0.5437        0.6780        0.0000  10.0324
     32      0.9760        0.0794       0.2773      0.5438        0.6780        0.0000  10.0771
     33      [36m0.9867[0m        0.0801       0.2774      0.5438        [94m0.6779[0m     +  0.0000  10.0475
     34      0.9861        0.0760       0.2774      0.5438        0.6780        0.0000  10.0933
     35      0.9746        0.0759       0.2774      0.5438        [94m0.6779[0m     +  0.0000  10.1006
     36      [36m0.9892[0m        0.0730       0.2774      0.5438        0.6779        0.0000  10.0383
     37      0.9646        0.0796       0.2774      0.5439        0.6780        0.0000  10.0469
     38      0.9867        [32m0.0710[0m       0.2774      0.5439        0.6779        0.0000  10.0626
     39      [36m0.9968[0m        0.0713       0.2774      0.5439        [94m0.6779[0m     +  0.0000  10.0790
     40      0.9760        0.0862       0.2774      0.5439        [94m0.6779[0m     +  0.0000  10.0341
     41      0.9892        0.0758       0.2774      0.5439        0.6779        0.0000  10.0773
     42      0.9892        0.0724       0.2774      0.5439        0.6779        0.0000  10.2051
     43      0.9746        0.0772       0.2774      0.5439        0.6779        0.0000  10.0917
     44      0.9892        [32m0.0710[0m       0.2774      0.5439        0.6779        0.0000  10.0508
     45      0.9760        0.0798       0.2774      0.5439        0.6779        0.0000  10.0861
     46      0.9697        0.0814       0.2774      0.5439        0.6779        0.0000  10.0449
     47      0.9830        0.0792       0.2774      0.5439        0.6779        0.0000  10.0937
     48      [36m1.0000[0m        0.0731       0.2774      0.5439        0.6779        0.0000  10.0502
     49      0.9746        0.0743       0.2774      0.5439        0.6779        0.0000  10.1109
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.6076005630046671
F1 Macro Score after query 2: 0.5984072192882589
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8957[0m        [32m0.2228[0m       [35m0.2601[0m      [31m0.5933[0m        [94m1.1320[0m     +  0.0001  10.1579
      2      [36m0.9239[0m        [32m0.1948[0m       [35m0.2875[0m      [31m0.5987[0m        [94m0.8306[0m     +  0.0001  10.1657
      3      [36m0.9586[0m        [32m0.1469[0m       0.2819      0.5809        [94m0.7771[0m     +  0.0001  10.1176
      4      [36m0.9601[0m        [32m0.1268[0m       0.2771      0.5606        [94m0.7453[0m     +  0.0001  10.2194
      5      [36m0.9713[0m        [32m0.1044[0m       0.2719      0.5487        [94m0.7305[0m     +  0.0001  10.2350
      6      [36m0.9724[0m        [32m0.0902[0m       0.2802      0.5402        [94m0.7287[0m     +  0.0000  10.1435
      7      [36m0.9797[0m        0.0906       0.2823      0.5450        0.7330        0.0000  10.2126
      8      0.9739        [32m0.0891[0m       0.2844      0.5420        0.7298        0.0000  10.1828
      9      0.9751        [32m0.0817[0m       [35m0.2887[0m      0.5440        0.7344        0.0000  10.1730
     10      0.9766        [32m0.0807[0m       [35m0.2936[0m      0.5509        0.7353        0.0000  10.2081
     11      0.9751        [32m0.0789[0m       0.2915      0.5479        0.7330        0.0000  10.2355
     12      0.9797        [32m0.0747[0m       [35m0.2944[0m      0.5513        0.7360        0.0000  10.2518
     13      0.9766        0.0762       [35m0.2955[0m      0.5515        0.7365        0.0000  10.1437
     14      0.9797        0.0775       0.2931      0.5515        0.7364        0.0000  10.1567
     15      [36m0.9828[0m        [32m0.0713[0m       0.2922      0.5508        0.7369        0.0000  10.1212
     16      0.9766        0.0741       0.2917      0.5496        0.7368        0.0000  10.1479
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.6013791079812207
F1 Macro Score after query 3: 0.5862219595328496
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9504[0m        [32m0.1555[0m       [35m0.2465[0m      [31m0.5903[0m        [94m0.9371[0m     +  0.0001  10.3386
      2      [36m0.9719[0m        [32m0.1021[0m       [35m0.2658[0m      0.5130        [94m0.7972[0m     +  0.0001  10.3500
      3      [36m0.9819[0m        [32m0.0943[0m       [35m0.2720[0m      0.5357        0.7994        0.0001  10.3123
      4      0.9791        [32m0.0846[0m       0.2472      0.5385        0.8176        0.0001  10.3432
      5      0.9819        [32m0.0793[0m       0.2578      0.5407        0.8195        0.0001  10.3427
      6      0.9768        [32m0.0703[0m       0.2569      0.5552        0.8354        0.0000  10.3417
      7      0.9817        [32m0.0697[0m       0.2542      0.5537        0.8353        0.0000  10.3051
      8      0.9819        0.0700       0.2668      0.5469        0.8176        0.0000  10.3919
      9      0.9791        0.0705       0.2599      0.5463        0.8261        0.0000  10.3768
     10      0.9819        [32m0.0640[0m       0.2646      0.5370        0.8070        0.0000  10.4048
     11      0.9819        [32m0.0613[0m       0.2622      0.5402        0.8126        0.0000  10.3413
     12      0.9819        0.0652       0.2681      0.5431        0.8142        0.0000  10.4478
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.5882603147596767
F1 Macro Score after query 4: 0.5696054588366958
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9339[0m        [32m0.1588[0m       [35m0.2403[0m      [31m0.5636[0m        [94m0.8899[0m     +  0.0001  11.1878
      2      [36m0.9493[0m        [32m0.1229[0m       0.2366      0.4691        [94m0.7510[0m     +  0.0001  10.6518
      3      [36m0.9610[0m        [32m0.1038[0m       [35m0.2986[0m      0.4770        [94m0.7214[0m     +  0.0001  10.6692
      4      [36m0.9674[0m        [32m0.1018[0m       [35m0.2995[0m      0.4909        [94m0.7119[0m     +  0.0001  10.6967
      5      [36m0.9714[0m        [32m0.0940[0m       [35m0.3181[0m      0.5127        [94m0.7006[0m     +  0.0001  10.8133
      6      [36m0.9748[0m        [32m0.0808[0m       0.3035      0.5393        0.7201        0.0000  10.7357
      7      0.9739        [32m0.0740[0m       0.3028      0.5463        0.7241        0.0000  10.7021
      8      [36m0.9756[0m        [32m0.0736[0m       0.3120      0.5513        0.7244        0.0000  10.7168
      9      [36m0.9767[0m        [32m0.0706[0m       0.3085      0.5415        0.7114        0.0000  10.6936
     10      [36m0.9775[0m        0.0716       [35m0.3187[0m      0.5551        0.7182        0.0000  10.7168
     11      0.9767        [32m0.0644[0m       0.3168      [31m0.5654[0m        0.7214        0.0000  10.6537
     12      [36m0.9781[0m        [32m0.0633[0m       0.3170      [31m0.5682[0m        0.7245        0.0000  10.6876
     13      [36m0.9782[0m        0.0650       0.3168      0.5652        0.7221        0.0000  10.7343
     14      [36m0.9799[0m        [32m0.0615[0m       [35m0.3191[0m      [31m0.5682[0m        0.7211        0.0000  10.7139
     15      [36m0.9809[0m        [32m0.0597[0m       0.3141      [31m0.5742[0m        0.7251        0.0000  10.6648
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.620574126246859
F1 Macro Score after query 5: 0.6036093456390499
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9648[0m        [32m0.0987[0m       [35m0.2401[0m      [31m0.5889[0m        [94m0.8608[0m     +  0.0001  11.2931
      2      [36m0.9748[0m        [32m0.0791[0m       [35m0.2519[0m      0.5767        [94m0.8139[0m     +  0.0001  11.2480
      3      [36m0.9792[0m        [32m0.0704[0m       [35m0.2615[0m      0.5721        [94m0.7859[0m     +  0.0001  11.1914
      4      [36m0.9805[0m        [32m0.0659[0m       [35m0.2646[0m      0.5712        [94m0.7849[0m     +  0.0001  11.2178
      5      [36m0.9811[0m        [32m0.0599[0m       0.2608      0.5866        [94m0.7773[0m     +  0.0001  11.1351
      6      [36m0.9829[0m        [32m0.0505[0m       [35m0.2687[0m      0.5744        [94m0.7620[0m     +  0.0000  11.1980
      7      [36m0.9856[0m        [32m0.0497[0m       0.2625      0.5795        [94m0.7600[0m     +  0.0000  11.2124
      8      0.9849        [32m0.0479[0m       0.2641      0.5792        [94m0.7522[0m     +  0.0000  11.1675
      9      0.9853        [32m0.0471[0m       [35m0.2727[0m      0.5835        [94m0.7417[0m     +  0.0000  11.1955
     10      0.9845        0.0488       0.2701      0.5828        0.7424        0.0000  11.1324
     11      0.9854        [32m0.0424[0m       0.2660      0.5831        0.7455        0.0000  11.1806
     12      [36m0.9862[0m        [32m0.0418[0m       0.2694      0.5834        [94m0.7406[0m     +  0.0000  11.2140
     13      0.9849        0.0428       0.2684      0.5857        [94m0.7372[0m     +  0.0000  11.1804
     14      [36m0.9863[0m        [32m0.0414[0m       0.2700      0.5858        [94m0.7369[0m     +  0.0000  11.3053
     15      0.9853        [32m0.0411[0m       0.2687      0.5867        0.7386        0.0000  11.1631
     16      0.9858        [32m0.0399[0m       0.2705      [31m0.5917[0m        0.7389        0.0000  11.1148
     17      0.9863        [32m0.0390[0m       0.2710      [31m0.5941[0m        0.7403        0.0000  11.1014
     18      0.9858        0.0393       0.2707      0.5925        0.7388        0.0000  11.1785
     19      [36m0.9867[0m        0.0391       0.2696      0.5907        0.7374        0.0000  11.1639
     20      0.9862        [32m0.0388[0m       0.2694      0.5928        0.7387        0.0000  11.1940
     21      0.9867        [32m0.0387[0m       0.2705      [31m0.5943[0m        0.7390        0.0000  11.1487
     22      0.9858        [32m0.0387[0m       0.2712      [31m0.5944[0m        0.7388        0.0000  11.2455
     23      0.9863        0.0397       0.2712      [31m0.5949[0m        0.7390        0.0000  11.1333
     24      0.9860        [32m0.0361[0m       0.2707      [31m0.5960[0m        0.7406        0.0000  11.2110
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6448329276388581
F1 Macro Score after query 6: 0.6319436000973658
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9592[0m        [32m0.1008[0m       [35m0.3024[0m      [31m0.6531[0m        [94m0.7181[0m     +  0.0001  12.2273
      2      [36m0.9778[0m        [32m0.0648[0m       [35m0.3118[0m      [31m0.6665[0m        [94m0.6888[0m     +  0.0001  12.2123
      3      [36m0.9793[0m        [32m0.0616[0m       [35m0.3299[0m      [31m0.6718[0m        [94m0.6804[0m     +  0.0001  12.3385
      4      0.9789        [32m0.0563[0m       0.3293      0.6648        [94m0.6721[0m     +  0.0001  12.2732
      5      [36m0.9807[0m        [32m0.0554[0m       [35m0.3363[0m      [31m0.6729[0m        0.6816        0.0001  12.2761
      6      [36m0.9844[0m        [32m0.0464[0m       0.3314      0.6707        0.6917        0.0000  12.2752
      7      [36m0.9858[0m        [32m0.0442[0m       0.3352      [31m0.6739[0m        0.6870        0.0000  12.2145
      8      [36m0.9859[0m        [32m0.0420[0m       0.3295      0.6706        0.6992        0.0000  12.3834
      9      [36m0.9873[0m        0.0429       0.3255      0.6637        0.6903        0.0000  12.1516
     10      0.9864        [32m0.0419[0m       0.3241      0.6615        0.6986        0.0000  12.2110
     11      [36m0.9878[0m        [32m0.0389[0m       0.3191      0.6538        0.7009        0.0000  12.2587
     12      [36m0.9882[0m        [32m0.0384[0m       0.3200      0.6544        0.7008        0.0000  12.1632
     13      0.9864        [32m0.0366[0m       0.3184      0.6549        0.7072        0.0000  12.3229
     14      0.9868        0.0374       0.3179      0.6558        0.7091        0.0000  12.2291
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.6864686468646866
F1 Macro Score after query 7: 0.6819473703503737
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9588[0m        [32m0.1179[0m       [35m0.4840[0m      [31m0.7252[0m        [94m0.5703[0m     +  0.0001  14.1353
      2      [36m0.9685[0m        [32m0.0932[0m       0.4470      [31m0.7294[0m        0.5898        0.0001  14.1696
      3      [36m0.9723[0m        [32m0.0803[0m       0.4382      0.7253        0.5842        0.0001  14.1193
      4      [36m0.9752[0m        [32m0.0736[0m       0.4538      0.7191        [94m0.5646[0m     +  0.0001  14.1691
      5      [36m0.9754[0m        [32m0.0699[0m       0.4637      0.7263        0.5664        0.0001  14.0713
      6      [36m0.9810[0m        [32m0.0601[0m       0.4616      0.7172        [94m0.5624[0m     +  0.0000  14.1998
      7      [36m0.9812[0m        [32m0.0580[0m       0.4616      0.7154        0.5713        0.0000  14.2614
      8      [36m0.9814[0m        [32m0.0547[0m       0.4658      0.7096        0.5653        0.0000  14.1349
      9      0.9805        0.0554       0.4700      0.7082        0.5641        0.0000  14.4474
     10      [36m0.9824[0m        [32m0.0531[0m       0.4729      0.7057        0.5629        0.0000  14.1981
     11      [36m0.9829[0m        [32m0.0517[0m       0.4698      0.7016        0.5677        0.0000  14.1964
     12      [36m0.9835[0m        [32m0.0497[0m       0.4726      0.7040        0.5647        0.0000  14.1495
     13      [36m0.9837[0m        [32m0.0480[0m       0.4733      0.7025        0.5653        0.0000  14.1484
     14      0.9830        0.0497       0.4729      0.7002        0.5713        0.0000  14.1540
     15      [36m0.9849[0m        0.0483       0.4771      0.7021        0.5659        0.0000  14.2144
     16      0.9835        0.0489       0.4748      0.7003        0.5686        0.0000  14.0908
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.703554303980516
F1 Macro Score after query 8: 0.7134281065882946
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9762[0m        [32m0.0939[0m       [35m0.4328[0m      [31m0.7097[0m        [94m0.5632[0m     +  0.0001  17.6513
      2      [36m0.9789[0m        [32m0.0831[0m       0.4224      0.6998        0.5957        0.0001  17.5105
      3      [36m0.9795[0m        [32m0.0798[0m       [35m0.4349[0m      0.7092        [94m0.5596[0m     +  0.0001  17.7024
      4      [36m0.9809[0m        [32m0.0772[0m       [35m0.4561[0m      [31m0.7135[0m        [94m0.5290[0m     +  0.0001  17.5746
      5      [36m0.9817[0m        [32m0.0730[0m       0.4415      0.7080        0.5312        0.0001  17.5127
      6      [36m0.9825[0m        [32m0.0669[0m       [35m0.4688[0m      [31m0.7163[0m        0.5389        0.0000  17.4817
      7      [36m0.9831[0m        [32m0.0645[0m       [35m0.4797[0m      [31m0.7195[0m        0.5342        0.0000  17.5251
      8      [36m0.9833[0m        [32m0.0636[0m       [35m0.4892[0m      [31m0.7242[0m        [94m0.5283[0m     +  0.0000  17.5125
      9      [36m0.9835[0m        [32m0.0624[0m       [35m0.4922[0m      0.7237        0.5343        0.0000  17.5763
     10      [36m0.9839[0m        [32m0.0609[0m       [35m0.4993[0m      [31m0.7250[0m        [94m0.5221[0m     +  0.0000  17.5740
     11      [36m0.9848[0m        [32m0.0584[0m       [35m0.4998[0m      [31m0.7272[0m        0.5474        0.0000  17.6542
     12      [36m0.9848[0m        [32m0.0567[0m       [35m0.5092[0m      [31m0.7321[0m        0.5258        0.0000  17.5923
     13      0.9847        0.0577       0.5050      0.7299        0.5357        0.0000  17.5780
     14      [36m0.9848[0m        0.0573       0.5035      0.7289        0.5398        0.0000  17.6234
     15      0.9847        0.0573       [35m0.5097[0m      0.7315        0.5305        0.0000  17.5892
     16      [36m0.9850[0m        [32m0.0561[0m       0.5080      0.7316        0.5427        0.0000  17.6236
     17      0.9840        0.0564       0.5080      0.7312        0.5466        0.0000  17.6681
     18      [36m0.9853[0m        [32m0.0560[0m       0.5085      0.7317        0.5458        0.0000  17.9337
     19      [36m0.9856[0m        [32m0.0546[0m       0.5094      [31m0.7326[0m        0.5495        0.0000  17.6387
     20      0.9847        0.0551       [35m0.5101[0m      0.7316        0.5464        0.0000  17.5103
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.7435194942044258
F1 Macro Score after query 9: 0.7404024223794713
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9744[0m        [32m0.1085[0m       [35m0.5569[0m      [31m0.7923[0m        [94m0.3567[0m     +  0.0001  23.8311
      2      [36m0.9777[0m        [32m0.0938[0m       [35m0.6269[0m      [31m0.8049[0m        [94m0.3152[0m     +  0.0001  23.5617
      3      [36m0.9781[0m        [32m0.0874[0m       [35m0.6311[0m      0.8025        0.3297        0.0001  23.7682
      4      [36m0.9796[0m        [32m0.0825[0m       0.6156      0.8016        0.3503        0.0001  23.6604
      5      [36m0.9812[0m        [32m0.0792[0m       0.6177      0.7819        0.3407        0.0001  23.7005
      6      [36m0.9840[0m        [32m0.0693[0m       0.6266      0.8011        0.3749        0.0000  23.7504
      7      [36m0.9841[0m        [32m0.0665[0m       0.6215      0.7963        0.3602        0.0000  23.6292
      8      [36m0.9846[0m        [32m0.0658[0m       0.6179      0.7960        0.3776        0.0000  23.8118
      9      0.9844        [32m0.0651[0m       0.6175      0.7947        0.3768        0.0000  23.5169
     10      [36m0.9850[0m        [32m0.0643[0m       0.6226      0.7959        0.3771        0.0000  23.7685
     11      [36m0.9858[0m        [32m0.0606[0m       0.6134      0.7975        0.3922        0.0000  23.7190
     12      0.9856        [32m0.0599[0m       0.6189      0.8015        0.3921        0.0000  23.6430
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8446526151444185
F1 Macro Score after query 10: 0.8375311490231162
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9427[0m        [32m0.1737[0m       [35m0.6870[0m      [31m0.8177[0m        [94m0.2958[0m     +  0.0001  35.0099
      2      [36m0.9525[0m        [32m0.1437[0m       [35m0.7116[0m      [31m0.8351[0m        [94m0.2860[0m     +  0.0001  34.6520
      3      [36m0.9585[0m        [32m0.1284[0m       0.7083      0.8264        0.2974        0.0001  34.6199
      4      [36m0.9614[0m        [32m0.1195[0m       0.7014      0.8174        0.2941        0.0001  34.4831
      5      [36m0.9621[0m        [32m0.1135[0m       [35m0.7186[0m      0.8321        [94m0.2859[0m     +  0.0001  34.7248
      6      [36m0.9677[0m        [32m0.1002[0m       0.7146      0.8348        0.2973        0.0000  34.8417
      7      [36m0.9685[0m        [32m0.0979[0m       [35m0.7250[0m      [31m0.8463[0m        0.2988        0.0000  34.7140
      8      [36m0.9690[0m        [32m0.0952[0m       [35m0.7252[0m      0.8460        0.3014        0.0000  34.8257
      9      [36m0.9701[0m        [32m0.0919[0m       0.7210      0.8396        0.3086        0.0000  34.5878
     10      [36m0.9702[0m        [32m0.0917[0m       0.7191      0.8381        0.3026        0.0000  34.7163
     11      [36m0.9720[0m        [32m0.0870[0m       [35m0.7309[0m      [31m0.8507[0m        0.3079        0.0000  34.7010
     12      [36m0.9724[0m        [32m0.0850[0m       0.7253      0.8463        0.3044        0.0000  34.6640
     13      0.9723        0.0851       0.7271      0.8458        0.3084        0.0000  34.7317
     14      0.9724        [32m0.0847[0m       0.7286      0.8483        0.3082        0.0000  34.5291
     15      [36m0.9725[0m        [32m0.0843[0m       0.7276      0.8468        0.3051        0.0000  34.4950
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8926544889234357
F1 Macro Score after query 11: 0.8836015815749713
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9465[0m        [32m0.1111[0m       [35m0.7826[0m      [31m0.8636[0m        [94m0.2338[0m     +  0.0001  53.9477
      2      [36m0.9507[0m        [32m0.0988[0m       0.7793      0.8636        0.2416        0.0001  54.0603
      3      [36m0.9537[0m        [32m0.0915[0m       0.7773      0.8636        0.2511        0.0001  54.3036
      4      [36m0.9566[0m        [32m0.0851[0m       0.7698      0.8635        0.2817        0.0001  54.1019
      5      [36m0.9576[0m        [32m0.0812[0m       0.7767      [31m0.8669[0m        0.2501        0.0001  54.2572
      6      [36m0.9633[0m        [32m0.0699[0m       0.7590      0.8646        0.3378        0.0000  53.6340
      7      [36m0.9655[0m        [32m0.0675[0m       0.7592      0.8596        0.3056        0.0000  54.0497
      8      0.9651        [32m0.0659[0m       0.7602      0.8592        0.2969        0.0000  53.9118
      9      [36m0.9664[0m        [32m0.0642[0m       0.7512      0.8605        0.3584        0.0000  53.9920
     10      0.9663        [32m0.0636[0m       0.7424      0.8544        0.3671        0.0000  54.0502
     11      [36m0.9686[0m        [32m0.0599[0m       0.7488      0.8601        0.3874        0.0000  53.6815
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8910295003010233
F1 Macro Score after query 12: 0.8794955750742465
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9415[0m        [32m0.1040[0m       [35m0.7049[0m      [31m0.8040[0m        [94m0.3389[0m     +  0.0001  61.6988
      2      [36m0.9461[0m        [32m0.0936[0m       0.7009      0.8019        0.3647        0.0001  61.9826
      3      [36m0.9506[0m        [32m0.0869[0m       [35m0.7102[0m      [31m0.8219[0m        0.3507        0.0001  61.8072
      4      [36m0.9527[0m        [32m0.0816[0m       0.7052      0.8192        0.3908        0.0001  61.9651
      5      [36m0.9561[0m        [32m0.0775[0m       [35m0.7252[0m      [31m0.8393[0m        0.3459        0.0001  61.8573
      6      [36m0.9618[0m        [32m0.0671[0m       [35m0.7295[0m      [31m0.8453[0m        0.4094        0.0000  61.9828
      7      [36m0.9637[0m        [32m0.0638[0m       0.7292      0.8434        0.3770        0.0000  62.0101
      8      [36m0.9637[0m        [32m0.0629[0m       0.7266      0.8422        0.4187        0.0000  61.9031
      9      [36m0.9645[0m        [32m0.0619[0m       0.7194      0.8389        0.4222        0.0000  61.6075
     10      [36m0.9659[0m        [32m0.0601[0m       0.7286      0.8420        0.3903        0.0000  61.3372
     11      [36m0.9674[0m        [32m0.0569[0m       [35m0.7326[0m      [31m0.8454[0m        0.3561        0.0000  61.5638
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8938350925500994
F1 Macro Score after query 13: 0.8817556339778537
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed46_config2\AL_max_score_results_for_multilabel_classification.pickle
