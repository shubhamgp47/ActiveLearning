Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6963[0m        [32m0.6694[0m       [35m0.0502[0m      [31m0.2983[0m        [94m0.7190[0m     +  0.0001  10.9250
      2      0.6498        [32m0.6421[0m       [35m0.1720[0m      [31m0.4558[0m        [94m0.6983[0m     +  0.0001  9.7988
      3      [36m0.7963[0m        [32m0.6193[0m       [35m0.2663[0m      0.4267        [94m0.6873[0m     +  0.0001  9.6072
      4      0.7368        [32m0.5757[0m       0.1826      0.4468        0.7050        0.0001  9.7014
      5      0.7222        0.5919       0.2655      0.4145        0.6883        0.0001  9.5971
      6      0.7222        [32m0.5485[0m       0.2269      0.4425        0.6966        0.0000  9.6856
      7      0.6627        0.5662       0.2170      0.4459        0.7001        0.0000  9.7997
      8      0.7963        [32m0.5172[0m       0.2314      0.4487        0.7015        0.0000  9.7230
      9      0.7963        0.5277       0.2486      0.4525        0.7004        0.0000  9.8477
     10      [36m0.8333[0m        [32m0.5022[0m       0.2611      0.4518        0.7003        0.0000  9.8067
     11      0.6333        0.5754       0.2531      0.4541        0.7040        0.0000  9.8592
     12      0.7963        0.5327       0.2524      0.4526        0.7032        0.0000  9.8412
     13      0.8333        0.5051       0.2481      0.4518        0.7033        0.0000  9.8312
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4573
Pre F1 macro score = 0.4548
Pre Accuracy = 0.2510

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.4694[0m        [32m0.6554[0m       [35m0.3844[0m      [31m0.2606[0m        [94m0.6149[0m     +  0.0001  9.8997
      2      0.4152        [32m0.5532[0m       0.3802      [31m0.2936[0m        [94m0.5965[0m     +  0.0001  10.0152
      3      0.4026        0.5680       [35m0.3917[0m      [31m0.3127[0m        [94m0.5828[0m     +  0.0001  9.9945
      4      0.4444        [32m0.5085[0m       [35m0.3972[0m      [31m0.3357[0m        [94m0.5701[0m     +  0.0001  9.8156
      5      0.4091        [32m0.5000[0m       [35m0.4007[0m      [31m0.3765[0m        [94m0.5599[0m     +  0.0001  9.9264
      6      0.4476        [32m0.4672[0m       0.4005      [31m0.3901[0m        [94m0.5581[0m     +  0.0000  9.9533
      7      [36m0.6061[0m        [32m0.4430[0m       [35m0.4040[0m      [31m0.3944[0m        [94m0.5546[0m     +  0.0000  9.9867
      8      0.5714        [32m0.4290[0m       [35m0.4092[0m      [31m0.4222[0m        [94m0.5490[0m     +  0.0000  10.2659
      9      [36m0.6364[0m        [32m0.4249[0m       [35m0.4135[0m      [31m0.4469[0m        [94m0.5428[0m     +  0.0000  10.1127
     10      [36m0.6471[0m        [32m0.4227[0m       [35m0.4167[0m      [31m0.4622[0m        [94m0.5396[0m     +  0.0000  10.0397
     11      [36m0.6775[0m        0.4295       [35m0.4186[0m      [31m0.4696[0m        [94m0.5380[0m     +  0.0000  9.9361
     12      [36m0.7616[0m        [32m0.3970[0m       [35m0.4214[0m      [31m0.4726[0m        [94m0.5369[0m     +  0.0000  9.9833
     13      0.7594        [32m0.3962[0m       0.4214      [31m0.4759[0m        [94m0.5348[0m     +  0.0000  9.9977
     14      0.6364        [32m0.3940[0m       [35m0.4241[0m      [31m0.4832[0m        [94m0.5341[0m     +  0.0000  9.9908
     15      [36m0.7676[0m        [32m0.3880[0m       [35m0.4253[0m      0.4832        [94m0.5331[0m     +  0.0000  9.9386
     16      0.6946        [32m0.3837[0m       [35m0.4264[0m      [31m0.4861[0m        [94m0.5324[0m     +  0.0000  9.9214
     17      0.6349        0.3864       [35m0.4269[0m      [31m0.4884[0m        [94m0.5320[0m     +  0.0000  9.9256
     18      [36m0.8190[0m        0.3850       0.4264      [31m0.4890[0m        [94m0.5315[0m     +  0.0000  10.0452
     19      0.6918        0.4014       [35m0.4274[0m      [31m0.4892[0m        [94m0.5310[0m     +  0.0000  10.0148
     20      0.6113        0.4012       0.4267      [31m0.4926[0m        [94m0.5304[0m     +  0.0000  9.9370
     21      0.7364        0.3847       0.4271      [31m0.4933[0m        [94m0.5302[0m     +  0.0000  9.9994
     22      0.6761        0.4123       0.4273      [31m0.4934[0m        [94m0.5301[0m     +  0.0000  9.9321
     23      0.6244        0.4008       [35m0.4280[0m      [31m0.4956[0m        [94m0.5298[0m     +  0.0000  10.0318
     24      0.7422        0.3859       [35m0.4286[0m      [31m0.4965[0m        [94m0.5297[0m     +  0.0000  9.9955
     25      0.7291        0.4092       [35m0.4288[0m      [31m0.4975[0m        [94m0.5295[0m     +  0.0000  9.9407
     26      0.6428        0.3950       [35m0.4290[0m      [31m0.4981[0m        [94m0.5294[0m     +  0.0000  10.0794
     27      0.6770        0.3849       0.4290      [31m0.4995[0m        [94m0.5293[0m     +  0.0000  9.9579
     28      0.6712        0.3957       0.4288      0.4993        [94m0.5292[0m     +  0.0000  10.0830
     29      0.6590        0.4125       [35m0.4293[0m      0.4990        [94m0.5291[0m     +  0.0000  10.0463
     30      0.7364        [32m0.3657[0m       [35m0.4295[0m      [31m0.4996[0m        [94m0.5290[0m     +  0.0000  10.0167
     31      0.6244        0.3846       0.4293      0.4995        [94m0.5290[0m     +  0.0000  9.9822
     32      [36m0.8674[0m        [32m0.3624[0m       0.4293      0.4995        [94m0.5290[0m     +  0.0000  9.9241
     33      0.8110        0.3734       0.4293      0.4995        [94m0.5290[0m     +  0.0000  9.9521
     34      0.6649        0.3942       0.4295      0.4996        [94m0.5290[0m     +  0.0000  10.0451
     35      0.7422        0.3891       0.4295      [31m0.4997[0m        [94m0.5290[0m     +  0.0000  9.9486
     36      0.7635        0.3832       [35m0.4297[0m      [31m0.4997[0m        [94m0.5289[0m     +  0.0000  9.9225
     37      0.7937        0.3801       0.4297      0.4997        [94m0.5289[0m     +  0.0000  9.9356
     38      0.6138        0.4169       [35m0.4299[0m      [31m0.5003[0m        [94m0.5289[0m     +  0.0000  9.9709
     39      0.7807        0.3686       0.4297      0.5000        [94m0.5289[0m     +  0.0000  10.0641
     40      0.6761        0.3850       0.4299      0.5003        [94m0.5289[0m     +  0.0000  10.1419
     41      0.7817        0.3662       0.4299      0.5003        [94m0.5289[0m     +  0.0000  9.9732
     42      0.7381        0.3744       0.4299      [31m0.5005[0m        [94m0.5289[0m     +  0.0000  10.3724
     43      0.7643        0.3837       [35m0.4300[0m      [31m0.5006[0m        [94m0.5289[0m     +  0.0000  10.2205
     44      0.7937        0.3688       0.4300      [31m0.5007[0m        [94m0.5289[0m     +  0.0000  10.2672
     45      0.7704        0.3750       0.4300      0.5007        [94m0.5289[0m     +  0.0000  9.9268
     46      0.7251        0.3925       0.4300      0.5007        [94m0.5289[0m     +  0.0000  10.0333
     47      0.7381        0.3714       0.4300      0.5006        [94m0.5289[0m     +  0.0000  10.0523
     48      0.7633        0.3809       0.4300      0.5007        [94m0.5289[0m     +  0.0000  10.0934
     49      [36m0.8918[0m        0.3715       0.4300      0.5007        [94m0.5289[0m     +  0.0000  10.1190
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.5716666666666667
F1 Macro Score after query 1: 0.5442095583707295
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5956[0m        [32m0.5393[0m       [35m0.5549[0m      [31m0.6116[0m        [94m0.4932[0m     +  0.0001  10.0068
      2      [36m0.7807[0m        [32m0.4411[0m       [35m0.5651[0m      [31m0.6348[0m        [94m0.4492[0m     +  0.0001  10.0217
      3      [36m0.8394[0m        [32m0.3641[0m       [35m0.6035[0m      [31m0.7060[0m        [94m0.4102[0m     +  0.0001  9.9808
      4      [36m0.8480[0m        [32m0.3424[0m       0.5969      0.6986        [94m0.4022[0m     +  0.0001  10.0760
      5      [36m0.8660[0m        [32m0.2982[0m       [35m0.6262[0m      [31m0.7546[0m        [94m0.3698[0m     +  0.0001  9.9687
      6      [36m0.8829[0m        [32m0.2585[0m       [35m0.6472[0m      [31m0.7817[0m        [94m0.3575[0m     +  0.0000  9.9092
      7      [36m0.8935[0m        [32m0.2486[0m       [35m0.6512[0m      [31m0.7878[0m        [94m0.3524[0m     +  0.0000  9.9843
      8      0.8829        [32m0.2484[0m       [35m0.6575[0m      [31m0.7951[0m        [94m0.3495[0m     +  0.0000  9.9531
      9      [36m0.9114[0m        [32m0.2228[0m       0.6573      [31m0.7978[0m        [94m0.3435[0m     +  0.0000  10.0649
     10      0.9095        0.2266       [35m0.6594[0m      [31m0.7982[0m        [94m0.3361[0m     +  0.0000  9.9276
     11      0.9006        0.2272       [35m0.6616[0m      [31m0.7996[0m        [94m0.3354[0m     +  0.0000  10.0156
     12      [36m0.9272[0m        [32m0.2142[0m       0.6609      0.7986        [94m0.3344[0m     +  0.0000  10.1728
     13      0.9106        0.2231       [35m0.6634[0m      [31m0.8006[0m        [94m0.3340[0m     +  0.0000  9.9991
     14      [36m0.9351[0m        [32m0.1998[0m       0.6611      0.7981        [94m0.3322[0m     +  0.0000  10.0634
     15      0.9084        0.2108       [35m0.6639[0m      [31m0.8014[0m        [94m0.3313[0m     +  0.0000  10.0631
     16      0.9255        0.2070       0.6639      [31m0.8020[0m        [94m0.3310[0m     +  0.0000  10.0662
     17      0.9277        0.2012       0.6639      0.8020        [94m0.3303[0m     +  0.0000  9.9749
     18      0.9255        0.2179       [35m0.6646[0m      [31m0.8027[0m        [94m0.3294[0m     +  0.0000  10.0201
     19      0.8935        0.2108       0.6644      [31m0.8029[0m        [94m0.3291[0m     +  0.0000  9.9655
     20      [36m0.9416[0m        [32m0.1977[0m       [35m0.6648[0m      [31m0.8039[0m        [94m0.3286[0m     +  0.0000  10.0000
     21      0.9198        0.2072       0.6646      0.8033        [94m0.3286[0m     +  0.0000  10.0902
     22      0.9222        0.2000       0.6644      0.8032        [94m0.3283[0m     +  0.0000  9.9857
     23      0.9329        0.2017       0.6648      0.8032        [94m0.3280[0m     +  0.0000  9.9784
     24      0.8997        0.2037       [35m0.6653[0m      0.8034        [94m0.3277[0m     +  0.0000  10.2031
     25      0.9106        [32m0.1966[0m       0.6653      0.8037        [94m0.3275[0m     +  0.0000  10.1418
     26      0.9272        [32m0.1955[0m       0.6653      0.8036        [94m0.3274[0m     +  0.0000  9.9549
     27      0.9017        0.2125       [35m0.6655[0m      0.8036        [94m0.3273[0m     +  0.0000  9.9524
     28      0.9255        0.2139       [35m0.6656[0m      0.8037        [94m0.3272[0m     +  0.0000  10.0312
     29      0.9351        0.2033       0.6655      0.8038        [94m0.3271[0m     +  0.0000  9.9821
     30      0.9106        0.2023       0.6656      0.8037        [94m0.3270[0m     +  0.0000  10.0222
     31      0.9337        0.1974       0.6655      0.8036        [94m0.3270[0m     +  0.0000  9.9828
     32      0.9351        [32m0.1864[0m       [35m0.6658[0m      0.8038        [94m0.3269[0m     +  0.0000  10.0287
     33      0.9112        0.2055       0.6656      0.8037        [94m0.3268[0m     +  0.0000  10.0157
     34      0.9182        0.2006       0.6656      0.8037        [94m0.3268[0m     +  0.0000  9.9688
     35      [36m0.9419[0m        0.2006       0.6655      0.8037        [94m0.3268[0m     +  0.0000  9.9557
     36      0.8975        0.2005       0.6655      0.8037        [94m0.3268[0m     +  0.0000  10.0009
     37      0.9155        0.2042       0.6656      0.8037        [94m0.3268[0m     +  0.0000  10.1109
     38      0.9182        0.1902       0.6656      0.8037        [94m0.3268[0m     +  0.0000  10.0412
     39      0.9255        0.1955       0.6656      0.8037        [94m0.3268[0m     +  0.0000  9.9635
     40      0.9272        0.1971       0.6656      [31m0.8039[0m        [94m0.3268[0m     +  0.0000  9.9563
     41      0.9185        0.2046       0.6656      0.8039        [94m0.3268[0m     +  0.0000  10.0467
     42      0.9229        0.2024       0.6656      0.8039        [94m0.3268[0m     +  0.0000  9.9918
     43      0.9143        0.2003       0.6656      0.8039        [94m0.3268[0m     +  0.0000  10.1194
     44      [36m0.9421[0m        0.2107       0.6656      0.8039        [94m0.3267[0m     +  0.0000  10.0624
     45      0.9244        0.1954       0.6656      0.8039        [94m0.3267[0m     +  0.0000  10.0942
     46      0.9182        0.2042       0.6656      0.8039        [94m0.3267[0m     +  0.0000  10.0788
     47      0.9329        0.1921       0.6656      0.8039        [94m0.3267[0m     +  0.0000  10.0262
     48      0.9070        0.2091       0.6656      0.8039        [94m0.3267[0m     +  0.0000  10.0145
     49      0.9097        0.2148       0.6656      0.8039        [94m0.3267[0m     +  0.0000  9.9939
     50      0.9255        0.1919       0.6656      0.8039        [94m0.3267[0m     +  0.0000  9.9843
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.818882769472856
F1 Macro Score after query 2: 0.8064444786700612
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8164[0m        [32m0.3170[0m       [35m0.6599[0m      [31m0.8194[0m        [94m0.3210[0m     +  0.0001  10.0471
      2      [36m0.8670[0m        [32m0.2469[0m       [35m0.6609[0m      0.8185        [94m0.3024[0m     +  0.0001  10.1765
      3      [36m0.8766[0m        [32m0.2102[0m       [35m0.6694[0m      [31m0.8242[0m        [94m0.2929[0m     +  0.0001  10.1545
      4      [36m0.8832[0m        0.2125       [35m0.6802[0m      [31m0.8291[0m        [94m0.2859[0m     +  0.0001  10.1556
      5      [36m0.8916[0m        [32m0.1812[0m       [35m0.6821[0m      [31m0.8298[0m        0.2921        0.0001  10.1046
      6      [36m0.9099[0m        [32m0.1677[0m       [35m0.6849[0m      [31m0.8312[0m        [94m0.2713[0m     +  0.0000  10.1097
      7      [36m0.9328[0m        [32m0.1547[0m       [35m0.6858[0m      [31m0.8324[0m        [94m0.2706[0m     +  0.0000  10.0686
      8      0.9194        0.1564       [35m0.6863[0m      0.8324        [94m0.2675[0m     +  0.0000  10.1566
      9      [36m0.9368[0m        [32m0.1422[0m       [35m0.6885[0m      [31m0.8337[0m        0.2684        0.0000  10.0800
     10      0.9218        0.1461       0.6877      0.8323        [94m0.2638[0m     +  0.0000  10.0360
     11      [36m0.9393[0m        0.1428       [35m0.6891[0m      [31m0.8338[0m        0.2656        0.0000  10.0484
     12      0.9161        0.1436       [35m0.6898[0m      0.8336        0.2655        0.0000  10.0669
     13      0.9319        0.1469       [35m0.6913[0m      [31m0.8340[0m        [94m0.2637[0m     +  0.0000  10.2134
     14      0.9288        0.1436       0.6913      [31m0.8342[0m        0.2638        0.0000  10.2211
     15      [36m0.9433[0m        0.1442       0.6910      0.8337        0.2641        0.0000  10.0780
     16      0.9364        0.1422       0.6910      0.8336        0.2642        0.0000  10.0779
     17      0.9357        [32m0.1386[0m       [35m0.6925[0m      0.8338        0.2639        0.0000  10.0784
     18      0.9371        0.1398       [35m0.6927[0m      0.8341        [94m0.2634[0m     +  0.0000  10.0781
     19      0.9408        [32m0.1341[0m       0.6920      0.8336        0.2638        0.0000  10.1755
     20      0.9287        [32m0.1341[0m       [35m0.6931[0m      [31m0.8343[0m        0.2637        0.0000  10.1667
     21      0.9344        [32m0.1331[0m       0.6925      0.8340        0.2638        0.0000  10.0447
     22      0.9386        [32m0.1318[0m       0.6925      0.8339        0.2636        0.0000  10.0353
     23      [36m0.9513[0m        [32m0.1262[0m       0.6920      0.8337        0.2636        0.0000  10.0936
     24      0.9426        0.1314       0.6927      0.8339        0.2635        0.0000  10.1093
     25      0.9463        0.1286       0.6927      0.8339        0.2636        0.0000  10.1361
     26      0.9237        0.1378       0.6927      0.8339        0.2635        0.0000  10.1255
     27      [36m0.9538[0m        0.1303       0.6931      0.8340        0.2635        0.0000  10.1683
     28      0.9370        0.1280       0.6929      0.8339        0.2634        0.0000  10.0815
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.8465715172199815
F1 Macro Score after query 3: 0.8319139003807243
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8490[0m        [32m0.2602[0m       [35m0.6589[0m      [31m0.7871[0m        [94m0.2820[0m     +  0.0001  10.2812
      2      [36m0.8737[0m        [32m0.1975[0m       [35m0.6884[0m      [31m0.8238[0m        [94m0.2445[0m     +  0.0001  10.2810
      3      [36m0.9008[0m        [32m0.1783[0m       [35m0.7045[0m      [31m0.8391[0m        [94m0.2380[0m     +  0.0001  10.2225
      4      [36m0.9041[0m        [32m0.1652[0m       [35m0.7068[0m      0.8390        [94m0.2351[0m     +  0.0001  10.2206
      5      [36m0.9100[0m        [32m0.1597[0m       0.7068      0.8381        0.2380        0.0001  10.2467
      6      [36m0.9147[0m        [32m0.1442[0m       [35m0.7134[0m      [31m0.8443[0m        [94m0.2321[0m     +  0.0000  10.3704
      7      [36m0.9161[0m        [32m0.1397[0m       [35m0.7144[0m      [31m0.8450[0m        [94m0.2317[0m     +  0.0000  10.2834
      8      [36m0.9231[0m        [32m0.1354[0m       [35m0.7165[0m      [31m0.8481[0m        0.2342        0.0000  10.2371
      9      0.9208        0.1375       [35m0.7172[0m      0.8468        0.2346        0.0000  10.2160
     10      [36m0.9290[0m        [32m0.1267[0m       [35m0.7181[0m      0.8464        0.2327        0.0000  10.3718
     11      [36m0.9385[0m        [32m0.1223[0m       0.7179      0.8471        0.2338        0.0000  10.2359
     12      0.9253        [32m0.1215[0m       [35m0.7194[0m      [31m0.8486[0m        0.2342        0.0000  10.2006
     13      0.9297        0.1236       [35m0.7196[0m      0.8479        0.2334        0.0000  10.2695
     14      0.9249        0.1264       0.7191      0.8477        0.2340        0.0000  10.2904
     15      0.9317        0.1222       0.7188      0.8451        0.2351        0.0000  10.2812
     16      [36m0.9395[0m        [32m0.1206[0m       0.7175      0.8460        0.2349        0.0000  10.2499
     17      0.9379        0.1210       [35m0.7200[0m      0.8483        0.2347        0.0000  10.3423
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.8666771110762964
F1 Macro Score after query 4: 0.8516824797245709
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8780[0m        [32m0.2136[0m       [35m0.7326[0m      [31m0.8514[0m        [94m0.2252[0m     +  0.0001  10.6250
      2      [36m0.8971[0m        [32m0.1798[0m       [35m0.7368[0m      0.8512        [94m0.2199[0m     +  0.0001  10.5965
      3      [36m0.9124[0m        [32m0.1641[0m       0.7363      0.8487        [94m0.2197[0m     +  0.0001  10.6403
      4      0.9092        [32m0.1606[0m       [35m0.7434[0m      [31m0.8564[0m        0.2236        0.0001  10.5746
      5      0.9093        [32m0.1568[0m       [35m0.7490[0m      [31m0.8567[0m        0.2205        0.0001  10.5936
      6      [36m0.9245[0m        [32m0.1448[0m       0.7370      0.8434        0.2220        0.0000  10.6096
      7      [36m0.9274[0m        [32m0.1354[0m       0.7424      0.8499        0.2202        0.0000  10.6600
      8      0.9207        0.1440       0.7418      0.8478        0.2204        0.0000  10.5537
      9      0.9238        [32m0.1351[0m       0.7439      0.8485        0.2201        0.0000  10.6947
     10      [36m0.9299[0m        0.1382       0.7420      0.8489        0.2205        0.0000  10.5300
     11      [36m0.9325[0m        [32m0.1273[0m       0.7425      0.8494        0.2204        0.0000  10.5411
     12      0.9282        0.1292       0.7451      0.8508        0.2202        0.0000  10.5251
     13      [36m0.9359[0m        [32m0.1262[0m       0.7406      0.8487        0.2216        0.0000  10.5737
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.8766408350466551
F1 Macro Score after query 5: 0.8603624585718738
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8642[0m        [32m0.2199[0m       [35m0.7484[0m      [31m0.8503[0m        [94m0.2244[0m     +  0.0001  11.1339
      2      [36m0.8839[0m        [32m0.1925[0m       0.7453      [31m0.8527[0m        0.2267        0.0001  11.1331
      3      [36m0.8921[0m        [32m0.1824[0m       0.7443      0.8498        0.2273        0.0001  11.1154
      4      [36m0.9038[0m        [32m0.1748[0m       0.7365      0.8513        0.2342        0.0001  11.1173
      5      [36m0.9050[0m        [32m0.1660[0m       0.7337      [31m0.8539[0m        0.2420        0.0001  11.0703
      6      0.9035        [32m0.1600[0m       0.7477      [31m0.8570[0m        0.2300        0.0000  11.1504
      7      [36m0.9117[0m        [32m0.1565[0m       0.7403      0.8560        0.2343        0.0000  11.1182
      8      [36m0.9120[0m        [32m0.1497[0m       0.7365      0.8564        0.2369        0.0000  11.2433
      9      [36m0.9151[0m        0.1521       0.7441      [31m0.8583[0m        0.2307        0.0000  11.0883
     10      [36m0.9165[0m        [32m0.1477[0m       0.7401      0.8564        0.2329        0.0000  11.1026
     11      [36m0.9192[0m        [32m0.1426[0m       0.7474      0.8556        0.2290        0.0000  11.0876
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8802275522755227
F1 Macro Score after query 6: 0.8633732068311885
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8697[0m        [32m0.2033[0m       [35m0.7194[0m      [31m0.8252[0m        [94m0.2303[0m     +  0.0001  12.2900
      2      [36m0.8886[0m        [32m0.1838[0m       [35m0.7243[0m      [31m0.8312[0m        [94m0.2268[0m     +  0.0001  12.2791
      3      [36m0.8889[0m        [32m0.1788[0m       [35m0.7344[0m      [31m0.8405[0m        [94m0.2241[0m     +  0.0001  12.1791
      4      [36m0.8973[0m        [32m0.1674[0m       0.7257      0.8316        0.2281        0.0001  12.2131
      5      0.8963        [32m0.1646[0m       [35m0.7457[0m      [31m0.8448[0m        [94m0.2232[0m     +  0.0001  12.1676
      6      [36m0.9085[0m        [32m0.1519[0m       [35m0.7488[0m      [31m0.8493[0m        [94m0.2184[0m     +  0.0000  12.2297
      7      [36m0.9123[0m        [32m0.1437[0m       [35m0.7519[0m      [31m0.8542[0m        [94m0.2158[0m     +  0.0000  12.2605
      8      [36m0.9123[0m        0.1439       0.7516      0.8496        0.2163        0.0000  12.1970
      9      0.9102        [32m0.1416[0m       0.7490      0.8506        0.2165        0.0000  12.2410
     10      0.9123        [32m0.1395[0m       [35m0.7550[0m      [31m0.8550[0m        0.2161        0.0000  12.2854
     11      [36m0.9152[0m        [32m0.1346[0m       [35m0.7622[0m      [31m0.8643[0m        [94m0.2121[0m     +  0.0000  12.1697
     12      [36m0.9226[0m        [32m0.1327[0m       0.7616      [31m0.8646[0m        [94m0.2119[0m     +  0.0000  12.2451
     13      0.9167        [32m0.1314[0m       0.7615      [31m0.8648[0m        [94m0.2108[0m     +  0.0000  12.2280
     14      0.9209        [32m0.1312[0m       [35m0.7635[0m      0.8647        0.2115        0.0000  12.1664
     15      [36m0.9229[0m        [32m0.1273[0m       [35m0.7644[0m      [31m0.8659[0m        [94m0.2105[0m     +  0.0000  12.2246
     16      [36m0.9306[0m        [32m0.1260[0m       [35m0.7648[0m      [31m0.8675[0m        [94m0.2097[0m     +  0.0000  12.2458
     17      0.9191        0.1273       0.7644      0.8656        0.2102        0.0000  12.2595
     18      0.9214        0.1274       [35m0.7663[0m      0.8666        [94m0.2094[0m     +  0.0000  12.2117
     19      0.9272        [32m0.1223[0m       0.7635      0.8660        0.2102        0.0000  12.2462
     20      0.9231        0.1230       0.7651      0.8665        0.2099        0.0000  12.1961
     21      0.9224        0.1228       0.7660      [31m0.8685[0m        [94m0.2090[0m     +  0.0000  12.2289
     22      0.9248        0.1232       0.7660      [31m0.8692[0m        [94m0.2089[0m     +  0.0000  12.3692
     23      0.9227        [32m0.1217[0m       0.7661      0.8682        0.2089        0.0000  12.2600
     24      0.9212        0.1227       0.7661      0.8682        [94m0.2088[0m     +  0.0000  12.2762
     25      0.9268        0.1219       0.7660      0.8689        [94m0.2088[0m     +  0.0000  12.1682
     26      0.9215        0.1236       0.7658      0.8689        0.2088        0.0000  12.3744
     27      0.9212        0.1221       [35m0.7665[0m      0.8688        [94m0.2088[0m     +  0.0000  12.1805
     28      0.9265        0.1218       0.7663      0.8680        [94m0.2087[0m     +  0.0000  12.2288
     29      0.9260        [32m0.1213[0m       0.7663      0.8680        [94m0.2086[0m     +  0.0000  12.2619
     30      0.9270        [32m0.1200[0m       [35m0.7667[0m      0.8679        0.2087        0.0000  12.3096
     31      0.9291        0.1243       0.7651      0.8678        0.2087        0.0000  12.3248
     32      0.9271        0.1210       0.7656      0.8682        0.2087        0.0000  12.2291
     33      0.9268        [32m0.1198[0m       0.7658      0.8684        0.2087        0.0000  12.2421
     34      0.9243        0.1225       0.7667      0.8688        [94m0.2086[0m     +  0.0000  12.2281
     35      0.9293        [32m0.1197[0m       [35m0.7668[0m      0.8692        [94m0.2086[0m     +  0.0000  12.2782
     36      0.9183        0.1231       0.7665      0.8690        [94m0.2086[0m     +  0.0000  12.6344
     37      0.9266        0.1204       0.7663      0.8689        0.2086        0.0000  12.2283
     38      0.9270        0.1218       0.7663      0.8689        0.2086        0.0000  12.1669
     39      0.9264        0.1225       0.7661      0.8688        0.2086        0.0000  12.2126
     40      0.9256        0.1224       0.7663      0.8689        0.2086        0.0000  12.1985
     41      0.9264        0.1217       0.7661      0.8688        0.2086        0.0000  12.1645
     42      0.9249        0.1241       0.7661      0.8688        0.2086        0.0000  12.5090
     43      0.9238        0.1229       0.7661      0.8688        0.2086        0.0000  12.2662
     44      0.9279        0.1217       0.7661      0.8688        0.2086        0.0000  12.5390
     45      0.9257        0.1205       0.7663      0.8690        0.2086        0.0000  12.1820
     46      0.9241        0.1226       0.7661      0.8688        0.2086        0.0000  12.2274
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.8858185205309322
F1 Macro Score after query 7: 0.8694857352772041
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9000[0m        [32m0.1569[0m       [35m0.7602[0m      [31m0.8728[0m        [94m0.2158[0m     +  0.0001  14.1033
      2      [36m0.9135[0m        [32m0.1409[0m       [35m0.7648[0m      [31m0.8740[0m        [94m0.2132[0m     +  0.0001  14.0613
      3      0.9128        [32m0.1364[0m       0.7627      [31m0.8755[0m        0.2167        0.0001  14.2633
      4      [36m0.9224[0m        [32m0.1305[0m       [35m0.7703[0m      [31m0.8795[0m        0.2158        0.0001  14.1182
      5      0.9206        [32m0.1252[0m       0.7674      0.8754        0.2136        0.0001  14.0582
      6      [36m0.9327[0m        [32m0.1113[0m       [35m0.7720[0m      [31m0.8803[0m        [94m0.2125[0m     +  0.0000  14.1987
      7      [36m0.9341[0m        [32m0.1081[0m       0.7698      [31m0.8804[0m        0.2149        0.0000  14.2278
      8      [36m0.9344[0m        [32m0.1073[0m       0.7675      0.8774        0.2151        0.0000  14.0079
      9      [36m0.9376[0m        [32m0.1041[0m       0.7719      0.8795        0.2156        0.0000  14.1218
     10      0.9354        [32m0.1017[0m       0.7672      0.8790        0.2206        0.0000  14.4798
     11      [36m0.9419[0m        [32m0.0963[0m       0.7677      0.8777        0.2209        0.0000  14.0756
     12      [36m0.9427[0m        [32m0.0950[0m       0.7689      0.8794        0.2216        0.0000  14.0859
     13      [36m0.9453[0m        0.0961       0.7696      0.8787        0.2195        0.0000  14.0904
     14      [36m0.9492[0m        [32m0.0938[0m       0.7663      0.8772        0.2218        0.0000  14.0902
     15      0.9449        [32m0.0927[0m       0.7686      0.8778        0.2221        0.0000  14.1043
     16      0.9485        [32m0.0892[0m       0.7700      0.8755        0.2182        0.0000  14.2297
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8903710518245936
F1 Macro Score after query 8: 0.8750256054585556
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9137[0m        [32m0.1389[0m       [35m0.7587[0m      [31m0.8702[0m        [94m0.2327[0m     +  0.0001  17.5473
      2      [36m0.9192[0m        [32m0.1237[0m       0.7566      [31m0.8735[0m        0.2446        0.0001  17.4628
      3      [36m0.9267[0m        [32m0.1178[0m       0.7540      0.8678        0.2662        0.0001  17.6072
      4      [36m0.9300[0m        [32m0.1137[0m       [35m0.7606[0m      0.8733        0.2518        0.0001  17.4525
      5      [36m0.9300[0m        [32m0.1106[0m       0.7486      0.8663        0.2677        0.0001  17.4368
      6      [36m0.9407[0m        [32m0.0945[0m       0.7519      [31m0.8745[0m        0.2601        0.0000  17.4360
      7      [36m0.9444[0m        [32m0.0908[0m       0.7575      0.8741        0.2539        0.0000  17.6068
      8      0.9439        [32m0.0901[0m       0.7523      0.8720        0.2567        0.0000  17.4679
      9      [36m0.9472[0m        [32m0.0881[0m       0.7569      0.8724        0.2581        0.0000  17.6035
     10      [36m0.9492[0m        [32m0.0879[0m       0.7507      0.8703        0.2598        0.0000  17.5454
     11      [36m0.9525[0m        [32m0.0809[0m       0.7549      0.8689        0.2430        0.0000  17.4686
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8910119229593396
F1 Macro Score after query 9: 0.8782010065778522
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9182[0m        [32m0.1296[0m       [35m0.7674[0m      [31m0.8653[0m        [94m0.2073[0m     +  0.0001  23.8438
      2      [36m0.9282[0m        [32m0.1178[0m       0.7648      [31m0.8691[0m        0.2096        0.0001  23.6719
      3      [36m0.9318[0m        [32m0.1126[0m       0.7623      0.8569        [94m0.2071[0m     +  0.0001  23.8906
      4      [36m0.9358[0m        [32m0.1070[0m       0.7639      0.8628        0.2084        0.0001  23.6855
      5      [36m0.9379[0m        [32m0.1020[0m       0.7512      0.8567        0.2211        0.0001  23.7210
      6      [36m0.9477[0m        [32m0.0878[0m       0.7672      0.8589        0.2123        0.0000  23.7177
      7      [36m0.9503[0m        [32m0.0842[0m       [35m0.7710[0m      0.8626        0.2097        0.0000  23.7016
      8      [36m0.9520[0m        [32m0.0827[0m       0.7701      0.8639        0.2132        0.0000  23.5678
      9      [36m0.9521[0m        [32m0.0805[0m       0.7661      0.8585        0.2153        0.0000  23.7186
     10      [36m0.9526[0m        [32m0.0785[0m       0.7635      0.8568        0.2189        0.0000  23.5415
     11      [36m0.9563[0m        [32m0.0734[0m       0.7639      0.8583        0.2233        0.0000  23.6560
     12      [36m0.9581[0m        [32m0.0722[0m       0.7601      0.8569        0.2288        0.0000  23.6550
     13      0.9562        [32m0.0719[0m       0.7625      0.8573        0.2253        0.0000  23.6594
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8952674105425164
F1 Macro Score after query 10: 0.8817688958336358
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9288[0m        [32m0.1153[0m       [35m0.7811[0m      [31m0.8724[0m        [94m0.1970[0m     +  0.0001  34.5667
      2      [36m0.9373[0m        [32m0.1058[0m       0.7766      0.8659        0.2096        0.0001  34.3536
      3      [36m0.9386[0m        [32m0.1004[0m       0.7710      0.8648        0.2121        0.0001  34.4542
      4      [36m0.9428[0m        [32m0.0952[0m       0.7688      0.8621        0.2208        0.0001  34.3283
      5      [36m0.9454[0m        [32m0.0905[0m       0.7733      0.8620        0.2130        0.0001  34.4843
      6      [36m0.9551[0m        [32m0.0777[0m       0.7606      0.8607        0.2303        0.0000  34.2113
      7      [36m0.9580[0m        [32m0.0738[0m       0.7630      0.8581        0.2225        0.0000  34.4773
      8      0.9561        0.0745       0.7630      0.8555        0.2225        0.0000  34.4874
      9      [36m0.9586[0m        [32m0.0716[0m       0.7580      0.8563        0.2284        0.0000  34.3656
     10      0.9583        [32m0.0713[0m       0.7562      0.8551        0.2277        0.0000  34.5400
     11      [36m0.9624[0m        [32m0.0656[0m       0.7552      0.8581        0.2358        0.0000  34.3122
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8912442396313364
F1 Macro Score after query 11: 0.8780314388082243
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9358[0m        [32m0.1086[0m       [35m0.7833[0m      [31m0.8603[0m        [94m0.1946[0m     +  0.0001  54.7997
      2      [36m0.9422[0m        [32m0.0975[0m       [35m0.7847[0m      [31m0.8634[0m        0.1990        0.0001  54.9203
      3      [36m0.9463[0m        [32m0.0911[0m       0.7788      0.8569        0.2040        0.0001  54.8124
      4      [36m0.9496[0m        [32m0.0860[0m       0.7785      0.8512        0.2103        0.0001  54.9202
      5      [36m0.9519[0m        [32m0.0826[0m       0.7734      0.8567        0.2150        0.0001  54.8502
      6      [36m0.9601[0m        [32m0.0697[0m       0.7660      0.8552        0.2271        0.0000  54.7882
      7      [36m0.9612[0m        [32m0.0674[0m       0.7743      0.8569        0.2157        0.0000  54.7321
      8      [36m0.9624[0m        [32m0.0666[0m       0.7665      0.8484        0.2207        0.0000  54.4392
      9      [36m0.9634[0m        [32m0.0643[0m       0.7658      0.8480        0.2252        0.0000  54.5952
     10      [36m0.9636[0m        [32m0.0633[0m       0.7726      0.8544        0.2208        0.0000  54.8218
     11      [36m0.9662[0m        [32m0.0588[0m       0.7660      0.8594        0.2320        0.0000  54.8456
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8976341063480908
F1 Macro Score after query 12: 0.8822089096030695
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9412[0m        [32m0.0984[0m       [35m0.7583[0m      [31m0.8664[0m        [94m0.2207[0m     +  0.0001  61.0972
      2      [36m0.9470[0m        [32m0.0895[0m       [35m0.7589[0m      0.8616        0.2277        0.0001  61.5351
      3      [36m0.9502[0m        [32m0.0858[0m       0.7464      0.8577        0.2622        0.0001  61.4949
      4      [36m0.9530[0m        [32m0.0803[0m       0.7554      0.8595        0.2557        0.0001  61.5891
      5      [36m0.9546[0m        [32m0.0777[0m       0.7486      0.8571        0.2583        0.0001  61.0776
      6      [36m0.9624[0m        [32m0.0657[0m       0.7528      0.8622        0.2711        0.0000  61.3941
      7      [36m0.9631[0m        [32m0.0634[0m       0.7556      0.8632        0.2655        0.0000  61.0754
      8      [36m0.9641[0m        [32m0.0619[0m       [35m0.7611[0m      [31m0.8672[0m        0.2815        0.0000  61.2962
      9      [36m0.9651[0m        [32m0.0614[0m       0.7559      0.8626        0.2787        0.0000  61.2943
     10      [36m0.9662[0m        [32m0.0597[0m       0.7609      0.8648        0.2733        0.0000  61.1730
     11      [36m0.9671[0m        [32m0.0562[0m       0.7594      0.8628        0.2623        0.0000  61.3456
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.899201446436643
F1 Macro Score after query 13: 0.8867339279588328
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_config2\AL_average_confidence_results_for_multilabel_classification.pickle
