Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5152[0m        [32m0.7299[0m       [35m0.0769[0m      [31m0.4301[0m        [94m0.7166[0m     +  0.0001  11.5511
      2      [36m0.6829[0m        [32m0.6723[0m       [35m0.3358[0m      0.2320        [94m0.6690[0m     +  0.0001  10.4844
      3      0.5167        [32m0.6271[0m       0.1760      [31m0.4389[0m        0.6979        0.0001  10.2724
      4      [36m0.7833[0m        [32m0.6164[0m       0.2965      0.3396        [94m0.6651[0m     +  0.0001  10.2516
      5      0.6468        [32m0.5992[0m       0.2790      0.4261        0.6822        0.0001  10.4674
      6      [36m0.8333[0m        [32m0.5498[0m       0.2927      0.4177        0.6779        0.0000  10.3624
      7      0.7857        0.5693       0.2922      0.4116        0.6781        0.0000  10.5629
      8      0.7963        0.5755       0.2918      0.4151        0.6789        0.0000  10.3945
      9      0.7857        0.5544       0.2905      0.4268        0.6807        0.0000  10.5460
     10      0.7857        0.5861       0.2632      [31m0.4415[0m        0.6878        0.0000  10.4800
     11      0.7500        [32m0.5226[0m       0.2738      [31m0.4420[0m        0.6866        0.0000  10.4844
     12      0.7368        0.5485       0.2773      0.4404        0.6857        0.0000  10.5050
     13      0.7857        [32m0.5152[0m       0.2734      [31m0.4424[0m        0.6863        0.0000  10.5067
     14      0.7500        0.5497       0.2745      [31m0.4427[0m        0.6867        0.0000  10.6249
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4625
Pre F1 macro score = 0.4614
Pre Accuracy = 0.3108

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6437[0m        [32m0.5549[0m       [35m0.3866[0m      [31m0.1766[0m        [94m0.6351[0m     +  0.0001  10.6719
      2      0.3722        0.5834       [35m0.3974[0m      [31m0.1844[0m        [94m0.6171[0m     +  0.0001  10.7276
      3      0.3952        [32m0.5331[0m       0.3877      [31m0.2161[0m        [94m0.6023[0m     +  0.0001  10.5806
      4      0.3074        0.5762       [35m0.4045[0m      [31m0.2440[0m        [94m0.5913[0m     +  0.0001  10.6875
      5      [36m0.6667[0m        [32m0.4879[0m       [35m0.4111[0m      [31m0.2507[0m        [94m0.5849[0m     +  0.0001  10.6644
      6      0.4286        [32m0.4632[0m       [35m0.4141[0m      [31m0.3037[0m        [94m0.5807[0m     +  0.0000  10.5881
      7      [36m0.6789[0m        [32m0.4457[0m       0.4109      [31m0.3273[0m        [94m0.5781[0m     +  0.0000  10.4863
      8      0.5456        0.4544       0.4024      [31m0.3695[0m        [94m0.5724[0m     +  0.0000  10.6411
      9      0.6667        [32m0.4400[0m       0.4102      0.3593        [94m0.5722[0m     +  0.0000  10.7298
     10      [36m0.7222[0m        0.4504       [35m0.4160[0m      0.3554        [94m0.5713[0m     +  0.0000  10.5624
     11      0.6152        [32m0.4039[0m       0.4123      [31m0.3733[0m        [94m0.5685[0m     +  0.0000  10.6395
     12      0.6504        0.4190       0.4118      [31m0.3866[0m        [94m0.5665[0m     +  0.0000  10.5000
     13      0.6374        [32m0.4011[0m       0.4139      [31m0.4013[0m        [94m0.5646[0m     +  0.0000  10.6876
     14      0.6901        [32m0.3878[0m       0.4108      [31m0.4089[0m        [94m0.5628[0m     +  0.0000  10.8785
     15      [36m0.7789[0m        [32m0.3794[0m       0.4144      [31m0.4133[0m        [94m0.5610[0m     +  0.0000  10.4197
     16      0.6607        0.4132       0.4135      [31m0.4172[0m        [94m0.5606[0m     +  0.0000  10.5770
     17      0.7251        0.3888       0.4128      [31m0.4192[0m        [94m0.5602[0m     +  0.0000  10.6776
     18      [36m0.8000[0m        [32m0.3720[0m       0.4134      [31m0.4201[0m        [94m0.5599[0m     +  0.0000  10.4804
     19      0.7174        0.3920       0.4151      [31m0.4218[0m        [94m0.5597[0m     +  0.0000  10.4887
     20      0.6901        0.3901       0.4155      [31m0.4240[0m        [94m0.5589[0m     +  0.0000  10.3854
     21      0.7504        0.3927       0.4155      0.4240        [94m0.5587[0m     +  0.0000  10.6719
     22      0.7672        [32m0.3624[0m       [35m0.4161[0m      [31m0.4261[0m        [94m0.5586[0m     +  0.0000  10.6002
     23      0.7242        0.3895       0.4161      [31m0.4267[0m        [94m0.5584[0m     +  0.0000  10.6825
     24      [36m0.8808[0m        [32m0.3589[0m       0.4155      0.4248        [94m0.5582[0m     +  0.0000  10.5287
     25      0.7504        0.4005       0.4161      [31m0.4271[0m        [94m0.5581[0m     +  0.0000  10.6925
     26      0.6937        0.3837       0.4161      0.4271        [94m0.5580[0m     +  0.0000  10.5139
     27      0.8000        0.3749       [35m0.4163[0m      [31m0.4273[0m        [94m0.5579[0m     +  0.0000  10.4697
     28      0.8344        0.3797       0.4161      0.4269        [94m0.5579[0m     +  0.0000  10.6811
     29      0.7379        0.3753       [35m0.4165[0m      [31m0.4280[0m        [94m0.5579[0m     +  0.0000  10.6321
     30      0.8554        0.3888       0.4165      [31m0.4281[0m        [94m0.5578[0m     +  0.0000  10.3850
     31      0.7504        0.4029       0.4165      0.4281        [94m0.5578[0m     +  0.0000  10.7662
     32      0.7556        0.4050       0.4165      0.4281        [94m0.5577[0m     +  0.0000  10.4366
     33      0.7379        0.3992       [35m0.4167[0m      [31m0.4284[0m        [94m0.5577[0m     +  0.0000  10.5269
     34      0.7174        0.3910       0.4167      0.4284        [94m0.5577[0m     +  0.0000  10.4840
     35      0.7270        0.3806       0.4167      [31m0.4286[0m        [94m0.5576[0m     +  0.0000  10.7084
     36      0.7709        0.3891       0.4167      0.4286        [94m0.5576[0m     +  0.0000  10.6244
     37      0.7855        [32m0.3568[0m       0.4167      0.4286        [94m0.5576[0m     +  0.0000  10.2983
     38      0.7504        0.3824       [35m0.4168[0m      [31m0.4289[0m        [94m0.5576[0m     +  0.0000  10.3903
     39      0.7251        0.3718       [35m0.4172[0m      [31m0.4294[0m        [94m0.5576[0m     +  0.0000  10.4039
     40      0.7746        0.3935       [35m0.4174[0m      [31m0.4296[0m        [94m0.5576[0m     +  0.0000  10.4997
     41      0.7379        0.3695       0.4174      0.4296        [94m0.5576[0m     +  0.0000  10.7062
     42      0.7178        0.3928       0.4172      0.4294        [94m0.5576[0m     +  0.0000  10.5305
     43      0.7196        0.3839       0.4172      0.4294        [94m0.5576[0m     +  0.0000  10.5909
     44      0.8540        0.3634       0.4172      0.4296        [94m0.5576[0m     +  0.0000  10.8788
     45      0.7714        0.3733       0.4174      [31m0.4297[0m        [94m0.5576[0m     +  0.0000  10.6847
     46      0.7556        0.3817       0.4174      0.4297        [94m0.5576[0m     +  0.0000  10.4065
     47      0.7504        0.3684       0.4174      0.4297        [94m0.5576[0m     +  0.0000  10.5473
     48      0.8190        0.3939       0.4172      0.4296        [94m0.5576[0m     +  0.0000  10.6506
     49      0.7131        0.3821       0.4174      0.4297        [94m0.5576[0m     +  0.0000  10.4417
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.5038423645320197
F1 Macro Score after query 1: 0.46519549633473184
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5963[0m        [32m0.4632[0m       [35m0.4299[0m      [31m0.5772[0m        [94m0.5669[0m     +  0.0001  10.5108
      2      [36m0.7046[0m        [32m0.3897[0m       [35m0.4799[0m      [31m0.6233[0m        [94m0.5117[0m     +  0.0001  10.5756
      3      [36m0.7336[0m        [32m0.3355[0m       [35m0.5000[0m      [31m0.6349[0m        [94m0.4962[0m     +  0.0001  10.8310
      4      [36m0.7461[0m        [32m0.3080[0m       [35m0.5226[0m      [31m0.6647[0m        [94m0.4882[0m     +  0.0001  10.5095
      5      [36m0.7704[0m        [32m0.3057[0m       [35m0.5312[0m      [31m0.6686[0m        [94m0.4610[0m     +  0.0001  10.7547
      6      [36m0.8135[0m        [32m0.2658[0m       [35m0.5375[0m      0.6507        [94m0.4572[0m     +  0.0000  10.3910
      7      0.7925        [32m0.2552[0m       [35m0.5394[0m      0.6562        [94m0.4526[0m     +  0.0000  10.5139
      8      [36m0.8264[0m        [32m0.2402[0m       [35m0.5432[0m      0.6637        [94m0.4506[0m     +  0.0000  10.6323
      9      0.8145        0.2535       0.5422      0.6604        [94m0.4488[0m     +  0.0000  10.8229
     10      0.8034        [32m0.2391[0m       0.5431      [31m0.6721[0m        0.4491        0.0000  10.7243
     11      0.8229        0.2402       [35m0.5443[0m      0.6675        [94m0.4473[0m     +  0.0000  10.6246
     12      0.8128        [32m0.2348[0m       0.5436      0.6706        [94m0.4443[0m     +  0.0000  10.6090
     13      [36m0.8605[0m        [32m0.2205[0m       [35m0.5467[0m      0.6681        0.4445        0.0000  10.5588
     14      0.8489        0.2343       0.5453      0.6695        [94m0.4423[0m     +  0.0000  10.7459
     15      0.8419        0.2229       0.5457      0.6693        [94m0.4421[0m     +  0.0000  10.7162
     16      0.8034        0.2302       0.5457      0.6699        [94m0.4413[0m     +  0.0000  10.7168
     17      0.7886        0.2251       0.5460      [31m0.6721[0m        [94m0.4405[0m     +  0.0000  10.5913
     18      0.8324        0.2313       0.5455      [31m0.6736[0m        [94m0.4398[0m     +  0.0000  10.6732
     19      0.8442        0.2257       0.5453      0.6732        [94m0.4393[0m     +  0.0000  10.6118
     20      0.8454        0.2210       0.5434      [31m0.6759[0m        [94m0.4380[0m     +  0.0000  10.7770
     21      [36m0.8827[0m        0.2238       0.5439      [31m0.6767[0m        [94m0.4377[0m     +  0.0000  10.3575
     22      0.8728        [32m0.2105[0m       0.5429      0.6757        0.4378        0.0000  10.6589
     23      0.8612        0.2195       0.5432      0.6758        0.4378        0.0000  10.8237
     24      0.8693        0.2146       0.5437      [31m0.6768[0m        [94m0.4377[0m     +  0.0000  10.6293
     25      0.8544        0.2169       0.5439      [31m0.6771[0m        [94m0.4377[0m     +  0.0000  10.4471
     26      0.8751        0.2226       0.5434      0.6768        [94m0.4376[0m     +  0.0000  10.5014
     27      0.8597        0.2215       0.5437      0.6770        [94m0.4374[0m     +  0.0000  10.7083
     28      0.8442        0.2279       0.5436      0.6767        [94m0.4373[0m     +  0.0000  10.6507
     29      0.8621        [32m0.2096[0m       0.5437      0.6768        [94m0.4373[0m     +  0.0000  10.7343
     30      0.8540        0.2207       0.5439      0.6768        [94m0.4372[0m     +  0.0000  10.7230
     31      0.8189        0.2142       0.5439      0.6768        [94m0.4372[0m     +  0.0000  10.5186
     32      0.8298        0.2265       0.5443      0.6769        [94m0.4372[0m     +  0.0000  10.8768
     33      0.8435        0.2117       0.5439      0.6770        [94m0.4371[0m     +  0.0000  10.5479
     34      0.8694        0.2145       0.5439      0.6770        [94m0.4371[0m     +  0.0000  10.6858
     35      0.8617        0.2159       0.5439      [31m0.6771[0m        0.4371        0.0000  10.5448
     36      0.8167        0.2317       0.5439      0.6771        [94m0.4371[0m     +  0.0000  10.4669
     37      0.8419        0.2170       0.5439      0.6771        [94m0.4371[0m     +  0.0000  10.6896
     38      0.8360        0.2237       0.5441      [31m0.6773[0m        0.4371        0.0000  10.5065
     39      0.8649        [32m0.2086[0m       0.5441      0.6773        [94m0.4371[0m     +  0.0000  10.6771
     40      [36m0.8850[0m        0.2173       0.5441      0.6773        [94m0.4371[0m     +  0.0000  10.5669
     41      0.8324        0.2208       0.5441      0.6773        [94m0.4371[0m     +  0.0000  10.6078
     42      0.8419        0.2224       0.5441      0.6773        [94m0.4371[0m     +  0.0000  10.6166
     43      0.8285        0.2175       0.5441      0.6773        [94m0.4371[0m     +  0.0000  10.7514
     44      0.8258        0.2183       0.5441      0.6773        [94m0.4371[0m     +  0.0000  10.6575
     45      0.8692        0.2165       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.6112
     46      0.8600        0.2177       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.5798
     47      0.8273        0.2285       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.8336
     48      0.8563        0.2224       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.6876
     49      0.8203        0.2242       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.7509
     50      0.8633        0.2234       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.5648
     51      0.8594        0.2119       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.7346
     52      [36m0.8870[0m        0.2104       0.5441      0.6773        0.4370        0.0000  10.6191
     53      0.8695        0.2142       0.5441      0.6773        0.4370        0.0000  10.5498
     54      0.8308        0.2196       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.6723
     55      0.8338        0.2226       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.7404
     56      0.8305        0.2144       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.6101
     57      0.8169        0.2192       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.5470
     58      [36m0.8972[0m        [32m0.2016[0m       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.6148
     59      0.8442        0.2112       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.4583
     60      0.8369        0.2146       0.5441      0.6773        [94m0.4370[0m     +  0.0000  10.5624
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.7159533073929961
F1 Macro Score after query 2: 0.709880445722748
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6984[0m        [32m0.3822[0m       [35m0.5222[0m      [31m0.7624[0m        [94m0.4095[0m     +  0.0001  10.8394
      2      [36m0.7662[0m        [32m0.3322[0m       [35m0.5977[0m      [31m0.7811[0m        [94m0.3501[0m     +  0.0001  10.6774
      3      [36m0.8116[0m        [32m0.2869[0m       [35m0.6196[0m      [31m0.7918[0m        [94m0.3371[0m     +  0.0001  10.7986
      4      0.8048        [32m0.2743[0m       [35m0.6253[0m      [31m0.7981[0m        [94m0.3365[0m     +  0.0001  10.8147
      5      [36m0.8319[0m        [32m0.2483[0m       [35m0.6429[0m      0.7973        [94m0.3147[0m     +  0.0001  10.8784
      6      [36m0.8537[0m        [32m0.2323[0m       0.6417      0.7782        [94m0.3090[0m     +  0.0000  10.7673
      7      0.8445        0.2358       [35m0.6436[0m      0.7772        [94m0.3079[0m     +  0.0000  10.6873
      8      0.8508        [32m0.2267[0m       [35m0.6467[0m      0.7824        [94m0.3064[0m     +  0.0000  10.7788
      9      0.8478        0.2298       [35m0.6507[0m      0.7861        [94m0.3053[0m     +  0.0000  10.8465
     10      [36m0.8740[0m        [32m0.2167[0m       [35m0.6547[0m      0.7870        0.3056        0.0000  10.7152
     11      [36m0.8773[0m        [32m0.2037[0m       0.6526      0.7824        0.3063        0.0000  10.9671
     12      [36m0.8818[0m        0.2059       [35m0.6549[0m      0.7846        0.3064        0.0000  10.8121
     13      0.8779        0.2045       [35m0.6562[0m      0.7855        0.3063        0.0000  10.8559
     14      0.8735        0.2069       0.6562      0.7859        0.3059        0.0000  10.6857
     15      0.8752        [32m0.1988[0m       [35m0.6564[0m      0.7867        [94m0.3051[0m     +  0.0000  10.5939
     16      [36m0.8886[0m        [32m0.1967[0m       0.6562      0.7852        0.3060        0.0000  10.8272
     17      0.8693        0.2002       0.6559      0.7844        0.3059        0.0000  10.8286
     18      0.8601        0.2054       0.6559      0.7842        0.3058        0.0000  10.8128
     19      0.8694        0.2100       0.6561      0.7853        0.3053        0.0000  10.7030
     20      [36m0.8939[0m        [32m0.1919[0m       0.6561      0.7852        0.3056        0.0000  10.8909
     21      0.8698        0.2032       0.6561      0.7851        0.3056        0.0000  10.9263
     22      0.8839        0.2099       [35m0.6568[0m      0.7857        0.3056        0.0000  10.7675
     23      0.8686        0.2006       0.6568      0.7858        0.3056        0.0000  10.7185
     24      0.8866        0.1984       [35m0.6569[0m      0.7858        0.3057        0.0000  10.7518
     25      0.8714        0.2094       0.6566      0.7860        0.3055        0.0000  10.7676
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.8406972030806648
F1 Macro Score after query 3: 0.8194343671110041
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8113[0m        [32m0.2952[0m       [35m0.6378[0m      [31m0.7442[0m        [94m0.3148[0m     +  0.0001  10.9640
      2      [36m0.8308[0m        [32m0.2391[0m       [35m0.6474[0m      [31m0.7466[0m        [94m0.3079[0m     +  0.0001  10.7241
      3      [36m0.8418[0m        [32m0.2245[0m       [35m0.6556[0m      [31m0.7535[0m        [94m0.2978[0m     +  0.0001  11.0475
      4      [36m0.8702[0m        [32m0.2118[0m       [35m0.6576[0m      [31m0.7590[0m        0.3038        0.0001  11.1570
      5      0.8602        [32m0.1966[0m       [35m0.6615[0m      0.7574        0.2989        0.0001  11.0060
      6      0.8532        [32m0.1857[0m       [35m0.6760[0m      [31m0.7905[0m        [94m0.2786[0m     +  0.0000  11.0772
      7      0.8581        0.1899       [35m0.6859[0m      [31m0.8065[0m        [94m0.2777[0m     +  0.0000  10.8720
      8      [36m0.8808[0m        [32m0.1823[0m       0.6806      0.7992        [94m0.2768[0m     +  0.0000  10.8625
      9      0.8750        [32m0.1761[0m       [35m0.6910[0m      [31m0.8114[0m        [94m0.2747[0m     +  0.0000  10.9061
     10      0.8787        [32m0.1739[0m       0.6905      0.8104        0.2754        0.0000  11.0277
     11      0.8712        [32m0.1662[0m       [35m0.6939[0m      [31m0.8148[0m        0.2767        0.0000  10.8281
     12      0.8719        0.1732       0.6932      0.8130        0.2774        0.0000  10.9571
     13      [36m0.8905[0m        [32m0.1627[0m       [35m0.6944[0m      [31m0.8154[0m        0.2756        0.0000  10.9017
     14      0.8855        0.1666       0.6931      0.8135        0.2748        0.0000  11.0301
     15      0.8864        [32m0.1622[0m       0.6943      [31m0.8155[0m        0.2747        0.0000  10.9247
     16      0.8889        0.1648       0.6943      0.8152        [94m0.2746[0m     +  0.0000  11.0299
     17      [36m0.8905[0m        [32m0.1603[0m       [35m0.6950[0m      [31m0.8163[0m        0.2747        0.0000  10.8439
     18      0.8814        0.1636       0.6948      [31m0.8164[0m        0.2750        0.0000  10.9364
     19      0.8888        [32m0.1588[0m       0.6939      0.8152        0.2753        0.0000  11.0155
     20      [36m0.8984[0m        [32m0.1505[0m       [35m0.6960[0m      [31m0.8172[0m        0.2756        0.0000  10.7681
     21      0.8925        0.1616       [35m0.6969[0m      [31m0.8183[0m        0.2754        0.0000  10.6958
     22      0.8872        0.1549       0.6946      0.8161        0.2755        0.0000  11.2971
     23      0.8864        0.1562       0.6948      0.8163        0.2753        0.0000  10.9063
     24      [36m0.9016[0m        [32m0.1492[0m       0.6960      0.8176        0.2754        0.0000  10.9284
     25      0.8926        [32m0.1474[0m       0.6964      0.8178        0.2752        0.0000  11.0160
     26      [36m0.9068[0m        0.1477       0.6960      0.8173        0.2752        0.0000  11.0972
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.8575498575498576
F1 Macro Score after query 4: 0.837689708652427
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8476[0m        [32m0.2305[0m       [35m0.6873[0m      [31m0.7913[0m        [94m0.2802[0m     +  0.0001  10.9936
      2      [36m0.8811[0m        [32m0.1911[0m       [35m0.6991[0m      [31m0.8072[0m        [94m0.2672[0m     +  0.0001  11.3124
      3      [36m0.8865[0m        [32m0.1794[0m       [35m0.7056[0m      [31m0.8153[0m        [94m0.2640[0m     +  0.0001  11.4350
      4      [36m0.8877[0m        [32m0.1673[0m       [35m0.7158[0m      [31m0.8171[0m        [94m0.2597[0m     +  0.0001  11.5587
      5      [36m0.8955[0m        [32m0.1632[0m       [35m0.7203[0m      [31m0.8182[0m        [94m0.2547[0m     +  0.0001  11.1720
      6      [36m0.9103[0m        [32m0.1464[0m       [35m0.7304[0m      [31m0.8334[0m        [94m0.2469[0m     +  0.0000  11.1240
      7      [36m0.9113[0m        0.1501       [35m0.7333[0m      [31m0.8375[0m        [94m0.2448[0m     +  0.0000  11.0202
      8      [36m0.9114[0m        [32m0.1391[0m       [35m0.7354[0m      [31m0.8389[0m        0.2455        0.0000  11.2656
      9      0.8970        0.1429       [35m0.7366[0m      0.8362        [94m0.2438[0m     +  0.0000  11.2311
     10      [36m0.9162[0m        [32m0.1331[0m       0.7347      0.8346        0.2478        0.0000  11.2652
     11      0.9147        0.1341       0.7361      0.8374        0.2462        0.0000  11.3492
     12      [36m0.9204[0m        [32m0.1316[0m       [35m0.7373[0m      0.8381        0.2461        0.0000  11.1708
     13      0.9083        [32m0.1241[0m       [35m0.7399[0m      0.8367        0.2448        0.0000  11.2818
     14      0.9093        0.1293       [35m0.7411[0m      0.8382        0.2440        0.0000  11.3177
     15      [36m0.9248[0m        0.1268       [35m0.7415[0m      [31m0.8396[0m        [94m0.2436[0m     +  0.0000  11.1247
     16      0.9155        0.1257       0.7392      0.8390        0.2445        0.0000  11.2844
     17      0.9211        0.1252       0.7401      [31m0.8398[0m        0.2449        0.0000  11.4182
     18      0.9131        0.1262       0.7403      [31m0.8399[0m        0.2447        0.0000  11.3723
     19      0.9177        [32m0.1227[0m       0.7394      0.8399        0.2451        0.0000  11.3136
     20      0.9129        0.1248       0.7403      [31m0.8402[0m        0.2448        0.0000  11.2153
     21      0.9164        0.1249       0.7411      [31m0.8404[0m        0.2451        0.0000  11.3599
     22      0.9219        [32m0.1186[0m       0.7406      [31m0.8405[0m        0.2453        0.0000  11.4635
     23      0.9194        0.1225       0.7408      0.8399        0.2455        0.0000  11.3757
     24      [36m0.9374[0m        [32m0.1178[0m       0.7401      0.8393        0.2459        0.0000  11.4762
     25      0.9251        0.1194       0.7405      0.8401        0.2457        0.0000  11.3878
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.8821406151914626
F1 Macro Score after query 5: 0.8663305660657988
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8787[0m        [32m0.1981[0m       [35m0.7297[0m      [31m0.8041[0m        [94m0.2507[0m     +  0.0001  11.7355
      2      [36m0.9028[0m        [32m0.1663[0m       [35m0.7387[0m      [31m0.8088[0m        [94m0.2431[0m     +  0.0001  11.8877
      3      [36m0.9035[0m        [32m0.1601[0m       [35m0.7391[0m      [31m0.8096[0m        0.2511        0.0001  11.8716
      4      [36m0.9125[0m        [32m0.1525[0m       [35m0.7460[0m      [31m0.8215[0m        0.2470        0.0001  11.8140
      5      0.9104        [32m0.1421[0m       [35m0.7470[0m      0.8137        0.2552        0.0001  12.3371
      6      [36m0.9192[0m        [32m0.1356[0m       [35m0.7694[0m      [31m0.8504[0m        [94m0.2247[0m     +  0.0000  11.7941
      7      [36m0.9261[0m        [32m0.1281[0m       0.7688      0.8451        0.2313        0.0000  11.8675
      8      [36m0.9310[0m        [32m0.1260[0m       [35m0.7696[0m      0.8495        0.2275        0.0000  11.9777
      9      0.9225        0.1267       0.7686      0.8467        0.2307        0.0000  11.9165
     10      0.9282        [32m0.1210[0m       [35m0.7714[0m      [31m0.8537[0m        0.2275        0.0000  12.0516
     11      [36m0.9378[0m        [32m0.1150[0m       [35m0.7769[0m      [31m0.8634[0m        [94m0.2222[0m     +  0.0000  11.5379
     12      [36m0.9384[0m        [32m0.1117[0m       0.7759      0.8624        [94m0.2217[0m     +  0.0000  11.7106
     13      0.9357        0.1143       0.7741      0.8634        [94m0.2203[0m     +  0.0000  11.9002
     14      0.9381        0.1128       [35m0.7774[0m      [31m0.8656[0m        0.2222        0.0000  11.7434
     15      0.9336        0.1133       0.7766      0.8646        0.2214        0.0000  11.6655
     16      [36m0.9448[0m        [32m0.1079[0m       0.7736      [31m0.8695[0m        0.2212        0.0000  11.9937
     17      0.9396        0.1106       0.7750      0.8679        0.2213        0.0000  11.8328
     18      0.9433        [32m0.1058[0m       0.7745      0.8672        0.2214        0.0000  11.8829
     19      0.9364        0.1072       0.7750      0.8669        0.2221        0.0000  11.8223
     20      0.9425        0.1064       0.7738      0.8663        0.2221        0.0000  11.5731
     21      0.9445        0.1064       0.7734      0.8664        0.2223        0.0000  12.0376
     22      0.9420        0.1058       0.7741      0.8673        0.2226        0.0000  11.7413
     23      0.9382        0.1080       0.7731      0.8669        0.2221        0.0000  11.7747
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8935422239205196
F1 Macro Score after query 6: 0.8805159682070646
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8992[0m        [32m0.1678[0m       [35m0.7837[0m      [31m0.8600[0m        [94m0.2213[0m     +  0.0001  12.7767
      2      [36m0.9132[0m        [32m0.1414[0m       [35m0.7925[0m      [31m0.8669[0m        [94m0.2168[0m     +  0.0001  13.1123
      3      [36m0.9183[0m        [32m0.1378[0m       0.7858      [31m0.8701[0m        [94m0.2163[0m     +  0.0001  12.9033
      4      [36m0.9246[0m        [32m0.1281[0m       0.7903      [31m0.8720[0m        [94m0.2157[0m     +  0.0001  13.0629
      5      0.9233        [32m0.1267[0m       0.7859      [31m0.8725[0m        0.2166        0.0001  13.0612
      6      [36m0.9330[0m        [32m0.1094[0m       0.7863      0.8720        0.2250        0.0000  12.8211
      7      [36m0.9371[0m        [32m0.1080[0m       0.7852      [31m0.8742[0m        0.2246        0.0000  13.1852
      8      [36m0.9435[0m        [32m0.1036[0m       0.7845      [31m0.8755[0m        0.2230        0.0000  13.0139
      9      0.9390        0.1046       0.7872      [31m0.8769[0m        0.2231        0.0000  12.9799
     10      0.9430        [32m0.0984[0m       0.7852      [31m0.8787[0m        0.2177        0.0000  13.2909
     11      [36m0.9443[0m        [32m0.0967[0m       0.7854      0.8770        0.2224        0.0000  12.8870
     12      0.9397        [32m0.0966[0m       0.7828      0.8756        0.2235        0.0000  13.0604
     13      0.9440        [32m0.0938[0m       0.7839      0.8765        0.2250        0.0000  12.8726
     14      [36m0.9528[0m        [32m0.0879[0m       0.7811      0.8763        0.2253        0.0000  12.9811
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.8969489414694894
F1 Macro Score after query 7: 0.8861508527361374
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9083[0m        [32m0.1551[0m       [35m0.7694[0m      [31m0.8674[0m        [94m0.2150[0m     +  0.0001  15.2518
      2      [36m0.9171[0m        [32m0.1385[0m       [35m0.7731[0m      [31m0.8724[0m        [94m0.2131[0m     +  0.0001  15.1243
      3      [36m0.9222[0m        [32m0.1322[0m       [35m0.7750[0m      0.8719        [94m0.2108[0m     +  0.0001  15.0327
      4      [36m0.9259[0m        [32m0.1258[0m       0.7642      0.8662        0.2243        0.0001  14.9221
      5      [36m0.9275[0m        [32m0.1246[0m       0.7679      0.8689        0.2172        0.0001  15.5603
      6      [36m0.9392[0m        [32m0.1099[0m       [35m0.7778[0m      [31m0.8732[0m        0.2150        0.0000  15.1070
      7      [36m0.9399[0m        [32m0.1064[0m       [35m0.7788[0m      [31m0.8751[0m        0.2155        0.0000  15.2459
      8      [36m0.9440[0m        [32m0.1035[0m       0.7769      0.8745        0.2166        0.0000  15.1723
      9      0.9440        [32m0.1028[0m       0.7729      0.8731        0.2177        0.0000  14.7502
     10      0.9410        [32m0.1008[0m       [35m0.7790[0m      [31m0.8761[0m        0.2203        0.0000  14.7159
     11      [36m0.9462[0m        [32m0.0942[0m       0.7760      0.8744        0.2212        0.0000  15.0629
     12      [36m0.9499[0m        0.0942       0.7734      0.8738        0.2215        0.0000  15.1694
     13      0.9441        [32m0.0918[0m       0.7736      0.8725        0.2218        0.0000  15.1057
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.895126229883304
F1 Macro Score after query 8: 0.8819871279066144
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9137[0m        [32m0.1419[0m       [35m0.7844[0m      [31m0.8739[0m        [94m0.2101[0m     +  0.0001  18.5602
      2      [36m0.9217[0m        [32m0.1273[0m       [35m0.7924[0m      [31m0.8793[0m        [94m0.2018[0m     +  0.0001  18.5514
      3      [36m0.9256[0m        [32m0.1232[0m       0.7859      0.8729        0.2120        0.0001  18.6891
      4      [36m0.9310[0m        [32m0.1149[0m       0.7828      0.8753        0.2116        0.0001  18.4857
      5      [36m0.9356[0m        [32m0.1109[0m       0.7804      0.8724        0.2165        0.0001  18.8960
      6      [36m0.9417[0m        [32m0.0974[0m       0.7783      0.8725        0.2191        0.0000  18.5308
      7      [36m0.9458[0m        [32m0.0932[0m       0.7799      0.8740        0.2232        0.0000  18.7347
      8      [36m0.9474[0m        [32m0.0924[0m       0.7786      0.8727        0.2247        0.0000  18.5658
      9      [36m0.9481[0m        [32m0.0896[0m       0.7795      0.8722        0.2166        0.0000  18.4893
     10      0.9459        [32m0.0894[0m       0.7792      0.8726        0.2233        0.0000  18.5019
     11      [36m0.9506[0m        [32m0.0825[0m       0.7767      0.8731        0.2264        0.0000  18.6426
     12      [36m0.9545[0m        [32m0.0800[0m       0.7762      0.8714        0.2237        0.0000  18.3934
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8979120117112258
F1 Macro Score after query 9: 0.8828969039136011
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9232[0m        [32m0.1307[0m       [35m0.7826[0m      [31m0.8698[0m        [94m0.1979[0m     +  0.0001  24.7867
      2      [36m0.9315[0m        [32m0.1195[0m       0.7776      0.8630        0.2018        0.0001  25.1154
      3      [36m0.9341[0m        [32m0.1119[0m       0.7795      0.8670        0.2011        0.0001  25.0099
      4      [36m0.9375[0m        [32m0.1067[0m       0.7677      0.8649        0.2142        0.0001  24.7760
      5      [36m0.9396[0m        [32m0.1018[0m       0.7731      0.8595        0.2106        0.0001  24.8194
      6      [36m0.9502[0m        [32m0.0871[0m       0.7646      0.8613        0.2309        0.0000  25.0707
      7      [36m0.9510[0m        [32m0.0855[0m       0.7611      0.8583        0.2250        0.0000  25.0547
      8      [36m0.9521[0m        [32m0.0827[0m       0.7608      0.8626        0.2383        0.0000  25.2896
      9      [36m0.9543[0m        [32m0.0805[0m       0.7602      0.8584        0.2349        0.0000  25.0134
     10      [36m0.9563[0m        [32m0.0775[0m       0.7595      0.8574        0.2434        0.0000  25.0735
     11      [36m0.9596[0m        [32m0.0742[0m       0.7635      0.8621        0.2459        0.0000  25.0234
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.892241709427893
F1 Macro Score after query 10: 0.8764945019716867
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9277[0m        [32m0.1203[0m       [35m0.7644[0m      [31m0.8708[0m        [94m0.2426[0m     +  0.0001  35.8507
      2      [36m0.9362[0m        [32m0.1073[0m       0.7549      0.8580        [94m0.2394[0m     +  0.0001  37.2017
      3      [36m0.9408[0m        [32m0.1000[0m       0.7540      0.8624        0.2574        0.0001  36.7782
      4      [36m0.9435[0m        [32m0.0954[0m       0.7398      0.8588        0.2998        0.0001  36.8852
      5      [36m0.9457[0m        [32m0.0905[0m       0.7450      0.8583        0.2846        0.0001  37.1085
      6      [36m0.9559[0m        [32m0.0762[0m       0.7533      0.8580        0.2677        0.0000  36.7336
      7      [36m0.9572[0m        [32m0.0734[0m       0.7470      0.8556        0.2766        0.0000  36.8165
      8      [36m0.9588[0m        [32m0.0718[0m       0.7533      0.8581        0.2719        0.0000  36.6601
      9      [36m0.9593[0m        [32m0.0702[0m       0.7484      0.8548        0.2753        0.0000  36.7365
     10      [36m0.9601[0m        [32m0.0685[0m       0.7474      0.8542        0.2791        0.0000  36.6695
     11      [36m0.9634[0m        [32m0.0640[0m       0.7502      0.8557        0.2698        0.0000  36.9339
     12      0.9628        [32m0.0629[0m       0.7483      0.8555        0.2757        0.0000  36.1080
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8961068528496623
F1 Macro Score after query 11: 0.8822311207105473
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9379[0m        [32m0.1036[0m       [35m0.7646[0m      [31m0.8622[0m        [94m0.2260[0m     +  0.0001  58.1407
      2      [36m0.9451[0m        [32m0.0943[0m       0.7575      0.8528        0.2386        0.0001  57.5987
      3      [36m0.9479[0m        [32m0.0887[0m       0.7578      0.8558        0.2453        0.0001  57.5490
      4      [36m0.9511[0m        [32m0.0841[0m       0.7538      0.8561        0.2623        0.0001  57.6263
      5      [36m0.9536[0m        [32m0.0801[0m       [35m0.7658[0m      0.8470        [94m0.2244[0m     +  0.0001  57.9399
      6      [36m0.9611[0m        [32m0.0675[0m       0.7568      0.8577        0.2885        0.0000  56.0869
      7      [36m0.9620[0m        [32m0.0660[0m       0.7576      0.8562        0.2710        0.0000  56.5284
      8      [36m0.9624[0m        [32m0.0636[0m       0.7549      0.8566        0.2861        0.0000  58.0937
      9      [36m0.9636[0m        [32m0.0625[0m       0.7524      0.8571        0.3033        0.0000  58.1008
     10      [36m0.9644[0m        [32m0.0605[0m       0.7530      0.8557        0.2948        0.0000  58.2967
     11      [36m0.9671[0m        [32m0.0562[0m       0.7599      0.8597        0.2836        0.0000  58.0422
     12      [36m0.9679[0m        [32m0.0557[0m       0.7561      0.8588        0.2975        0.0000  57.9079
     13      0.9673        0.0558       0.7559      0.8584        0.2939        0.0000  58.2603
     14      [36m0.9680[0m        [32m0.0542[0m       0.7556      0.8563        0.2950        0.0000  57.9287
     15      [36m0.9688[0m        [32m0.0540[0m       0.7545      0.8553        0.2965        0.0000  58.2031
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8928217255320772
F1 Macro Score after query 12: 0.8792797788656482
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9538[0m        [32m0.0786[0m       [35m0.7569[0m      [31m0.8460[0m        [94m0.2576[0m     +  0.0001  64.2971
      2      [36m0.9561[0m        [32m0.0755[0m       [35m0.7667[0m      [31m0.8573[0m        [94m0.2422[0m     +  0.0001  66.5414
      3      [36m0.9574[0m        [32m0.0720[0m       0.7622      0.8553        0.2549        0.0001  66.8523
      4      [36m0.9585[0m        [32m0.0707[0m       0.7589      0.8423        0.2448        0.0001  66.8274
      5      [36m0.9598[0m        [32m0.0685[0m       0.7658      0.8542        [94m0.2372[0m     +  0.0001  67.0510
      6      [36m0.9658[0m        [32m0.0585[0m       0.7601      0.8530        0.2467        0.0000  66.7209
      7      [36m0.9666[0m        [32m0.0569[0m       0.7601      0.8518        0.2583        0.0000  66.8510
      8      [36m0.9670[0m        [32m0.0563[0m       0.7618      0.8551        0.2482        0.0000  66.8699
      9      [36m0.9678[0m        [32m0.0553[0m       0.7540      0.8517        0.2654        0.0000  66.6866
     10      0.9676        [32m0.0537[0m       0.7595      0.8568        0.2685        0.0000  66.9676
     11      [36m0.9701[0m        [32m0.0509[0m       0.7571      0.8559        0.2796        0.0000  66.7575
     12      [36m0.9707[0m        [32m0.0501[0m       0.7615      0.8571        0.2778        0.0000  66.5478
     13      0.9699        [32m0.0500[0m       0.7616      [31m0.8590[0m        0.2871        0.0000  65.6984
     14      0.9695        0.0502       0.7615      [31m0.8591[0m        0.2753        0.0000  66.2029
     15      [36m0.9709[0m        [32m0.0492[0m       0.7635      [31m0.8596[0m        0.2782        0.0000  66.6427
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.891986593540524
F1 Macro Score after query 13: 0.87708584927018
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed45_config2\AL_average_confidence_results_for_multilabel_classification.pickle
