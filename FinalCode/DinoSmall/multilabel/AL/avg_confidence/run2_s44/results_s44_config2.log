Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5460[0m        [32m0.7305[0m       [35m0.0606[0m      [31m0.1748[0m        [94m0.6982[0m     +  0.0001  11.8437
      2      0.5000        [32m0.6546[0m       [35m0.3118[0m      [31m0.5036[0m        [94m0.6765[0m     +  0.0001  10.3538
      3      [36m0.6984[0m        [32m0.6165[0m       0.3059      [31m0.5187[0m        [94m0.6743[0m     +  0.0001  10.4845
      4      0.5675        0.6462       [35m0.3158[0m      0.4720        0.6783        0.0001  10.6892
      5      [36m0.8214[0m        [32m0.5715[0m       0.2073      0.4845        0.6887        0.0001  10.6885
      6      0.7667        [32m0.5593[0m       0.2906      0.4912        0.6802        0.0000  10.6850
      7      [36m0.8320[0m        [32m0.5395[0m       0.2708      0.4806        0.6846        0.0000  10.8403
      8      0.7667        0.5659       0.2970      0.4869        0.6792        0.0000  10.8080
      9      0.7667        0.5557       0.3035      0.4821        0.6774        0.0000  10.8749
     10      0.7963        [32m0.5302[0m       0.3089      0.4837        0.6771        0.0000  10.7682
     11      0.7857        [32m0.5224[0m       0.3080      0.4812        0.6779        0.0000  10.7522
     12      [36m0.8519[0m        [32m0.5205[0m       0.3073      0.4780        0.6762        0.0000  10.7916
     13      0.8333        [32m0.5047[0m       0.3082      0.4801        0.6753        0.0000  10.8980
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4935
Pre F1 macro score = 0.5063
Pre Accuracy = 0.3436

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5863[0m        [32m0.6667[0m       [35m0.1601[0m      [31m0.4132[0m        [94m0.6496[0m     +  0.0001  10.9375
      2      0.5573        [32m0.6430[0m       [35m0.2080[0m      0.3995        [94m0.5961[0m     +  0.0001  10.8612
      3      [36m0.5970[0m        [32m0.5967[0m       [35m0.2568[0m      [31m0.5149[0m        [94m0.5826[0m     +  0.0001  10.9198
      4      0.5737        [32m0.5601[0m       [35m0.2797[0m      [31m0.6278[0m        0.5851        0.0001  10.9578
      5      [36m0.6854[0m        [32m0.5523[0m       [35m0.3281[0m      [31m0.6532[0m        [94m0.5592[0m     +  0.0001  10.7799
      6      [36m0.7790[0m        [32m0.5035[0m       [35m0.3535[0m      [31m0.6598[0m        [94m0.5471[0m     +  0.0000  10.8469
      7      [36m0.8244[0m        [32m0.4974[0m       [35m0.3634[0m      [31m0.6661[0m        [94m0.5400[0m     +  0.0000  10.8173
      8      0.7882        [32m0.4848[0m       [35m0.3795[0m      [31m0.6691[0m        [94m0.5308[0m     +  0.0000  10.8892
      9      0.7941        [32m0.4796[0m       [35m0.3891[0m      [31m0.6724[0m        [94m0.5242[0m     +  0.0000  10.9387
     10      0.8223        [32m0.4652[0m       [35m0.3970[0m      [31m0.6785[0m        [94m0.5204[0m     +  0.0000  10.8470
     11      0.8077        [32m0.4605[0m       [35m0.4002[0m      [31m0.6803[0m        [94m0.5170[0m     +  0.0000  10.8405
     12      [36m0.8310[0m        [32m0.4337[0m       [35m0.4028[0m      [31m0.6808[0m        [94m0.5137[0m     +  0.0000  11.1094
     13      [36m0.8702[0m        0.4564       [35m0.4038[0m      [31m0.6811[0m        [94m0.5119[0m     +  0.0000  11.0564
     14      0.8429        0.4491       [35m0.4068[0m      0.6799        [94m0.5095[0m     +  0.0000  10.8938
     15      [36m0.9157[0m        [32m0.4152[0m       [35m0.4083[0m      0.6805        [94m0.5072[0m     +  0.0000  10.8330
     16      0.8638        0.4309       [35m0.4101[0m      0.6804        [94m0.5061[0m     +  0.0000  10.8368
     17      0.8233        0.4209       [35m0.4109[0m      [31m0.6821[0m        [94m0.5054[0m     +  0.0000  10.8736
     18      0.8918        0.4257       [35m0.4113[0m      [31m0.6823[0m        [94m0.5045[0m     +  0.0000  10.8491
     19      0.8727        0.4209       [35m0.4116[0m      [31m0.6826[0m        [94m0.5038[0m     +  0.0000  11.0026
     20      [36m0.9172[0m        0.4182       [35m0.4125[0m      [31m0.6828[0m        [94m0.5030[0m     +  0.0000  11.0298
     21      0.8615        [32m0.4113[0m       [35m0.4130[0m      [31m0.6834[0m        [94m0.5028[0m     +  0.0000  10.8285
     22      0.8465        0.4307       0.4128      0.6834        [94m0.5025[0m     +  0.0000  10.9210
     23      0.8526        0.4328       [35m0.4132[0m      0.6834        [94m0.5022[0m     +  0.0000  10.8131
     24      0.8475        0.4329       [35m0.4134[0m      0.6833        [94m0.5019[0m     +  0.0000  10.9031
     25      0.8070        0.4194       [35m0.4141[0m      [31m0.6841[0m        [94m0.5017[0m     +  0.0000  10.8740
     26      0.8707        0.4366       [35m0.4144[0m      0.6839        [94m0.5016[0m     +  0.0000  10.9459
     27      [36m0.9183[0m        [32m0.4080[0m       0.4141      0.6839        [94m0.5015[0m     +  0.0000  10.8881
     28      0.8442        0.4173       0.4142      0.6838        [94m0.5014[0m     +  0.0000  10.8464
     29      0.8821        0.4357       [35m0.4148[0m      0.6837        [94m0.5013[0m     +  0.0000  10.7866
     30      0.8576        0.4083       [35m0.4153[0m      [31m0.6841[0m        [94m0.5012[0m     +  0.0000  10.9323
     31      0.8586        0.4188       0.4151      0.6838        [94m0.5011[0m     +  0.0000  10.8729
     32      0.8552        0.4351       [35m0.4155[0m      [31m0.6841[0m        [94m0.5011[0m     +  0.0000  10.9032
     33      0.8663        [32m0.4025[0m       0.4155      0.6841        [94m0.5010[0m     +  0.0000  10.8781
     34      0.9172        [32m0.3879[0m       [35m0.4158[0m      [31m0.6842[0m        [94m0.5010[0m     +  0.0000  11.0035
     35      0.8885        0.3948       0.4156      0.6842        [94m0.5010[0m     +  0.0000  10.8306
     36      0.8786        0.3926       0.4156      0.6842        [94m0.5010[0m     +  0.0000  10.8717
     37      0.9076        0.3880       0.4158      [31m0.6844[0m        [94m0.5009[0m     +  0.0000  10.8153
     38      0.8638        0.4048       [35m0.4160[0m      [31m0.6844[0m        [94m0.5009[0m     +  0.0000  10.8715
     39      0.8697        0.4161       0.4158      0.6844        [94m0.5009[0m     +  0.0000  10.9776
     40      0.8475        0.4039       0.4158      0.6844        [94m0.5009[0m     +  0.0000  10.8458
     41      0.8650        0.4253       0.4160      0.6844        [94m0.5009[0m     +  0.0000  10.8943
     42      0.8638        0.4055       0.4158      0.6844        [94m0.5009[0m     +  0.0000  10.9826
     43      0.8786        0.4160       0.4160      0.6844        [94m0.5009[0m     +  0.0000  10.9861
     44      0.8980        0.4082       0.4160      0.6844        [94m0.5009[0m     +  0.0000  11.0444
     45      0.8554        0.4071       0.4160      0.6844        [94m0.5008[0m     +  0.0000  10.8565
     46      0.8808        0.4148       0.4160      0.6844        [94m0.5008[0m     +  0.0000  11.0623
     47      0.9046        0.4156       0.4160      0.6844        [94m0.5008[0m     +  0.0000  10.9394
     48      0.8121        0.4374       0.4160      0.6844        [94m0.5008[0m     +  0.0000  10.9723
     49      0.8638        0.4139       0.4160      0.6844        [94m0.5008[0m     +  0.0000  10.8958
     50      0.8915        0.4111       0.4160      0.6844        [94m0.5008[0m     +  0.0000  10.9739
     51      0.8650        0.4159       0.4160      0.6844        [94m0.5008[0m     +  0.0000  10.9376
     52      0.8885        0.3944       0.4160      0.6844        [94m0.5008[0m     +  0.0000  11.1751
     53      0.8987        0.4167       0.4160      0.6844        [94m0.5008[0m     +  0.0000  10.6276
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.7075567114578819
F1 Macro Score after query 1: 0.7035538161858342
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7079[0m        [32m0.4914[0m       [35m0.5738[0m      [31m0.7153[0m        [94m0.4422[0m     +  0.0001  11.0011
      2      [36m0.7931[0m        [32m0.4276[0m       [35m0.5839[0m      [31m0.7333[0m        [94m0.4032[0m     +  0.0001  10.9726
      3      [36m0.8421[0m        [32m0.3507[0m       [35m0.5913[0m      [31m0.7402[0m        [94m0.3822[0m     +  0.0001  10.8804
      4      [36m0.8758[0m        [32m0.3111[0m       [35m0.6106[0m      [31m0.7632[0m        [94m0.3644[0m     +  0.0001  10.9512
      5      0.8397        [32m0.3085[0m       [35m0.6207[0m      [31m0.7757[0m        [94m0.3483[0m     +  0.0001  11.0302
      6      0.8596        [32m0.2835[0m       [35m0.6233[0m      [31m0.7760[0m        [94m0.3391[0m     +  0.0000  10.8530
      7      [36m0.8842[0m        [32m0.2626[0m       [35m0.6274[0m      [31m0.7771[0m        [94m0.3321[0m     +  0.0000  10.9258
      8      [36m0.9040[0m        [32m0.2503[0m       [35m0.6300[0m      [31m0.7805[0m        [94m0.3290[0m     +  0.0000  11.0769
      9      0.8522        0.2684       [35m0.6326[0m      [31m0.7893[0m        0.3303        0.0000  10.9846
     10      0.8815        0.2564       0.6321      0.7858        [94m0.3262[0m     +  0.0000  10.9578
     11      0.9001        [32m0.2466[0m       [35m0.6340[0m      0.7877        [94m0.3258[0m     +  0.0000  10.9181
     12      [36m0.9096[0m        [32m0.2383[0m       [35m0.6359[0m      [31m0.7901[0m        [94m0.3255[0m     +  0.0000  11.0992
     13      0.8909        0.2413       0.6351      0.7895        [94m0.3250[0m     +  0.0000  11.0621
     14      [36m0.9172[0m        [32m0.2280[0m       0.6349      0.7877        [94m0.3245[0m     +  0.0000  11.0676
     15      0.8896        0.2401       0.6352      0.7889        [94m0.3245[0m     +  0.0000  10.8258
     16      0.8880        0.2352       0.6347      0.7880        [94m0.3242[0m     +  0.0000  10.9995
     17      0.9030        0.2411       0.6347      0.7880        [94m0.3242[0m     +  0.0000  10.9343
     18      0.9132        [32m0.2280[0m       0.6342      0.7870        [94m0.3239[0m     +  0.0000  11.0047
     19      0.9050        [32m0.2260[0m       0.6342      0.7872        0.3239        0.0000  10.9668
     20      0.9172        0.2289       0.6351      0.7873        [94m0.3238[0m     +  0.0000  11.0615
     21      0.9108        0.2328       0.6354      0.7873        [94m0.3238[0m     +  0.0000  10.9900
     22      0.9028        [32m0.2159[0m       0.6359      0.7874        0.3238        0.0000  11.0192
     23      0.9050        0.2413       [35m0.6361[0m      0.7874        0.3238        0.0000  10.9830
     24      0.9132        0.2282       0.6361      0.7874        [94m0.3237[0m     +  0.0000  11.0464
     25      0.9172        0.2193       0.6359      0.7872        [94m0.3236[0m     +  0.0000  10.8453
     26      0.9096        0.2289       0.6356      0.7872        [94m0.3236[0m     +  0.0000  11.0154
     27      0.9105        [32m0.2127[0m       0.6356      0.7873        [94m0.3235[0m     +  0.0000  11.0434
     28      0.8934        0.2397       0.6358      0.7874        [94m0.3235[0m     +  0.0000  11.1406
     29      0.9055        0.2255       0.6358      0.7873        [94m0.3235[0m     +  0.0000  11.0529
     30      0.8869        0.2256       [35m0.6363[0m      0.7875        [94m0.3234[0m     +  0.0000  11.0270
     31      0.8963        0.2193       0.6361      0.7875        0.3234        0.0000  11.0652
     32      0.8919        0.2350       0.6363      0.7875        [94m0.3234[0m     +  0.0000  11.0167
     33      0.9149        0.2285       0.6359      0.7874        0.3234        0.0000  10.9861
     34      0.8957        0.2217       0.6361      0.7875        0.3234        0.0000  10.9507
     35      0.8843        0.2205       0.6361      0.7875        [94m0.3234[0m     +  0.0000  11.1247
     36      0.8924        0.2278       0.6361      0.7875        [94m0.3234[0m     +  0.0000  10.9448
     37      0.9161        0.2144       0.6361      0.7875        [94m0.3234[0m     +  0.0000  10.9357
     38      [36m0.9227[0m        0.2274       0.6361      0.7875        [94m0.3234[0m     +  0.0000  10.8422
     39      0.9050        0.2128       0.6361      0.7875        [94m0.3234[0m     +  0.0000  10.9272
     40      0.9095        0.2338       0.6359      0.7874        [94m0.3234[0m     +  0.0000  10.9873
     41      0.9227        0.2165       0.6359      0.7874        [94m0.3234[0m     +  0.0000  11.1347
     42      [36m0.9318[0m        0.2230       0.6359      0.7874        [94m0.3234[0m     +  0.0000  11.0685
     43      0.9172        0.2289       0.6361      0.7875        [94m0.3234[0m     +  0.0000  10.9253
     44      0.8939        0.2238       0.6361      0.7875        [94m0.3234[0m     +  0.0000  11.0828
     45      0.9162        0.2284       0.6361      0.7875        [94m0.3234[0m     +  0.0000  11.1296
     46      0.9012        0.2166       0.6361      0.7875        [94m0.3234[0m     +  0.0000  10.9060
     47      0.9167        0.2173       0.6361      0.7875        [94m0.3234[0m     +  0.0000  11.0935
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.8120613865967455
F1 Macro Score after query 2: 0.7995064045086758
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8268[0m        [32m0.3403[0m       [35m0.6290[0m      [31m0.7618[0m        [94m0.3094[0m     +  0.0001  10.8438
      2      [36m0.8786[0m        [32m0.2458[0m       [35m0.6460[0m      [31m0.7814[0m        [94m0.3014[0m     +  0.0001  11.0940
      3      [36m0.8840[0m        [32m0.2388[0m       [35m0.6517[0m      [31m0.7845[0m        [94m0.2987[0m     +  0.0001  11.2318
      4      [36m0.9016[0m        [32m0.2055[0m       0.6453      0.7730        0.3016        0.0001  11.0788
      5      0.8863        0.2058       0.6495      0.7798        [94m0.2937[0m     +  0.0001  11.0123
      6      0.8827        [32m0.1944[0m       [35m0.6582[0m      [31m0.7965[0m        [94m0.2895[0m     +  0.0000  11.1820
      7      [36m0.9056[0m        [32m0.1878[0m       [35m0.6589[0m      0.7941        [94m0.2889[0m     +  0.0000  11.0817
      8      0.8835        [32m0.1860[0m       0.6578      0.7875        0.2923        0.0000  11.1091
      9      0.9024        [32m0.1845[0m       [35m0.6627[0m      [31m0.8017[0m        [94m0.2871[0m     +  0.0000  11.1288
     10      0.8896        [32m0.1778[0m       0.6623      0.7970        0.2873        0.0000  11.0762
     11      0.8943        [32m0.1704[0m       [35m0.6670[0m      [31m0.8044[0m        [94m0.2840[0m     +  0.0000  11.1928
     12      0.9024        0.1752       0.6667      [31m0.8062[0m        [94m0.2838[0m     +  0.0000  11.1722
     13      0.8924        0.1766       0.6658      0.8034        0.2844        0.0000  11.1883
     14      0.9003        0.1720       0.6665      0.8036        [94m0.2837[0m     +  0.0000  10.9794
     15      0.9056        [32m0.1692[0m       [35m0.6675[0m      0.8054        [94m0.2831[0m     +  0.0000  11.1704
     16      0.9046        [32m0.1649[0m       0.6674      [31m0.8071[0m        [94m0.2821[0m     +  0.0000  11.1513
     17      0.8866        0.1710       0.6670      0.8069        0.2822        0.0000  11.0620
     18      0.9023        [32m0.1614[0m       [35m0.6677[0m      [31m0.8087[0m        [94m0.2817[0m     +  0.0000  11.0408
     19      [36m0.9089[0m        0.1653       [35m0.6679[0m      [31m0.8089[0m        0.2819        0.0000  11.0313
     20      0.8995        0.1700       [35m0.6693[0m      [31m0.8105[0m        [94m0.2814[0m     +  0.0000  11.1748
     21      0.9089        0.1684       [35m0.6694[0m      [31m0.8111[0m        [94m0.2812[0m     +  0.0000  11.1999
     22      0.8967        [32m0.1570[0m       [35m0.6698[0m      [31m0.8113[0m        0.2813        0.0000  11.2002
     23      [36m0.9106[0m        0.1696       0.6694      0.8112        0.2814        0.0000  11.0805
     24      [36m0.9154[0m        0.1612       [35m0.6700[0m      0.8113        [94m0.2812[0m     +  0.0000  11.1091
     25      0.9081        0.1581       0.6698      [31m0.8115[0m        [94m0.2811[0m     +  0.0000  11.0970
     26      0.9032        0.1638       0.6700      0.8115        [94m0.2811[0m     +  0.0000  11.2356
     27      0.8878        0.1667       0.6698      0.8113        0.2811        0.0000  11.1722
     28      0.8991        0.1646       0.6700      0.8114        [94m0.2811[0m     +  0.0000  10.8910
     29      0.9060        0.1593       0.6700      0.8114        [94m0.2811[0m     +  0.0000  11.2225
     30      0.9044        [32m0.1516[0m       [35m0.6701[0m      0.8115        0.2812        0.0000  11.1690
     31      0.9012        0.1680       0.6701      0.8115        0.2812        0.0000  11.1252
     32      0.8975        [32m0.1513[0m       0.6698      0.8113        0.2812        0.0000  11.2044
     33      0.8963        0.1663       0.6698      0.8112        0.2812        0.0000  11.0263
     34      0.9079        0.1656       0.6694      0.8110        0.2812        0.0000  11.1796
     35      0.9041        0.1583       0.6694      0.8108        0.2812        0.0000  11.1250
     36      0.8990        0.1655       0.6694      0.8109        0.2812        0.0000  11.1979
     37      0.8909        0.1626       0.6693      0.8108        0.2812        0.0000  11.2347
     38      0.8986        0.1712       0.6693      0.8108        0.2812        0.0000  11.0205
     39      0.8971        0.1683       0.6694      0.8109        0.2812        0.0000  10.9680
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.846578631452581
F1 Macro Score after query 3: 0.835261341750067
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8499[0m        [32m0.2532[0m       [35m0.6500[0m      [31m0.8177[0m        [94m0.3309[0m     +  0.0001  11.1561
      2      [36m0.9014[0m        [32m0.2012[0m       [35m0.6786[0m      0.8088        [94m0.2966[0m     +  0.0001  11.3102
      3      0.8951        [32m0.1858[0m       [35m0.6845[0m      0.8048        0.2983        0.0001  11.2994
      4      0.9008        [32m0.1841[0m       0.6774      0.7960        0.3024        0.0001  11.3425
      5      [36m0.9112[0m        [32m0.1711[0m       [35m0.6891[0m      0.8165        0.2987        0.0001  11.3749
      6      [36m0.9196[0m        [32m0.1536[0m       0.6823      0.8057        0.3034        0.0000  11.3770
      7      [36m0.9230[0m        [32m0.1532[0m       0.6844      0.8083        0.3034        0.0000  11.2717
      8      0.9180        [32m0.1475[0m       0.6852      0.8093        0.3014        0.0000  11.3333
      9      [36m0.9317[0m        [32m0.1446[0m       0.6851      0.8089        0.3014        0.0000  11.3268
     10      0.9227        0.1480       0.6882      0.8117        0.2990        0.0000  11.3439
     11      [36m0.9324[0m        [32m0.1423[0m       0.6863      0.8098        0.2996        0.0000  11.2710
     12      [36m0.9331[0m        [32m0.1344[0m       0.6858      0.8071        0.3010        0.0000  11.2788
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.843885174990169
F1 Macro Score after query 4: 0.8269651822048374
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8650[0m        [32m0.2379[0m       [35m0.6818[0m      [31m0.8159[0m        [94m0.2824[0m     +  0.0001  11.6086
      2      [36m0.8866[0m        [32m0.1930[0m       [35m0.6925[0m      [31m0.8263[0m        0.2834        0.0001  11.7655
      3      [36m0.8995[0m        [32m0.1794[0m       [35m0.6946[0m      0.8261        [94m0.2794[0m     +  0.0001  11.5911
      4      0.8985        [32m0.1719[0m       [35m0.6950[0m      0.8238        0.2803        0.0001  11.6090
      5      0.8956        [32m0.1708[0m       [35m0.7005[0m      [31m0.8350[0m        [94m0.2776[0m     +  0.0001  11.7019
      6      [36m0.9092[0m        [32m0.1641[0m       [35m0.7101[0m      0.8301        [94m0.2647[0m     +  0.0000  11.6116
      7      0.9062        [32m0.1525[0m       [35m0.7146[0m      0.8323        [94m0.2598[0m     +  0.0000  11.7003
      8      [36m0.9145[0m        0.1552       0.7118      0.8306        0.2621        0.0000  11.7034
      9      0.9143        [32m0.1459[0m       [35m0.7160[0m      [31m0.8353[0m        0.2619        0.0000  11.6829
     10      0.9123        0.1494       [35m0.7186[0m      [31m0.8386[0m        0.2613        0.0000  11.7349
     11      [36m0.9187[0m        [32m0.1428[0m       [35m0.7193[0m      0.8370        [94m0.2593[0m     +  0.0000  11.6825
     12      0.9159        [32m0.1407[0m       [35m0.7212[0m      0.8378        [94m0.2574[0m     +  0.0000  11.7334
     13      [36m0.9222[0m        0.1473       [35m0.7217[0m      [31m0.8394[0m        [94m0.2566[0m     +  0.0000  11.7322
     14      0.9202        [32m0.1387[0m       0.7217      0.8378        0.2577        0.0000  11.7056
     15      0.9153        [32m0.1367[0m       [35m0.7226[0m      0.8390        [94m0.2546[0m     +  0.0000  11.6831
     16      [36m0.9265[0m        [32m0.1345[0m       0.7217      0.8382        0.2546        0.0000  11.5783
     17      [36m0.9281[0m        0.1356       [35m0.7227[0m      0.8368        0.2561        0.0000  11.6940
     18      0.9275        [32m0.1274[0m       0.7217      0.8381        0.2568        0.0000  11.6881
     19      0.9203        0.1331       0.7220      0.8369        0.2557        0.0000  11.4008
     20      0.9272        0.1330       0.7224      0.8358        0.2562        0.0000  11.7645
     21      0.9204        0.1362       0.7219      0.8358        0.2559        0.0000  11.7693
     22      0.9237        0.1332       0.7219      0.8357        0.2561        0.0000  11.6415
     23      0.9245        0.1336       0.7214      0.8360        0.2562        0.0000  11.7355
     24      0.9268        0.1357       0.7222      0.8362        0.2563        0.0000  11.6256
     25      0.9244        0.1308       0.7217      0.8357        0.2566        0.0000  11.7039
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.8644568938686586
F1 Macro Score after query 5: 0.851850816066356
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8842[0m        [32m0.1936[0m       [35m0.7257[0m      [31m0.7948[0m        [94m0.2559[0m     +  0.0001  12.3884
      2      [36m0.8970[0m        [32m0.1672[0m       [35m0.7384[0m      [31m0.8189[0m        [94m0.2464[0m     +  0.0001  12.3564
      3      [36m0.9068[0m        [32m0.1522[0m       0.7266      0.8008        0.2658        0.0001  12.4635
      4      [36m0.9191[0m        0.1552       [35m0.7439[0m      [31m0.8261[0m        [94m0.2452[0m     +  0.0001  12.5880
      5      0.9119        [32m0.1494[0m       [35m0.7470[0m      [31m0.8350[0m        [94m0.2402[0m     +  0.0001  12.4190
      6      [36m0.9234[0m        [32m0.1343[0m       0.7403      [31m0.8369[0m        [94m0.2401[0m     +  0.0000  12.2140
      7      [36m0.9248[0m        [32m0.1309[0m       0.7372      0.8332        0.2425        0.0000  12.1387
      8      0.9244        [32m0.1274[0m       [35m0.7493[0m      [31m0.8461[0m        [94m0.2349[0m     +  0.0000  12.4345
      9      [36m0.9273[0m        0.1294       0.7448      0.8431        0.2374        0.0000  12.2643
     10      [36m0.9287[0m        [32m0.1234[0m       0.7446      0.8414        0.2383        0.0000  12.1787
     11      [36m0.9366[0m        [32m0.1209[0m       0.7344      0.8368        0.2471        0.0000  12.2159
     12      [36m0.9370[0m        [32m0.1182[0m       0.7328      0.8348        0.2481        0.0000  12.4030
     13      0.9351        0.1183       0.7398      0.8409        0.2433        0.0000  12.3703
     14      0.9330        [32m0.1151[0m       0.7372      0.8365        0.2476        0.0000  12.4341
     15      0.9352        0.1172       0.7356      0.8361        0.2469        0.0000  12.4314
     16      [36m0.9374[0m        [32m0.1121[0m       0.7351      0.8369        0.2473        0.0000  12.5737
     17      0.9370        0.1164       0.7330      0.8359        0.2500        0.0000  12.0903
     18      0.9373        0.1152       0.7323      0.8362        0.2478        0.0000  12.3252
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8821679167674812
F1 Macro Score after query 6: 0.8711359444385387
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9001[0m        [32m0.1697[0m       [35m0.7427[0m      [31m0.8586[0m        [94m0.2354[0m     +  0.0001  13.5126
      2      [36m0.9194[0m        [32m0.1524[0m       0.7380      0.8580        0.2385        0.0001  13.5450
      3      0.9152        [32m0.1458[0m       [35m0.7474[0m      [31m0.8636[0m        0.2387        0.0001  13.5762
      4      [36m0.9232[0m        [32m0.1393[0m       0.7417      0.8586        0.2409        0.0001  13.3731
      5      [36m0.9237[0m        [32m0.1326[0m       0.7370      0.8575        0.2478        0.0001  13.6548
      6      [36m0.9308[0m        [32m0.1212[0m       [35m0.7514[0m      [31m0.8638[0m        [94m0.2297[0m     +  0.0000  13.5444
      7      [36m0.9328[0m        [32m0.1193[0m       [35m0.7582[0m      [31m0.8668[0m        0.2313        0.0000  13.5910
      8      [36m0.9333[0m        [32m0.1184[0m       [35m0.7589[0m      [31m0.8680[0m        0.2306        0.0000  13.4500
      9      [36m0.9403[0m        [32m0.1145[0m       0.7582      0.8667        0.2304        0.0000  13.4797
     10      0.9380        [32m0.1142[0m       0.7587      0.8669        [94m0.2288[0m     +  0.0000  13.7011
     11      0.9391        [32m0.1105[0m       [35m0.7641[0m      0.8675        [94m0.2225[0m     +  0.0000  13.1335
     12      0.9382        [32m0.1102[0m       [35m0.7656[0m      0.8669        [94m0.2213[0m     +  0.0000  13.7003
     13      [36m0.9469[0m        [32m0.1073[0m       [35m0.7660[0m      0.8662        0.2217        0.0000  13.5745
     14      0.9398        [32m0.1063[0m       0.7632      0.8676        0.2234        0.0000  13.4206
     15      0.9449        [32m0.1056[0m       [35m0.7661[0m      0.8674        0.2217        0.0000  13.4980
     16      0.9447        [32m0.1048[0m       [35m0.7679[0m      0.8671        [94m0.2206[0m     +  0.0000  13.6060
     17      0.9461        [32m0.1041[0m       [35m0.7686[0m      0.8675        0.2209        0.0000  13.5770
     18      0.9452        [32m0.1029[0m       0.7679      0.8666        [94m0.2204[0m     +  0.0000  13.4028
     19      0.9424        [32m0.1006[0m       0.7670      0.8673        0.2215        0.0000  13.5316
     20      0.9422        0.1034       0.7655      0.8662        0.2216        0.0000  13.5457
     21      [36m0.9474[0m        [32m0.1005[0m       0.7649      0.8653        0.2215        0.0000  13.6219
     22      0.9448        [32m0.0999[0m       0.7649      0.8654        0.2217        0.0000  13.7153
     23      0.9430        0.1013       0.7644      0.8653        0.2214        0.0000  13.8263
     24      0.9451        0.0999       0.7635      0.8646        0.2214        0.0000  13.5282
     25      0.9467        [32m0.0998[0m       0.7651      0.8654        0.2214        0.0000  13.3732
     26      0.9453        0.0998       0.7648      0.8650        0.2219        0.0000  13.4830
     27      [36m0.9476[0m        0.1018       0.7642      0.8649        0.2221        0.0000  13.4992
     28      0.9455        [32m0.0990[0m       0.7641      0.8644        0.2220        0.0000  13.4339
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.8979847878930448
F1 Macro Score after query 7: 0.8848432906353593
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9167[0m        [32m0.1444[0m       [35m0.7323[0m      [31m0.8406[0m        [94m0.2401[0m     +  0.0001  15.6582
      2      [36m0.9268[0m        [32m0.1248[0m       0.7299      0.8332        0.2486        0.0001  15.6892
      3      [36m0.9286[0m        [32m0.1190[0m       0.7156      0.8219        0.2732        0.0001  15.5274
      4      [36m0.9336[0m        [32m0.1137[0m       0.7234      0.8243        0.2567        0.0001  15.5768
      5      [36m0.9372[0m        [32m0.1099[0m       0.7208      0.8297        0.2669        0.0001  15.6191
      6      [36m0.9489[0m        [32m0.0982[0m       [35m0.7469[0m      [31m0.8499[0m        [94m0.2382[0m     +  0.0000  15.6069
      7      0.9436        [32m0.0958[0m       [35m0.7604[0m      [31m0.8558[0m        [94m0.2316[0m     +  0.0000  15.6102
      8      0.9475        [32m0.0930[0m       0.7523      0.8553        0.2352        0.0000  15.7796
      9      0.9486        [32m0.0910[0m       0.7519      0.8519        0.2398        0.0000  15.5930
     10      [36m0.9498[0m        [32m0.0879[0m       0.7453      0.8491        0.2475        0.0000  15.6554
     11      [36m0.9532[0m        [32m0.0839[0m       0.7578      0.8548        0.2391        0.0000  15.6251
     12      [36m0.9532[0m        [32m0.0830[0m       0.7540      0.8545        0.2412        0.0000  15.5776
     13      [36m0.9539[0m        [32m0.0814[0m       0.7585      [31m0.8558[0m        0.2397        0.0000  15.2127
     14      [36m0.9550[0m        0.0818       0.7535      0.8530        0.2420        0.0000  15.7019
     15      0.9548        0.0830       0.7571      0.8547        0.2404        0.0000  15.7652
     16      0.9538        [32m0.0797[0m       0.7583      0.8548        0.2396        0.0000  15.7198
     17      [36m0.9589[0m        [32m0.0777[0m       0.7582      0.8550        0.2407        0.0000  15.5775
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8935941695435367
F1 Macro Score after query 8: 0.879407136737396
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9263[0m        [32m0.1240[0m       [35m0.7547[0m      [31m0.8600[0m        [94m0.2166[0m     +  0.0001  18.9894
      2      [36m0.9293[0m        [32m0.1124[0m       [35m0.7594[0m      [31m0.8630[0m        [94m0.2112[0m     +  0.0001  18.9569
      3      [36m0.9337[0m        [32m0.1081[0m       [35m0.7601[0m      0.8629        0.2154        0.0001  19.0047
      4      [36m0.9352[0m        [32m0.1061[0m       0.7483      0.8571        0.2324        0.0001  19.0316
      5      [36m0.9389[0m        [32m0.0990[0m       [35m0.7644[0m      0.8621        0.2207        0.0001  18.9263
      6      [36m0.9490[0m        [32m0.0862[0m       0.7514      0.8605        0.2456        0.0000  19.0654
      7      [36m0.9498[0m        [32m0.0837[0m       0.7495      0.8615        0.2482        0.0000  19.0341
      8      [36m0.9504[0m        [32m0.0808[0m       0.7540      0.8604        0.2430        0.0000  19.1251
      9      [36m0.9531[0m        0.0812       0.7477      0.8571        0.2523        0.0000  18.8758
     10      0.9528        [32m0.0786[0m       0.7543      0.8620        0.2464        0.0000  19.2062
     11      [36m0.9557[0m        [32m0.0752[0m       0.7519      0.8600        0.2484        0.0000  19.1271
     12      [36m0.9563[0m        [32m0.0735[0m       0.7528      0.8605        0.2489        0.0000  19.0489
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8918133129303749
F1 Macro Score after query 9: 0.8804762414211748
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9267[0m        [32m0.1266[0m       [35m0.7802[0m      [31m0.8746[0m        [94m0.2055[0m     +  0.0001  25.6477
      2      [36m0.9322[0m        [32m0.1133[0m       0.7703      0.8628        0.2153        0.0001  25.7435
      3      [36m0.9327[0m        [32m0.1093[0m       0.7646      0.8653        0.2233        0.0001  25.5850
      4      [36m0.9388[0m        [32m0.1040[0m       0.7694      0.8661        0.2205        0.0001  25.7544
      5      [36m0.9400[0m        [32m0.1017[0m       0.7736      0.8685        0.2205        0.0001  25.8340
      6      [36m0.9493[0m        [32m0.0864[0m       0.7677      0.8621        0.2285        0.0000  25.7220
      7      [36m0.9508[0m        [32m0.0838[0m       0.7585      0.8581        0.2346        0.0000  25.7253
      8      [36m0.9517[0m        [32m0.0802[0m       0.7557      0.8577        0.2421        0.0000  25.6302
      9      [36m0.9544[0m        [32m0.0796[0m       0.7590      0.8584        0.2430        0.0000  25.3469
     10      0.9521        [32m0.0775[0m       0.7554      0.8580        0.2407        0.0000  25.6793
     11      [36m0.9564[0m        [32m0.0732[0m       0.7578      0.8554        0.2488        0.0000  25.2997
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8909412760717309
F1 Macro Score after query 10: 0.8766602448003082
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9311[0m        [32m0.1182[0m       [35m0.7747[0m      [31m0.8699[0m        [94m0.2146[0m     +  0.0001  37.6135
      2      [36m0.9357[0m        [32m0.1064[0m       0.7509      0.8559        0.2400        0.0001  37.0640
      3      [36m0.9395[0m        [32m0.0996[0m       0.7712      [31m0.8709[0m        0.2339        0.0001  36.9447
      4      [36m0.9437[0m        [32m0.0948[0m       0.7677      0.8654        0.2241        0.0001  37.0142
      5      [36m0.9462[0m        [32m0.0913[0m       0.7639      0.8655        0.2393        0.0001  37.1518
      6      [36m0.9552[0m        [32m0.0779[0m       0.7743      0.8688        0.2226        0.0000  37.1889
      7      [36m0.9570[0m        [32m0.0752[0m       0.7729      0.8668        0.2352        0.0000  36.8932
      8      0.9567        [32m0.0735[0m       0.7712      0.8674        0.2355        0.0000  37.0355
      9      [36m0.9582[0m        [32m0.0715[0m       [35m0.7752[0m      0.8665        0.2324        0.0000  37.1502
     10      [36m0.9597[0m        [32m0.0693[0m       0.7712      0.8660        0.2319        0.0000  37.3107
     11      [36m0.9639[0m        [32m0.0647[0m       0.7750      0.8654        0.2332        0.0000  37.6416
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8913010243082097
F1 Macro Score after query 11: 0.8793152325472747
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9345[0m        [32m0.1076[0m       [35m0.7655[0m      [31m0.8644[0m        [94m0.2176[0m     +  0.0001  58.4567
      2      [36m0.9425[0m        [32m0.0972[0m       0.7592      0.8608        0.2184        0.0001  57.9766
      3      [36m0.9473[0m        [32m0.0900[0m       [35m0.7701[0m      0.8607        [94m0.2131[0m     +  0.0001  58.1260
      4      [36m0.9493[0m        [32m0.0859[0m       0.7649      0.8602        0.2221        0.0001  58.1886
      5      [36m0.9518[0m        [32m0.0822[0m       0.7681      0.8619        [94m0.2027[0m     +  0.0001  58.3610
      6      [36m0.9608[0m        [32m0.0687[0m       0.7644      0.8587        0.2392        0.0000  58.8909
      7      [36m0.9611[0m        [32m0.0666[0m       0.7606      0.8569        0.2412        0.0000  58.3480
      8      [36m0.9625[0m        [32m0.0649[0m       0.7594      0.8606        0.2432        0.0000  58.5209
      9      [36m0.9636[0m        [32m0.0632[0m       0.7622      0.8537        0.2328        0.0000  57.2302
     10      [36m0.9643[0m        [32m0.0626[0m       0.7559      0.8520        0.2474        0.0000  57.2847
     11      [36m0.9665[0m        [32m0.0574[0m       0.7620      0.8604        0.2637        0.0000  58.2518
     12      [36m0.9673[0m        [32m0.0568[0m       0.7595      0.8597        0.2605        0.0000  58.3868
     13      [36m0.9674[0m        [32m0.0559[0m       0.7597      0.8573        0.2532        0.0000  58.3282
     14      [36m0.9678[0m        0.0562       0.7587      0.8572        0.2557        0.0000  58.1972
     15      [36m0.9680[0m        [32m0.0542[0m       0.7566      0.8584        0.2776        0.0000  58.1888
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.896050214329455
F1 Macro Score after query 12: 0.8821753856414198
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9522[0m        [32m0.0817[0m       [35m0.7693[0m      [31m0.8728[0m        [94m0.2043[0m     +  0.0001  67.0544
      2      [36m0.9558[0m        [32m0.0773[0m       0.7625      0.8680        0.2100        0.0001  66.7514
      3      [36m0.9564[0m        [32m0.0746[0m       [35m0.7698[0m      0.8703        0.2152        0.0001  67.0477
      4      [36m0.9576[0m        [32m0.0729[0m       0.7648      0.8625        [94m0.1973[0m     +  0.0001  66.7583
      5      [36m0.9588[0m        [32m0.0698[0m       0.7587      0.8679        0.2249        0.0001  65.6706
      6      [36m0.9657[0m        [32m0.0597[0m       [35m0.7707[0m      0.8666        0.2169        0.0000  67.2155
      7      [36m0.9668[0m        [32m0.0581[0m       0.7618      0.8626        0.2282        0.0000  67.2675
      8      [36m0.9669[0m        [32m0.0571[0m       0.7677      0.8685        0.2244        0.0000  67.4829
      9      0.9669        [32m0.0559[0m       0.7634      0.8624        0.2348        0.0000  67.2963
     10      [36m0.9680[0m        [32m0.0554[0m       0.7625      0.8616        0.2230        0.0000  67.0679
     11      [36m0.9704[0m        [32m0.0516[0m       0.7649      0.8607        0.2330        0.0000  67.0481
     12      0.9701        [32m0.0509[0m       0.7642      0.8618        0.2340        0.0000  66.9192
     13      0.9701        [32m0.0505[0m       0.7613      0.8606        0.2374        0.0000  66.7613
     14      0.9704        0.0508       0.7630      0.8599        0.2334        0.0000  66.9059
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8929321203638908
F1 Macro Score after query 13: 0.882130149545095
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed44_config2\AL_average_confidence_results_for_multilabel_classification.pickle
