Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5556[0m        [32m0.6869[0m       [35m0.2349[0m      [31m0.5648[0m        [94m0.6892[0m     +  0.0001  11.7601
      2      [36m0.6313[0m        0.6994       0.0997      0.3476        [94m0.6785[0m     +  0.0001  10.0735
      3      0.5945        [32m0.6623[0m       0.1566      0.4336        [94m0.6757[0m     +  0.0001  10.0246
      4      [36m0.7130[0m        [32m0.5900[0m       [35m0.2663[0m      0.3519        [94m0.6747[0m     +  0.0001  10.2074
      5      [36m0.8796[0m        0.6231       0.1536      0.5009        0.7018        0.0001  10.2830
      6      0.6985        0.6312       0.1727      0.4538        0.6888        0.0000  10.3387
      7      0.8130        0.6034       0.2568      0.4692        0.6791        0.0000  10.2752
      8      0.7857        [32m0.5544[0m       0.2562      0.4766        0.6772        0.0000  10.3613
      9      0.7424        [32m0.5443[0m       0.2564      0.4699        [94m0.6719[0m     +  0.0000  10.6222
     10      0.7857        [32m0.5361[0m       [35m0.2686[0m      0.4721        [94m0.6710[0m     +  0.0000  10.9040
     11      0.7500        0.5526       [35m0.2759[0m      0.4746        [94m0.6704[0m     +  0.0000  10.7123
     12      0.8333        [32m0.5334[0m       0.2747      0.4741        0.6718        0.0000  10.4960
     13      0.6905        0.5616       0.2738      0.4740        0.6723        0.0000  10.6265
     14      0.7500        0.5547       0.2736      0.4726        0.6712        0.0000  10.9997
     15      0.7857        [32m0.5206[0m       [35m0.2766[0m      0.4738        0.6714        0.0000  10.7173
     16      0.8426        [32m0.4995[0m       0.2759      0.4721        0.6707        0.0000  10.7033
     17      0.7857        0.5310       0.2759      0.4730        0.6708        0.0000  10.7650
     18      0.8333        0.5341       0.2760      0.4723        [94m0.6704[0m     +  0.0000  10.6923
     19      0.7857        0.5084       [35m0.2767[0m      0.4746        [94m0.6703[0m     +  0.0000  10.8491
     20      0.7963        [32m0.4736[0m       0.2767      0.4747        [94m0.6702[0m     +  0.0000  10.8836
     21      0.7857        0.5279       0.2753      0.4744        0.6703        0.0000  10.9064
     22      0.8796        0.5139       0.2759      0.4732        [94m0.6700[0m     +  0.0000  10.8315
     23      0.7685        0.5104       0.2757      0.4727        [94m0.6700[0m     +  0.0000  10.8715
     24      0.7222        0.5279       0.2752      0.4741        0.6703        0.0000  10.8753
     25      0.7857        0.5278       0.2755      0.4739        0.6702        0.0000  10.7661
     26      0.7857        0.5162       0.2753      0.4739        0.6701        0.0000  10.8896
     27      0.8333        0.5214       0.2752      0.4736        0.6701        0.0000  10.9010
     28      0.8333        0.4963       0.2752      0.4741        0.6701        0.0000  10.5949
     29      0.7667        0.5383       0.2748      0.4741        0.6701        0.0000  10.6682
     30      0.8426        0.5036       0.2748      0.4744        0.6701        0.0000  10.9528
     31      0.7857        0.4833       0.2748      0.4744        0.6701        0.0000  10.8034
     32      0.7963        0.5281       0.2750      0.4744        0.6701        0.0000  10.8151
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4928
Pre F1 macro score = 0.4914
Pre Accuracy = 0.3075

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7212[0m        [32m0.6035[0m       [35m0.3507[0m      [31m0.2309[0m        [94m0.6432[0m     +  0.0001  11.0141
      2      0.4530        [32m0.5851[0m       0.3378      [31m0.3007[0m        [94m0.6310[0m     +  0.0001  10.9498
      3      0.5167        [32m0.5244[0m       0.3128      [31m0.3181[0m        [94m0.6310[0m     +  0.0001  11.1700
      4      0.5877        [32m0.5113[0m       0.3137      [31m0.3210[0m        [94m0.6201[0m     +  0.0001  10.9496
      5      0.6815        [32m0.4672[0m       0.3394      [31m0.3363[0m        [94m0.6147[0m     +  0.0001  10.9523
      6      0.6974        [32m0.4442[0m       0.3359      [31m0.3441[0m        [94m0.6098[0m     +  0.0000  10.8245
      7      0.6942        [32m0.4109[0m       0.3337      [31m0.3503[0m        [94m0.6055[0m     +  0.0000  11.2339
      8      0.6397        0.4350       0.3316      [31m0.3615[0m        [94m0.6017[0m     +  0.0000  11.1605
      9      0.6815        0.4351       0.3389      0.3588        [94m0.5980[0m     +  0.0000  10.8195
     10      0.6942        0.4318       0.3415      [31m0.3646[0m        [94m0.5926[0m     +  0.0000  11.0630
     11      0.6757        0.4129       0.3422      [31m0.3692[0m        [94m0.5903[0m     +  0.0000  11.0743
     12      [36m0.7444[0m        [32m0.3940[0m       0.3446      [31m0.3731[0m        [94m0.5888[0m     +  0.0000  10.7822
     13      0.6623        0.4103       0.3450      [31m0.3757[0m        [94m0.5872[0m     +  0.0000  10.8791
     14      0.6688        0.3990       0.3481      [31m0.3797[0m        [94m0.5841[0m     +  0.0000  11.0452
     15      [36m0.7556[0m        0.4019       [35m0.3533[0m      [31m0.3845[0m        [94m0.5826[0m     +  0.0000  11.0509
     16      0.6926        [32m0.3879[0m       [35m0.3542[0m      [31m0.3864[0m        [94m0.5821[0m     +  0.0000  10.7411
     17      0.7066        [32m0.3738[0m       [35m0.3554[0m      [31m0.3869[0m        [94m0.5816[0m     +  0.0000  11.0158
     18      0.6926        0.3844       0.3550      [31m0.3874[0m        [94m0.5808[0m     +  0.0000  10.8904
     19      0.7529        0.3743       [35m0.3557[0m      [31m0.3890[0m        [94m0.5803[0m     +  0.0000  10.8425
     20      0.7251        0.3926       0.3556      [31m0.3904[0m        [94m0.5800[0m     +  0.0000  11.0268
     21      0.6778        0.3761       0.3557      [31m0.3904[0m        [94m0.5798[0m     +  0.0000  10.8021
     22      [36m0.7585[0m        0.3806       0.3556      [31m0.3907[0m        [94m0.5796[0m     +  0.0000  10.9014
     23      [36m0.8059[0m        [32m0.3578[0m       0.3556      [31m0.3912[0m        [94m0.5794[0m     +  0.0000  10.6293
     24      [36m0.8251[0m        0.3769       [35m0.3559[0m      [31m0.3913[0m        [94m0.5792[0m     +  0.0000  10.6721
     25      0.7251        0.3915       [35m0.3564[0m      [31m0.3915[0m        [94m0.5789[0m     +  0.0000  11.0811
     26      0.7251        0.3716       0.3564      0.3915        [94m0.5788[0m     +  0.0000  11.1394
     27      0.7638        0.3962       0.3564      [31m0.3921[0m        [94m0.5788[0m     +  0.0000  11.0359
     28      0.6778        0.4017       [35m0.3566[0m      [31m0.3925[0m        [94m0.5787[0m     +  0.0000  10.7733
     29      0.7585        0.4025       0.3566      [31m0.3926[0m        [94m0.5786[0m     +  0.0000  10.9031
     30      0.7898        0.3858       [35m0.3573[0m      [31m0.3927[0m        [94m0.5785[0m     +  0.0000  10.7758
     31      0.7740        0.3736       0.3571      [31m0.3928[0m        [94m0.5785[0m     +  0.0000  10.7763
     32      0.7757        0.3934       0.3573      [31m0.3928[0m        [94m0.5784[0m     +  0.0000  10.8010
     33      0.7407        0.3896       0.3573      0.3928        [94m0.5784[0m     +  0.0000  11.0715
     34      0.7333        0.4006       0.3573      [31m0.3929[0m        [94m0.5784[0m     +  0.0000  10.7164
     35      0.7232        0.3822       0.3573      0.3929        [94m0.5783[0m     +  0.0000  10.8124
     36      0.8232        [32m0.3555[0m       0.3573      0.3929        [94m0.5783[0m     +  0.0000  10.8508
     37      0.7540        0.3799       0.3573      0.3929        [94m0.5783[0m     +  0.0000  10.5817
     38      0.6897        0.3857       0.3571      0.3929        [94m0.5783[0m     +  0.0000  10.7902
     39      [36m0.8407[0m        0.3852       0.3571      0.3929        [94m0.5783[0m     +  0.0000  11.0315
     40      0.7111        0.3944       0.3571      0.3929        [94m0.5783[0m     +  0.0000  10.9841
     41      0.7822        0.3776       0.3571      0.3929        [94m0.5783[0m     +  0.0000  10.9016
     42      0.6757        0.3910       0.3571      0.3929        [94m0.5783[0m     +  0.0000  10.7241
     43      0.7787        0.3864       0.3571      0.3929        [94m0.5783[0m     +  0.0000  10.8683
     44      0.7869        0.3674       0.3571      0.3929        [94m0.5783[0m     +  0.0000  10.6347
     45      0.8251        [32m0.3517[0m       0.3571      0.3929        [94m0.5783[0m     +  0.0000  10.7843
     46      0.6537        0.3726       0.3571      0.3929        [94m0.5783[0m     +  0.0000  10.8124
     47      0.7740        0.3591       0.3571      0.3929        [94m0.5783[0m     +  0.0000  10.6035
     48      0.7094        0.4029       0.3571      0.3929        [94m0.5783[0m     +  0.0000  11.0000
     49      0.7222        0.3774       0.3571      0.3929        [94m0.5783[0m     +  0.0000  10.7384
     50      0.7963        0.3761       0.3571      0.3929        [94m0.5783[0m     +  0.0000  10.3445
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.45509203588937197
F1 Macro Score after query 1: 0.3752578396712372
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5525[0m        [32m0.5527[0m       [35m0.3825[0m      [31m0.4900[0m        [94m0.5088[0m     +  0.0001  11.0155
      2      [36m0.6873[0m        [32m0.4608[0m       [35m0.5410[0m      [31m0.6411[0m        [94m0.4481[0m     +  0.0001  11.1105
      3      [36m0.8230[0m        [32m0.3783[0m       [35m0.6106[0m      [31m0.7159[0m        [94m0.4056[0m     +  0.0001  11.1083
      4      [36m0.8242[0m        [32m0.3709[0m       [35m0.6337[0m      [31m0.7726[0m        [94m0.3788[0m     +  0.0001  10.7659
      5      [36m0.8503[0m        [32m0.3275[0m       [35m0.6422[0m      [31m0.7813[0m        [94m0.3585[0m     +  0.0001  11.0325
      6      [36m0.9206[0m        [32m0.2761[0m       [35m0.6438[0m      [31m0.7865[0m        [94m0.3542[0m     +  0.0000  10.9477
      7      0.8838        0.2940       [35m0.6458[0m      [31m0.7881[0m        [94m0.3513[0m     +  0.0000  11.1408
      8      0.8829        0.2764       [35m0.6493[0m      [31m0.7946[0m        [94m0.3485[0m     +  0.0000  10.9319
      9      0.8938        [32m0.2504[0m       0.6460      0.7894        [94m0.3428[0m     +  0.0000  11.0625
     10      0.8938        [32m0.2452[0m       0.6491      0.7938        [94m0.3394[0m     +  0.0000  11.1879
     11      0.9028        0.2607       [35m0.6497[0m      0.7917        [94m0.3375[0m     +  0.0000  10.9051
     12      0.9185        [32m0.2420[0m       [35m0.6516[0m      0.7922        [94m0.3369[0m     +  0.0000  10.9699
     13      0.8979        0.2540       0.6516      0.7907        [94m0.3361[0m     +  0.0000  11.0047
     14      [36m0.9243[0m        [32m0.2378[0m       [35m0.6521[0m      0.7903        [94m0.3358[0m     +  0.0000  10.8628
     15      0.9218        0.2512       0.6510      0.7881        [94m0.3353[0m     +  0.0000  10.9529
     16      0.9160        0.2421       0.6505      0.7881        [94m0.3351[0m     +  0.0000  11.1231
     17      0.9134        0.2462       0.6507      0.7885        [94m0.3347[0m     +  0.0000  10.9895
     18      0.9025        [32m0.2373[0m       0.6519      0.7891        [94m0.3344[0m     +  0.0000  11.2487
     19      0.8968        0.2381       [35m0.6526[0m      0.7892        [94m0.3343[0m     +  0.0000  11.0979
     20      0.8887        0.2395       [35m0.6530[0m      0.7897        [94m0.3338[0m     +  0.0000  10.7275
     21      0.8842        0.2524       0.6530      0.7897        [94m0.3336[0m     +  0.0000  10.9696
     22      [36m0.9266[0m        [32m0.2357[0m       [35m0.6536[0m      0.7899        [94m0.3336[0m     +  0.0000  10.9867
     23      0.9185        [32m0.2350[0m       [35m0.6538[0m      0.7900        [94m0.3334[0m     +  0.0000  11.0033
     24      0.9156        [32m0.2254[0m       0.6538      0.7901        [94m0.3334[0m     +  0.0000  10.9009
     25      0.9160        0.2269       0.6536      0.7902        [94m0.3333[0m     +  0.0000  11.0240
     26      0.9019        0.2314       0.6535      0.7900        [94m0.3333[0m     +  0.0000  11.0100
     27      0.9211        [32m0.2196[0m       0.6535      0.7900        [94m0.3333[0m     +  0.0000  10.9579
     28      0.9218        0.2353       0.6535      0.7901        [94m0.3333[0m     +  0.0000  11.0313
     29      0.8968        0.2343       0.6535      0.7901        [94m0.3332[0m     +  0.0000  10.8713
     30      0.9074        0.2256       0.6535      0.7902        [94m0.3332[0m     +  0.0000  11.1055
     31      [36m0.9317[0m        0.2234       0.6535      0.7901        [94m0.3332[0m     +  0.0000  10.8777
     32      0.9053        0.2423       0.6535      0.7902        0.3332        0.0000  11.1538
     33      0.9134        0.2249       0.6535      0.7901        [94m0.3332[0m     +  0.0000  11.0950
     34      0.8972        0.2243       0.6535      0.7901        [94m0.3331[0m     +  0.0000  11.1299
     35      0.9087        [32m0.2185[0m       0.6536      0.7900        [94m0.3331[0m     +  0.0000  10.9010
     36      0.9266        0.2277       0.6536      0.7900        [94m0.3331[0m     +  0.0000  11.0054
     37      0.8968        0.2383       0.6536      0.7900        [94m0.3331[0m     +  0.0000  10.8681
     38      0.9110        0.2411       0.6536      0.7900        [94m0.3331[0m     +  0.0000  10.7063
     39      0.9185        0.2242       0.6536      0.7900        [94m0.3331[0m     +  0.0000  10.9734
     40      0.9079        0.2382       0.6536      0.7900        [94m0.3331[0m     +  0.0000  10.9746
     41      0.9300        0.2352       0.6536      0.7900        [94m0.3331[0m     +  0.0000  10.6342
     42      0.9002        0.2338       0.6536      0.7900        [94m0.3331[0m     +  0.0000  11.0149
     43      0.9134        0.2281       0.6536      0.7900        [94m0.3331[0m     +  0.0000  10.9426
     44      0.9157        0.2248       0.6536      0.7900        [94m0.3331[0m     +  0.0000  10.9575
     45      0.9079        0.2418       0.6536      0.7900        [94m0.3331[0m     +  0.0000  11.1146
     46      0.9289        0.2262       0.6536      0.7900        [94m0.3331[0m     +  0.0000  10.8073
     47      0.9060        0.2336       0.6536      0.7900        [94m0.3331[0m     +  0.0000  10.8528
     48      0.9039        0.2488       0.6536      0.7900        [94m0.3331[0m     +  0.0000  10.9385
     49      0.9134        0.2225       0.6536      0.7900        [94m0.3331[0m     +  0.0000  11.1248
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.8384202515420973
F1 Macro Score after query 2: 0.8192156489802859
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7784[0m        [32m0.3805[0m       [35m0.6811[0m      [31m0.8040[0m        [94m0.3224[0m     +  0.0001  11.1560
      2      [36m0.8472[0m        [32m0.2931[0m       [35m0.6825[0m      [31m0.8059[0m        [94m0.3040[0m     +  0.0001  11.1303
      3      0.8414        [32m0.2681[0m       [35m0.6991[0m      [31m0.8260[0m        [94m0.2907[0m     +  0.0001  11.1564
      4      [36m0.8598[0m        [32m0.2527[0m       0.6977      0.8215        [94m0.2874[0m     +  0.0001  11.3329
      5      [36m0.8627[0m        [32m0.2344[0m       [35m0.7059[0m      [31m0.8348[0m        [94m0.2770[0m     +  0.0001  10.9688
      6      [36m0.9047[0m        [32m0.2196[0m       [35m0.7085[0m      [31m0.8367[0m        [94m0.2761[0m     +  0.0000  11.0077
      7      0.8984        [32m0.2094[0m       [35m0.7097[0m      [31m0.8371[0m        [94m0.2751[0m     +  0.0000  11.4121
      8      0.9020        [32m0.1966[0m       [35m0.7106[0m      [31m0.8390[0m        [94m0.2742[0m     +  0.0000  11.0976
      9      0.8864        0.1996       0.7104      0.8386        [94m0.2729[0m     +  0.0000  11.0772
     10      0.9018        0.1973       0.7097      0.8379        [94m0.2713[0m     +  0.0000  11.0051
     11      [36m0.9166[0m        [32m0.1884[0m       0.7099      0.8375        0.2717        0.0000  11.5407
     12      0.9099        [32m0.1807[0m       0.7101      0.8376        0.2726        0.0000  11.2650
     13      0.8973        0.1894       0.7106      0.8388        0.2717        0.0000  10.9379
     14      0.9129        0.1903       [35m0.7109[0m      [31m0.8390[0m        0.2713        0.0000  11.0626
     15      0.9127        [32m0.1801[0m       0.7102      0.8373        [94m0.2705[0m     +  0.0000  10.7184
     16      [36m0.9193[0m        [32m0.1774[0m       [35m0.7111[0m      0.8388        0.2711        0.0000  10.9644
     17      0.9143        0.1810       0.7111      0.8383        0.2708        0.0000  11.1932
     18      0.9112        0.1834       0.7101      0.8370        0.2708        0.0000  10.9373
     19      0.9180        [32m0.1722[0m       0.7109      0.8383        0.2708        0.0000  11.1250
     20      0.9190        0.1848       0.7111      0.8386        0.2709        0.0000  11.1830
     21      0.9112        0.1793       [35m0.7113[0m      0.8387        0.2709        0.0000  10.9544
     22      0.9172        [32m0.1692[0m       0.7111      0.8383        0.2708        0.0000  11.1578
     23      0.9099        0.1794       0.7106      0.8379        0.2707        0.0000  11.0601
     24      [36m0.9285[0m        [32m0.1679[0m       0.7101      0.8375        [94m0.2705[0m     +  0.0000  11.2951
     25      0.9261        0.1799       0.7101      0.8375        [94m0.2705[0m     +  0.0000  11.2306
     26      0.9109        0.1886       0.7104      0.8377        0.2705        0.0000  10.9254
     27      0.9224        0.1727       0.7101      0.8375        0.2705        0.0000  10.8593
     28      0.9268        0.1725       0.7101      0.8376        0.2705        0.0000  11.1780
     29      0.9031        0.1729       0.7102      0.8376        0.2705        0.0000  11.0422
     30      0.9038        0.1721       0.7099      0.8375        0.2705        0.0000  11.2118
     31      0.9137        0.1770       0.7101      0.8376        0.2705        0.0000  10.8235
     32      0.9173        0.1736       0.7099      0.8375        0.2705        0.0000  11.0167
     33      0.9117        0.1687       0.7101      0.8376        0.2705        0.0000  11.3542
     34      0.9281        0.1772       0.7099      0.8375        0.2705        0.0000  11.0393
     35      [36m0.9293[0m        0.1782       0.7102      0.8376        0.2705        0.0000  10.8495
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.8523206751054851
F1 Macro Score after query 3: 0.8323172962876879
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8014[0m        [32m0.2886[0m       [35m0.6663[0m      [31m0.8045[0m        [94m0.2834[0m     +  0.0001  11.3797
      2      [36m0.8521[0m        [32m0.2436[0m       [35m0.7040[0m      [31m0.8217[0m        [94m0.2586[0m     +  0.0001  11.2281
      3      [36m0.8621[0m        [32m0.2237[0m       [35m0.7255[0m      [31m0.8301[0m        [94m0.2456[0m     +  0.0001  11.4357
      4      [36m0.8787[0m        [32m0.2003[0m       [35m0.7273[0m      [31m0.8406[0m        0.2482        0.0001  11.4268
      5      [36m0.8917[0m        0.2023       [35m0.7323[0m      0.8331        [94m0.2363[0m     +  0.0001  11.5154
      6      [36m0.8943[0m        [32m0.1856[0m       [35m0.7347[0m      [31m0.8447[0m        [94m0.2348[0m     +  0.0000  11.4699
      7      0.8908        [32m0.1742[0m       [35m0.7387[0m      [31m0.8480[0m        [94m0.2332[0m     +  0.0000  11.3285
      8      [36m0.9035[0m        [32m0.1725[0m       [35m0.7424[0m      [31m0.8545[0m        [94m0.2314[0m     +  0.0000  11.1422
      9      0.8963        0.1757       0.7422      0.8508        [94m0.2309[0m     +  0.0000  11.2326
     10      0.8972        0.1770       [35m0.7488[0m      [31m0.8561[0m        [94m0.2287[0m     +  0.0000  11.6943
     11      0.8957        [32m0.1699[0m       0.7488      [31m0.8594[0m        0.2300        0.0000  11.4141
     12      0.9013        [32m0.1595[0m       0.7462      0.8571        0.2299        0.0000  11.3249
     13      [36m0.9053[0m        0.1643       [35m0.7493[0m      [31m0.8608[0m        0.2295        0.0000  11.1313
     14      0.9035        [32m0.1595[0m       0.7474      0.8589        0.2302        0.0000  11.3545
     15      [36m0.9069[0m        0.1638       0.7474      0.8589        0.2299        0.0000  11.4662
     16      0.9040        [32m0.1592[0m       0.7476      0.8595        0.2298        0.0000  11.2280
     17      [36m0.9091[0m        0.1606       0.7486      [31m0.8609[0m        0.2300        0.0000  11.4727
     18      0.9071        0.1596       0.7476      0.8603        0.2304        0.0000  11.2301
     19      0.8911        [32m0.1515[0m       0.7491      0.8608        0.2299        0.0000  11.2584
     20      [36m0.9180[0m        0.1621       0.7490      0.8608        0.2300        0.0000  11.5002
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.8668599639526683
F1 Macro Score after query 4: 0.8466054605490237
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8367[0m        [32m0.2430[0m       [35m0.7599[0m      [31m0.8551[0m        [94m0.2343[0m     +  0.0001  11.6247
      2      [36m0.8495[0m        [32m0.2100[0m       0.7549      [31m0.8572[0m        [94m0.2322[0m     +  0.0001  11.6100
      3      [36m0.8631[0m        [32m0.1924[0m       [35m0.7641[0m      [31m0.8583[0m        [94m0.2271[0m     +  0.0001  11.9331
      4      [36m0.8746[0m        [32m0.1836[0m       [35m0.7665[0m      [31m0.8617[0m        [94m0.2248[0m     +  0.0001  11.5091
      5      [36m0.8784[0m        [32m0.1739[0m       0.7644      [31m0.8630[0m        [94m0.2238[0m     +  0.0001  11.5711
      6      [36m0.8910[0m        [32m0.1583[0m       0.7658      0.8609        [94m0.2227[0m     +  0.0000  11.6654
      7      [36m0.8925[0m        [32m0.1543[0m       [35m0.7670[0m      0.8614        [94m0.2201[0m     +  0.0000  11.6823
      8      0.8923        [32m0.1499[0m       [35m0.7677[0m      [31m0.8634[0m        0.2204        0.0000  11.2426
      9      [36m0.9013[0m        [32m0.1479[0m       [35m0.7679[0m      [31m0.8650[0m        [94m0.2185[0m     +  0.0000  11.5524
     10      0.8998        0.1485       [35m0.7689[0m      [31m0.8676[0m        [94m0.2170[0m     +  0.0000  11.7866
     11      [36m0.9041[0m        [32m0.1395[0m       [35m0.7691[0m      0.8655        0.2182        0.0000  11.6160
     12      [36m0.9094[0m        0.1402       [35m0.7693[0m      0.8658        0.2181        0.0000  11.8134
     13      0.9034        [32m0.1385[0m       [35m0.7705[0m      0.8653        0.2193        0.0000  11.3707
     14      0.8991        0.1390       0.7693      0.8633        0.2202        0.0000  11.8017
     15      0.9069        [32m0.1355[0m       [35m0.7710[0m      0.8650        0.2192        0.0000  11.5050
     16      0.9056        0.1383       0.7694      [31m0.8698[0m        0.2176        0.0000  11.5951
     17      [36m0.9249[0m        [32m0.1310[0m       0.7696      [31m0.8699[0m        0.2176        0.0000  11.4503
     18      0.9167        [32m0.1280[0m       0.7696      0.8697        0.2176        0.0000  12.1078
     19      0.9019        0.1365       0.7694      0.8684        0.2172        0.0000  11.7918
     20      0.9142        0.1328       0.7698      0.8681        0.2174        0.0000  11.6567
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.8712778429073857
F1 Macro Score after query 5: 0.8530377901510078
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8759[0m        [32m0.1971[0m       [35m0.7682[0m      [31m0.8720[0m        [94m0.2215[0m     +  0.0001  12.8844
      2      [36m0.8891[0m        [32m0.1709[0m       [35m0.7703[0m      [31m0.8753[0m        [94m0.2205[0m     +  0.0001  12.1174
      3      [36m0.8989[0m        [32m0.1631[0m       [35m0.7733[0m      [31m0.8755[0m        [94m0.2156[0m     +  0.0001  12.2781
      4      0.8911        [32m0.1582[0m       [35m0.7780[0m      [31m0.8778[0m        [94m0.2138[0m     +  0.0001  12.4208
      5      [36m0.9044[0m        [32m0.1512[0m       0.7731      0.8763        0.2175        0.0001  12.2336
      6      [36m0.9096[0m        [32m0.1403[0m       [35m0.7842[0m      [31m0.8786[0m        [94m0.2099[0m     +  0.0000  12.4002
      7      [36m0.9101[0m        [32m0.1361[0m       0.7799      [31m0.8798[0m        0.2107        0.0000  12.1228
      8      [36m0.9178[0m        [32m0.1325[0m       [35m0.7891[0m      [31m0.8811[0m        0.2102        0.0000  12.5502
      9      0.9156        [32m0.1322[0m       0.7875      [31m0.8812[0m        [94m0.2092[0m     +  0.0000  12.5137
     10      0.9174        [32m0.1288[0m       0.7866      0.8801        0.2112        0.0000  12.1852
     11      [36m0.9203[0m        0.1299       0.7865      0.8779        0.2125        0.0000  12.0497
     12      [36m0.9220[0m        [32m0.1251[0m       0.7863      0.8781        0.2121        0.0000  12.5960
     13      [36m0.9283[0m        [32m0.1210[0m       0.7870      0.8783        0.2120        0.0000  12.3243
     14      0.9234        0.1225       0.7868      0.8780        0.2129        0.0000  12.3521
     15      0.9270        0.1215       0.7868      0.8778        0.2136        0.0000  12.3088
     16      [36m0.9300[0m        [32m0.1191[0m       0.7866      0.8780        0.2142        0.0000  12.3055
     17      0.9263        0.1192       0.7861      0.8787        0.2133        0.0000  12.4031
     18      0.9209        0.1240       0.7877      0.8787        0.2138        0.0000  12.3221
     19      0.9286        0.1197       0.7870      0.8786        0.2136        0.0000  12.5461
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8761919773031759
F1 Macro Score after query 6: 0.857714862646521
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8961[0m        [32m0.1792[0m       [35m0.7533[0m      [31m0.8622[0m        [94m0.2264[0m     +  0.0001  13.4746
      2      [36m0.9094[0m        [32m0.1566[0m       [35m0.7589[0m      [31m0.8689[0m        [94m0.2225[0m     +  0.0001  13.8715
      3      0.9082        [32m0.1513[0m       0.7587      [31m0.8696[0m        0.2272        0.0001  13.6623
      4      [36m0.9100[0m        [32m0.1464[0m       [35m0.7632[0m      [31m0.8747[0m        0.2231        0.0001  13.4857
      5      [36m0.9198[0m        [32m0.1372[0m       [35m0.7712[0m      [31m0.8768[0m        [94m0.2191[0m     +  0.0001  13.4062
      6      [36m0.9217[0m        [32m0.1300[0m       [35m0.7759[0m      [31m0.8789[0m        [94m0.2152[0m     +  0.0000  13.5655
      7      [36m0.9300[0m        [32m0.1254[0m       [35m0.7780[0m      [31m0.8816[0m        0.2160        0.0000  13.6876
      8      0.9252        [32m0.1249[0m       [35m0.7799[0m      [31m0.8829[0m        0.2158        0.0000  13.6719
      9      0.9259        [32m0.1197[0m       0.7776      0.8821        0.2163        0.0000  13.6769
     10      [36m0.9317[0m        [32m0.1189[0m       0.7773      0.8816        0.2196        0.0000  13.4455
     11      0.9313        [32m0.1167[0m       [35m0.7905[0m      [31m0.8860[0m        [94m0.2075[0m     +  0.0000  13.5919
     12      0.9316        [32m0.1144[0m       [35m0.7920[0m      [31m0.8868[0m        [94m0.2072[0m     +  0.0000  13.2588
     13      [36m0.9346[0m        [32m0.1134[0m       0.7911      0.8850        0.2075        0.0000  13.6973
     14      [36m0.9350[0m        [32m0.1127[0m       [35m0.7925[0m      0.8865        0.2073        0.0000  13.4778
     15      [36m0.9358[0m        [32m0.1123[0m       0.7915      0.8861        0.2081        0.0000  13.3892
     16      [36m0.9366[0m        [32m0.1113[0m       [35m0.7927[0m      0.8843        [94m0.2035[0m     +  0.0000  13.2081
     17      0.9338        [32m0.1078[0m       0.7925      0.8828        0.2045        0.0000  13.4646
     18      0.9334        [32m0.1070[0m       [35m0.7937[0m      0.8846        0.2037        0.0000  13.4218
     19      0.9364        0.1081       [35m0.7939[0m      0.8831        0.2041        0.0000  13.4583
     20      0.9355        [32m0.1053[0m       0.7939      0.8830        0.2042        0.0000  13.1463
     21      [36m0.9380[0m        0.1069       [35m0.7941[0m      0.8840        [94m0.2034[0m     +  0.0000  13.2964
     22      0.9344        0.1080       0.7939      0.8843        [94m0.2026[0m     +  0.0000  13.4805
     23      [36m0.9384[0m        0.1067       0.7939      0.8844        0.2034        0.0000  13.4472
     24      0.9360        0.1074       0.7941      0.8840        0.2032        0.0000  12.9992
     25      0.9352        0.1075       0.7939      0.8835        [94m0.2025[0m     +  0.0000  13.3640
     26      [36m0.9420[0m        0.1062       [35m0.7946[0m      0.8842        0.2026        0.0000  13.7019
     27      0.9389        0.1054       0.7943      0.8841        [94m0.2024[0m     +  0.0000  13.7348
     28      0.9374        0.1061       0.7934      0.8838        0.2029        0.0000  13.0096
     29      0.9398        0.1065       0.7937      0.8837        0.2028        0.0000  13.4511
     30      0.9376        [32m0.1050[0m       0.7941      0.8840        0.2026        0.0000  13.6615
     31      [36m0.9421[0m        [32m0.1032[0m       0.7941      0.8841        0.2026        0.0000  13.6429
     32      0.9366        0.1059       0.7937      0.8840        0.2027        0.0000  13.0170
     33      0.9412        [32m0.1021[0m       0.7939      0.8841        0.2027        0.0000  13.6264
     34      0.9391        0.1039       0.7937      0.8838        0.2027        0.0000  13.4930
     35      0.9370        0.1043       0.7941      0.8839        0.2028        0.0000  13.3499
     36      0.9393        0.1054       0.7937      0.8838        0.2028        0.0000  13.3441
     37      0.9401        0.1043       0.7941      0.8840        0.2028        0.0000  13.7203
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.884504854368932
F1 Macro Score after query 7: 0.8664629059781216
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9088[0m        [32m0.1553[0m       [35m0.7703[0m      [31m0.8442[0m        [94m0.2195[0m     +  0.0001  15.0118
      2      [36m0.9201[0m        [32m0.1340[0m       0.7604      0.8346        0.2242        0.0001  15.6446
      3      [36m0.9236[0m        [32m0.1284[0m       [35m0.7799[0m      [31m0.8593[0m        [94m0.2164[0m     +  0.0001  15.5236
      4      [36m0.9263[0m        [32m0.1264[0m       0.7773      0.8472        [94m0.2153[0m     +  0.0001  15.2472
      5      [36m0.9306[0m        [32m0.1189[0m       0.7693      0.8349        0.2215        0.0001  15.7450
      6      [36m0.9377[0m        [32m0.1060[0m       0.7792      [31m0.8599[0m        0.2190        0.0000  15.7968
      7      0.9373        [32m0.1034[0m       [35m0.7832[0m      [31m0.8611[0m        0.2185        0.0000  15.4953
      8      [36m0.9416[0m        [32m0.1020[0m       0.7773      0.8584        0.2230        0.0000  15.5652
      9      [36m0.9432[0m        [32m0.0989[0m       0.7745      0.8483        0.2273        0.0000  15.1425
     10      [36m0.9456[0m        [32m0.0971[0m       0.7738      0.8505        0.2248        0.0000  15.1408
     11      [36m0.9505[0m        [32m0.0915[0m       0.7786      [31m0.8633[0m        0.2217        0.0000  15.4272
     12      [36m0.9522[0m        [32m0.0896[0m       0.7797      0.8630        0.2220        0.0000  15.5020
     13      0.9509        0.0899       0.7790      0.8627        0.2255        0.0000  15.5059
     14      [36m0.9525[0m        [32m0.0859[0m       0.7785      0.8616        0.2266        0.0000  15.6288
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8867496282382407
F1 Macro Score after query 8: 0.865761015048167
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9167[0m        [32m0.1376[0m       [35m0.7814[0m      [31m0.8761[0m        [94m0.2110[0m     +  0.0001  19.6170
      2      [36m0.9254[0m        [32m0.1237[0m       0.7748      0.8711        0.2153        0.0001  19.2995
      3      [36m0.9315[0m        [32m0.1179[0m       0.7811      0.8731        [94m0.2089[0m     +  0.0001  18.9640
      4      0.9309        [32m0.1154[0m       [35m0.7878[0m      [31m0.8779[0m        [94m0.2004[0m     +  0.0001  18.6063
      5      [36m0.9330[0m        [32m0.1082[0m       0.7698      0.8718        0.2200        0.0001  19.0896
      6      [36m0.9445[0m        [32m0.0935[0m       0.7679      0.8701        0.2277        0.0000  19.2045
      7      [36m0.9484[0m        [32m0.0920[0m       0.7703      0.8717        0.2271        0.0000  18.2664
      8      0.9464        [32m0.0907[0m       0.7712      0.8680        0.2257        0.0000  19.3063
      9      [36m0.9496[0m        [32m0.0862[0m       0.7644      0.8683        0.2342        0.0000  19.0513
     10      0.9489        [32m0.0855[0m       0.7656      0.8664        0.2312        0.0000  18.4685
     11      [36m0.9529[0m        [32m0.0825[0m       0.7681      0.8695        0.2343        0.0000  19.3759
     12      [36m0.9556[0m        [32m0.0801[0m       0.7696      0.8686        0.2343        0.0000  19.3603
     13      0.9548        [32m0.0779[0m       0.7649      0.8676        0.2412        0.0000  18.6714
     14      [36m0.9566[0m        0.0784       0.7644      0.8650        0.2396        0.0000  18.7839
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8947976878612717
F1 Macro Score after query 9: 0.8824066864176502
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9250[0m        [32m0.1204[0m       [35m0.7630[0m      [31m0.8728[0m        [94m0.2334[0m     +  0.0001  24.6958
      2      [36m0.9347[0m        [32m0.1104[0m       0.7616      [31m0.8730[0m        [94m0.2299[0m     +  0.0001  25.2752
      3      [36m0.9361[0m        [32m0.1058[0m       0.7585      0.8683        0.2367        0.0001  24.9350
      4      [36m0.9414[0m        [32m0.1006[0m       0.7503      0.8659        0.2483        0.0001  24.9858
      5      [36m0.9442[0m        [32m0.0973[0m       0.7561      0.8676        0.2388        0.0001  25.3740
      6      [36m0.9512[0m        [32m0.0823[0m       0.7503      0.8628        0.2518        0.0000  24.8891
      7      [36m0.9533[0m        [32m0.0801[0m       0.7507      0.8635        0.2423        0.0000  25.3105
      8      [36m0.9549[0m        [32m0.0784[0m       0.7477      0.8612        0.2573        0.0000  24.8118
      9      [36m0.9569[0m        [32m0.0770[0m       0.7526      0.8650        0.2517        0.0000  24.9325
     10      0.9557        [32m0.0756[0m       0.7451      0.8606        0.2558        0.0000  25.4058
     11      [36m0.9600[0m        [32m0.0690[0m       0.7526      0.8614        0.2466        0.0000  25.1890
     12      [36m0.9605[0m        0.0694       0.7523      0.8591        0.2425        0.0000  25.5740
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8963149462119477
F1 Macro Score after query 10: 0.8831264940289262
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9335[0m        [32m0.1109[0m       [35m0.7696[0m      [31m0.8496[0m        [94m0.2087[0m     +  0.0001  37.0447
      2      [36m0.9384[0m        [32m0.1023[0m       [35m0.7743[0m      [31m0.8555[0m        [94m0.2067[0m     +  0.0001  37.1356
      3      [36m0.9442[0m        [32m0.0968[0m       0.7729      [31m0.8606[0m        0.2151        0.0001  37.1675
      4      [36m0.9465[0m        [32m0.0924[0m       0.7670      0.8556        0.2147        0.0001  37.2492
      5      [36m0.9473[0m        [32m0.0894[0m       0.7667      0.8497        0.2164        0.0001  36.7249
      6      [36m0.9564[0m        [32m0.0754[0m       0.7701      0.8594        0.2298        0.0000  37.1711
      7      [36m0.9577[0m        [32m0.0734[0m       0.7627      0.8539        0.2431        0.0000  37.0480
      8      [36m0.9593[0m        [32m0.0713[0m       0.7602      0.8530        0.2402        0.0000  36.2920
      9      0.9583        [32m0.0708[0m       0.7589      0.8498        0.2421        0.0000  36.7016
     10      0.9591        [32m0.0685[0m       0.7561      0.8519        0.2477        0.0000  36.6012
     11      [36m0.9624[0m        [32m0.0651[0m       0.7559      0.8516        0.2538        0.0000  36.3257
     12      [36m0.9633[0m        [32m0.0626[0m       0.7611      0.8524        0.2461        0.0000  36.3594
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8912861809617868
F1 Macro Score after query 11: 0.8762629311874859
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9420[0m        [32m0.0985[0m       [35m0.7589[0m      [31m0.8652[0m        [94m0.2442[0m     +  0.0001  57.2466
      2      [36m0.9468[0m        [32m0.0908[0m       [35m0.7609[0m      [31m0.8681[0m        [94m0.2360[0m     +  0.0001  56.9383
      3      [36m0.9497[0m        [32m0.0860[0m       0.7491      0.8624        0.2877        0.0001  56.6944
      4      [36m0.9517[0m        [32m0.0821[0m       0.7531      0.8592        0.2516        0.0001  56.3161
      5      [36m0.9540[0m        [32m0.0786[0m       [35m0.7625[0m      0.8630        0.2390        0.0001  56.8481
      6      [36m0.9618[0m        [32m0.0665[0m       0.7616      0.8621        0.2432        0.0000  56.7039
      7      [36m0.9631[0m        [32m0.0644[0m       0.7536      0.8581        0.2639        0.0000  56.8289
      8      [36m0.9647[0m        [32m0.0636[0m       0.7583      0.8582        0.2566        0.0000  58.0732
      9      0.9646        [32m0.0621[0m       0.7590      0.8611        0.2540        0.0000  57.0144
     10      [36m0.9652[0m        [32m0.0615[0m       [35m0.7682[0m      0.8627        0.2450        0.0000  57.2344
     11      [36m0.9669[0m        [32m0.0566[0m       0.7564      0.8587        0.2659        0.0000  57.1731
     12      [36m0.9672[0m        [32m0.0557[0m       0.7549      0.8561        0.2696        0.0000  56.7725
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8991987790919496
F1 Macro Score after query 12: 0.8871702613810669
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9489[0m        [32m0.0867[0m       [35m0.7681[0m      [31m0.8577[0m        [94m0.2404[0m     +  0.0001  64.6835
      2      [36m0.9534[0m        [32m0.0808[0m       0.7594      0.8517        0.2481        0.0001  65.0316
      3      [36m0.9547[0m        [32m0.0779[0m       0.7540      0.8484        0.2609        0.0001  63.9821
      4      [36m0.9566[0m        [32m0.0743[0m       0.7559      0.8390        0.2535        0.0001  64.4832
      5      [36m0.9575[0m        [32m0.0730[0m       0.7479      0.8287        0.2683        0.0001  64.6829
      6      [36m0.9652[0m        [32m0.0607[0m       0.7583      0.8554        0.2589        0.0000  64.2160
      7      [36m0.9664[0m        [32m0.0592[0m       0.7545      0.8532        0.2599        0.0000  64.8906
      8      [36m0.9671[0m        [32m0.0588[0m       0.7556      0.8488        0.2541        0.0000  65.0388
      9      0.9664        [32m0.0575[0m       0.7503      0.8470        0.2708        0.0000  64.1089
     10      [36m0.9674[0m        [32m0.0562[0m       0.7528      0.8472        0.2610        0.0000  64.3468
     11      [36m0.9694[0m        [32m0.0522[0m       0.7554      0.8531        0.2664        0.0000  64.5705
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8964734372635085
F1 Macro Score after query 13: 0.8824287528439879
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed46_config2\AL_average_confidence_results_for_multilabel_classification.pickle
