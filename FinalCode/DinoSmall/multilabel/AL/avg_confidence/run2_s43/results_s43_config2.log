Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2434[0m        [32m0.6979[0m       [35m0.1743[0m      [31m0.4814[0m        [94m0.6974[0m     +  0.0001  12.3703
      2      [36m0.8320[0m        [32m0.6060[0m       0.1276      0.4306        0.7038        0.0001  10.8001
      3      0.7667        0.6264       0.1323      0.4351        0.7086        0.0001  10.7360
      4      0.5985        0.6300       [35m0.2733[0m      0.4432        [94m0.6808[0m     +  0.0001  10.9068
      5      0.7368        [32m0.5420[0m       0.2479      0.4483        0.6907        0.0001  10.6255
      6      0.7963        0.5478       0.2483      0.4404        0.6928        0.0000  10.7262
      7      0.6905        0.5752       0.2500      0.4425        0.6925        0.0000  10.6094
      8      0.7857        0.5549       0.2576      0.4437        0.6927        0.0000  10.9648
      9      0.7222        0.5526       0.2585      0.4446        0.6912        0.0000  10.9951
     10      0.7500        0.5567       0.2540      0.4484        0.6946        0.0000  10.8908
     11      0.6111        0.5854       0.2481      0.4463        0.6956        0.0000  10.6516
     12      [36m0.8690[0m        [32m0.4682[0m       0.2500      0.4457        0.6959        0.0000  11.0455
     13      0.8333        0.5104       0.2587      0.4473        0.6939        0.0000  10.9163
     14      0.6111        0.5341       0.2528      0.4475        0.6950        0.0000  10.8713
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4688
Pre F1 macro score = 0.4682
Pre Accuracy = 0.2630

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5660[0m        [32m0.6509[0m       [35m0.4698[0m      [31m0.2476[0m        [94m0.5988[0m     +  0.0001  11.0457
      2      0.5402        [32m0.5890[0m       [35m0.4717[0m      [31m0.2595[0m        [94m0.5807[0m     +  0.0001  10.6569
      3      [36m0.6500[0m        [32m0.5365[0m       [35m0.4769[0m      [31m0.4485[0m        [94m0.5497[0m     +  0.0001  11.0731
      4      [36m0.6792[0m        [32m0.5140[0m       [35m0.5035[0m      [31m0.5361[0m        [94m0.5329[0m     +  0.0001  10.9679
      5      [36m0.7956[0m        [32m0.4945[0m       [35m0.5052[0m      [31m0.6156[0m        [94m0.5129[0m     +  0.0001  10.9346
      6      [36m0.8471[0m        [32m0.4412[0m       0.4951      [31m0.6569[0m        [94m0.5031[0m     +  0.0000  10.8437
      7      0.8412        [32m0.4130[0m       0.5009      [31m0.6690[0m        [94m0.4946[0m     +  0.0000  11.0155
      8      0.8043        0.4318       0.5028      [31m0.6715[0m        [94m0.4914[0m     +  0.0000  10.8594
      9      [36m0.9666[0m        [32m0.3716[0m       [35m0.5127[0m      [31m0.6758[0m        [94m0.4833[0m     +  0.0000  10.9837
     10      0.8975        0.3824       0.5113      [31m0.6930[0m        [94m0.4764[0m     +  0.0000  10.9058
     11      0.8582        [32m0.3608[0m       [35m0.5134[0m      [31m0.6936[0m        [94m0.4732[0m     +  0.0000  10.9837
     12      0.9364        [32m0.3472[0m       [35m0.5158[0m      [31m0.6969[0m        [94m0.4708[0m     +  0.0000  10.9749
     13      0.8834        0.3626       [35m0.5188[0m      [31m0.7001[0m        [94m0.4695[0m     +  0.0000  10.8020
     14      0.9091        [32m0.3401[0m       [35m0.5220[0m      [31m0.7040[0m        [94m0.4673[0m     +  0.0000  11.0317
     15      0.9249        0.3420       0.5201      [31m0.7054[0m        [94m0.4661[0m     +  0.0000  10.8750
     16      0.9105        [32m0.3298[0m       0.5210      0.7052        [94m0.4656[0m     +  0.0000  10.9533
     17      0.9188        0.3470       [35m0.5222[0m      0.7053        [94m0.4646[0m     +  0.0000  11.0002
     18      0.9275        [32m0.3238[0m       [35m0.5240[0m      [31m0.7068[0m        [94m0.4641[0m     +  0.0000  10.7957
     19      0.9158        0.3446       0.5231      0.7066        [94m0.4629[0m     +  0.0000  10.7038
     20      0.9508        0.3326       [35m0.5245[0m      [31m0.7072[0m        [94m0.4616[0m     +  0.0000  10.9702
     21      0.8841        0.3334       0.5245      0.7069        [94m0.4614[0m     +  0.0000  11.0411
     22      0.8965        0.3289       [35m0.5248[0m      [31m0.7074[0m        [94m0.4610[0m     +  0.0000  10.8906
     23      0.9666        [32m0.3172[0m       [35m0.5255[0m      0.7073        [94m0.4609[0m     +  0.0000  10.9337
     24      0.9312        0.3339       [35m0.5262[0m      [31m0.7077[0m        [94m0.4606[0m     +  0.0000  11.0468
     25      0.8920        0.3190       [35m0.5271[0m      [31m0.7081[0m        [94m0.4602[0m     +  0.0000  11.0315
     26      0.9508        0.3336       0.5269      [31m0.7081[0m        [94m0.4601[0m     +  0.0000  11.1049
     27      0.9312        0.3345       0.5269      0.7081        [94m0.4601[0m     +  0.0000  11.0815
     28      0.9119        0.3323       [35m0.5273[0m      [31m0.7085[0m        [94m0.4599[0m     +  0.0000  10.7763
     29      [36m0.9667[0m        [32m0.3138[0m       0.5273      [31m0.7088[0m        [94m0.4598[0m     +  0.0000  10.9747
     30      0.9332        0.3157       [35m0.5276[0m      [31m0.7090[0m        [94m0.4597[0m     +  0.0000  10.9151
     31      0.9152        0.3185       0.5276      0.7090        [94m0.4597[0m     +  0.0000  10.8200
     32      0.8965        0.3450       0.5274      0.7089        [94m0.4596[0m     +  0.0000  10.9924
     33      0.9508        0.3287       0.5274      0.7088        [94m0.4596[0m     +  0.0000  10.9294
     34      0.9333        0.3218       0.5276      [31m0.7090[0m        [94m0.4595[0m     +  0.0000  10.8814
     35      0.9364        0.3151       0.5274      0.7089        [94m0.4595[0m     +  0.0000  10.7873
     36      0.8944        0.3332       0.5276      [31m0.7090[0m        [94m0.4595[0m     +  0.0000  10.8826
     37      0.9333        [32m0.3136[0m       0.5276      0.7090        [94m0.4595[0m     +  0.0000  10.8661
     38      0.9470        0.3160       0.5276      0.7090        [94m0.4595[0m     +  0.0000  10.8511
     39      0.9333        0.3229       0.5276      0.7088        [94m0.4594[0m     +  0.0000  10.9439
     40      0.8770        0.3262       0.5276      0.7088        [94m0.4594[0m     +  0.0000  10.8657
     41      0.9100        0.3216       0.5276      0.7088        [94m0.4594[0m     +  0.0000  10.7414
     42      0.9315        [32m0.3111[0m       0.5276      0.7089        [94m0.4594[0m     +  0.0000  10.8813
     43      0.8552        0.3221       0.5276      0.7088        [94m0.4594[0m     +  0.0000  10.5564
     44      0.9137        0.3245       0.5276      0.7089        [94m0.4594[0m     +  0.0000  11.0372
     45      0.9316        0.3240       0.5276      0.7089        [94m0.4594[0m     +  0.0000  10.8661
     46      0.9158        0.3350       0.5276      0.7090        [94m0.4594[0m     +  0.0000  11.0205
     47      0.9364        0.3117       0.5276      0.7090        [94m0.4594[0m     +  0.0000  10.9124
     48      0.9137        0.3418       0.5276      0.7090        [94m0.4594[0m     +  0.0000  10.8660
     49      0.9332        0.3261       0.5276      0.7090        [94m0.4594[0m     +  0.0000  10.8510
     50      0.8751        0.3518       0.5276      0.7090        [94m0.4594[0m     +  0.0000  10.9597
     51      0.8944        0.3340       0.5276      0.7089        [94m0.4594[0m     +  0.0000  10.7562
     52      0.8552        0.3455       0.5276      0.7089        [94m0.4594[0m     +  0.0000  10.9609
     53      0.8801        0.3323       0.5276      0.7089        [94m0.4594[0m     +  0.0000  10.8046
     54      0.9470        0.3240       0.5276      0.7089        [94m0.4594[0m     +  0.0000  11.0998
     55      0.9333        0.3306       0.5276      0.7089        [94m0.4594[0m     +  0.0000  10.7868
     56      0.9091        0.3302       0.5276      0.7089        [94m0.4594[0m     +  0.0000  10.8969
     57      0.9138        0.3264       0.5276      0.7089        [94m0.4594[0m     +  0.0000  10.8821
     58      0.9508        0.3399       0.5276      0.7089        [94m0.4594[0m     +  0.0000  10.5530
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.7327139685932746
F1 Macro Score after query 1: 0.719241210800269
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7320[0m        [32m0.4368[0m       [35m0.4780[0m      [31m0.7059[0m        [94m0.4118[0m     +  0.0001  10.8653
      2      [36m0.8240[0m        [32m0.3299[0m       [35m0.5507[0m      [31m0.7436[0m        [94m0.3743[0m     +  0.0001  10.8807
      3      [36m0.8650[0m        [32m0.3042[0m       [35m0.5878[0m      [31m0.7829[0m        [94m0.3656[0m     +  0.0001  10.7415
      4      [36m0.8748[0m        [32m0.2603[0m       [35m0.6062[0m      0.7786        [94m0.3527[0m     +  0.0001  11.0070
      5      [36m0.8938[0m        [32m0.2467[0m       [35m0.6170[0m      [31m0.7856[0m        [94m0.3434[0m     +  0.0001  10.8656
      6      [36m0.8947[0m        [32m0.2242[0m       [35m0.6200[0m      0.7701        0.3494        0.0000  11.1787
      7      [36m0.9084[0m        [32m0.2028[0m       [35m0.6276[0m      0.7793        0.3470        0.0000  10.9735
      8      [36m0.9263[0m        0.2047       [35m0.6326[0m      0.7821        0.3481        0.0000  10.7098
      9      0.9071        0.2214       [35m0.6417[0m      [31m0.7898[0m        0.3485        0.0000  11.1128
     10      0.9084        [32m0.1938[0m       0.6396      [31m0.7964[0m        [94m0.3406[0m     +  0.0000  10.9269
     11      0.9157        [32m0.1845[0m       0.6411      0.7937        0.3429        0.0000  10.8657
     12      0.9129        0.1896       [35m0.6420[0m      [31m0.7967[0m        0.3431        0.0000  10.9757
     13      0.9263        0.1851       [35m0.6422[0m      0.7937        0.3445        0.0000  10.7762
     14      [36m0.9384[0m        [32m0.1824[0m       0.6418      0.7965        0.3432        0.0000  10.9128
     15      0.9229        0.1870       [35m0.6432[0m      0.7953        0.3444        0.0000  10.9282
     16      0.9381        [32m0.1765[0m       [35m0.6448[0m      [31m0.7973[0m        0.3438        0.0000  10.9592
     17      0.9172        0.1863       [35m0.6451[0m      [31m0.7978[0m        0.3433        0.0000  10.7565
     18      0.9256        0.1833       [35m0.6453[0m      [31m0.7983[0m        0.3429        0.0000  10.9122
     19      0.9166        0.1773       0.6451      0.7978        0.3437        0.0000  10.9135
     20      0.9361        0.1817       [35m0.6462[0m      [31m0.7991[0m        0.3437        0.0000  10.8969
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.7929023248172185
F1 Macro Score after query 2: 0.7755149300610874
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7933[0m        [32m0.3175[0m       [35m0.6707[0m      [31m0.8169[0m        [94m0.3274[0m     +  0.0001  11.2105
      2      [36m0.8358[0m        [32m0.2495[0m       [35m0.6811[0m      [31m0.8177[0m        [94m0.3131[0m     +  0.0001  11.0697
      3      [36m0.8813[0m        [32m0.2150[0m       [35m0.6861[0m      [31m0.8260[0m        [94m0.3051[0m     +  0.0001  10.9762
      4      0.8711        [32m0.1923[0m       [35m0.6892[0m      [31m0.8320[0m        [94m0.3010[0m     +  0.0001  11.1156
      5      [36m0.8947[0m        [32m0.1856[0m       0.6878      0.8279        0.3063        0.0001  10.9756
      6      [36m0.9047[0m        [32m0.1753[0m       [35m0.6932[0m      [31m0.8381[0m        [94m0.2994[0m     +  0.0000  11.1622
      7      [36m0.9178[0m        [32m0.1646[0m       0.6925      0.8359        0.3013        0.0000  11.1944
      8      0.8958        0.1665       [35m0.6941[0m      [31m0.8392[0m        [94m0.2994[0m     +  0.0000  11.2100
      9      0.9119        [32m0.1590[0m       [35m0.6950[0m      0.8373        [94m0.2988[0m     +  0.0000  11.1151
     10      [36m0.9200[0m        0.1592       0.6939      0.8357        0.3010        0.0000  11.0387
     11      [36m0.9228[0m        [32m0.1493[0m       0.6931      0.8371        0.3013        0.0000  11.1474
     12      0.9106        0.1533       0.6925      0.8364        0.3016        0.0000  11.1627
     13      [36m0.9255[0m        0.1549       0.6922      0.8366        0.3024        0.0000  11.1782
     14      [36m0.9435[0m        [32m0.1404[0m       0.6927      0.8363        0.3026        0.0000  10.4347
     15      0.9309        0.1452       0.6929      0.8376        0.3014        0.0000  11.1000
     16      0.9310        [32m0.1386[0m       0.6925      0.8359        0.3024        0.0000  11.1476
     17      0.9260        0.1459       0.6925      0.8359        0.3032        0.0000  10.9438
     18      0.9102        0.1511       0.6927      0.8358        0.3030        0.0000  11.1771
     19      0.9356        0.1503       0.6927      0.8363        0.3029        0.0000  11.2101
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.8358470991939988
F1 Macro Score after query 3: 0.8236960525672411
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8207[0m        [32m0.2821[0m       [35m0.6830[0m      [31m0.8345[0m        [94m0.2771[0m     +  0.0001  11.4436
      2      [36m0.8541[0m        [32m0.2304[0m       [35m0.7012[0m      [31m0.8443[0m        [94m0.2613[0m     +  0.0001  11.4142
      3      [36m0.8583[0m        [32m0.2127[0m       [35m0.7085[0m      0.8365        [94m0.2586[0m     +  0.0001  11.2727
      4      [36m0.8777[0m        [32m0.2084[0m       [35m0.7115[0m      [31m0.8454[0m        [94m0.2564[0m     +  0.0001  11.3809
      5      [36m0.8783[0m        [32m0.1990[0m       [35m0.7188[0m      0.8377        [94m0.2545[0m     +  0.0001  11.3977
      6      [36m0.8871[0m        [32m0.1907[0m       0.7177      0.8341        0.2618        0.0000  11.2580
      7      0.8767        0.1925       0.7142      0.8253        0.2647        0.0000  11.3993
      8      [36m0.9028[0m        [32m0.1809[0m       0.7181      0.8321        0.2613        0.0000  11.4466
      9      0.8853        [32m0.1804[0m       0.7177      0.8316        0.2644        0.0000  11.3666
     10      [36m0.9088[0m        [32m0.1728[0m       0.7170      0.8291        0.2617        0.0000  11.2100
     11      0.9056        [32m0.1722[0m       [35m0.7220[0m      0.8363        0.2561        0.0000  11.4744
     12      0.9003        [32m0.1716[0m       [35m0.7226[0m      0.8345        0.2590        0.0000  11.2597
     13      [36m0.9108[0m        [32m0.1666[0m       [35m0.7233[0m      0.8370        0.2554        0.0000  11.2744
     14      0.8976        0.1683       [35m0.7236[0m      0.8371        0.2574        0.0000  11.2728
     15      0.8990        0.1688       [35m0.7248[0m      0.8380        0.2562        0.0000  11.3351
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.8633430138754438
F1 Macro Score after query 4: 0.8523762989524403
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8484[0m        [32m0.2346[0m       [35m0.6911[0m      [31m0.8400[0m        [94m0.2714[0m     +  0.0001  11.6339
      2      [36m0.8551[0m        [32m0.2031[0m       [35m0.7045[0m      [31m0.8472[0m        [94m0.2594[0m     +  0.0001  11.6951
      3      [36m0.8648[0m        [32m0.1966[0m       0.7021      [31m0.8482[0m        0.2596        0.0001  11.5542
      4      [36m0.8771[0m        [32m0.1826[0m       0.7021      0.8478        0.2605        0.0001  11.6018
      5      [36m0.8830[0m        [32m0.1741[0m       [35m0.7144[0m      [31m0.8529[0m        [94m0.2506[0m     +  0.0001  11.4765
      6      [36m0.8955[0m        [32m0.1689[0m       [35m0.7380[0m      [31m0.8603[0m        [94m0.2347[0m     +  0.0000  11.7423
      7      [36m0.8987[0m        [32m0.1602[0m       0.7375      0.8595        [94m0.2325[0m     +  0.0000  11.6784
      8      0.8934        [32m0.1571[0m       [35m0.7389[0m      [31m0.8618[0m        0.2334        0.0000  11.6801
      9      [36m0.9023[0m        0.1587       0.7377      0.8614        0.2354        0.0000  11.6153
     10      [36m0.9123[0m        [32m0.1570[0m       [35m0.7403[0m      [31m0.8630[0m        0.2332        0.0000  11.6023
     11      0.9123        0.1582       [35m0.7425[0m      0.8593        0.2357        0.0000  11.5932
     12      0.9045        [32m0.1541[0m       [35m0.7439[0m      0.8605        0.2345        0.0000  11.6586
     13      0.9120        [32m0.1517[0m       [35m0.7450[0m      0.8611        0.2333        0.0000  11.6651
     14      0.9110        [32m0.1480[0m       [35m0.7464[0m      0.8627        [94m0.2324[0m     +  0.0000  11.6147
     15      0.9103        [32m0.1466[0m       0.7457      0.8621        0.2339        0.0000  11.5710
     16      0.9089        [32m0.1434[0m       0.7455      0.8592        0.2370        0.0000  11.4819
     17      [36m0.9177[0m        [32m0.1384[0m       0.7464      0.8586        0.2383        0.0000  11.7259
     18      0.9111        0.1439       0.7462      0.8591        0.2368        0.0000  11.7417
     19      [36m0.9192[0m        0.1430       0.7457      0.8587        0.2365        0.0000  11.8040
     20      0.9103        0.1417       [35m0.7469[0m      0.8600        0.2362        0.0000  11.6791
     21      0.9169        0.1392       [35m0.7470[0m      0.8589        0.2371        0.0000  11.5526
     22      0.9048        0.1438       0.7469      0.8591        0.2375        0.0000  11.6763
     23      0.9158        0.1406       [35m0.7474[0m      0.8599        0.2369        0.0000  11.4446
     24      0.9187        0.1429       0.7470      0.8591        0.2376        0.0000  11.6164
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.8745399263882222
F1 Macro Score after query 5: 0.8620432955582201
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8584[0m        [32m0.2148[0m       [35m0.7280[0m      [31m0.8522[0m        [94m0.2482[0m     +  0.0001  12.4291
      2      [36m0.8856[0m        [32m0.1841[0m       0.7264      0.8514        [94m0.2460[0m     +  0.0001  12.3663
      3      [36m0.8984[0m        [32m0.1731[0m       0.7269      0.8514        0.2500        0.0001  12.3990
      4      0.8954        [32m0.1718[0m       [35m0.7330[0m      [31m0.8542[0m        0.2467        0.0001  12.1496
      5      [36m0.9081[0m        [32m0.1599[0m       [35m0.7335[0m      [31m0.8553[0m        [94m0.2429[0m     +  0.0001  12.4307
      6      [36m0.9115[0m        [32m0.1468[0m       [35m0.7373[0m      [31m0.8600[0m        [94m0.2314[0m     +  0.0000  12.4757
      7      0.9073        [32m0.1459[0m       [35m0.7394[0m      [31m0.8611[0m        0.2331        0.0000  12.3044
      8      [36m0.9151[0m        [32m0.1450[0m       0.7358      0.8596        0.2336        0.0000  12.3960
      9      0.9120        [32m0.1405[0m       [35m0.7398[0m      [31m0.8627[0m        0.2326        0.0000  12.5406
     10      [36m0.9210[0m        [32m0.1392[0m       0.7387      0.8605        0.2355        0.0000  12.5279
     11      0.9179        0.1396       [35m0.7455[0m      [31m0.8639[0m        [94m0.2292[0m     +  0.0000  12.1316
     12      [36m0.9227[0m        [32m0.1350[0m       [35m0.7484[0m      [31m0.8649[0m        [94m0.2276[0m     +  0.0000  12.3048
     13      [36m0.9290[0m        [32m0.1325[0m       0.7477      [31m0.8652[0m        0.2286        0.0000  12.1323
     14      0.9207        [32m0.1300[0m       [35m0.7516[0m      [31m0.8660[0m        [94m0.2271[0m     +  0.0000  12.3221
     15      0.9212        [32m0.1299[0m       0.7493      0.8654        0.2284        0.0000  12.2726
     16      [36m0.9295[0m        [32m0.1256[0m       [35m0.7521[0m      0.8650        [94m0.2271[0m     +  0.0000  12.3051
     17      0.9269        [32m0.1254[0m       [35m0.7524[0m      0.8653        [94m0.2260[0m     +  0.0000  12.1014
     18      0.9272        0.1286       [35m0.7557[0m      [31m0.8671[0m        [94m0.2251[0m     +  0.0000  12.3512
     19      0.9263        0.1267       0.7547      0.8659        0.2255        0.0000  12.2120
     20      0.9245        0.1303       0.7556      0.8665        [94m0.2246[0m     +  0.0000  12.4301
     21      0.9264        0.1267       [35m0.7585[0m      0.8669        0.2250        0.0000  12.4299
     22      0.9270        0.1276       0.7580      0.8656        0.2266        0.0000  12.1159
     23      0.9271        [32m0.1229[0m       0.7585      0.8666        0.2261        0.0000  12.2260
     24      0.9250        0.1258       [35m0.7590[0m      [31m0.8671[0m        0.2261        0.0000  12.2577
     25      [36m0.9325[0m        [32m0.1227[0m       0.7582      0.8667        0.2268        0.0000  12.2233
     26      0.9272        0.1269       0.7580      0.8662        0.2273        0.0000  12.2570
     27      0.9203        0.1276       0.7575      0.8655        0.2277        0.0000  12.3034
     28      0.9248        0.1258       0.7569      0.8649        0.2277        0.0000  12.4619
     29      0.9279        0.1233       0.7568      0.8647        0.2277        0.0000  12.1789
     30      0.9270        [32m0.1222[0m       0.7573      0.8651        0.2273        0.0000  12.3200
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8842302878598248
F1 Macro Score after query 6: 0.8726861248705933
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9058[0m        [32m0.1684[0m       [35m0.7344[0m      [31m0.8285[0m        [94m0.2420[0m     +  0.0001  13.4155
      2      [36m0.9159[0m        [32m0.1487[0m       [35m0.7495[0m      [31m0.8436[0m        [94m0.2333[0m     +  0.0001  13.4779
      3      [36m0.9217[0m        [32m0.1405[0m       0.7477      0.8403        0.2399        0.0001  13.6177
      4      [36m0.9247[0m        [32m0.1352[0m       [35m0.7524[0m      [31m0.8444[0m        0.2427        0.0001  13.1951
      5      [36m0.9263[0m        [32m0.1310[0m       [35m0.7672[0m      [31m0.8607[0m        [94m0.2311[0m     +  0.0001  13.6950
      6      [36m0.9357[0m        [32m0.1188[0m       [35m0.7717[0m      [31m0.8614[0m        [94m0.2252[0m     +  0.0000  13.4483
      7      [36m0.9381[0m        [32m0.1167[0m       [35m0.7774[0m      [31m0.8660[0m        [94m0.2209[0m     +  0.0000  13.5253
      8      0.9362        [32m0.1110[0m       0.7764      0.8612        0.2269        0.0000  13.6507
      9      0.9365        [32m0.1093[0m       0.7767      0.8656        0.2230        0.0000  13.5239
     10      0.9373        0.1117       0.7658      0.8544        0.2325        0.0000  13.5411
     11      [36m0.9405[0m        [32m0.1052[0m       [35m0.7821[0m      [31m0.8664[0m        0.2210        0.0000  13.4759
     12      [36m0.9424[0m        [32m0.1031[0m       [35m0.7847[0m      [31m0.8717[0m        [94m0.2171[0m     +  0.0000  13.7271
     13      0.9399        0.1054       0.7823      0.8687        0.2190        0.0000  13.6019
     14      [36m0.9454[0m        [32m0.1027[0m       0.7811      0.8668        0.2202        0.0000  13.5244
     15      0.9440        0.1028       0.7830      0.8700        0.2181        0.0000  13.3982
     16      0.9430        [32m0.0998[0m       [35m0.7856[0m      [31m0.8721[0m        [94m0.2171[0m     +  0.0000  13.6331
     17      0.9440        0.1011       [35m0.7863[0m      [31m0.8734[0m        [94m0.2158[0m     +  0.0000  13.6177
     18      [36m0.9455[0m        [32m0.0976[0m       0.7854      [31m0.8740[0m        [94m0.2155[0m     +  0.0000  13.4633
     19      0.9405        0.0987       0.7852      0.8730        0.2160        0.0000  13.5239
     20      0.9414        0.0990       0.7861      0.8726        0.2160        0.0000  13.4938
     21      0.9440        0.0980       0.7851      [31m0.8747[0m        [94m0.2154[0m     +  0.0000  13.2718
     22      [36m0.9489[0m        [32m0.0965[0m       0.7851      [31m0.8747[0m        [94m0.2148[0m     +  0.0000  13.6020
     23      0.9463        0.0980       0.7839      0.8747        0.2151        0.0000  13.5261
     24      0.9466        [32m0.0955[0m       0.7847      [31m0.8751[0m        0.2154        0.0000  13.3514
     25      0.9467        0.0973       0.7842      0.8749        0.2156        0.0000  13.5401
     26      0.9405        0.0989       0.7839      [31m0.8755[0m        0.2155        0.0000  13.5247
     27      [36m0.9492[0m        0.0971       0.7847      0.8754        0.2156        0.0000  13.3989
     28      0.9466        0.0968       0.7844      0.8750        0.2156        0.0000  13.4761
     29      0.9471        0.0981       0.7854      0.8755        0.2158        0.0000  13.4775
     30      0.9458        0.0971       0.7851      0.8750        0.2155        0.0000  13.5078
     31      0.9437        0.0975       0.7852      [31m0.8757[0m        0.2155        0.0000  13.4915
     32      0.9461        0.0987       0.7852      0.8755        0.2156        0.0000  13.5082
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.8946019417475728
F1 Macro Score after query 7: 0.8816736401696339
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9132[0m        [32m0.1424[0m       [35m0.7863[0m      [31m0.8761[0m        [94m0.2087[0m     +  0.0001  15.5719
      2      [36m0.9177[0m        [32m0.1273[0m       0.7710      0.8664        0.2176        0.0001  15.1030
      3      [36m0.9230[0m        [32m0.1218[0m       0.7788      0.8681        0.2131        0.0001  15.4943
      4      [36m0.9278[0m        [32m0.1190[0m       [35m0.7875[0m      0.8723        [94m0.2084[0m     +  0.0001  15.4615
      5      [36m0.9284[0m        [32m0.1154[0m       0.7764      0.8620        0.2134        0.0001  15.7608
      6      [36m0.9352[0m        [32m0.1026[0m       0.7675      0.8554        0.2210        0.0000  15.3850
      7      [36m0.9403[0m        [32m0.1002[0m       0.7771      0.8580        0.2153        0.0000  15.7602
      8      [36m0.9426[0m        [32m0.0967[0m       0.7747      0.8571        0.2162        0.0000  15.7434
      9      0.9394        [32m0.0963[0m       0.7757      0.8592        0.2156        0.0000  15.3824
     10      [36m0.9440[0m        [32m0.0935[0m       0.7760      0.8566        0.2161        0.0000  15.7275
     11      [36m0.9497[0m        [32m0.0880[0m       0.7823      0.8661        0.2136        0.0000  15.5863
     12      0.9481        [32m0.0874[0m       0.7795      0.8648        0.2157        0.0000  15.6953
     13      0.9481        0.0881       0.7821      0.8660        0.2122        0.0000  15.6343
     14      0.9478        [32m0.0864[0m       0.7795      0.8631        0.2160        0.0000  15.5725
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8914868575912124
F1 Macro Score after query 8: 0.8745208713859144
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9157[0m        [32m0.1350[0m       [35m0.7901[0m      [31m0.8805[0m        [94m0.2016[0m     +  0.0001  19.2134
      2      [36m0.9239[0m        [32m0.1220[0m       0.7852      0.8742        [94m0.2007[0m     +  0.0001  19.4650
      3      [36m0.9266[0m        [32m0.1180[0m       0.7849      0.8748        [94m0.1960[0m     +  0.0001  19.1843
      4      [36m0.9320[0m        [32m0.1118[0m       0.7837      0.8722        0.2033        0.0001  18.9809
      5      0.9316        [32m0.1080[0m       0.7818      0.8777        0.2085        0.0001  19.2137
      6      [36m0.9433[0m        [32m0.0940[0m       0.7863      0.8765        0.2017        0.0000  19.1336
      7      [36m0.9453[0m        [32m0.0908[0m       0.7856      0.8756        0.2054        0.0000  18.9157
      8      [36m0.9460[0m        0.0911       0.7835      0.8712        0.2045        0.0000  19.5898
      9      [36m0.9465[0m        [32m0.0896[0m       0.7830      0.8734        0.2062        0.0000  19.3732
     10      [36m0.9481[0m        [32m0.0869[0m       0.7819      0.8738        0.2071        0.0000  19.5277
     11      [36m0.9519[0m        [32m0.0816[0m       0.7812      0.8756        0.2125        0.0000  19.3879
     12      [36m0.9526[0m        [32m0.0801[0m       0.7814      0.8750        0.2103        0.0000  19.5899
     13      [36m0.9550[0m        [32m0.0787[0m       0.7811      0.8746        0.2102        0.0000  19.2609
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8902921485088252
F1 Macro Score after query 9: 0.8753610903224102
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9234[0m        [32m0.1241[0m       [35m0.7769[0m      [31m0.8709[0m        [94m0.2204[0m     +  0.0001  26.0938
      2      [36m0.9307[0m        [32m0.1146[0m       0.7712      [31m0.8730[0m        [94m0.2158[0m     +  0.0001  26.2971
      3      [36m0.9343[0m        [32m0.1088[0m       0.7705      0.8683        0.2195        0.0001  26.2810
      4      [36m0.9372[0m        [32m0.1046[0m       0.7707      0.8684        0.2237        0.0001  25.5311
      5      [36m0.9400[0m        [32m0.1008[0m       0.7689      0.8695        0.2241        0.0001  26.1240
      6      [36m0.9480[0m        [32m0.0865[0m       0.7677      0.8645        0.2207        0.0000  26.4049
      7      [36m0.9495[0m        [32m0.0835[0m       0.7672      0.8651        0.2224        0.0000  26.0471
      8      [36m0.9512[0m        [32m0.0820[0m       0.7634      0.8600        0.2261        0.0000  25.5940
      9      [36m0.9517[0m        [32m0.0798[0m       0.7608      0.8622        0.2281        0.0000  26.2959
     10      [36m0.9521[0m        [32m0.0794[0m       0.7635      0.8575        0.2267        0.0000  26.0786
     11      [36m0.9564[0m        [32m0.0736[0m       0.7620      0.8567        0.2283        0.0000  25.8850
     12      [36m0.9571[0m        [32m0.0728[0m       0.7595      0.8592        0.2313        0.0000  26.0617
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8819750793282254
F1 Macro Score after query 10: 0.8638525097955849
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9310[0m        [32m0.1156[0m       [35m0.7740[0m      [31m0.8726[0m        [94m0.2136[0m     +  0.0001  36.9880
      2      [36m0.9372[0m        [32m0.1047[0m       [35m0.7781[0m      [31m0.8747[0m        [94m0.2134[0m     +  0.0001  38.4928
      3      [36m0.9396[0m        [32m0.0989[0m       0.7774      0.8743        0.2146        0.0001  37.7907
      4      [36m0.9432[0m        [32m0.0941[0m       0.7672      0.8695        0.2261        0.0001  38.1154
      5      [36m0.9456[0m        [32m0.0907[0m       0.7682      0.8723        0.2389        0.0001  38.3511
      6      [36m0.9541[0m        [32m0.0760[0m       0.7641      0.8641        0.2423        0.0000  37.7722
      7      [36m0.9553[0m        [32m0.0748[0m       0.7592      0.8603        0.2380        0.0000  38.2079
      8      [36m0.9572[0m        [32m0.0719[0m       0.7689      0.8680        0.2417        0.0000  38.4446
      9      [36m0.9574[0m        [32m0.0718[0m       0.7641      0.8637        0.2445        0.0000  38.0051
     10      [36m0.9586[0m        [32m0.0699[0m       0.7646      0.8647        0.2517        0.0000  38.3337
     11      [36m0.9627[0m        [32m0.0645[0m       0.7646      0.8624        0.2503        0.0000  38.3831
     12      0.9623        [32m0.0642[0m       0.7606      0.8621        0.2607        0.0000  37.7729
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8857513546516066
F1 Macro Score after query 11: 0.870147810912997
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9393[0m        [32m0.1006[0m       [35m0.7759[0m      [31m0.8722[0m        [94m0.2119[0m     +  0.0001  59.8486
      2      [36m0.9448[0m        [32m0.0923[0m       0.7743      0.8701        0.2179        0.0001  59.6966
      3      [36m0.9480[0m        [32m0.0863[0m       0.7663      0.8662        0.2360        0.0001  59.7704
      4      [36m0.9507[0m        [32m0.0825[0m       0.7644      0.8600        0.2233        0.0001  57.3554
      5      [36m0.9528[0m        [32m0.0791[0m       0.7663      0.8595        0.2350        0.0001  59.4717
      6      [36m0.9614[0m        [32m0.0655[0m       0.7707      0.8635        0.2342        0.0000  59.5654
      7      [36m0.9618[0m        [32m0.0640[0m       0.7661      0.8606        0.2482        0.0000  59.8130
      8      [36m0.9630[0m        [32m0.0625[0m       0.7665      0.8617        0.2547        0.0000  59.3486
      9      [36m0.9644[0m        [32m0.0611[0m       0.7639      0.8582        0.2493        0.0000  59.5034
     10      [36m0.9652[0m        [32m0.0596[0m       0.7602      0.8573        0.2730        0.0000  59.1445
     11      [36m0.9666[0m        [32m0.0550[0m       0.7679      0.8661        0.2681        0.0000  59.4267
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8892794376098418
F1 Macro Score after query 12: 0.8738263757885737
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9446[0m        [32m0.0945[0m       [35m0.7497[0m      [31m0.8632[0m        [94m0.2515[0m     +  0.0001  68.1175
      2      [36m0.9486[0m        [32m0.0873[0m       [35m0.7500[0m      0.8582        [94m0.2371[0m     +  0.0001  67.9158
      3      [36m0.9513[0m        [32m0.0821[0m       [35m0.7523[0m      [31m0.8645[0m        0.2506        0.0001  68.1289
      4      [36m0.9544[0m        [32m0.0783[0m       0.7424      0.8588        0.2962        0.0001  67.8802
      5      [36m0.9565[0m        [32m0.0754[0m       0.7448      0.8578        0.2760        0.0001  63.7093
      6      [36m0.9635[0m        [32m0.0636[0m       0.7505      0.8576        0.2542        0.0000  61.7611
      7      [36m0.9641[0m        [32m0.0621[0m       0.7484      0.8569        0.2730        0.0000  61.6525
      8      [36m0.9650[0m        [32m0.0606[0m       [35m0.7531[0m      0.8590        0.2685        0.0000  62.0241
      9      [36m0.9653[0m        [32m0.0596[0m       [35m0.7543[0m      0.8609        0.2727        0.0000  61.6957
     10      [36m0.9661[0m        [32m0.0581[0m       [35m0.7575[0m      0.8628        0.2733        0.0000  61.6483
     11      [36m0.9674[0m        [32m0.0540[0m       0.7562      0.8598        0.2703        0.0000  61.7585
     12      [36m0.9688[0m        [32m0.0531[0m       0.7545      0.8601        0.2741        0.0000  61.6974
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8876507403449855
F1 Macro Score after query 13: 0.87361724760678
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_config2\AL_average_confidence_results_for_multilabel_classification.pickle
