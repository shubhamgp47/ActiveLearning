Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5152[0m        [32m0.7299[0m       [35m0.0769[0m      [31m0.4301[0m        [94m0.7166[0m     +  0.0001  12.2688
      2      [36m0.6829[0m        [32m0.6723[0m       [35m0.3358[0m      0.2320        [94m0.6690[0m     +  0.0001  10.7172
      3      0.5167        [32m0.6271[0m       0.1760      [31m0.4389[0m        0.6979        0.0001  10.6574
      4      [36m0.7833[0m        [32m0.6164[0m       0.2965      0.3396        [94m0.6651[0m     +  0.0001  10.6562
      5      0.6468        [32m0.5992[0m       0.2790      0.4261        0.6822        0.0001  10.6908
      6      [36m0.8333[0m        [32m0.5498[0m       0.2927      0.4177        0.6779        0.0000  10.7955
      7      0.7857        0.5693       0.2922      0.4116        0.6781        0.0000  10.5917
      8      0.7963        0.5755       0.2918      0.4151        0.6789        0.0000  10.6854
      9      0.7857        0.5544       0.2905      0.4268        0.6807        0.0000  10.6070
     10      0.7857        0.5861       0.2632      [31m0.4415[0m        0.6878        0.0000  10.6876
     11      0.7500        [32m0.5226[0m       0.2738      [31m0.4420[0m        0.6866        0.0000  10.7932
     12      0.7368        0.5485       0.2773      0.4404        0.6857        0.0000  10.8775
     13      0.7857        [32m0.5152[0m       0.2734      [31m0.4424[0m        0.6863        0.0000  10.6921
     14      0.7500        0.5497       0.2745      [31m0.4427[0m        0.6867        0.0000  10.8276
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4625
Pre F1 macro score = 0.4614
Pre Accuracy = 0.3108

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9410[0m        [32m0.4032[0m       [35m0.2339[0m      [31m0.5508[0m        [94m0.8451[0m     +  0.0001  10.8244
      2      [36m0.9527[0m        [32m0.3325[0m       [35m0.2453[0m      0.5011        [94m0.8142[0m     +  0.0001  10.9159
      3      0.9434        [32m0.2888[0m       [35m0.2970[0m      0.4774        [94m0.7895[0m     +  0.0001  10.7812
      4      0.9500        [32m0.2631[0m       [35m0.2983[0m      0.4774        0.8018        0.0001  10.9249
      5      0.9423        [32m0.2450[0m       [35m0.3066[0m      0.4824        [94m0.7843[0m     +  0.0001  10.7180
      6      0.9500        [32m0.2293[0m       [35m0.3172[0m      0.4780        [94m0.7709[0m     +  0.0000  10.7342
      7      [36m0.9756[0m        [32m0.1951[0m       0.3045      0.4808        0.7757        0.0000  10.7792
      8      0.9671        [32m0.1891[0m       0.2983      0.4853        0.7794        0.0000  10.6957
      9      0.9581        0.2156       0.2722      0.4842        0.7903        0.0000  10.8493
     10      0.9667        0.1933       0.3038      0.4863        [94m0.7663[0m     +  0.0000  10.7265
     11      0.9667        [32m0.1827[0m       0.2934      0.4845        0.7702        0.0000  10.7372
     12      0.9667        0.2058       0.2898      0.4847        0.7675        0.0000  10.7346
     13      0.9585        [32m0.1808[0m       0.2925      0.4865        [94m0.7636[0m     +  0.0000  10.6127
     14      0.9752        [32m0.1790[0m       0.2892      0.4878        0.7650        0.0000  10.6594
     15      0.9667        0.1881       0.2880      0.4875        0.7653        0.0000  10.7826
     16      0.9581        0.1855       0.2878      0.4879        0.7643        0.0000  10.6408
     17      [36m0.9919[0m        [32m0.1656[0m       0.2865      0.4875        0.7652        0.0000  10.7200
     18      0.9837        [32m0.1633[0m       0.2866      0.4876        [94m0.7634[0m     +  0.0000  10.7498
     19      0.9756        0.1830       0.2854      0.4866        [94m0.7623[0m     +  0.0000  10.7448
     20      0.9667        0.1801       0.2839      0.4863        [94m0.7608[0m     +  0.0000  10.7212
     21      0.9837        0.1690       0.2837      0.4862        [94m0.7604[0m     +  0.0000  10.8589
     22      0.9752        0.1705       0.2837      0.4860        [94m0.7601[0m     +  0.0000  10.6416
     23      0.9752        0.1939       0.2828      0.4854        [94m0.7596[0m     +  0.0000  10.9381
     24      0.9756        0.1733       0.2837      0.4860        [94m0.7588[0m     +  0.0000  10.7769
     25      0.9752        0.1803       0.2833      0.4858        [94m0.7586[0m     +  0.0000  10.8629
     26      0.9837        0.1760       0.2833      0.4858        [94m0.7585[0m     +  0.0000  10.5762
     27      0.9667        0.1841       0.2828      0.4856        [94m0.7585[0m     +  0.0000  10.6865
     28      0.9752        0.1702       0.2825      0.4857        0.7586        0.0000  10.8591
     29      0.9837        0.1675       0.2826      0.4858        0.7588        0.0000  10.8489
     30      0.9667        0.1924       0.2823      0.4856        0.7586        0.0000  10.5467
     31      0.9667        0.1829       0.2825      0.4858        0.7586        0.0000  10.7826
     32      0.9667        0.1743       0.2825      0.4858        0.7586        0.0000  10.8182
     33      0.9667        0.1732       0.2823      0.4857        0.7587        0.0000  10.8590
     34      0.9667        0.1920       0.2823      0.4857        0.7586        0.0000  10.9531
     35      0.9671        0.1928       0.2823      0.4857        0.7586        0.0000  10.8749
     36      0.9752        0.1886       0.2825      0.4858        0.7585        0.0000  10.7797
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.4961681926076636
F1 Macro Score after query 1: 0.4870069980937603
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9904[0m        [32m0.1130[0m       [35m0.2359[0m      [31m0.5564[0m        [94m1.0479[0m     +  0.0001  10.8186
      2      0.9781        [32m0.1057[0m       [35m0.3054[0m      0.4940        [94m0.8045[0m     +  0.0001  10.6747
      3      0.9872        [32m0.0796[0m       0.2618      0.5115        0.8197        0.0001  11.1077
      4      0.9904        [32m0.0742[0m       0.2455      0.5133        [94m0.7851[0m     +  0.0001  10.6756
      5      [36m0.9937[0m        [32m0.0583[0m       0.2832      0.5158        [94m0.7563[0m     +  0.0001  10.8117
      6      [36m0.9968[0m        [32m0.0570[0m       0.2847      0.5168        [94m0.7488[0m     +  0.0000  11.0122
      7      0.9968        [32m0.0512[0m       0.2686      0.5203        0.7545        0.0000  10.6866
      8      0.9968        [32m0.0475[0m       0.2755      0.5194        [94m0.7437[0m     +  0.0000  11.0000
      9      0.9968        0.0478       0.2720      0.5204        0.7520        0.0000  11.0616
     10      0.9968        [32m0.0474[0m       0.2663      0.5206        0.7440        0.0000  10.9363
     11      0.9937        [32m0.0455[0m       0.2679      0.5212        0.7475        0.0000  10.7346
     12      0.9968        [32m0.0430[0m       0.2684      0.5208        [94m0.7422[0m     +  0.0000  10.8737
     13      0.9968        0.0436       0.2613      0.5205        0.7472        0.0000  10.8549
     14      0.9968        0.0458       0.2615      0.5228        0.7482        0.0000  10.8304
     15      0.9968        0.0465       0.2599      0.5235        0.7479        0.0000  10.9499
     16      0.9968        [32m0.0421[0m       0.2592      0.5248        0.7481        0.0000  10.4852
     17      0.9968        [32m0.0365[0m       0.2597      0.5251        0.7470        0.0000  10.7492
     18      0.9968        0.0408       0.2590      0.5253        0.7477        0.0000  10.8931
     19      0.9968        0.0426       0.2608      0.5252        0.7469        0.0000  10.8377
     20      0.9968        0.0432       0.2613      0.5236        0.7434        0.0000  10.9414
     21      0.9968        0.0452       0.2604      0.5241        0.7437        0.0000  10.7969
     22      0.9968        0.0380       0.2609      0.5254        0.7446        0.0000  10.9102
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.5448933029123606
F1 Macro Score after query 2: 0.5266534886233271
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9906[0m        [32m0.0931[0m       [35m0.2372[0m      [31m0.5736[0m        [94m1.0462[0m     +  0.0001  10.8408
      2      0.9861        0.1061       [35m0.2773[0m      0.5281        [94m0.7792[0m     +  0.0001  10.9847
      3      [36m0.9906[0m        [32m0.0766[0m       0.2582      0.5318        [94m0.7445[0m     +  0.0001  10.8311
      4      0.9890        [32m0.0744[0m       [35m0.2774[0m      0.5340        0.7493        0.0001  10.9353
      5      [36m0.9922[0m        [32m0.0643[0m       0.2648      0.5361        [94m0.7307[0m     +  0.0001  11.1278
      6      0.9922        [32m0.0636[0m       0.2675      0.5336        [94m0.7114[0m     +  0.0000  10.8500
      7      0.9922        [32m0.0608[0m       0.2665      0.5315        [94m0.7060[0m     +  0.0000  11.1249
      8      0.9922        [32m0.0601[0m       0.2686      0.5299        [94m0.7001[0m     +  0.0000  10.7504
      9      0.9922        0.0653       0.2679      0.5307        0.7010        0.0000  11.0311
     10      0.9922        [32m0.0550[0m       0.2632      0.5279        [94m0.6931[0m     +  0.0000  11.0918
     11      0.9922        0.0559       0.2642      0.5288        [94m0.6928[0m     +  0.0000  11.0616
     12      0.9922        [32m0.0531[0m       0.2693      0.5301        [94m0.6926[0m     +  0.0000  10.9690
     13      0.9922        0.0582       0.2707      0.5309        [94m0.6898[0m     +  0.0000  10.8870
     14      0.9922        0.0550       0.2736      0.5327        [94m0.6864[0m     +  0.0000  11.0002
     15      0.9922        [32m0.0503[0m       0.2722      0.5333        [94m0.6848[0m     +  0.0000  10.8282
     16      0.9922        0.0504       0.2736      0.5344        [94m0.6846[0m     +  0.0000  10.8848
     17      0.9922        [32m0.0441[0m       0.2750      0.5348        [94m0.6834[0m     +  0.0000  11.0617
     18      0.9922        0.0496       0.2752      0.5353        0.6835        0.0000  10.8261
     19      0.9922        0.0498       0.2760      0.5363        0.6834        0.0000  10.9217
     20      0.9922        0.0510       [35m0.2783[0m      0.5363        [94m0.6817[0m     +  0.0000  10.9299
     21      0.9922        0.0479       [35m0.2786[0m      0.5368        [94m0.6814[0m     +  0.0000  11.0541
     22      0.9922        0.0526       [35m0.2788[0m      0.5360        [94m0.6809[0m     +  0.0000  11.0733
     23      [36m0.9937[0m        0.0523       [35m0.2792[0m      0.5360        [94m0.6806[0m     +  0.0000  10.9826
     24      0.9922        0.0555       [35m0.2799[0m      0.5358        [94m0.6804[0m     +  0.0000  11.0134
     25      0.9922        0.0506       0.2797      0.5356        0.6804        0.0000  11.0183
     26      0.9922        0.0509       0.2795      0.5355        [94m0.6803[0m     +  0.0000  10.7337
     27      0.9922        0.0501       [35m0.2802[0m      0.5352        [94m0.6801[0m     +  0.0000  10.9893
     28      0.9922        0.0503       [35m0.2804[0m      0.5358        0.6801        0.0000  11.1734
     29      0.9906        0.0487       [35m0.2809[0m      0.5360        0.6802        0.0000  10.9081
     30      0.9922        0.0533       [35m0.2811[0m      0.5360        0.6803        0.0000  10.7365
     31      0.9922        0.0528       [35m0.2814[0m      0.5357        0.6803        0.0000  10.9326
     32      0.9922        0.0508       0.2812      0.5358        0.6803        0.0000  10.8623
     33      0.9922        0.0532       0.2812      0.5359        0.6802        0.0000  10.9542
     34      0.9922        0.0563       0.2811      0.5357        0.6802        0.0000  11.1662
     35      0.9922        0.0513       0.2812      0.5358        0.6801        0.0000  10.7656
     36      0.9922        0.0521       0.2811      0.5357        [94m0.6801[0m     +  0.0000  10.9090
     37      0.9922        0.0548       0.2811      0.5358        [94m0.6800[0m     +  0.0000  10.8908
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.5687144748111812
F1 Macro Score after query 3: 0.5414630294710534
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9838[0m        [32m0.1165[0m       [35m0.2377[0m      [31m0.6004[0m        [94m1.1036[0m     +  0.0001  10.2519
      2      0.9790        0.1316       [35m0.2905[0m      0.5531        [94m0.7285[0m     +  0.0001  10.1711
      3      [36m0.9839[0m        [32m0.1108[0m       [35m0.2997[0m      0.5814        [94m0.7171[0m     +  0.0001  10.1114
      4      0.9839        0.1119       [35m0.3217[0m      0.5824        [94m0.6824[0m     +  0.0001  10.1757
      5      0.9839        [32m0.0994[0m       0.3174      0.5834        [94m0.6720[0m     +  0.0001  10.2390
      6      [36m0.9847[0m        [32m0.0931[0m       0.3198      0.5758        [94m0.6612[0m     +  0.0000  10.4838
      7      0.9847        0.0947       [35m0.3274[0m      0.5741        [94m0.6562[0m     +  0.0000  10.3456
      8      0.9838        0.0939       0.3245      0.5747        [94m0.6534[0m     +  0.0000  10.4092
      9      [36m0.9855[0m        [32m0.0928[0m       [35m0.3429[0m      0.5795        [94m0.6490[0m     +  0.0000  10.3304
     10      0.9838        [32m0.0895[0m       0.3356      0.5783        [94m0.6459[0m     +  0.0000  10.4053
     11      0.9847        [32m0.0785[0m       0.3368      0.5788        0.6465        0.0000  10.4490
     12      0.9829        0.0819       0.3415      0.5766        [94m0.6447[0m     +  0.0000  10.2349
     13      0.9855        0.0809       [35m0.3470[0m      0.5719        0.6460        0.0000  10.3394
     14      0.9838        [32m0.0734[0m       [35m0.3491[0m      0.5729        0.6478        0.0000  10.2596
     15      0.9838        0.0795       [35m0.3540[0m      0.5697        0.6489        0.0000  10.2494
     16      0.9838        0.0756       [35m0.3561[0m      0.5692        0.6491        0.0000  10.2154
     17      0.9838        [32m0.0732[0m       [35m0.3597[0m      0.5666        0.6494        0.0000  10.2843
     18      0.9854        0.0743       [35m0.3642[0m      0.5645        0.6500        0.0000  10.2679
     19      0.9837        [32m0.0700[0m       [35m0.3679[0m      0.5640        0.6503        0.0000  10.2625
     20      0.9854        [32m0.0690[0m       [35m0.3714[0m      0.5652        0.6504        0.0000  10.2602
     21      0.9846        0.0775       [35m0.3724[0m      0.5653        0.6505        0.0000  10.2481
     22      0.9838        0.0707       [35m0.3734[0m      0.5655        0.6506        0.0000  10.2236
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.6187125358352881
F1 Macro Score after query 4: 0.5961694184937195
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9868[0m        [32m0.0912[0m       [35m0.3016[0m      [31m0.6374[0m        [94m1.0031[0m     +  0.0001  11.1267
      2      0.9833        0.0944       [35m0.3095[0m      0.5913        [94m0.6901[0m     +  0.0001  11.0931
      3      [36m0.9873[0m        [32m0.0759[0m       [35m0.3123[0m      0.5845        [94m0.6681[0m     +  0.0001  10.9519
      4      [36m0.9882[0m        [32m0.0706[0m       0.3063      0.5806        [94m0.6656[0m     +  0.0001  10.9639
      5      0.9867        0.0738       [35m0.3274[0m      0.5810        [94m0.6526[0m     +  0.0001  11.0731
      6      0.9877        [32m0.0601[0m       [35m0.3547[0m      0.5810        0.6558        0.0000  11.0996
      7      [36m0.9886[0m        [32m0.0580[0m       [35m0.3745[0m      0.5787        0.6616        0.0000  11.2414
      8      [36m0.9890[0m        [32m0.0553[0m       [35m0.3845[0m      0.5777        0.6604        0.0000  11.2651
      9      0.9890        0.0560       [35m0.3877[0m      0.5765        0.6644        0.0000  11.2057
     10      [36m0.9895[0m        0.0596       [35m0.4010[0m      0.5710        0.6687        0.0000  11.2058
     11      [36m0.9903[0m        [32m0.0467[0m       0.3974      0.5736        0.6666        0.0000  11.1976
     12      0.9894        [32m0.0462[0m       0.3990      0.5723        0.6671        0.0000  11.1238
     13      [36m0.9908[0m        0.0494       [35m0.4019[0m      0.5725        0.6674        0.0000  11.1265
     14      0.9894        0.0480       0.4003      0.5720        0.6676        0.0000  11.1634
     15      0.9907        0.0470       0.3892      0.5731        0.6672        0.0000  11.2002
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.6273633551048471
F1 Macro Score after query 5: 0.608996844489955
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9820[0m        [32m0.1054[0m       [35m0.2710[0m      [31m0.6063[0m        [94m1.0160[0m     +  0.0001  11.8001
      2      0.9803        [32m0.1018[0m       [35m0.3076[0m      [31m0.6299[0m        [94m0.7839[0m     +  0.0001  11.8619
      3      [36m0.9822[0m        [32m0.0955[0m       [35m0.3198[0m      [31m0.6348[0m        [94m0.7252[0m     +  0.0001  12.0078
      4      0.9814        [32m0.0879[0m       [35m0.3337[0m      [31m0.6399[0m        [94m0.7025[0m     +  0.0001  11.9502
      5      0.9818        0.0882       [35m0.3354[0m      0.6375        [94m0.6957[0m     +  0.0001  11.9197
      6      [36m0.9827[0m        [32m0.0768[0m       [35m0.3727[0m      [31m0.6421[0m        [94m0.6627[0m     +  0.0000  11.9179
      7      [36m0.9848[0m        [32m0.0734[0m       [35m0.4003[0m      [31m0.6422[0m        [94m0.6440[0m     +  0.0000  11.8283
      8      0.9840        [32m0.0712[0m       0.3986      [31m0.6443[0m        0.6477        0.0000  11.9576
      9      0.9840        0.0715       [35m0.4283[0m      0.6382        [94m0.6351[0m     +  0.0000  11.9533
     10      [36m0.9865[0m        [32m0.0664[0m       0.4142      0.6363        0.6357        0.0000  11.8962
     11      0.9862        [32m0.0631[0m       [35m0.4313[0m      0.6338        [94m0.6343[0m     +  0.0000  11.8859
     12      [36m0.9890[0m        [32m0.0599[0m       0.4281      0.6318        0.6375        0.0000  11.8163
     13      [36m0.9902[0m        [32m0.0597[0m       [35m0.4339[0m      0.6304        0.6357        0.0000  11.8590
     14      0.9880        0.0610       [35m0.4358[0m      0.6299        0.6347        0.0000  11.7249
     15      0.9889        0.0607       [35m0.4378[0m      0.6305        [94m0.6323[0m     +  0.0000  11.9389
     16      0.9885        [32m0.0566[0m       0.4372      0.6309        [94m0.6320[0m     +  0.0000  12.2234
     17      0.9882        0.0588       [35m0.4392[0m      0.6286        [94m0.6319[0m     +  0.0000  12.0627
     18      0.9894        [32m0.0541[0m       0.4366      0.6300        0.6323        0.0000  12.0639
     19      0.9882        0.0585       0.4344      0.6306        [94m0.6317[0m     +  0.0000  12.2339
     20      0.9887        0.0581       0.4356      0.6303        0.6317        0.0000  12.3266
     21      0.9892        0.0577       0.4345      0.6299        [94m0.6317[0m     +  0.0000  12.1962
     22      0.9890        0.0573       0.4345      0.6301        [94m0.6316[0m     +  0.0000  12.0847
     23      0.9889        0.0574       0.4332      0.6306        [94m0.6315[0m     +  0.0000  12.0669
     24      0.9897        0.0551       0.4335      0.6304        [94m0.6312[0m     +  0.0000  12.2996
     25      0.9897        0.0561       0.4326      0.6306        [94m0.6310[0m     +  0.0000  12.1586
     26      0.9892        0.0547       0.4342      0.6306        0.6311        0.0000  12.1410
     27      0.9897        0.0565       0.4344      0.6304        [94m0.6310[0m     +  0.0000  12.0294
     28      0.9892        0.0552       0.4351      0.6307        [94m0.6309[0m     +  0.0000  12.1850
     29      0.9894        [32m0.0538[0m       0.4339      0.6307        0.6309        0.0000  12.2810
     30      0.9897        0.0542       0.4345      0.6307        0.6310        0.0000  12.1601
     31      0.9879        0.0562       0.4347      0.6305        0.6310        0.0000  12.2037
     32      0.9897        0.0571       0.4345      0.6304        0.6310        0.0000  12.3750
     33      0.9889        0.0578       0.4345      0.6304        0.6310        0.0000  12.2190
     34      0.9897        0.0541       0.4347      0.6305        0.6310        0.0000  12.1577
     35      0.9897        0.0542       0.4345      0.6304        [94m0.6309[0m     +  0.0000  12.0028
     36      0.9892        0.0548       0.4345      0.6304        [94m0.6309[0m     +  0.0000  12.1559
     37      0.9892        0.0554       0.4349      0.6306        0.6309        0.0000  12.2032
     38      [36m0.9905[0m        [32m0.0537[0m       0.4349      0.6306        0.6309        0.0000  12.2190
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6718673016915749
F1 Macro Score after query 6: 0.6624323945129079
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9652[0m        [32m0.1286[0m       [35m0.3368[0m      [31m0.6568[0m        [94m0.8070[0m     +  0.0001  13.4078
      2      [36m0.9742[0m        [32m0.1068[0m       0.3227      0.6405        [94m0.7164[0m     +  0.0001  13.2514
      3      [36m0.9767[0m        [32m0.0960[0m       0.3309      0.6413        [94m0.6790[0m     +  0.0001  13.2855
      4      [36m0.9778[0m        [32m0.0920[0m       [35m0.3385[0m      0.6456        [94m0.6743[0m     +  0.0001  13.3701
      5      [36m0.9791[0m        [32m0.0834[0m       0.3236      0.6422        0.6878        0.0001  13.1075
      6      [36m0.9841[0m        [32m0.0730[0m       [35m0.3441[0m      0.6385        0.6760        0.0000  13.2814
      7      [36m0.9842[0m        [32m0.0715[0m       [35m0.3587[0m      0.6361        0.6779        0.0000  13.3758
      8      [36m0.9843[0m        [32m0.0708[0m       0.3512      0.6330        0.6856        0.0000  13.4715
      9      0.9835        [32m0.0706[0m       0.3516      0.6306        0.6888        0.0000  13.2263
     10      [36m0.9848[0m        [32m0.0680[0m       0.3531      0.6283        0.6972        0.0000  13.3743
     11      [36m0.9858[0m        [32m0.0630[0m       [35m0.3592[0m      0.6240        0.6927        0.0000  13.6513
     12      [36m0.9859[0m        [32m0.0625[0m       0.3535      0.6249        0.6989        0.0000  13.5480
     13      [36m0.9866[0m        [32m0.0620[0m       0.3550      0.6242        0.7025        0.0000  13.4412
     14      [36m0.9872[0m        [32m0.0616[0m       0.3543      0.6211        0.7036        0.0000  13.2529
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.6754938137616671
F1 Macro Score after query 7: 0.6666824209113992
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9842[0m        [32m0.0862[0m       [35m0.3467[0m      [31m0.6817[0m        [94m0.6918[0m     +  0.0001  15.2723
      2      [36m0.9852[0m        [32m0.0767[0m       [35m0.3602[0m      [31m0.6890[0m        [94m0.6542[0m     +  0.0001  15.3795
      3      [36m0.9858[0m        [32m0.0718[0m       0.3486      [31m0.6940[0m        [94m0.6291[0m     +  0.0001  15.3140
      4      [36m0.9858[0m        [32m0.0681[0m       0.3462      0.6876        0.6875        0.0001  15.1737
      5      [36m0.9866[0m        [32m0.0647[0m       0.3535      [31m0.6970[0m        0.6539        0.0001  15.6302
      6      [36m0.9891[0m        [32m0.0540[0m       [35m0.3609[0m      [31m0.7017[0m        0.6301        0.0000  15.4945
      7      [36m0.9896[0m        [32m0.0536[0m       0.3606      0.6999        [94m0.6261[0m     +  0.0000  15.4529
      8      0.9895        [32m0.0532[0m       [35m0.3688[0m      [31m0.7043[0m        [94m0.5915[0m     +  0.0000  15.6560
      9      [36m0.9901[0m        [32m0.0521[0m       0.3625      0.7002        0.6197        0.0000  15.3736
     10      [36m0.9901[0m        [32m0.0508[0m       0.3594      0.6950        0.6122        0.0000  15.4543
     11      [36m0.9906[0m        [32m0.0494[0m       0.3613      0.6901        0.5930        0.0000  15.3133
     12      [36m0.9906[0m        [32m0.0477[0m       0.3594      0.6900        [94m0.5900[0m     +  0.0000  15.4049
     13      [36m0.9913[0m        0.0481       0.3611      0.6935        0.5949        0.0000  15.2120
     14      0.9913        [32m0.0463[0m       0.3627      0.6913        [94m0.5882[0m     +  0.0000  15.4351
     15      0.9909        0.0474       0.3637      0.6894        [94m0.5847[0m     +  0.0000  15.1628
     16      0.9909        [32m0.0451[0m       0.3618      0.6862        0.5898        0.0000  15.5287
     17      0.9908        0.0463       0.3630      0.6876        0.5893        0.0000  15.5013
     18      0.9912        0.0467       0.3637      0.6896        0.5912        0.0000  15.2314
     19      0.9908        0.0456       0.3675      0.6898        [94m0.5829[0m     +  0.0000  15.4844
     20      [36m0.9917[0m        [32m0.0432[0m       0.3677      0.6898        0.5872        0.0000  15.4776
     21      0.9908        0.0452       0.3668      0.6903        0.5865        0.0000  15.3214
     22      [36m0.9918[0m        0.0436       0.3668      0.6902        0.5872        0.0000  15.3737
     23      0.9912        0.0446       0.3677      0.6908        0.5856        0.0000  15.4179
     24      0.9913        0.0437       0.3667      0.6890        0.5881        0.0000  15.4779
     25      0.9909        0.0451       0.3674      0.6895        0.5858        0.0000  15.3446
     26      0.9911        [32m0.0431[0m       0.3679      0.6901        0.5852        0.0000  15.6212
     27      0.9913        0.0438       0.3674      0.6898        0.5859        0.0000  15.4235
     28      0.9911        0.0437       0.3667      0.6890        0.5869        0.0000  15.5317
     29      0.9910        0.0451       0.3672      0.6890        0.5861        0.0000  15.2067
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.724874201006392
F1 Macro Score after query 8: 0.7317516368187892
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9825[0m        [32m0.0972[0m       [35m0.3464[0m      [31m0.7177[0m        [94m0.7416[0m     +  0.0001  19.0620
      2      [36m0.9848[0m        [32m0.0850[0m       [35m0.3523[0m      [31m0.7550[0m        [94m0.6623[0m     +  0.0001  18.8905
      3      [36m0.9857[0m        [32m0.0783[0m       [35m0.3595[0m      [31m0.7591[0m        [94m0.6327[0m     +  0.0001  18.7966
      4      [36m0.9864[0m        [32m0.0750[0m       [35m0.3811[0m      0.7575        [94m0.5730[0m     +  0.0001  18.9073
      5      0.9863        [32m0.0703[0m       [35m0.3870[0m      [31m0.7667[0m        0.6144        0.0001  19.0002
      6      [36m0.9878[0m        [32m0.0621[0m       0.3644      0.7488        [94m0.5648[0m     +  0.0000  19.0929
      7      [36m0.9884[0m        [32m0.0610[0m       0.3701      0.7481        0.5673        0.0000  18.8652
      8      [36m0.9885[0m        [32m0.0592[0m       [35m0.3905[0m      0.7482        [94m0.5395[0m     +  0.0000  18.8903
      9      [36m0.9890[0m        [32m0.0571[0m       [35m0.3991[0m      0.7525        0.5500        0.0000  19.0382
     10      [36m0.9890[0m        [32m0.0570[0m       [35m0.3995[0m      0.7515        0.5518        0.0000  19.0144
     11      [36m0.9893[0m        [32m0.0538[0m       [35m0.4075[0m      0.7541        [94m0.5285[0m     +  0.0000  19.0521
     12      [36m0.9896[0m        [32m0.0526[0m       0.4014      0.7525        0.5477        0.0000  18.8766
     13      [36m0.9900[0m        [32m0.0520[0m       0.4075      0.7553        0.5344        0.0000  19.1075
     14      0.9899        [32m0.0516[0m       [35m0.4085[0m      0.7541        [94m0.5264[0m     +  0.0000  18.6669
     15      [36m0.9905[0m        0.0519       [35m0.4092[0m      0.7546        [94m0.5249[0m     +  0.0000  19.2652
     16      0.9902        [32m0.0492[0m       [35m0.4120[0m      0.7557        [94m0.5187[0m     +  0.0000  19.1879
     17      0.9902        0.0506       0.4071      0.7524        0.5200        0.0000  19.0312
     18      0.9898        [32m0.0492[0m       0.4054      0.7528        0.5271        0.0000  18.9920
     19      [36m0.9905[0m        0.0499       0.4068      0.7520        [94m0.5156[0m     +  0.0000  18.9723
     20      0.9904        0.0502       0.4095      0.7530        [94m0.5122[0m     +  0.0000  19.2945
     21      [36m0.9909[0m        [32m0.0489[0m       0.4087      0.7520        [94m0.5084[0m     +  0.0000  18.9266
     22      0.9905        [32m0.0488[0m       0.4090      0.7522        0.5095        0.0000  18.9578
     23      0.9903        [32m0.0488[0m       0.4083      0.7523        0.5093        0.0000  18.8951
     24      0.9900        0.0488       0.4095      0.7516        [94m0.5047[0m     +  0.0000  19.0311
     25      0.9901        [32m0.0486[0m       0.4076      0.7507        0.5096        0.0000  18.9222
     26      0.9906        [32m0.0483[0m       0.4057      0.7485        0.5094        0.0000  19.1751
     27      0.9904        0.0489       0.4052      0.7481        0.5082        0.0000  18.9053
     28      0.9906        [32m0.0481[0m       0.4061      0.7484        0.5072        0.0000  18.8250
     29      [36m0.9913[0m        0.0483       0.4075      0.7487        0.5053        0.0000  18.9374
     30      0.9908        0.0483       0.4061      0.7472        0.5066        0.0000  18.8742
     31      0.9904        0.0488       0.4066      0.7469        [94m0.5047[0m     +  0.0000  19.1296
     32      0.9906        [32m0.0478[0m       0.4066      0.7470        [94m0.5046[0m     +  0.0000  18.8123
     33      0.9902        0.0486       0.4066      0.7470        0.5048        0.0000  18.8687
     34      0.9905        [32m0.0474[0m       0.4064      0.7471        [94m0.5044[0m     +  0.0000  19.1107
     35      0.9903        0.0486       0.4068      0.7471        [94m0.5043[0m     +  0.0000  19.2888
     36      0.9908        0.0483       0.4068      0.7468        [94m0.5038[0m     +  0.0000  18.8542
     37      0.9906        0.0482       0.4066      0.7467        [94m0.5038[0m     +  0.0000  19.1020
     38      0.9905        0.0479       0.4066      0.7468        [94m0.5035[0m     +  0.0000  18.6760
     39      0.9904        0.0490       0.4064      0.7467        [94m0.5034[0m     +  0.0000  19.0603
     40      0.9901        [32m0.0473[0m       0.4066      0.7468        0.5034        0.0000  19.1710
     41      0.9908        0.0475       0.4064      0.7467        [94m0.5033[0m     +  0.0000  19.0157
     42      0.9906        0.0474       0.4066      0.7467        [94m0.5032[0m     +  0.0000  19.0665
     43      0.9909        0.0482       0.4068      0.7468        [94m0.5031[0m     +  0.0000  19.0975
     44      0.9908        0.0482       0.4068      0.7467        [94m0.5029[0m     +  0.0000  18.8340
     45      0.9908        0.0484       0.4069      0.7468        [94m0.5028[0m     +  0.0000  19.0460
     46      0.9905        0.0480       0.4069      0.7468        [94m0.5028[0m     +  0.0000  19.1630
     47      0.9906        0.0478       0.4068      0.7467        [94m0.5027[0m     +  0.0000  18.9405
     48      0.9901        0.0480       0.4068      0.7467        [94m0.5026[0m     +  0.0000  18.9368
     49      0.9904        0.0483       0.4068      0.7467        [94m0.5026[0m     +  0.0000  19.0314
     50      0.9903        0.0489       0.4068      0.7467        [94m0.5026[0m     +  0.0000  18.8388
     51      0.9905        0.0488       0.4069      0.7467        0.5026        0.0000  18.8773
     52      0.9903        0.0489       0.4071      0.7468        [94m0.5026[0m     +  0.0000  18.9367
     53      0.9905        0.0479       0.4071      0.7468        [94m0.5026[0m     +  0.0000  18.9681
     54      0.9906        0.0480       0.4071      0.7468        [94m0.5026[0m     +  0.0000  19.1042
     55      0.9899        0.0483       0.4071      0.7468        [94m0.5026[0m     +  0.0000  19.0089
     56      0.9909        0.0488       0.4071      0.7468        [94m0.5026[0m     +  0.0000  18.7814
     57      0.9905        0.0483       0.4071      0.7469        [94m0.5025[0m     +  0.0000  19.0135
     58      0.9906        0.0475       0.4071      0.7469        [94m0.5025[0m     +  0.0000  19.1089
     59      0.9907        0.0484       0.4071      0.7469        [94m0.5025[0m     +  0.0000  18.8153
     60      0.9904        0.0487       0.4071      0.7469        [94m0.5025[0m     +  0.0000  19.2045
     61      0.9903        0.0488       0.4071      0.7469        [94m0.5025[0m     +  0.0000  18.8568
     62      0.9903        0.0496       0.4071      0.7469        [94m0.5025[0m     +  0.0000  19.0003
     63      0.9904        0.0479       0.4071      0.7469        [94m0.5025[0m     +  0.0000  19.0211
     64      0.9903        0.0483       0.4069      0.7467        [94m0.5025[0m     +  0.0000  19.0629
     65      0.9904        0.0474       0.4069      0.7467        [94m0.5025[0m     +  0.0000  19.0990
     66      0.9908        0.0479       0.4069      0.7467        [94m0.5025[0m     +  0.0000  18.8907
     67      0.9903        0.0476       0.4069      0.7467        [94m0.5025[0m     +  0.0000  18.9803
     68      0.9907        [32m0.0472[0m       0.4069      0.7467        [94m0.5025[0m     +  0.0000  19.1240
     69      0.9905        0.0484       0.4069      0.7467        [94m0.5025[0m     +  0.0000  18.6925
     70      0.9907        0.0479       0.4069      0.7467        [94m0.5025[0m     +  0.0000  18.9999
     71      0.9902        0.0476       0.4069      0.7467        [94m0.5025[0m     +  0.0000  19.0142
     72      0.9906        0.0492       0.4069      0.7467        [94m0.5025[0m     +  0.0000  19.2187
     73      0.9900        0.0487       0.4069      0.7467        [94m0.5025[0m     +  0.0000  18.9398
     74      0.9905        0.0478       0.4069      0.7467        [94m0.5025[0m     +  0.0000  19.1067
     75      0.9905        0.0487       0.4069      0.7467        [94m0.5025[0m     +  0.0000  19.0826
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.768724279835391
F1 Macro Score after query 9: 0.7880668316797707
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9667[0m        [32m0.1280[0m       [35m0.4420[0m      [31m0.7692[0m        [94m0.4372[0m     +  0.0001  25.5558
      2      [36m0.9708[0m        [32m0.1097[0m       [35m0.4913[0m      [31m0.7725[0m        [94m0.4128[0m     +  0.0001  25.5030
      3      [36m0.9740[0m        [32m0.0998[0m       0.4696      0.7707        0.4760        0.0001  25.2958
      4      [36m0.9757[0m        [32m0.0942[0m       [35m0.5026[0m      [31m0.7831[0m        0.4636        0.0001  25.4769
      5      [36m0.9775[0m        [32m0.0902[0m       0.4958      [31m0.7840[0m        0.4753        0.0001  25.4484
      6      [36m0.9802[0m        [32m0.0786[0m       0.5012      [31m0.7851[0m        0.4646        0.0000  25.5682
      7      [36m0.9810[0m        [32m0.0758[0m       0.4859      0.7793        0.4972        0.0000  25.7030
      8      0.9809        [32m0.0742[0m       0.4861      0.7801        0.4910        0.0000  25.6732
      9      [36m0.9816[0m        [32m0.0738[0m       0.4698      0.7805        0.5088        0.0000  25.7297
     10      0.9812        [32m0.0722[0m       0.4535      0.7813        0.5439        0.0000  25.5168
     11      [36m0.9826[0m        [32m0.0686[0m       0.4431      0.7748        0.5500        0.0000  25.7680
     12      [36m0.9834[0m        [32m0.0674[0m       0.4443      0.7727        0.5436        0.0000  25.7155
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.7891491985203453
F1 Macro Score after query 10: 0.8097069680620136
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9477[0m        [32m0.1494[0m       [35m0.7085[0m      [31m0.8207[0m        [94m0.2606[0m     +  0.0001  37.1599
      2      [36m0.9562[0m        [32m0.1255[0m       [35m0.7175[0m      [31m0.8323[0m        0.2725        0.0001  37.1431
      3      [36m0.9606[0m        [32m0.1154[0m       0.7113      0.8257        0.2844        0.0001  37.2359
      4      [36m0.9627[0m        [32m0.1077[0m       0.7167      0.8303        0.2792        0.0001  37.2361
      5      [36m0.9649[0m        [32m0.1031[0m       [35m0.7201[0m      0.8288        0.2798        0.0001  37.3582
      6      [36m0.9699[0m        [32m0.0908[0m       [35m0.7222[0m      [31m0.8342[0m        0.3006        0.0000  37.4389
      7      [36m0.9709[0m        [32m0.0871[0m       [35m0.7276[0m      [31m0.8373[0m        0.2994        0.0000  37.4713
      8      [36m0.9713[0m        [32m0.0861[0m       [35m0.7299[0m      [31m0.8378[0m        0.2881        0.0000  37.2973
      9      [36m0.9719[0m        [32m0.0834[0m       [35m0.7363[0m      [31m0.8425[0m        0.2979        0.0000  37.3332
     10      [36m0.9720[0m        [32m0.0823[0m       0.7326      0.8386        0.2961        0.0000  37.1217
     11      [36m0.9740[0m        [32m0.0781[0m       [35m0.7370[0m      [31m0.8480[0m        0.3003        0.0000  36.6407
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8921699520929867
F1 Macro Score after query 11: 0.8788862709726116
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9366[0m        [32m0.1281[0m       [35m0.7222[0m      [31m0.7955[0m        [94m0.2515[0m     +  0.0001  58.4975
      2      [36m0.9434[0m        [32m0.1105[0m       [35m0.7509[0m      [31m0.8392[0m        [94m0.2376[0m     +  0.0001  58.6406
      3      [36m0.9485[0m        [32m0.0994[0m       0.7490      [31m0.8503[0m        0.2446        0.0001  58.6248
      4      [36m0.9515[0m        [32m0.0928[0m       0.7476      0.8435        0.2472        0.0001  58.1250
      5      [36m0.9535[0m        [32m0.0884[0m       0.7384      0.8367        0.2494        0.0001  59.1832
      6      [36m0.9601[0m        [32m0.0762[0m       [35m0.7519[0m      0.8436        0.2746        0.0000  58.6743
      7      [36m0.9619[0m        [32m0.0735[0m       0.7516      0.8454        0.2892        0.0000  58.9361
      8      [36m0.9626[0m        [32m0.0718[0m       [35m0.7557[0m      0.8441        0.2466        0.0000  58.9753
      9      0.9623        [32m0.0704[0m       0.7490      0.8433        0.2794        0.0000  58.9534
     10      [36m0.9639[0m        [32m0.0685[0m       [35m0.7568[0m      [31m0.8522[0m        0.2806        0.0000  58.7343
     11      [36m0.9661[0m        [32m0.0642[0m       [35m0.7620[0m      0.8510        0.2883        0.0000  59.1117
     12      [36m0.9669[0m        [32m0.0630[0m       [35m0.7625[0m      [31m0.8531[0m        0.2857        0.0000  58.0726
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8922100046461205
F1 Macro Score after query 12: 0.8785770127417624
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9374[0m        [32m0.1093[0m       [35m0.7766[0m      [31m0.8582[0m        [94m0.2325[0m     +  0.0001  67.6234
      2      [36m0.9435[0m        [32m0.0976[0m       0.7703      [31m0.8594[0m        0.2654        0.0001  67.4537
      3      [36m0.9473[0m        [32m0.0900[0m       0.7366      0.8429        0.3218        0.0001  67.5248
      4      [36m0.9497[0m        [32m0.0850[0m       0.7484      0.8465        0.2973        0.0001  67.2301
      5      [36m0.9526[0m        [32m0.0810[0m       0.7606      0.8539        0.2854        0.0001  67.1534
      6      [36m0.9598[0m        [32m0.0687[0m       0.7668      [31m0.8619[0m        0.3052        0.0000  67.3303
      7      [36m0.9615[0m        [32m0.0670[0m       0.7599      0.8586        0.3228        0.0000  66.7609
      8      [36m0.9623[0m        [32m0.0647[0m       0.7486      0.8527        0.3486        0.0000  67.1635
      9      [36m0.9630[0m        [32m0.0637[0m       0.7538      0.8532        0.3477        0.0000  67.1746
     10      [36m0.9635[0m        [32m0.0626[0m       0.7623      0.8533        0.2994        0.0000  66.5749
     11      [36m0.9665[0m        [32m0.0591[0m       0.7583      0.8519        0.3269        0.0000  67.2221
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8986434994665448
F1 Macro Score after query 13: 0.8843537314432982
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_config2\AL_average_score_results_for_multilabel_classification.pickle
