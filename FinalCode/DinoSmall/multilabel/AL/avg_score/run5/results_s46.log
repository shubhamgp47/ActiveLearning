Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5556[0m        [32m0.6869[0m       [35m0.1859[0m      [31m0.5403[0m        [94m0.6979[0m     +  0.0000  24.4845
      2      [36m0.6833[0m        [32m0.6858[0m       0.1476      0.4470        [94m0.6882[0m     +  0.0000  23.1404
      3      0.6722        [32m0.6446[0m       [35m0.1981[0m      0.4584        0.6915        0.0000  23.1383
      4      [36m0.8350[0m        [32m0.6036[0m       [35m0.2899[0m      0.4102        [94m0.6826[0m     +  0.0000  23.2801
      5      0.7222        0.6210       0.2344      0.4254        0.6899        0.0000  23.3542
      6      0.8350        [32m0.5965[0m       0.2651      0.4395        0.6858        0.0000  23.4385
      7      0.8148        [32m0.5547[0m       0.2773      0.4432        0.6834        0.0000  23.4944
      8      0.7593        [32m0.5228[0m       0.2642      0.4369        0.6838        0.0000  22.4395
      9      [36m0.9630[0m        0.5230       0.2616      0.4589        0.6835        0.0000  19.2324
     10      0.9259        [32m0.4998[0m       0.2655      0.4598        [94m0.6817[0m     +  0.0000  21.9473
     11      0.8426        0.5413       0.2724      0.4593        [94m0.6814[0m     +  0.0000  14.0306
     12      0.9153        0.5251       0.2658      0.4609        0.6814        0.0000  10.9602
     13      0.9153        0.5339       0.2634      0.4553        0.6827        0.0000  10.9281
     14      0.9259        0.5187       0.2644      0.4610        0.6825        0.0000  10.7680
     15      0.9630        [32m0.4953[0m       0.2726      0.4624        0.6815        0.0000  11.0300
     16      0.9333        [32m0.4932[0m       0.2736      0.4620        [94m0.6811[0m     +  0.0000  11.0750
     17      0.9630        [32m0.4929[0m       0.2734      0.4633        0.6813        0.0000  11.0627
     18      0.8487        0.5119       0.2719      0.4635        0.6816        0.0000  10.9392
     19      0.9630        0.4939       0.2708      0.4634        0.6817        0.0000  10.5940
     20      0.9630        [32m0.4892[0m       0.2694      0.4647        0.6819        0.0000  10.5187
     21      0.9167        0.5014       0.2681      0.4648        0.6820        0.0000  10.8618
     22      0.9630        [32m0.4857[0m       0.2677      0.4650        0.6819        0.0000  10.8595
     23      0.9259        0.4931       0.2681      0.4656        0.6819        0.0000  10.7641
     24      0.9630        0.5094       0.2682      0.4662        0.6819        0.0000  11.1092
     25      0.9630        0.4895       0.2684      0.4665        0.6819        0.0000  10.7622
     26      0.9259        [32m0.4809[0m       0.2684      0.4665        0.6819        0.0000  11.0358
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.5200
Pre F1 macro score = 0.5085
Pre Accuracy = 0.3510

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9412[0m        [32m0.4631[0m       [35m0.2026[0m      [31m0.5580[0m        [94m0.7384[0m     +  0.0000  11.1878
      2      0.8975        [32m0.4435[0m       0.1885      0.4916        [94m0.7339[0m     +  0.0000  11.2024
      3      0.9130        [32m0.4157[0m       [35m0.2285[0m      0.5295        0.7402        0.0000  11.0250
      4      0.9093        [32m0.3956[0m       0.2095      0.5123        [94m0.7326[0m     +  0.0000  10.8147
      5      0.9294        [32m0.3788[0m       0.2017      0.5217        [94m0.7325[0m     +  0.0000  11.2513
      6      0.9332        [32m0.3565[0m       0.1931      0.5096        [94m0.7173[0m     +  0.0000  10.6724
      7      0.9212        0.3656       0.2118      0.5253        [94m0.7170[0m     +  0.0000  10.9274
      8      0.9164        [32m0.3472[0m       0.1988      0.5142        [94m0.7079[0m     +  0.0000  10.9989
      9      0.9212        0.3680       0.2057      0.5221        [94m0.7063[0m     +  0.0000  11.2740
     10      0.9212        [32m0.3419[0m       0.1964      0.5210        [94m0.7051[0m     +  0.0000  11.0801
     11      0.9212        0.3446       0.2021      0.5217        [94m0.7047[0m     +  0.0000  10.6351
     12      [36m0.9596[0m        [32m0.3234[0m       0.2030      0.5243        0.7051        0.0000  11.2490
     13      0.9502        0.3257       0.2043      0.5225        [94m0.7041[0m     +  0.0000  11.1028
     14      0.9300        0.3307       0.2069      0.5226        [94m0.7032[0m     +  0.0000  10.7849
     15      0.9300        0.3385       0.2092      0.5230        [94m0.7025[0m     +  0.0000  11.2072
     16      0.9515        0.3251       0.2092      0.5222        [94m0.7021[0m     +  0.0000  10.7829
     17      0.9515        [32m0.3045[0m       0.2089      0.5220        [94m0.7017[0m     +  0.0000  10.6461
     18      0.9515        0.3221       0.2101      0.5223        [94m0.7007[0m     +  0.0000  11.0938
     19      0.9421        0.3196       0.2104      0.5247        0.7013        0.0000  10.5466
     20      0.9135        0.3359       0.2095      0.5253        0.7008        0.0000  10.8935
     21      [36m0.9696[0m        0.3060       0.2097      0.5251        0.7009        0.0000  11.0729
     22      0.9214        0.3328       0.2090      0.5246        [94m0.7007[0m     +  0.0000  10.9232
     23      0.9414        0.3185       0.2089      0.5244        [94m0.7006[0m     +  0.0000  11.0269
     24      0.9493        0.3137       0.2092      0.5249        0.7008        0.0000  11.1852
     25      0.9615        0.3180       0.2101      0.5258        0.7010        0.0000  10.9064
     26      0.9212        0.3339       0.2101      0.5258        0.7010        0.0000  10.5935
     27      0.9615        0.3069       0.2097      0.5256        0.7010        0.0000  10.8468
     28      0.9493        0.3276       0.2101      0.5258        0.7011        0.0000  11.1548
     29      0.9393        0.3307       0.2095      0.5254        0.7010        0.0000  11.0183
     30      0.9596        0.3190       0.2097      0.5255        0.7008        0.0000  11.2248
     31      0.9421        0.3334       0.2097      0.5253        0.7008        0.0000  11.0742
     32      0.9515        0.3206       0.2097      0.5253        0.7008        0.0000  11.1728
     33      0.9212        0.3277       0.2095      0.5252        0.7007        0.0000  10.6377
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.5374950922654104
F1 Macro Score after query 1: 0.5252202797082658
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9761[0m        [32m0.2982[0m       [35m0.2288[0m      [31m0.5528[0m        [94m0.7982[0m     +  0.0000  11.2449
      2      0.9583        [32m0.2676[0m       0.1800      0.5210        [94m0.7700[0m     +  0.0000  11.2398
      3      0.9730        [32m0.2479[0m       0.2010      0.5295        [94m0.7447[0m     +  0.0000  10.8297
      4      0.9758        [32m0.2287[0m       0.2222      0.5377        [94m0.7243[0m     +  0.0000  10.8088
      5      [36m0.9861[0m        0.2300       0.2234      0.5340        [94m0.7207[0m     +  0.0000  11.1654
      6      0.9858        [32m0.2063[0m       0.2253      0.5407        [94m0.7075[0m     +  0.0000  11.1094
      7      0.9760        0.2064       0.2280      0.5415        [94m0.6979[0m     +  0.0000  11.1718
      8      0.9858        [32m0.2049[0m       0.2257      0.5361        [94m0.6939[0m     +  0.0000  11.0650
      9      0.9858        [32m0.1979[0m       0.2255      0.5294        [94m0.6909[0m     +  0.0000  11.2194
     10      [36m0.9928[0m        [32m0.1950[0m       0.2222      0.5244        [94m0.6846[0m     +  0.0000  11.1563
     11      0.9926        [32m0.1833[0m       0.2241      0.5246        [94m0.6836[0m     +  0.0000  10.8441
     12      0.9892        0.1888       0.2248      0.5228        [94m0.6820[0m     +  0.0000  11.1404
     13      [36m0.9963[0m        0.1879       0.2266      0.5225        [94m0.6814[0m     +  0.0000  10.9195
     14      0.9896        0.1899       0.2240      0.5213        [94m0.6809[0m     +  0.0000  11.0309
     15      0.9892        0.1849       0.2264      0.5228        0.6814        0.0000  11.0749
     16      0.9928        0.1963       0.2274      0.5236        [94m0.6807[0m     +  0.0000  11.1253
     17      0.9896        [32m0.1799[0m       0.2276      0.5202        [94m0.6800[0m     +  0.0000  11.2039
     18      0.9928        0.1889       0.2271      0.5189        0.6804        0.0000  11.0141
     19      0.9932        0.1966       0.2283      0.5192        [94m0.6800[0m     +  0.0000  10.9670
     20      0.9963        0.1925       0.2262      0.5178        0.6802        0.0000  11.0456
     21      0.9892        0.1918       0.2267      0.5178        [94m0.6798[0m     +  0.0000  11.1096
     22      0.9963        0.1944       0.2269      0.5178        [94m0.6796[0m     +  0.0000  11.2030
     23      0.9932        0.1856       0.2269      0.5181        [94m0.6795[0m     +  0.0000  10.9588
     24      0.9896        [32m0.1784[0m       0.2273      0.5183        0.6796        0.0000  11.2488
     25      0.9963        0.1850       0.2273      0.5185        [94m0.6795[0m     +  0.0000  11.2831
     26      0.9932        0.1975       0.2271      0.5185        [94m0.6795[0m     +  0.0000  10.9147
     27      0.9932        0.1930       0.2271      0.5182        0.6796        0.0000  10.9062
     28      0.9928        0.1895       0.2273      0.5183        [94m0.6795[0m     +  0.0000  11.2990
     29      0.9932        0.1919       0.2271      0.5183        [94m0.6794[0m     +  0.0000  11.0515
     30      0.9928        0.2008       0.2274      0.5184        [94m0.6792[0m     +  0.0000  11.2502
     31      0.9928        0.1929       0.2274      0.5184        0.6792        0.0000  11.2669
     32      0.9963        0.1813       0.2274      0.5184        0.6793        0.0000  11.1518
     33      0.9963        [32m0.1749[0m       0.2273      0.5185        0.6793        0.0000  11.0556
     34      0.9896        0.1926       0.2273      0.5185        0.6792        0.0000  11.2654
     35      0.9963        0.1774       0.2273      0.5185        0.6793        0.0000  11.0157
     36      0.9963        0.1856       0.2273      0.5185        0.6793        0.0000  10.8284
     37      0.9963        0.1898       0.2273      0.5185        0.6793        0.0000  10.9098
     38      0.9963        0.1811       0.2273      0.5185        0.6792        0.0000  11.1420
     39      0.9963        0.1798       0.2274      0.5185        [94m0.6792[0m     +  0.0000  11.3559
     40      0.9963        0.1847       0.2274      0.5185        [94m0.6792[0m     +  0.0000  11.1241
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.542239169022418
F1 Macro Score after query 2: 0.5275649951811309
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9868[0m        [32m0.1893[0m       [35m0.2417[0m      [31m0.5536[0m        [94m0.7959[0m     +  0.0000  11.4594
      2      [36m0.9888[0m        [32m0.1692[0m       0.2095      0.5018        [94m0.7459[0m     +  0.0000  11.4489
      3      [36m0.9919[0m        [32m0.1586[0m       0.2257      0.5214        [94m0.7281[0m     +  0.0000  11.5462
      4      0.9919        [32m0.1561[0m       0.2170      0.5190        [94m0.7169[0m     +  0.0000  11.6717
      5      0.9919        0.1639       0.2286      0.5239        [94m0.7111[0m     +  0.0000  11.3634
      6      [36m0.9951[0m        [32m0.1491[0m       0.2215      0.5200        [94m0.7004[0m     +  0.0000  11.2207
      7      [36m0.9967[0m        [32m0.1473[0m       0.2174      0.5126        [94m0.6948[0m     +  0.0000  11.1247
      8      0.9967        [32m0.1406[0m       0.2207      0.5132        [94m0.6923[0m     +  0.0000  11.5824
      9      0.9952        0.1464       0.2217      0.5170        [94m0.6923[0m     +  0.0000  11.1979
     10      0.9952        0.1428       0.2220      0.5211        [94m0.6887[0m     +  0.0000  11.2030
     11      0.9952        [32m0.1343[0m       0.2205      0.5198        0.6892        0.0000  11.4814
     12      0.9952        0.1406       0.2224      0.5179        [94m0.6885[0m     +  0.0000  11.6561
     13      0.9967        0.1404       0.2243      0.5186        [94m0.6873[0m     +  0.0000  11.3800
     14      0.9967        0.1382       0.2222      0.5216        0.6886        0.0000  11.1342
     15      0.9967        0.1493       0.2233      0.5184        0.6879        0.0000  11.7501
     16      0.9967        0.1419       0.2250      0.5187        0.6875        0.0000  11.6837
     17      0.9967        0.1355       0.2238      0.5189        0.6877        0.0000  11.5449
     18      0.9952        0.1394       0.2240      0.5189        0.6882        0.0000  11.4172
     19      0.9967        0.1409       0.2253      0.5196        0.6879        0.0000  11.4288
     20      0.9967        0.1422       0.2234      0.5192        0.6878        0.0000  11.6562
     21      0.9967        0.1372       0.2234      0.5195        0.6881        0.0000  11.3096
     22      0.9967        0.1428       0.2231      0.5192        0.6880        0.0000  11.3138
     23      0.9952        0.1467       0.2234      0.5191        0.6878        0.0000  11.6832
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.5448996818388416
F1 Macro Score after query 3: 0.5295661324301674
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9788[0m        [32m0.1853[0m       [35m0.1951[0m      [31m0.5807[0m        [94m0.7508[0m     +  0.0000  11.6776
      2      [36m0.9860[0m        [32m0.1643[0m       [35m0.2101[0m      0.5330        [94m0.7040[0m     +  0.0000  11.2708
      3      0.9850        [32m0.1594[0m       [35m0.2293[0m      0.5382        [94m0.6927[0m     +  0.0000  11.7236
      4      0.9849        [32m0.1520[0m       0.2168      0.5092        [94m0.6810[0m     +  0.0000  11.3643
      5      [36m0.9911[0m        [32m0.1497[0m       0.2127      0.4958        [94m0.6775[0m     +  0.0000  12.1034
      6      0.9910        [32m0.1496[0m       0.2155      0.5242        0.6900        0.0000  11.8199
      7      0.9893        [32m0.1446[0m       0.2226      0.5241        0.6835        0.0000  11.7728
      8      [36m0.9911[0m        [32m0.1391[0m       0.2220      0.5249        0.6799        0.0000  11.8815
      9      0.9902        [32m0.1387[0m       0.2234      0.5285        0.6849        0.0000  11.4769
     10      0.9902        0.1405       0.2241      0.5266        0.6810        0.0000  12.0376
     11      0.9902        0.1393       0.2273      0.5330        0.6878        0.0000  11.7849
     12      [36m0.9919[0m        0.1392       [35m0.2306[0m      0.5352        0.6876        0.0000  11.4579
     13      0.9902        [32m0.1381[0m       0.2278      0.5321        0.6865        0.0000  12.0203
     14      0.9919        [32m0.1314[0m       0.2274      0.5321        0.6870        0.0000  11.6373
     15      [36m0.9928[0m        0.1341       0.2267      0.5316        0.6837        0.0000  12.3956
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.54956498813604
F1 Macro Score after query 4: 0.5349320514282597
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9856[0m        [32m0.1507[0m       [35m0.2852[0m      [31m0.6189[0m        [94m0.7734[0m     +  0.0000  12.1761
      2      [36m0.9893[0m        [32m0.1403[0m       0.2481      0.6017        [94m0.7426[0m     +  0.0000  12.5973
      3      0.9892        0.1419       0.2486      0.6000        [94m0.7283[0m     +  0.0000  12.7601
      4      [36m0.9902[0m        [32m0.1333[0m       0.2524      0.6017        [94m0.7275[0m     +  0.0000  12.5999
      5      0.9888        0.1346       0.2455      0.5969        0.7288        0.0000  12.3181
      6      0.9892        [32m0.1270[0m       0.2490      0.5834        [94m0.7145[0m     +  0.0000  12.0507
      7      [36m0.9902[0m        0.1282       0.2497      0.5863        [94m0.7131[0m     +  0.0000  12.4890
      8      0.9897        0.1305       0.2517      0.5817        [94m0.7064[0m     +  0.0000  12.5204
      9      0.9883        0.1292       0.2521      0.5854        0.7087        0.0000  12.2083
     10      0.9897        [32m0.1265[0m       0.2502      0.5838        [94m0.7053[0m     +  0.0000  12.2723
     11      0.9878        [32m0.1259[0m       0.2495      0.5797        0.7064        0.0000  12.6770
     12      [36m0.9906[0m        [32m0.1233[0m       0.2519      0.5815        0.7092        0.0000  12.4443
     13      [36m0.9911[0m        [32m0.1213[0m       0.2524      0.5806        0.7078        0.0000  12.1343
     14      0.9902        0.1261       0.2521      0.5801        0.7066        0.0000  12.6094
     15      0.9887        0.1238       0.2526      0.5819        0.7064        0.0000  12.1923
     16      0.9902        0.1230       0.2523      0.5805        0.7060        0.0000  13.0833
     17      0.9897        0.1276       0.2507      0.5788        0.7057        0.0000  12.1615
     18      0.9897        0.1235       0.2521      0.5809        0.7063        0.0000  12.0209
     19      0.9906        0.1234       0.2528      0.5809        0.7066        0.0000  12.4754
     20      0.9906        0.1214       0.2543      0.5817        0.7069        0.0000  12.5227
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.5745005725919329
F1 Macro Score after query 5: 0.5679013843403252
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9833[0m        [32m0.1503[0m       [35m0.3212[0m      [31m0.6504[0m        [94m0.7292[0m     +  0.0000  13.4429
      2      [36m0.9862[0m        [32m0.1387[0m       0.2939      0.6265        [94m0.6931[0m     +  0.0000  13.4448
      3      [36m0.9872[0m        [32m0.1309[0m       [35m0.3316[0m      [31m0.6547[0m        0.6938        0.0000  13.5101
      4      0.9871        [32m0.1266[0m       [35m0.3417[0m      [31m0.6562[0m        [94m0.6776[0m     +  0.0000  13.5839
      5      0.9872        [32m0.1236[0m       [35m0.3509[0m      0.6551        [94m0.6587[0m     +  0.0000  13.7084
      6      [36m0.9880[0m        [32m0.1169[0m       0.3130      0.6229        [94m0.6335[0m     +  0.0000  13.9899
      7      [36m0.9882[0m        0.1187       0.3094      0.6188        [94m0.6319[0m     +  0.0000  13.5209
      8      0.9879        [32m0.1167[0m       0.3122      0.6236        0.6374        0.0000  13.6056
      9      [36m0.9892[0m        [32m0.1158[0m       0.3120      0.6234        0.6346        0.0000  13.1934
     10      [36m0.9896[0m        [32m0.1135[0m       0.3139      0.6261        0.6401        0.0000  13.6146
     11      [36m0.9905[0m        [32m0.1108[0m       0.2910      0.6056        0.6341        0.0000  13.4284
     12      0.9890        0.1126       0.2884      0.6025        0.6354        0.0000  14.0829
     13      0.9889        0.1114       0.2894      0.6039        0.6355        0.0000  14.1163
     14      [36m0.9905[0m        0.1133       0.2908      0.6057        0.6363        0.0000  13.8023
     15      0.9904        [32m0.1107[0m       0.2885      0.6044        0.6350        0.0000  13.4107
     16      [36m0.9920[0m        [32m0.1094[0m       0.2816      0.5985        0.6343        0.0000  13.5207
     17      0.9907        0.1098       0.2804      0.5969        0.6348        0.0000  14.0211
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6173193052356346
F1 Macro Score after query 6: 0.6201600503346548
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9817[0m        [32m0.1398[0m       [35m0.2908[0m      [31m0.6265[0m        [94m0.6494[0m     +  0.0000  15.4435
      2      [36m0.9883[0m        [32m0.1157[0m       [35m0.3335[0m      [31m0.6528[0m        [94m0.6327[0m     +  0.0000  15.8020
      3      [36m0.9896[0m        [32m0.1097[0m       [35m0.3403[0m      [31m0.6616[0m        0.6395        0.0000  15.8034
      4      [36m0.9905[0m        [32m0.1041[0m       0.3358      0.6567        0.6413        0.0000  15.8668
      5      0.9905        [32m0.1009[0m       0.3276      0.6526        0.6503        0.0000  16.1653
      6      [36m0.9924[0m        [32m0.0976[0m       0.3238      0.6453        0.6519        0.0000  15.7144
      7      0.9918        [32m0.0962[0m       0.3280      0.6464        0.6526        0.0000  15.8661
      8      0.9921        [32m0.0933[0m       0.3259      0.6435        0.6518        0.0000  16.0703
      9      0.9922        [32m0.0915[0m       0.3285      0.6471        0.6544        0.0000  16.5221
     10      [36m0.9927[0m        [32m0.0890[0m       0.3269      0.6456        0.6555        0.0000  16.3364
     11      [36m0.9930[0m        [32m0.0874[0m       0.3193      0.6364        0.6556        0.0000  15.8661
     12      [36m0.9933[0m        [32m0.0866[0m       0.3200      0.6369        0.6560        0.0000  15.8474
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.6361202385298771
F1 Macro Score after query 7: 0.6445313812502289
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9826[0m        [32m0.1336[0m       [35m0.3649[0m      [31m0.6805[0m        [94m0.6375[0m     +  0.0000  19.4612
      2      [36m0.9866[0m        [32m0.1146[0m       0.3549      0.6805        0.6457        0.0000  19.0117
      3      [36m0.9875[0m        [32m0.1062[0m       0.3620      [31m0.6854[0m        0.6475        0.0000  19.3388
      4      [36m0.9884[0m        [32m0.1018[0m       0.3578      0.6816        0.6471        0.0000  19.3213
      5      [36m0.9893[0m        [32m0.0935[0m       0.3500      0.6752        0.6659        0.0000  20.1030
      6      [36m0.9911[0m        [32m0.0875[0m       0.3425      0.6677        0.6599        0.0000  19.6092
      7      0.9908        [32m0.0850[0m       0.3406      0.6636        0.6685        0.0000  20.3246
      8      0.9911        [32m0.0840[0m       0.3363      0.6600        0.6741        0.0000  19.6664
      9      0.9911        [32m0.0824[0m       0.3286      0.6541        0.6750        0.0000  19.8836
     10      [36m0.9917[0m        [32m0.0793[0m       0.3319      0.6557        0.6745        0.0000  20.2429
     11      [36m0.9922[0m        [32m0.0775[0m       0.3351      0.6581        0.6835        0.0000  19.3086
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.6467149059334297
F1 Macro Score after query 8: 0.6585597742727751
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9851[0m        [32m0.1199[0m       [35m0.2792[0m      [31m0.7050[0m        [94m0.5954[0m     +  0.0000  26.4799
      2      [36m0.9883[0m        [32m0.1028[0m       [35m0.2878[0m      [31m0.7168[0m        [94m0.5822[0m     +  0.0000  26.4658
      3      [36m0.9898[0m        [32m0.0910[0m       [35m0.2981[0m      [31m0.7217[0m        0.5870        0.0000  26.3729
      4      [36m0.9911[0m        [32m0.0842[0m       0.2804      0.7076        0.6311        0.0000  26.3745
      5      [36m0.9914[0m        [32m0.0782[0m       [35m0.2990[0m      0.7110        0.6316        0.0000  26.4986
      6      [36m0.9921[0m        [32m0.0710[0m       [35m0.3068[0m      [31m0.7227[0m        0.5915        0.0000  26.2941
      7      [36m0.9927[0m        [32m0.0676[0m       [35m0.3076[0m      [31m0.7237[0m        0.5952        0.0000  26.5143
      8      [36m0.9929[0m        [32m0.0647[0m       [35m0.3128[0m      [31m0.7237[0m        0.5857        0.0000  26.2841
      9      [36m0.9931[0m        [32m0.0628[0m       [35m0.3134[0m      [31m0.7247[0m        0.5872        0.0000  26.7794
     10      [36m0.9932[0m        [32m0.0604[0m       [35m0.3203[0m      [31m0.7298[0m        0.5846        0.0000  26.8580
     11      [36m0.9939[0m        [32m0.0576[0m       0.3196      0.7297        0.5835        0.0000  26.2623
     12      0.9939        [32m0.0566[0m       0.3167      0.7267        0.5933        0.0000  26.3547
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.7112688553682343
F1 Macro Score after query 9: 0.7348730361536154
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9802[0m        [32m0.1232[0m       [35m0.2998[0m      [31m0.7372[0m        [94m0.5520[0m     +  0.0000  38.8453
      2      [36m0.9848[0m        [32m0.1023[0m       [35m0.3193[0m      [31m0.7478[0m        [94m0.5484[0m     +  0.0000  38.6787
      3      [36m0.9865[0m        [32m0.0903[0m       [35m0.3385[0m      [31m0.7534[0m        [94m0.5455[0m     +  0.0000  38.7357
      4      [36m0.9873[0m        [32m0.0842[0m       [35m0.3470[0m      [31m0.7542[0m        0.5676        0.0000  38.8768
      5      [36m0.9885[0m        [32m0.0765[0m       [35m0.3760[0m      [31m0.7627[0m        [94m0.5331[0m     +  0.0000  38.8845
      6      [36m0.9902[0m        [32m0.0684[0m       [35m0.3826[0m      0.7591        [94m0.4974[0m     +  0.0000  38.8633
      7      [36m0.9906[0m        [32m0.0654[0m       0.3764      0.7567        0.5149        0.0000  38.7735
      8      [36m0.9910[0m        [32m0.0628[0m       0.3759      0.7540        0.5140        0.0000  39.3458
      9      [36m0.9916[0m        [32m0.0608[0m       0.3776      0.7551        0.5244        0.0000  39.2871
     10      0.9914        [32m0.0579[0m       [35m0.3842[0m      0.7568        0.5178        0.0000  38.6550
     11      [36m0.9926[0m        [32m0.0549[0m       [35m0.3991[0m      [31m0.7651[0m        [94m0.4907[0m     +  0.0000  38.4062
     12      0.9924        [32m0.0542[0m       0.3953      0.7632        0.5000        0.0000  39.2177
     13      0.9922        [32m0.0522[0m       [35m0.4014[0m      [31m0.7661[0m        0.4961        0.0000  38.9223
     14      [36m0.9932[0m        [32m0.0516[0m       0.4007      [31m0.7664[0m        0.5007        0.0000  38.5180
     15      0.9931        [32m0.0509[0m       [35m0.4021[0m      0.7653        0.5042        0.0000  39.4827
     16      [36m0.9935[0m        [32m0.0499[0m       [35m0.4030[0m      0.7650        0.4999        0.0000  38.9093
     17      [36m0.9936[0m        [32m0.0488[0m       [35m0.4047[0m      0.7660        0.5006        0.0000  38.6152
     18      [36m0.9939[0m        [32m0.0478[0m       0.4028      0.7651        0.5073        0.0000  39.5506
     19      [36m0.9940[0m        [32m0.0471[0m       0.4045      [31m0.7674[0m        0.5053        0.0000  38.8774
     20      [36m0.9941[0m        0.0473       [35m0.4054[0m      0.7672        0.5070        0.0000  38.5168
     21      [36m0.9944[0m        [32m0.0464[0m       0.4031      0.7644        0.5105        0.0000  38.7051
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.7510280373831775
F1 Macro Score after query 10: 0.7705365294456262
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9707[0m        [32m0.1300[0m       [35m0.7622[0m      [31m0.8380[0m        [94m0.2599[0m     +  0.0000  61.1891
      2      [36m0.9813[0m        [32m0.0976[0m       0.7495      [31m0.8435[0m        [94m0.2500[0m     +  0.0000  61.5154
      3      [36m0.9841[0m        [32m0.0843[0m       0.7418      0.8378        [94m0.2442[0m     +  0.0000  61.2206
      4      [36m0.9857[0m        [32m0.0748[0m       0.7493      [31m0.8507[0m        [94m0.2392[0m     +  0.0000  61.1573
      5      [36m0.9869[0m        [32m0.0674[0m       [35m0.7668[0m      [31m0.8595[0m        [94m0.2297[0m     +  0.0000  61.0693
      6      [36m0.9889[0m        [32m0.0576[0m       [35m0.7859[0m      [31m0.8770[0m        [94m0.2204[0m     +  0.0000  61.2502
      7      [36m0.9903[0m        [32m0.0533[0m       0.7854      [31m0.8775[0m        0.2231        0.0000  61.0301
      8      [36m0.9908[0m        [32m0.0503[0m       [35m0.7863[0m      [31m0.8780[0m        0.2224        0.0000  61.0291
      9      [36m0.9918[0m        [32m0.0472[0m       0.7861      [31m0.8791[0m        0.2264        0.0000  61.7776
     10      [36m0.9921[0m        [32m0.0445[0m       [35m0.7896[0m      [31m0.8825[0m        0.2251        0.0000  60.7670
     11      [36m0.9934[0m        [32m0.0408[0m       [35m0.7915[0m      [31m0.8859[0m        0.2299        0.0000  60.5034
     12      [36m0.9942[0m        [32m0.0389[0m       0.7877      0.8859        0.2351        0.0000  60.8420
     13      [36m0.9947[0m        [32m0.0375[0m       0.7905      [31m0.8876[0m        0.2363        0.0000  61.1104
     14      [36m0.9951[0m        [32m0.0359[0m       0.7910      [31m0.8878[0m        0.2369        0.0000  60.5281
     15      [36m0.9954[0m        [32m0.0346[0m       0.7899      0.8872        0.2397        0.0000  61.9675
     16      [36m0.9960[0m        [32m0.0328[0m       [35m0.7922[0m      [31m0.8890[0m        0.2404        0.0000  60.8886
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8994725173916367
F1 Macro Score after query 11: 0.8873577709145596
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9816[0m        [32m0.0674[0m       [35m0.8401[0m      [31m0.9094[0m        [94m0.1748[0m     +  0.0000  100.5022
      2      [36m0.9848[0m        [32m0.0531[0m       [35m0.8542[0m      [31m0.9119[0m        [94m0.1615[0m     +  0.0000  101.0972
      3      [36m0.9856[0m        [32m0.0444[0m       0.8444      0.9051        0.1655        0.0000  101.1296
      4      [36m0.9868[0m        [32m0.0378[0m       0.8424      0.8996        0.1728        0.0000  100.4836
      5      [36m0.9887[0m        [32m0.0331[0m       0.8444      0.9088        0.1773        0.0000  100.6373
      6      [36m0.9908[0m        [32m0.0271[0m       0.8266      0.8954        0.1970        0.0000  100.6047
      7      [36m0.9923[0m        [32m0.0235[0m       0.8240      0.8989        0.2088        0.0000  100.4121
      8      [36m0.9934[0m        [32m0.0211[0m       0.8231      0.8995        0.2155        0.0000  100.5698
      9      [36m0.9946[0m        [32m0.0189[0m       0.8226      0.8986        0.2227        0.0000  99.6154
     10      [36m0.9955[0m        [32m0.0171[0m       0.8356      0.9032        0.2120        0.0000  100.2412
     11      [36m0.9966[0m        [32m0.0150[0m       0.8253      0.9007        0.2236        0.0000  100.2128
     12      [36m0.9974[0m        [32m0.0132[0m       0.8259      0.9004        0.2261        0.0000  100.1240
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.9044439327653696
F1 Macro Score after query 12: 0.8884546477602058
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9835[0m        [32m0.0464[0m       [35m0.8436[0m      [31m0.9075[0m        [94m0.1660[0m     +  0.0000  116.0966
      2      [36m0.9853[0m        [32m0.0382[0m       [35m0.8637[0m      [31m0.9134[0m        [94m0.1629[0m     +  0.0000  116.8367
      3      [36m0.9869[0m        [32m0.0330[0m       0.8436      0.9040        0.1801        0.0000  116.3410
      4      [36m0.9880[0m        [32m0.0288[0m       0.8373      0.9043        0.1907        0.0000  117.3638
      5      [36m0.9892[0m        [32m0.0257[0m       0.8557      0.9113        0.1837        0.0000  117.1249
      6      [36m0.9916[0m        [32m0.0204[0m       0.8224      0.8944        0.2101        0.0000  117.0152
      7      [36m0.9933[0m        [32m0.0175[0m       0.8292      0.8972        0.2134        0.0000  116.7353
      8      [36m0.9945[0m        [32m0.0158[0m       0.8300      0.8987        0.2192        0.0000  116.1594
      9      [36m0.9955[0m        [32m0.0141[0m       0.8278      0.9001        0.2287        0.0000  113.3914
     10      [36m0.9962[0m        [32m0.0123[0m       0.8295      0.8998        0.2331        0.0000  113.2819
     11      [36m0.9972[0m        [32m0.0107[0m       0.8339      0.9018        0.2297        0.0000  113.0775
     12      [36m0.9977[0m        [32m0.0095[0m       0.8337      0.9017        0.2336        0.0000  113.0940
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.9073715215874738
F1 Macro Score after query 13: 0.8889539481617311
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_lowLR\AL_average_score_results_for_multilabel_classification_s46.pickle
