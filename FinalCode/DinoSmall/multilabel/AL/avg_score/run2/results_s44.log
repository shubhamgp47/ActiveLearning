Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2434[0m        [32m0.6979[0m       [35m0.2356[0m      [31m0.4635[0m        [94m0.6879[0m     +  0.0000  12.6197
      2      [36m0.8320[0m        [32m0.6229[0m       0.1953      0.4493        0.6886        0.0000  10.7031
      3      0.7460        0.6306       0.2273      0.4454        0.6916        0.0000  10.8615
      4      0.7054        0.6251       0.1556      0.4449        0.6932        0.0000  10.7292
      5      [36m0.8426[0m        [32m0.5746[0m       0.2014      [31m0.4773[0m        [94m0.6830[0m     +  0.0000  10.7030
      6      0.8426        [32m0.5676[0m       0.2083      0.4599        0.6870        0.0000  10.9337
      7      0.7963        [32m0.5644[0m       0.2033      0.4602        0.6952        0.0000  10.8281
      8      0.8333        [32m0.5369[0m       0.2113      0.4646        0.6927        0.0000  10.9385
      9      0.8320        [32m0.5339[0m       0.2056      0.4598        0.6932        0.0000  11.3311
     10      0.7857        [32m0.5283[0m       0.2073      0.4740        0.6929        0.0000  11.2675
     11      0.8130        0.5537       0.2066      0.4687        0.6947        0.0000  11.1663
     12      [36m0.9630[0m        [32m0.4794[0m       0.2083      0.4677        0.6938        0.0000  11.0756
     13      0.8796        0.4997       0.2122      0.4698        0.6929        0.0000  10.8930
     14      0.8889        0.5241       0.2115      0.4708        0.6932        0.0000  10.9478
     15      0.9167        0.4934       0.2125      0.4701        0.6944        0.0000  10.9246
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4810
Pre F1 macro score = 0.4786
Pre Accuracy = 0.2436

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8419[0m        [32m0.5120[0m       [35m0.1167[0m      [31m0.4694[0m        [94m0.7215[0m     +  0.0000  10.9513
      2      0.8409        [32m0.4657[0m       [35m0.1391[0m      0.4577        0.7332        0.0000  11.2515
      3      [36m0.8823[0m        [32m0.4279[0m       [35m0.1399[0m      [31m0.4724[0m        0.7514        0.0000  11.5152
      4      0.8258        [32m0.4034[0m       [35m0.1903[0m      0.4692        0.7475        0.0000  11.2658
      5      0.8625        0.4087       0.1576      0.4679        0.7490        0.0000  11.1298
      6      [36m0.9113[0m        [32m0.3821[0m       0.1674      0.4718        0.7473        0.0000  11.3439
      7      [36m0.9282[0m        0.3931       0.1724      0.4686        0.7448        0.0000  11.0810
      8      0.9044        [32m0.3605[0m       0.1854      [31m0.4813[0m        0.7445        0.0000  11.1379
      9      0.8726        0.3709       [35m0.2080[0m      [31m0.4846[0m        0.7446        0.0000  11.3126
     10      [36m0.9325[0m        [32m0.3556[0m       0.1901      0.4804        0.7384        0.0000  10.8329
     11      [36m0.9534[0m        [32m0.3399[0m       0.1990      [31m0.4861[0m        0.7407        0.0000  10.9668
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.5321100917431193
F1 Macro Score after query 1: 0.5142049078181291
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8129[0m        [32m0.5188[0m       [35m0.1932[0m      [31m0.5397[0m        [94m0.7156[0m     +  0.0000  11.1303
      2      [36m0.8261[0m        [32m0.4892[0m       [35m0.2035[0m      0.5086        0.7206        0.0000  11.2674
      3      [36m0.9059[0m        [32m0.4333[0m       [35m0.2069[0m      0.4983        [94m0.7093[0m     +  0.0000  11.2346
      4      0.9025        [32m0.4184[0m       [35m0.2198[0m      0.4807        [94m0.7032[0m     +  0.0000  10.9011
      5      [36m0.9407[0m        [32m0.3705[0m       [35m0.2451[0m      0.4954        [94m0.7019[0m     +  0.0000  11.1564
      6      [36m0.9527[0m        [32m0.3611[0m       0.2443      0.4765        [94m0.7008[0m     +  0.0000  11.1227
      7      0.9525        [32m0.3443[0m       [35m0.2540[0m      0.4730        [94m0.6948[0m     +  0.0000  11.5102
      8      [36m0.9574[0m        0.3457       [35m0.2635[0m      0.4744        [94m0.6907[0m     +  0.0000  11.0940
      9      [36m0.9626[0m        [32m0.3420[0m       0.2628      0.4731        [94m0.6901[0m     +  0.0000  11.0225
     10      0.9626        0.3445       [35m0.2672[0m      0.4706        [94m0.6867[0m     +  0.0000  11.1808
     11      [36m0.9671[0m        [32m0.3240[0m       0.2672      0.4701        [94m0.6863[0m     +  0.0000  11.5129
     12      0.9487        0.3262       [35m0.2691[0m      0.4712        [94m0.6841[0m     +  0.0000  11.4061
     13      [36m0.9723[0m        [32m0.3159[0m       [35m0.2693[0m      0.4716        [94m0.6840[0m     +  0.0000  11.3126
     14      0.9575        0.3208       0.2691      0.4707        [94m0.6831[0m     +  0.0000  11.3563
     15      0.9682        [32m0.3126[0m       0.2687      0.4702        0.6834        0.0000  11.2365
     16      0.9622        [32m0.3100[0m       0.2689      0.4695        [94m0.6829[0m     +  0.0000  11.3005
     17      0.9568        0.3151       0.2681      0.4698        0.6832        0.0000  11.4198
     18      0.9719        0.3106       0.2679      0.4703        [94m0.6823[0m     +  0.0000  11.1980
     19      [36m0.9735[0m        [32m0.3057[0m       0.2682      0.4697        [94m0.6820[0m     +  0.0000  11.2710
     20      [36m0.9753[0m        [32m0.3021[0m       0.2691      0.4700        [94m0.6815[0m     +  0.0000  10.9669
     21      0.9733        [32m0.3020[0m       0.2689      0.4701        0.6816        0.0000  11.3621
     22      0.9568        0.3147       0.2687      0.4701        0.6816        0.0000  11.3306
     23      [36m0.9830[0m        0.3076       0.2687      0.4706        0.6816        0.0000  10.9940
     24      0.9815        0.3052       0.2689      0.4700        [94m0.6814[0m     +  0.0000  11.5083
     25      0.9575        0.3117       0.2686      0.4699        [94m0.6813[0m     +  0.0000  11.0414
     26      0.9682        0.3031       0.2684      0.4699        0.6814        0.0000  11.1257
     27      0.9735        0.3026       0.2684      0.4700        0.6813        0.0000  11.3242
     28      0.9711        0.3076       0.2684      0.4699        0.6813        0.0000  11.3406
     29      0.9682        0.3106       0.2684      0.4699        [94m0.6813[0m     +  0.0000  11.4065
     30      0.9723        0.3070       0.2686      0.4700        [94m0.6812[0m     +  0.0000  11.2875
     31      0.9671        [32m0.3003[0m       0.2686      0.4700        [94m0.6812[0m     +  0.0000  11.1077
     32      0.9666        0.3019       0.2686      0.4700        0.6812        0.0000  11.1727
     33      0.9661        0.3071       0.2684      0.4699        0.6812        0.0000  11.1039
     34      0.9737        [32m0.2997[0m       0.2684      0.4699        0.6812        0.0000  11.1391
     35      0.9666        0.3024       0.2684      0.4699        [94m0.6812[0m     +  0.0000  11.2870
     36      0.9661        0.3074       0.2684      0.4699        [94m0.6812[0m     +  0.0000  10.9102
     37      0.9575        0.3142       0.2684      0.4699        [94m0.6811[0m     +  0.0000  11.3874
     38      0.9830        0.3005       0.2684      0.4699        [94m0.6811[0m     +  0.0000  11.2980
     39      0.9711        0.3068       0.2684      0.4699        [94m0.6811[0m     +  0.0000  11.3540
     40      0.9682        0.3067       0.2684      0.4699        0.6811        0.0000  11.1690
     41      0.9815        [32m0.2990[0m       0.2684      0.4699        0.6811        0.0000  11.2508
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.4824785682057452
F1 Macro Score after query 2: 0.4666474857104705
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9772[0m        [32m0.3056[0m       [35m0.2234[0m      [31m0.5330[0m        [94m0.6890[0m     +  0.0000  11.3869
      2      [36m0.9807[0m        [32m0.2507[0m       0.2163      0.5100        [94m0.6747[0m     +  0.0000  11.3614
      3      [36m0.9827[0m        [32m0.2451[0m       [35m0.2418[0m      0.5087        [94m0.6663[0m     +  0.0000  11.3514
      4      [36m0.9844[0m        [32m0.2390[0m       [35m0.2530[0m      0.4953        [94m0.6656[0m     +  0.0000  11.3418
      5      [36m0.9880[0m        [32m0.2287[0m       [35m0.2667[0m      0.4879        [94m0.6583[0m     +  0.0000  11.5940
      6      0.9878        [32m0.2164[0m       0.2653      0.4832        [94m0.6581[0m     +  0.0000  11.4407
      7      0.9858        0.2168       0.2639      0.4830        [94m0.6559[0m     +  0.0000  11.5916
      8      0.9878        0.2197       [35m0.2682[0m      0.4820        [94m0.6533[0m     +  0.0000  11.3591
      9      [36m0.9901[0m        [32m0.2077[0m       [35m0.2715[0m      0.4846        [94m0.6518[0m     +  0.0000  11.4118
     10      [36m0.9914[0m        0.2141       [35m0.2722[0m      0.4809        [94m0.6513[0m     +  0.0000  11.3778
     11      [36m0.9949[0m        [32m0.2052[0m       0.2722      0.4809        [94m0.6503[0m     +  0.0000  11.5604
     12      0.9914        0.2124       [35m0.2736[0m      0.4816        [94m0.6495[0m     +  0.0000  11.3124
     13      0.9934        [32m0.2051[0m       0.2731      0.4805        0.6506        0.0000  11.4094
     14      0.9932        0.2093       0.2722      0.4800        0.6501        0.0000  11.4533
     15      0.9949        [32m0.2037[0m       0.2726      0.4816        0.6496        0.0000  11.4540
     16      0.9911        0.2078       0.2731      0.4816        0.6497        0.0000  11.2668
     17      0.9934        [32m0.2024[0m       0.2717      0.4804        [94m0.6494[0m     +  0.0000  11.6230
     18      0.9930        [32m0.1975[0m       0.2717      0.4802        0.6498        0.0000  11.1353
     19      0.9949        0.2044       0.2722      0.4803        [94m0.6493[0m     +  0.0000  11.5395
     20      0.9932        0.2108       0.2722      0.4800        0.6497        0.0000  11.3748
     21      0.9930        0.2060       0.2720      0.4799        0.6498        0.0000  11.7070
     22      0.9934        0.2039       0.2726      0.4803        0.6497        0.0000  11.2760
     23      0.9949        0.2000       0.2729      0.4809        0.6497        0.0000  11.8049
     24      0.9949        0.2007       0.2727      0.4808        0.6495        0.0000  10.9916
     25      0.9949        0.2039       0.2726      0.4807        0.6496        0.0000  11.4441
     26      0.9917        0.2053       0.2727      0.4809        0.6496        0.0000  10.9424
     27      0.9932        0.1992       0.2726      0.4807        0.6496        0.0000  11.6167
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.5158524868819746
F1 Macro Score after query 3: 0.4867887769226815
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9867[0m        [32m0.2130[0m       [35m0.2163[0m      [31m0.5410[0m        [94m0.6653[0m     +  0.0000  11.6485
      2      [36m0.9948[0m        [32m0.1871[0m       [35m0.2311[0m      0.5241        [94m0.6534[0m     +  0.0000  11.5689
      3      [36m0.9958[0m        [32m0.1756[0m       [35m0.2394[0m      0.5170        [94m0.6520[0m     +  0.0000  11.7578
      4      0.9949        [32m0.1744[0m       [35m0.2446[0m      0.5213        [94m0.6514[0m     +  0.0000  11.9338
      5      [36m0.9966[0m        [32m0.1704[0m       0.2339      0.5097        [94m0.6478[0m     +  0.0000  11.7113
      6      0.9965        [32m0.1682[0m       [35m0.2465[0m      0.5019        [94m0.6441[0m     +  0.0000  11.6776
      7      [36m0.9973[0m        0.1701       [35m0.2531[0m      0.4997        [94m0.6415[0m     +  0.0000  11.6573
      8      0.9958        0.1719       0.2517      0.4984        0.6418        0.0000  11.6491
      9      [36m0.9983[0m        [32m0.1601[0m       [35m0.2561[0m      0.4976        [94m0.6410[0m     +  0.0000  11.8521
     10      0.9974        0.1633       [35m0.2573[0m      0.4948        0.6418        0.0000  11.9771
     11      0.9966        0.1608       0.2545      0.4928        [94m0.6405[0m     +  0.0000  11.7262
     12      0.9974        0.1603       [35m0.2580[0m      0.4937        [94m0.6399[0m     +  0.0000  11.7252
     13      0.9974        0.1667       [35m0.2616[0m      0.4927        [94m0.6397[0m     +  0.0000  11.8987
     14      0.9966        [32m0.1590[0m       0.2597      0.4954        0.6398        0.0000  11.8047
     15      0.9974        0.1597       0.2613      0.4944        [94m0.6392[0m     +  0.0000  11.7568
     16      0.9974        0.1643       [35m0.2620[0m      0.4897        [94m0.6387[0m     +  0.0000  11.7890
     17      0.9974        0.1613       0.2616      0.4920        [94m0.6386[0m     +  0.0000  11.9452
     18      0.9974        0.1622       0.2618      0.4927        [94m0.6382[0m     +  0.0000  11.7277
     19      0.9974        0.1591       0.2611      0.4920        0.6388        0.0000  11.9291
     20      0.9974        [32m0.1589[0m       0.2613      0.4931        0.6386        0.0000  11.7425
     21      0.9983        [32m0.1572[0m       0.2613      0.4906        0.6384        0.0000  11.8339
     22      0.9958        0.1629       0.2613      0.4907        0.6385        0.0000  11.7889
     23      0.9974        0.1584       0.2613      0.4902        0.6389        0.0000  11.7034
     24      0.9974        0.1599       0.2613      0.4894        0.6385        0.0000  11.8190
     25      0.9974        0.1610       0.2609      0.4893        0.6385        0.0000  11.9598
     26      0.9974        0.1602       0.2611      0.4891        0.6385        0.0000  11.9439
     27      0.9974        [32m0.1563[0m       0.2611      0.4893        0.6385        0.0000  11.7742
     28      0.9974        0.1606       0.2609      0.4891        0.6385        0.0000  11.6935
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.5295227041926592
F1 Macro Score after query 4: 0.4993442688281767
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9848[0m        [32m0.1905[0m       [35m0.1832[0m      [31m0.5572[0m        [94m0.6879[0m     +  0.0000  12.4451
      2      [36m0.9914[0m        [32m0.1702[0m       [35m0.2271[0m      [31m0.5642[0m        [94m0.6525[0m     +  0.0000  12.5705
      3      [36m0.9938[0m        [32m0.1618[0m       [35m0.2274[0m      0.5569        [94m0.6390[0m     +  0.0000  12.4287
      4      [36m0.9957[0m        [32m0.1523[0m       0.2222      0.5446        [94m0.6269[0m     +  0.0000  12.4769
      5      [36m0.9962[0m        0.1523       [35m0.2411[0m      0.5468        [94m0.6219[0m     +  0.0000  12.4755
      6      [36m0.9971[0m        [32m0.1474[0m       0.2394      0.5405        [94m0.6174[0m     +  0.0000  12.4752
      7      0.9967        [32m0.1444[0m       [35m0.2434[0m      0.5407        [94m0.6163[0m     +  0.0000  12.6340
      8      0.9971        [32m0.1437[0m       0.2392      0.5364        0.6180        0.0000  12.5552
      9      [36m0.9972[0m        [32m0.1416[0m       0.2413      0.5396        0.6167        0.0000  12.4594
     10      0.9967        [32m0.1413[0m       0.2432      0.5396        0.6185        0.0000  12.4917
     11      0.9967        0.1421       [35m0.2500[0m      0.5361        0.6171        0.0000  12.4114
     12      0.9972        [32m0.1400[0m       [35m0.2543[0m      0.5333        0.6184        0.0000  12.4426
     13      [36m0.9976[0m        [32m0.1392[0m       0.2533      0.5330        0.6201        0.0000  12.5241
     14      0.9967        0.1397       [35m0.2592[0m      0.5378        0.6174        0.0000  12.3472
     15      0.9972        [32m0.1360[0m       0.2578      0.5349        0.6185        0.0000  12.2711
     16      [36m0.9981[0m        0.1381       0.2590      0.5339        0.6187        0.0000  12.4020
     17      0.9972        0.1369       0.2589      0.5328        0.6203        0.0000  12.3994
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.5739967442848042
F1 Macro Score after query 5: 0.5695333942438495
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9883[0m        [32m0.1741[0m       [35m0.2269[0m      [31m0.5903[0m        [94m0.6737[0m     +  0.0000  14.1010
      2      [36m0.9891[0m        [32m0.1602[0m       [35m0.2483[0m      0.5796        [94m0.6257[0m     +  0.0000  13.6797
      3      [36m0.9895[0m        [32m0.1542[0m       [35m0.2727[0m      [31m0.5909[0m        [94m0.5970[0m     +  0.0000  13.4613
      4      [36m0.9910[0m        [32m0.1506[0m       [35m0.2863[0m      [31m0.5988[0m        [94m0.5918[0m     +  0.0000  13.6182
      5      0.9905        [32m0.1432[0m       [35m0.2885[0m      [31m0.6031[0m        [94m0.5814[0m     +  0.0000  13.8993
      6      [36m0.9923[0m        [32m0.1386[0m       [35m0.2896[0m      [31m0.6042[0m        0.5822        0.0000  13.6654
      7      [36m0.9925[0m        [32m0.1334[0m       [35m0.2943[0m      [31m0.6057[0m        [94m0.5798[0m     +  0.0000  14.0704
      8      0.9920        0.1349       [35m0.2990[0m      [31m0.6075[0m        [94m0.5783[0m     +  0.0000  14.1025
      9      [36m0.9928[0m        [32m0.1331[0m       [35m0.3009[0m      [31m0.6103[0m        0.5818        0.0000  13.9306
     10      [36m0.9933[0m        [32m0.1324[0m       0.2981      0.6103        0.5795        0.0000  13.8842
     11      [36m0.9933[0m        [32m0.1262[0m       0.2977      [31m0.6117[0m        [94m0.5767[0m     +  0.0000  13.8072
     12      0.9928        [32m0.1256[0m       0.2962      0.6085        0.5783        0.0000  13.9617
     13      [36m0.9935[0m        0.1278       0.3009      0.6107        0.5792        0.0000  13.5942
     14      [36m0.9938[0m        0.1287       [35m0.3026[0m      [31m0.6127[0m        0.5802        0.0000  13.5706
     15      [36m0.9941[0m        [32m0.1253[0m       0.3017      0.6127        0.5806        0.0000  14.0120
     16      0.9933        0.1268       [35m0.3052[0m      [31m0.6128[0m        0.5795        0.0000  14.0480
     17      0.9938        0.1254       [35m0.3054[0m      [31m0.6129[0m        0.5779        0.0000  13.5158
     18      0.9938        [32m0.1247[0m       [35m0.3061[0m      [31m0.6138[0m        0.5786        0.0000  13.7497
     19      0.9930        [32m0.1239[0m       [35m0.3066[0m      0.6125        0.5788        0.0000  13.6093
     20      0.9933        [32m0.1203[0m       [35m0.3069[0m      [31m0.6140[0m        0.5776        0.0000  13.4435
     21      0.9938        0.1229       [35m0.3073[0m      0.6140        0.5779        0.0000  13.7342
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6129625843385811
F1 Macro Score after query 6: 0.6161688631090189
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9866[0m        [32m0.1492[0m       [35m0.3507[0m      [31m0.6602[0m        [94m0.5910[0m     +  0.0000  15.5369
      2      [36m0.9905[0m        [32m0.1303[0m       0.3503      [31m0.6656[0m        0.6020        0.0000  15.6735
      3      [36m0.9919[0m        [32m0.1236[0m       [35m0.3538[0m      [31m0.6688[0m        0.6009        0.0000  15.7449
      4      [36m0.9922[0m        [32m0.1193[0m       [35m0.3602[0m      [31m0.6728[0m        0.6005        0.0000  15.6599
      5      [36m0.9926[0m        [32m0.1139[0m       [35m0.3644[0m      [31m0.6757[0m        0.6079        0.0000  15.6977
      6      [36m0.9935[0m        [32m0.1072[0m       0.3566      0.6669        [94m0.5747[0m     +  0.0000  15.8436
      7      [36m0.9938[0m        [32m0.1043[0m       [35m0.3646[0m      0.6674        [94m0.5738[0m     +  0.0000  15.9531
      8      [36m0.9938[0m        [32m0.1032[0m       [35m0.3731[0m      0.6707        [94m0.5651[0m     +  0.0000  15.6565
      9      [36m0.9941[0m        [32m0.1008[0m       [35m0.3769[0m      0.6718        [94m0.5648[0m     +  0.0000  15.7655
     10      [36m0.9944[0m        [32m0.0984[0m       0.3766      0.6716        [94m0.5641[0m     +  0.0000  15.5553
     11      [36m0.9948[0m        [32m0.0980[0m       0.3747      0.6739        [94m0.5575[0m     +  0.0000  16.0328
     12      [36m0.9953[0m        [32m0.0947[0m       0.3734      0.6729        [94m0.5565[0m     +  0.0000  15.7060
     13      [36m0.9959[0m        [32m0.0932[0m       [35m0.3771[0m      0.6742        0.5587        0.0000  15.8113
     14      0.9945        0.0936       [35m0.3788[0m      0.6740        [94m0.5561[0m     +  0.0000  15.8274
     15      0.9951        [32m0.0930[0m       [35m0.3790[0m      0.6738        0.5570        0.0000  15.7825
     16      0.9959        [32m0.0915[0m       [35m0.3807[0m      0.6736        [94m0.5547[0m     +  0.0000  15.6276
     17      0.9957        0.0924       [35m0.3811[0m      0.6739        0.5555        0.0000  15.9425
     18      0.9959        [32m0.0914[0m       [35m0.3819[0m      0.6731        0.5550        0.0000  15.6469
     19      0.9959        [32m0.0890[0m       [35m0.3830[0m      0.6749        0.5555        0.0000  15.7968
     20      [36m0.9962[0m        0.0891       0.3826      0.6738        [94m0.5545[0m     +  0.0000  15.8905
     21      [36m0.9962[0m        [32m0.0889[0m       [35m0.3833[0m      0.6735        [94m0.5541[0m     +  0.0000  15.6410
     22      [36m0.9965[0m        0.0889       [35m0.3840[0m      0.6738        0.5542        0.0000  15.9833
     23      0.9959        0.0902       0.3839      0.6733        0.5541        0.0000  15.7384
     24      [36m0.9969[0m        [32m0.0886[0m       0.3839      0.6734        0.5544        0.0000  15.7180
     25      0.9963        0.0897       0.3840      0.6733        [94m0.5540[0m     +  0.0000  15.8422
     26      0.9963        0.0889       [35m0.3842[0m      0.6733        0.5540        0.0000  15.6760
     27      0.9965        0.0902       [35m0.3844[0m      0.6733        0.5544        0.0000  15.7056
     28      0.9966        0.0894       [35m0.3849[0m      0.6733        0.5542        0.0000  15.7551
     29      0.9966        [32m0.0881[0m       [35m0.3851[0m      0.6733        0.5540        0.0000  15.7371
     30      0.9965        0.0881       [35m0.3854[0m      0.6734        0.5542        0.0000  15.9501
     31      0.9968        [32m0.0866[0m       0.3854      0.6733        0.5541        0.0000  15.6090
     32      0.9962        0.0889       [35m0.3856[0m      0.6734        0.5541        0.0000  15.8595
     33      0.9965        0.0890       [35m0.3859[0m      0.6735        0.5541        0.0000  15.8097
     34      0.9962        0.0893       0.3858      0.6733        [94m0.5539[0m     +  0.0000  15.6254
     35      0.9967        0.0887       0.3856      0.6733        0.5540        0.0000  16.0453
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.693702899476306
F1 Macro Score after query 7: 0.7111796715872335
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9798[0m        [32m0.1395[0m       [35m0.3578[0m      [31m0.6884[0m        [94m0.5387[0m     +  0.0000  19.5950
      2      [36m0.9869[0m        [32m0.1155[0m       [35m0.3590[0m      [31m0.7050[0m        [94m0.5001[0m     +  0.0000  19.5894
      3      [36m0.9886[0m        [32m0.1043[0m       [35m0.3708[0m      [31m0.7157[0m        [94m0.4898[0m     +  0.0000  19.8636
      4      [36m0.9899[0m        [32m0.0972[0m       [35m0.3866[0m      [31m0.7264[0m        [94m0.4720[0m     +  0.0000  19.3571
      5      0.9892        [32m0.0937[0m       [35m0.4130[0m      [31m0.7349[0m        [94m0.4600[0m     +  0.0000  19.6003
      6      [36m0.9921[0m        [32m0.0852[0m       [35m0.4238[0m      [31m0.7467[0m        [94m0.4586[0m     +  0.0000  19.9328
      7      [36m0.9925[0m        [32m0.0802[0m       [35m0.4243[0m      [31m0.7491[0m        0.4588        0.0000  19.6877
      8      [36m0.9932[0m        [32m0.0781[0m       [35m0.4347[0m      [31m0.7500[0m        [94m0.4498[0m     +  0.0000  19.7828
      9      0.9928        [32m0.0774[0m       0.4300      [31m0.7502[0m        0.4549        0.0000  19.6255
     10      [36m0.9939[0m        [32m0.0740[0m       [35m0.4431[0m      [31m0.7518[0m        [94m0.4453[0m     +  0.0000  19.6944
     11      [36m0.9944[0m        [32m0.0715[0m       [35m0.4436[0m      [31m0.7535[0m        0.4466        0.0000  19.7053
     12      [36m0.9947[0m        [32m0.0703[0m       [35m0.4444[0m      0.7512        [94m0.4439[0m     +  0.0000  19.5941
     13      [36m0.9948[0m        [32m0.0687[0m       0.4424      0.7524        0.4465        0.0000  19.7034
     14      [36m0.9951[0m        [32m0.0685[0m       [35m0.4460[0m      [31m0.7539[0m        0.4444        0.0000  19.6860
     15      0.9949        [32m0.0669[0m       [35m0.4472[0m      [31m0.7543[0m        [94m0.4438[0m     +  0.0000  19.6747
     16      [36m0.9955[0m        [32m0.0655[0m       0.4467      [31m0.7557[0m        0.4443        0.0000  19.3139
     17      [36m0.9958[0m        [32m0.0646[0m       0.4469      0.7553        [94m0.4435[0m     +  0.0000  19.5346
     18      [36m0.9962[0m        0.0647       0.4467      0.7552        0.4435        0.0000  19.3589
     19      0.9957        [32m0.0634[0m       [35m0.4474[0m      0.7555        [94m0.4427[0m     +  0.0000  19.6225
     20      0.9957        0.0641       0.4460      [31m0.7561[0m        0.4446        0.0000  19.3584
     21      [36m0.9966[0m        [32m0.0632[0m       0.4455      0.7557        0.4452        0.0000  19.6909
     22      0.9965        [32m0.0625[0m       0.4455      [31m0.7564[0m        0.4455        0.0000  19.4530
     23      0.9963        0.0625       0.4469      0.7562        0.4444        0.0000  19.6873
     24      0.9960        0.0635       [35m0.4477[0m      0.7562        0.4440        0.0000  19.5055
     25      [36m0.9968[0m        0.0634       0.4469      0.7558        0.4438        0.0000  19.8304
     26      [36m0.9969[0m        [32m0.0617[0m       0.4467      0.7561        0.4446        0.0000  19.3920
     27      [36m0.9970[0m        0.0619       0.4465      0.7563        0.4448        0.0000  19.7012
     28      0.9964        0.0629       0.4467      [31m0.7564[0m        0.4449        0.0000  19.3788
     29      0.9965        0.0618       0.4467      [31m0.7567[0m        0.4451        0.0000  19.9011
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7658478605388273
F1 Macro Score after query 8: 0.7814175232561916
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9894[0m        [32m0.0855[0m       [35m0.3155[0m      [31m0.7173[0m        [94m0.5815[0m     +  0.0000  26.7181
      2      [36m0.9923[0m        [32m0.0696[0m       [35m0.3351[0m      [31m0.7263[0m        [94m0.5524[0m     +  0.0000  26.4653
      3      [36m0.9928[0m        [32m0.0640[0m       [35m0.3389[0m      [31m0.7306[0m        0.5839        0.0000  26.4001
      4      [36m0.9936[0m        [32m0.0569[0m       [35m0.3726[0m      [31m0.7396[0m        [94m0.5472[0m     +  0.0000  26.4512
      5      [36m0.9937[0m        [32m0.0544[0m       [35m0.4068[0m      [31m0.7506[0m        [94m0.5171[0m     +  0.0000  26.1917
      6      [36m0.9954[0m        [32m0.0470[0m       [35m0.4087[0m      0.7501        [94m0.5049[0m     +  0.0000  26.5781
      7      [36m0.9959[0m        [32m0.0442[0m       [35m0.4184[0m      [31m0.7534[0m        0.5075        0.0000  26.3128
      8      [36m0.9961[0m        [32m0.0424[0m       [35m0.4276[0m      0.7512        [94m0.5032[0m     +  0.0000  26.7314
      9      [36m0.9967[0m        [32m0.0404[0m       [35m0.4281[0m      0.7500        0.5062        0.0000  26.5614
     10      0.9963        [32m0.0396[0m       [35m0.4451[0m      [31m0.7552[0m        [94m0.4981[0m     +  0.0000  26.3850
     11      [36m0.9972[0m        [32m0.0371[0m       [35m0.4467[0m      [31m0.7560[0m        0.4986        0.0000  26.6998
     12      [36m0.9974[0m        [32m0.0362[0m       [35m0.4557[0m      [31m0.7592[0m        [94m0.4924[0m     +  0.0000  26.5461
     13      [36m0.9977[0m        [32m0.0347[0m       [35m0.4611[0m      [31m0.7603[0m        [94m0.4914[0m     +  0.0000  26.6195
     14      [36m0.9979[0m        [32m0.0342[0m       0.4566      0.7580        0.5008        0.0000  26.3619
     15      0.9976        [32m0.0333[0m       0.4592      0.7589        0.5002        0.0000  26.6269
     16      [36m0.9980[0m        [32m0.0321[0m       0.4514      0.7563        0.5015        0.0000  26.6214
     17      [36m0.9981[0m        0.0322       0.4549      0.7576        0.5012        0.0000  26.5550
     18      0.9979        [32m0.0319[0m       0.4512      0.7563        0.5045        0.0000  26.6268
     19      0.9979        [32m0.0314[0m       0.4519      0.7562        0.5049        0.0000  26.6364
     20      [36m0.9983[0m        [32m0.0297[0m       0.4500      0.7553        0.5078        0.0000  26.6096
     21      0.9982        0.0309       0.4483      0.7548        0.5080        0.0000  26.4339
     22      [36m0.9984[0m        0.0305       0.4523      0.7562        0.5060        0.0000  26.5474
     23      0.9983        0.0300       0.4523      0.7561        0.5048        0.0000  26.2823
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.743308629876891
F1 Macro Score after query 9: 0.7613144463146432
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9823[0m        [32m0.0927[0m       [35m0.4733[0m      [31m0.7649[0m        [94m0.4091[0m     +  0.0000  38.7892
      2      [36m0.9869[0m        [32m0.0727[0m       [35m0.4984[0m      [31m0.7837[0m        [94m0.4079[0m     +  0.0000  39.1060
      3      [36m0.9884[0m        [32m0.0657[0m       0.4894      0.7700        0.4298        0.0000  38.9319
      4      [36m0.9898[0m        [32m0.0595[0m       0.4658      0.7630        0.4817        0.0000  39.2678
      5      [36m0.9905[0m        [32m0.0554[0m       0.4083      0.7279        0.5741        0.0000  39.0434
      6      [36m0.9932[0m        [32m0.0465[0m       [35m0.5481[0m      [31m0.7906[0m        0.4275        0.0000  38.4814
      7      [36m0.9935[0m        [32m0.0434[0m       0.5465      0.7885        0.4334        0.0000  38.6138
      8      [36m0.9940[0m        [32m0.0413[0m       0.5281      0.7812        0.4512        0.0000  38.3159
      9      [36m0.9945[0m        [32m0.0397[0m       0.5363      0.7826        0.4370        0.0000  38.8258
     10      [36m0.9953[0m        [32m0.0369[0m       0.5399      0.7806        0.4403        0.0000  38.9064
     11      [36m0.9960[0m        [32m0.0345[0m       [35m0.5589[0m      [31m0.7986[0m        0.4192        0.0000  38.9510
     12      [36m0.9963[0m        [32m0.0330[0m       0.5540      0.7942        0.4328        0.0000  39.0381
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8019432982829762
F1 Macro Score after query 10: 0.8084467962157751
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9713[0m        [32m0.1193[0m       [35m0.7861[0m      [31m0.8654[0m        [94m0.2201[0m     +  0.0000  60.8620
      2      [36m0.9790[0m        [32m0.0948[0m       [35m0.8172[0m      [31m0.8980[0m        [94m0.1958[0m     +  0.0000  60.2984
      3      [36m0.9818[0m        [32m0.0817[0m       0.8068      0.8812        [94m0.1931[0m     +  0.0000  60.9349
      4      [36m0.9844[0m        [32m0.0726[0m       [35m0.8212[0m      [31m0.9001[0m        [94m0.1880[0m     +  0.0000  60.7691
      5      [36m0.9860[0m        [32m0.0649[0m       0.8087      0.8971        0.2041        0.0000  60.7100
      6      [36m0.9880[0m        [32m0.0565[0m       0.8049      0.8932        0.2027        0.0000  60.9199
      7      [36m0.9894[0m        [32m0.0521[0m       0.8113      0.8993        0.2013        0.0000  60.4816
      8      [36m0.9907[0m        [32m0.0480[0m       0.8146      [31m0.9007[0m        0.2016        0.0000  60.8464
      9      [36m0.9912[0m        [32m0.0451[0m       0.8120      0.8991        0.2029        0.0000  60.7231
     10      [36m0.9923[0m        [32m0.0425[0m       0.8187      [31m0.9017[0m        0.1987        0.0000  60.7336
     11      [36m0.9936[0m        [32m0.0387[0m       0.8128      0.9001        0.2108        0.0000  61.3883
     12      [36m0.9943[0m        [32m0.0370[0m       0.8132      0.9002        0.2126        0.0000  60.6346
     13      [36m0.9951[0m        [32m0.0355[0m       0.8142      0.9009        0.2164        0.0000  60.9351
     14      [36m0.9952[0m        [32m0.0339[0m       0.8134      0.9007        0.2160        0.0000  61.0444
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.9258433873818489
F1 Macro Score after query 11: 0.916445255622921
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9793[0m        [32m0.0713[0m       [35m0.8410[0m      [31m0.8963[0m        [94m0.1725[0m     +  0.0000  99.7809
      2      [36m0.9831[0m        [32m0.0559[0m       [35m0.8465[0m      [31m0.9001[0m        [94m0.1588[0m     +  0.0000  98.9322
      3      [36m0.9849[0m        [32m0.0468[0m       0.8446      [31m0.9029[0m        0.1688        0.0000  98.9853
      4      [36m0.9854[0m        [32m0.0407[0m       0.8438      0.8957        0.1696        0.0000  99.2124
      5      [36m0.9860[0m        [32m0.0369[0m       0.8325      0.8828        0.1850        0.0000  99.3107
      6      [36m0.9893[0m        [32m0.0303[0m       [35m0.8538[0m      [31m0.9084[0m        0.1674        0.0000  99.3275
      7      [36m0.9909[0m        [32m0.0271[0m       0.8422      0.9052        0.1782        0.0000  100.2323
      8      [36m0.9923[0m        [32m0.0246[0m       [35m0.8550[0m      [31m0.9117[0m        0.1737        0.0000  101.2575
      9      [36m0.9933[0m        [32m0.0224[0m       [35m0.8602[0m      0.9092        0.1767        0.0000  99.7819
     10      [36m0.9936[0m        [32m0.0206[0m       0.8569      0.9114        0.1795        0.0000  100.1581
     11      [36m0.9948[0m        [32m0.0182[0m       0.8457      0.9077        0.1952        0.0000  99.3450
     12      [36m0.9957[0m        [32m0.0169[0m       0.8411      0.9051        0.1995        0.0000  100.0947
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.9294950738916254
F1 Macro Score after query 12: 0.9182801559408741
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9825[0m        [32m0.0474[0m       [35m0.8271[0m      [31m0.8790[0m        [94m0.1778[0m     +  0.0000  114.5151
      2      [36m0.9835[0m        [32m0.0398[0m       [35m0.8354[0m      [31m0.8913[0m        [94m0.1735[0m     +  0.0000  113.6843
      3      [36m0.9854[0m        [32m0.0360[0m       [35m0.8413[0m      [31m0.8928[0m        [94m0.1724[0m     +  0.0000  110.4817
      4      [36m0.9863[0m        [32m0.0326[0m       0.8302      0.8798        0.2023        0.0000  111.7197
      5      [36m0.9872[0m        [32m0.0290[0m       0.8286      0.8769        0.2275        0.0000  113.8312
      6      [36m0.9902[0m        [32m0.0234[0m       [35m0.8417[0m      [31m0.8996[0m        0.1889        0.0000  114.6568
      7      [36m0.9919[0m        [32m0.0206[0m       [35m0.8493[0m      [31m0.9047[0m        0.1879        0.0000  113.4085
      8      [36m0.9927[0m        [32m0.0188[0m       0.8460      0.9007        0.1963        0.0000  113.1186
      9      [36m0.9941[0m        [32m0.0168[0m       0.8488      0.9046        0.1951        0.0000  113.4224
     10      [36m0.9947[0m        [32m0.0152[0m       [35m0.8502[0m      0.9043        0.1964        0.0000  114.8215
     11      [36m0.9959[0m        [32m0.0136[0m       [35m0.8545[0m      [31m0.9116[0m        0.1983        0.0000  114.5155
     12      [36m0.9964[0m        [32m0.0123[0m       0.8481      0.9080        0.2063        0.0000  114.7293
     13      [36m0.9970[0m        [32m0.0114[0m       0.8491      0.9095        0.2144        0.0000  114.6936
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.9339796860572485
F1 Macro Score after query 13: 0.9219362862114284
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_lowLR\AL_average_score_results_for_multilabel_classification_s43.pickle
