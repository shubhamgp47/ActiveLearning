Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5152[0m        [32m0.7299[0m       [35m0.0061[0m      [31m0.6298[0m        [94m0.7097[0m     +  0.0000  14.5985
      2      0.4924        [32m0.6640[0m       [35m0.0769[0m      0.5615        [94m0.6983[0m     +  0.0000  10.4336
      3      [36m0.5556[0m        [32m0.6529[0m       [35m0.2003[0m      0.2952        [94m0.6960[0m     +  0.0000  11.0520
      4      [36m0.7146[0m        [32m0.6185[0m       [35m0.2849[0m      0.3663        [94m0.6905[0m     +  0.0000  10.9892
      5      [36m0.7685[0m        [32m0.6058[0m       [35m0.2988[0m      0.3867        [94m0.6894[0m     +  0.0000  10.7679
      6      [36m0.8690[0m        [32m0.5623[0m       [35m0.3146[0m      0.3911        [94m0.6892[0m     +  0.0000  10.9814
      7      0.7024        0.5662       0.3095      0.3967        0.6905        0.0000  10.9220
      8      [36m0.9153[0m        0.5654       [35m0.3160[0m      0.3987        [94m0.6871[0m     +  0.0000  11.0796
      9      0.8519        [32m0.5385[0m       [35m0.3201[0m      0.4022        0.6875        0.0000  10.9838
     10      0.7500        0.5809       0.2981      0.3964        0.6919        0.0000  11.0049
     11      0.8056        [32m0.5338[0m       0.2977      0.3974        0.6923        0.0000  10.9661
     12      0.9153        0.5491       0.3028      0.3984        0.6925        0.0000  11.0340
     13      0.8889        [32m0.5282[0m       0.3064      0.3979        0.6915        0.0000  11.0619
     14      0.8333        0.5388       0.3099      0.3976        0.6910        0.0000  10.9721
     15      0.8413        0.5354       0.3071      0.3975        0.6921        0.0000  10.8414
     16      [36m0.9630[0m        [32m0.5129[0m       0.3071      0.3974        0.6922        0.0000  11.3794
     17      0.8571        0.5212       0.3083      0.3974        0.6920        0.0000  11.0204
     18      0.9524        0.5348       0.3036      0.3958        0.6930        0.0000  10.9117
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4454
Pre F1 macro score = 0.4359
Pre Accuracy = 0.3345

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6216[0m        [32m0.6087[0m       [35m0.3481[0m      [31m0.1710[0m        [94m0.6383[0m     +  0.0000  11.0938
      2      0.2963        [32m0.5345[0m       0.3309      [31m0.1777[0m        0.6407        0.0000  11.2510
      3      0.3063        [32m0.4747[0m       0.3352      [31m0.1877[0m        0.6482        0.0000  11.2292
      4      0.4396        0.4750       0.3316      [31m0.5310[0m        0.6517        0.0000  11.1414
      5      [36m0.6619[0m        [32m0.4079[0m       0.3392      0.1834        0.6436        0.0000  11.1551
      6      0.5730        [32m0.4035[0m       0.3365      0.1928        0.6460        0.0000  11.0758
      7      0.6603        [32m0.3961[0m       0.3356      0.1969        0.6458        0.0000  10.9533
      8      0.5730        0.3977       0.3377      0.1976        0.6455        0.0000  11.0038
      9      0.5730        [32m0.3865[0m       0.3401      0.2020        0.6450        0.0000  10.8563
     10      [36m0.7593[0m        [32m0.3657[0m       0.3399      0.2074        0.6451        0.0000  10.7608
     11      0.5630        [32m0.3653[0m       0.3363      [31m0.5405[0m        0.6454        0.0000  11.0656
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.38993972147162753
F1 Macro Score after query 1: 0.23640590519777413
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5434[0m        [32m0.5512[0m       [35m0.4493[0m      [31m0.0135[0m        [94m0.6498[0m     +  0.0000  11.1384
      2      0.2373        [32m0.4769[0m       0.4479      [31m0.0158[0m        0.6512        0.0000  11.4183
      3      0.4779        [32m0.4246[0m       0.4483      [31m0.0275[0m        0.6525        0.0000  10.9833
      4      0.4606        [32m0.4043[0m       [35m0.4556[0m      [31m0.4003[0m        [94m0.6347[0m     +  0.0000  11.1831
      5      [36m0.6478[0m        [32m0.3685[0m       [35m0.4729[0m      [31m0.4487[0m        [94m0.6229[0m     +  0.0000  11.1521
      6      0.5084        [32m0.3531[0m       [35m0.4818[0m      0.1524        [94m0.6177[0m     +  0.0000  11.1047
      7      [36m0.6543[0m        [32m0.3293[0m       0.4795      0.1548        [94m0.6143[0m     +  0.0000  11.1094
      8      0.5650        [32m0.3247[0m       0.4783      0.1583        [94m0.6132[0m     +  0.0000  11.2292
      9      [36m0.7264[0m        [32m0.3197[0m       0.4762      0.1765        [94m0.6097[0m     +  0.0000  11.0145
     10      0.6443        [32m0.3138[0m       0.4759      0.1771        [94m0.6049[0m     +  0.0000  11.1450
     11      [36m0.7778[0m        [32m0.3019[0m       0.4759      0.1798        [94m0.6042[0m     +  0.0000  11.1350
     12      0.7778        0.3043       0.4764      0.1828        0.6042        0.0000  11.3067
     13      0.6765        [32m0.3013[0m       0.4773      0.1893        [94m0.6015[0m     +  0.0000  11.3283
     14      0.6761        [32m0.2971[0m       0.4774      0.1957        [94m0.6014[0m     +  0.0000  11.4691
     15      0.7567        [32m0.2905[0m       0.4752      0.2039        [94m0.5991[0m     +  0.0000  11.2544
     16      0.7167        0.2942       0.4753      0.2050        [94m0.5984[0m     +  0.0000  11.2377
     17      [36m0.7993[0m        [32m0.2878[0m       0.4755      0.2045        0.5987        0.0000  10.9705
     18      0.7031        0.2983       0.4759      0.2077        [94m0.5977[0m     +  0.0000  11.2090
     19      [36m0.8456[0m        0.2918       0.4753      0.2098        0.5979        0.0000  11.1561
     20      [36m0.8585[0m        [32m0.2840[0m       0.4745      0.2072        0.5984        0.0000  11.1858
     21      0.7993        [32m0.2825[0m       0.4747      0.2076        0.5981        0.0000  11.1874
     22      0.8238        0.2917       0.4745      0.2076        0.5981        0.0000  10.9978
     23      0.8585        0.2829       0.4747      0.2068        0.5982        0.0000  11.6119
     24      [36m0.8713[0m        0.2944       0.4747      0.2078        0.5979        0.0000  11.3197
     25      0.7762        [32m0.2796[0m       0.4747      0.2083        0.5979        0.0000  11.1374
     26      0.8713        0.2829       0.4747      0.2082        0.5978        0.0000  11.2498
     27      0.7106        0.2819       0.4745      0.2090        [94m0.5976[0m     +  0.0000  11.5467
     28      0.8301        0.2895       0.4745      0.2099        [94m0.5975[0m     +  0.0000  10.9671
     29      0.8519        0.2897       0.4747      0.2097        0.5975        0.0000  11.1897
     30      0.8519        [32m0.2788[0m       0.4750      0.2094        [94m0.5974[0m     +  0.0000  11.3557
     31      0.8585        0.2924       0.4750      0.2094        0.5974        0.0000  10.9266
     32      0.8390        0.2984       0.4750      0.2094        0.5974        0.0000  10.9211
     33      0.8056        0.2882       0.4750      0.2094        [94m0.5973[0m     +  0.0000  11.1060
     34      0.8238        0.2814       0.4750      0.2094        [94m0.5973[0m     +  0.0000  11.1119
     35      0.8238        0.2943       0.4750      0.2098        [94m0.5972[0m     +  0.0000  11.3490
     36      0.7167        0.2969       0.4752      0.2101        [94m0.5971[0m     +  0.0000  10.8837
     37      0.7937        0.2848       0.4750      0.2102        [94m0.5971[0m     +  0.0000  11.2565
     38      0.7412        [32m0.2693[0m       0.4750      0.2100        0.5972        0.0000  10.8066
     39      0.8456        0.2848       0.4750      0.2102        [94m0.5971[0m     +  0.0000  11.1616
     40      0.7104        0.2849       0.4750      0.2102        [94m0.5971[0m     +  0.0000  11.3906
     41      0.7993        0.2841       0.4750      0.2102        [94m0.5971[0m     +  0.0000  10.7936
     42      0.8456        0.2865       0.4750      0.2102        [94m0.5971[0m     +  0.0000  11.0610
     43      0.7349        0.2986       0.4750      0.2102        [94m0.5971[0m     +  0.0000  11.4619
     44      0.8301        0.2928       0.4750      0.2103        [94m0.5971[0m     +  0.0000  10.9164
     45      0.8519        0.2942       0.4750      0.2104        [94m0.5971[0m     +  0.0000  10.8180
     46      0.7630        0.2787       0.4750      0.2104        [94m0.5971[0m     +  0.0000  11.3577
     47      0.7569        0.2853       0.4750      0.2104        [94m0.5971[0m     +  0.0000  11.0003
     48      0.8713        0.2769       0.4750      0.2104        [94m0.5971[0m     +  0.0000  11.3153
     49      0.7567        0.2795       0.4750      0.2104        [94m0.5971[0m     +  0.0000  11.2835
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.3638861138861139
F1 Macro Score after query 2: 0.28378854966534234
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6771[0m        [32m0.3742[0m       [35m0.5240[0m      [31m0.3571[0m        [94m0.5799[0m     +  0.0000  11.7584
      2      [36m0.7435[0m        [32m0.2966[0m       0.4970      [31m0.3912[0m        [94m0.5697[0m     +  0.0000  11.3852
      3      [36m0.8103[0m        [32m0.2722[0m       0.4986      0.3823        [94m0.5592[0m     +  0.0000  11.4474
      4      [36m0.8128[0m        [32m0.2558[0m       0.5097      0.3729        [94m0.5515[0m     +  0.0000  11.9629
      5      0.7500        [32m0.2390[0m       0.4988      [31m0.4074[0m        [94m0.5402[0m     +  0.0000  11.3377
      6      [36m0.8148[0m        [32m0.2303[0m       0.5038      0.3944        0.5417        0.0000  11.8363
      7      0.7500        [32m0.2222[0m       0.4979      0.4025        0.5406        0.0000  11.6334
      8      0.7500        [32m0.2213[0m       0.5016      0.3997        0.5403        0.0000  11.6312
      9      0.7500        [32m0.2165[0m       0.5007      [31m0.4171[0m        [94m0.5338[0m     +  0.0000  11.4143
     10      0.8148        [32m0.2156[0m       0.4997      0.4157        0.5342        0.0000  11.5088
     11      0.8148        [32m0.2131[0m       0.4943      [31m0.4292[0m        [94m0.5315[0m     +  0.0000  10.9764
     12      0.8148        0.2186       0.4943      0.4170        0.5343        0.0000  11.5710
     13      0.7500        [32m0.2035[0m       0.4981      0.4165        0.5327        0.0000  11.4304
     14      0.7500        0.2098       0.4977      0.4238        0.5319        0.0000  11.3506
     15      0.8148        0.2072       0.4960      0.4238        0.5317        0.0000  11.9294
     16      0.8148        [32m0.2020[0m       0.4967      [31m0.4305[0m        [94m0.5300[0m     +  0.0000  11.9768
     17      0.8148        [32m0.2007[0m       0.4957      [31m0.4337[0m        [94m0.5296[0m     +  0.0000  11.6803
     18      [36m0.8667[0m        [32m0.1966[0m       0.4946      [31m0.4340[0m        0.5300        0.0000  11.5877
     19      0.8667        0.2055       0.4944      [31m0.4374[0m        [94m0.5291[0m     +  0.0000  11.5227
     20      0.8667        0.2023       0.4965      0.4358        [94m0.5286[0m     +  0.0000  11.3825
     21      0.8148        [32m0.1943[0m       0.4965      0.4361        [94m0.5284[0m     +  0.0000  11.3014
     22      0.8667        0.2040       0.4953      0.4351        0.5289        0.0000  11.4770
     23      0.8148        0.2025       0.4953      0.4355        0.5290        0.0000  11.3217
     24      0.8148        0.2048       0.4951      0.4357        0.5288        0.0000  11.3050
     25      0.8667        0.1966       0.4951      0.4367        [94m0.5283[0m     +  0.0000  11.6316
     26      0.8148        0.2050       0.4951      0.4367        [94m0.5283[0m     +  0.0000  11.4607
     27      0.8148        0.1992       0.4955      0.4363        0.5283        0.0000  11.8215
     28      0.8148        [32m0.1887[0m       0.4955      0.4359        0.5286        0.0000  11.3675
     29      0.8148        0.2050       0.4948      0.4366        0.5283        0.0000  11.6177
     30      0.7500        0.2110       0.4955      0.4361        0.5285        0.0000  10.9742
     31      0.8148        0.2005       0.4955      0.4363        0.5285        0.0000  11.0035
     32      0.8148        0.2075       0.4955      0.4359        0.5285        0.0000  11.8811
     33      0.8148        0.2030       0.4957      0.4363        0.5284        0.0000  11.3165
     34      0.8148        0.1990       0.4955      0.4358        0.5284        0.0000  11.6155
     35      0.8148        0.2118       0.4957      0.4356        0.5283        0.0000  11.5069
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.5793030623020063
F1 Macro Score after query 3: 0.483853176765155
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8842[0m        [32m0.2196[0m       [35m0.5134[0m      [31m0.5548[0m        [94m0.5083[0m     +  0.0000  11.8827
      2      [36m0.9231[0m        [32m0.1901[0m       [35m0.5161[0m      [31m0.5731[0m        [94m0.4980[0m     +  0.0000  11.8521
      3      0.8485        [32m0.1856[0m       [35m0.5373[0m      [31m0.6091[0m        [94m0.4850[0m     +  0.0000  12.0091
      4      0.9231        [32m0.1808[0m       0.5198      0.5730        0.4919        0.0000  12.1804
      5      0.8889        [32m0.1768[0m       0.5337      0.5820        [94m0.4789[0m     +  0.0000  11.8366
      6      0.8889        [32m0.1704[0m       0.5363      [31m0.6101[0m        [94m0.4691[0m     +  0.0000  11.4927
      7      [36m0.9524[0m        [32m0.1701[0m       0.5285      0.6066        0.4715        0.0000  11.6976
      8      [36m0.9778[0m        0.1712       0.5281      [31m0.6125[0m        0.4696        0.0000  11.8373
      9      0.9778        [32m0.1698[0m       0.5292      0.6057        0.4706        0.0000  11.4925
     10      0.9524        [32m0.1688[0m       0.5330      [31m0.6147[0m        [94m0.4659[0m     +  0.0000  11.8205
     11      0.9524        [32m0.1660[0m       0.5328      0.6128        [94m0.4658[0m     +  0.0000  11.6005
     12      0.9778        [32m0.1614[0m       0.5349      [31m0.6163[0m        [94m0.4638[0m     +  0.0000  11.5075
     13      0.9778        0.1649       0.5359      0.6141        [94m0.4631[0m     +  0.0000  12.0241
     14      0.9524        0.1622       0.5351      0.6110        0.4634        0.0000  11.8222
     15      0.9778        0.1620       0.5352      [31m0.6173[0m        [94m0.4616[0m     +  0.0000  11.8369
     16      0.9778        [32m0.1607[0m       0.5351      0.6108        0.4625        0.0000  12.2278
     17      0.9524        0.1614       0.5363      0.6160        [94m0.4615[0m     +  0.0000  12.1349
     18      0.9524        0.1618       0.5356      0.6136        [94m0.4615[0m     +  0.0000  11.6491
     19      0.9524        0.1634       [35m0.5392[0m      [31m0.6213[0m        [94m0.4592[0m     +  0.0000  11.9145
     20      0.9524        0.1638       0.5384      0.6182        0.4595        0.0000  12.1351
     21      0.9778        0.1611       0.5384      0.6156        0.4601        0.0000  11.7566
     22      0.9778        0.1625       0.5368      0.6131        0.4606        0.0000  12.0123
     23      0.9778        [32m0.1600[0m       0.5392      0.6192        [94m0.4591[0m     +  0.0000  11.9302
     24      0.9778        0.1614       [35m0.5394[0m      0.6183        [94m0.4590[0m     +  0.0000  11.7114
     25      0.9524        0.1675       0.5385      0.6183        [94m0.4588[0m     +  0.0000  11.7436
     26      0.9778        [32m0.1588[0m       0.5387      0.6187        0.4589        0.0000  11.5873
     27      0.9778        0.1591       0.5387      0.6186        0.4589        0.0000  11.4574
     28      0.9778        0.1641       0.5385      0.6190        [94m0.4587[0m     +  0.0000  11.9785
     29      0.9778        0.1628       0.5391      0.6203        [94m0.4584[0m     +  0.0000  11.6643
     30      0.9778        0.1618       0.5389      0.6196        0.4585        0.0000  11.9789
     31      0.9778        [32m0.1578[0m       0.5391      0.6207        [94m0.4582[0m     +  0.0000  11.6471
     32      0.9524        0.1596       0.5389      0.6206        0.4582        0.0000  12.6175
     33      0.9524        0.1598       0.5392      0.6212        [94m0.4582[0m     +  0.0000  11.9002
     34      0.9778        0.1633       0.5392      0.6210        0.4582        0.0000  11.6952
     35      0.9778        0.1632       0.5387      0.6202        0.4584        0.0000  12.0714
     36      0.9778        0.1639       0.5391      0.6207        0.4583        0.0000  11.8533
     37      0.9778        0.1607       0.5387      0.6202        0.4584        0.0000  12.2072
     38      0.9778        0.1616       0.5391      0.6204        0.4584        0.0000  11.8675
     39      0.9778        [32m0.1572[0m       0.5389      0.6203        0.4584        0.0000  12.0043
     40      0.9524        0.1583       0.5389      0.6203        0.4583        0.0000  11.6492
     41      0.9778        0.1662       0.5389      0.6203        0.4584        0.0000  11.6944
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.7032512685585416
F1 Macro Score after query 4: 0.6490592033670243
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9908[0m        [32m0.2070[0m       [35m0.4208[0m      [31m0.7211[0m        [94m0.5377[0m     +  0.0000  12.4312
      2      [36m0.9939[0m        [32m0.1857[0m       [35m0.5403[0m      [31m0.7556[0m        [94m0.4788[0m     +  0.0000  12.6041
      3      [36m0.9963[0m        [32m0.1736[0m       [35m0.5825[0m      [31m0.7646[0m        [94m0.4496[0m     +  0.0000  12.5863
      4      [36m0.9968[0m        [32m0.1669[0m       [35m0.5965[0m      [31m0.7654[0m        [94m0.4359[0m     +  0.0000  12.6336
      5      [36m0.9986[0m        [32m0.1579[0m       0.5943      [31m0.7662[0m        [94m0.4315[0m     +  0.0000  12.8531
      6      0.9959        [32m0.1558[0m       [35m0.6106[0m      0.7499        [94m0.4107[0m     +  0.0000  12.5292
      7      0.9968        [32m0.1509[0m       [35m0.6205[0m      0.7524        [94m0.4078[0m     +  0.0000  12.4463
      8      0.9977        0.1528       [35m0.6229[0m      0.7509        [94m0.4060[0m     +  0.0000  12.2418
      9      0.9954        [32m0.1498[0m       [35m0.6307[0m      0.7561        [94m0.4018[0m     +  0.0000  12.8221
     10      0.9972        [32m0.1494[0m       [35m0.6311[0m      0.7600        [94m0.3992[0m     +  0.0000  12.4309
     11      0.9982        0.1506       0.6299      0.7479        [94m0.3986[0m     +  0.0000  12.5559
     12      [36m0.9991[0m        [32m0.1474[0m       [35m0.6328[0m      0.7511        [94m0.3982[0m     +  0.0000  12.2887
     13      0.9982        0.1489       0.6318      0.7512        [94m0.3972[0m     +  0.0000  12.4936
     14      0.9968        [32m0.1454[0m       [35m0.6352[0m      0.7536        [94m0.3966[0m     +  0.0000  12.5721
     15      0.9972        0.1458       0.6307      0.7501        0.3970        0.0000  12.5411
     16      [36m0.9995[0m        0.1464       0.6330      0.7497        0.3969        0.0000  12.6795
     17      0.9982        [32m0.1430[0m       0.6325      0.7498        0.3971        0.0000  12.3522
     18      [36m0.9995[0m        0.1447       [35m0.6377[0m      0.7542        [94m0.3961[0m     +  0.0000  12.6787
     19      0.9968        0.1458       0.6356      0.7530        [94m0.3960[0m     +  0.0000  13.0101
     20      [36m1.0000[0m        0.1430       0.6366      0.7536        0.3961        0.0000  12.6959
     21      1.0000        [32m0.1397[0m       0.6358      0.7526        [94m0.3960[0m     +  0.0000  12.3525
     22      0.9977        0.1424       0.6345      0.7516        0.3961        0.0000  12.5562
     23      0.9991        0.1450       0.6352      0.7518        0.3962        0.0000  12.6795
     24      0.9972        0.1419       0.6352      0.7520        0.3964        0.0000  12.3067
     25      0.9991        0.1464       0.6354      0.7517        0.3962        0.0000  12.5074
     26      1.0000        0.1412       0.6351      0.7515        0.3962        0.0000  11.9402
     27      1.0000        0.1456       0.6354      0.7515        0.3962        0.0000  12.5540
     28      0.9991        0.1436       0.6354      0.7516        0.3961        0.0000  12.4145
     29      1.0000        0.1455       0.6352      0.7517        0.3961        0.0000  12.8697
     30      0.9982        0.1423       0.6356      0.7518        [94m0.3960[0m     +  0.0000  12.4919
     31      0.9991        0.1413       0.6359      0.7521        0.3960        0.0000  12.0038
     32      1.0000        0.1439       0.6365      0.7523        0.3960        0.0000  12.6796
     33      0.9991        0.1461       0.6349      0.7512        0.3960        0.0000  12.6942
     34      0.9991        0.1410       0.6351      0.7513        0.3960        0.0000  12.3510
     35      0.9991        0.1424       0.6359      0.7521        [94m0.3959[0m     +  0.0000  12.4935
     36      1.0000        0.1405       0.6352      0.7516        0.3959        0.0000  12.7116
     37      0.9991        0.1465       0.6359      0.7521        [94m0.3959[0m     +  0.0000  12.4618
     38      0.9991        0.1429       0.6358      0.7519        0.3959        0.0000  12.2895
     39      0.9986        0.1424       0.6354      0.7518        0.3959        0.0000  12.5748
     40      1.0000        0.1420       0.6358      0.7521        [94m0.3959[0m     +  0.0000  12.4756
     41      0.9991        0.1406       0.6358      0.7521        [94m0.3959[0m     +  0.0000  12.8849
     42      0.9986        0.1441       0.6358      0.7519        0.3959        0.0000  12.6497
     43      0.9977        0.1403       0.6358      0.7519        0.3959        0.0000  12.3664
     44      0.9982        0.1402       0.6356      0.7518        0.3959        0.0000  12.1785
     45      0.9991        0.1400       0.6356      0.7518        0.3959        0.0000  12.3510
     46      0.9991        0.1429       0.6356      0.7518        0.3959        0.0000  12.4568
     47      0.9982        0.1439       0.6356      0.7518        0.3959        0.0000  12.9722
     48      0.9995        0.1432       0.6354      0.7516        0.3959        0.0000  12.8983
     49      0.9991        0.1414       0.6352      0.7514        0.3959        0.0000  12.3524
     50      1.0000        0.1410       0.6354      0.7515        0.3959        0.0000  12.1499
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.8513830285982185
F1 Macro Score after query 5: 0.8310283317609404
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9927[0m        [32m0.1637[0m       [35m0.5587[0m      [31m0.7652[0m        [94m0.4248[0m     +  0.0000  13.6362
      2      [36m0.9949[0m        [32m0.1484[0m       [35m0.6073[0m      [31m0.7745[0m        [94m0.3954[0m     +  0.0000  13.6512
      3      0.9943        [32m0.1416[0m       0.6068      [31m0.7796[0m        [94m0.3901[0m     +  0.0000  13.6335
      4      [36m0.9957[0m        [32m0.1394[0m       0.6040      [31m0.7807[0m        [94m0.3889[0m     +  0.0000  14.2742
      5      0.9956        [32m0.1371[0m       [35m0.6189[0m      [31m0.7856[0m        [94m0.3846[0m     +  0.0000  13.8384
      6      [36m0.9968[0m        [32m0.1304[0m       [35m0.6330[0m      [31m0.7866[0m        [94m0.3674[0m     +  0.0000  13.6973
      7      0.9966        0.1332       [35m0.6363[0m      0.7835        0.3686        0.0000  13.7743
      8      [36m0.9973[0m        [32m0.1271[0m       [35m0.6403[0m      0.7865        [94m0.3657[0m     +  0.0000  13.8381
      9      0.9973        [32m0.1270[0m       0.6389      [31m0.7869[0m        [94m0.3642[0m     +  0.0000  13.7437
     10      0.9973        0.1302       0.6351      [31m0.7893[0m        [94m0.3625[0m     +  0.0000  13.6979
     11      0.9973        [32m0.1249[0m       0.6378      0.7856        [94m0.3618[0m     +  0.0000  14.2604
     12      [36m0.9976[0m        [32m0.1241[0m       0.6392      0.7858        [94m0.3607[0m     +  0.0000  14.1351
     13      0.9974        [32m0.1230[0m       0.6337      [31m0.7894[0m        0.3609        0.0000  14.1997
     14      0.9973        [32m0.1210[0m       [35m0.6417[0m      0.7884        [94m0.3590[0m     +  0.0000  13.9273
     15      0.9973        0.1218       0.6405      [31m0.7900[0m        0.3599        0.0000  13.6373
     16      0.9971        0.1226       0.6401      0.7860        0.3598        0.0000  14.1283
     17      0.9973        0.1216       0.6408      0.7880        0.3592        0.0000  13.7593
     18      0.9976        0.1217       0.6408      0.7892        [94m0.3589[0m     +  0.0000  13.5781
     19      0.9976        [32m0.1205[0m       0.6413      0.7884        [94m0.3588[0m     +  0.0000  13.9971
     20      0.9976        [32m0.1195[0m       0.6413      0.7887        [94m0.3582[0m     +  0.0000  13.5439
     21      0.9976        0.1210       [35m0.6420[0m      0.7883        [94m0.3578[0m     +  0.0000  13.5876
     22      0.9974        [32m0.1190[0m       [35m0.6425[0m      0.7890        [94m0.3577[0m     +  0.0000  13.7076
     23      0.9976        0.1225       0.6425      0.7897        [94m0.3574[0m     +  0.0000  13.5554
     24      0.9976        0.1210       [35m0.6431[0m      0.7897        [94m0.3572[0m     +  0.0000  13.5425
     25      0.9976        0.1211       [35m0.6438[0m      [31m0.7904[0m        0.3572        0.0000  13.5546
     26      0.9976        0.1212       0.6432      0.7900        0.3572        0.0000  13.4632
     27      0.9976        [32m0.1175[0m       0.6438      0.7900        [94m0.3571[0m     +  0.0000  13.7410
     28      [36m0.9980[0m        [32m0.1166[0m       [35m0.6439[0m      0.7902        [94m0.3570[0m     +  0.0000  13.7063
     29      0.9976        0.1225       0.6439      0.7901        0.3571        0.0000  13.6306
     30      0.9976        0.1216       0.6438      0.7899        [94m0.3570[0m     +  0.0000  13.8355
     31      0.9976        0.1214       0.6438      0.7899        0.3570        0.0000  13.5295
     32      0.9980        0.1226       0.6439      0.7901        0.3570        0.0000  13.8283
     33      0.9976        0.1192       0.6436      0.7901        0.3570        0.0000  13.8640
     34      0.9976        0.1226       0.6436      0.7900        0.3570        0.0000  13.7903
     35      0.9976        0.1202       0.6434      0.7899        0.3570        0.0000  13.5151
     36      0.9973        0.1201       0.6434      0.7899        0.3570        0.0000  13.9217
     37      0.9976        0.1206       0.6434      0.7899        0.3570        0.0000  13.6496
     38      0.9976        0.1184       0.6434      0.7899        0.3570        0.0000  13.4046
     39      0.9976        0.1201       0.6434      0.7899        0.3570        0.0000  13.5233
     40      0.9976        0.1177       0.6436      0.7900        0.3570        0.0000  13.7733
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8690978886756238
F1 Macro Score after query 6: 0.8561584969078018
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9941[0m        [32m0.1320[0m       [35m0.5066[0m      [31m0.7667[0m        [94m0.4598[0m     +  0.0000  15.7553
      2      [36m0.9943[0m        [32m0.1249[0m       [35m0.5186[0m      [31m0.7879[0m        [94m0.3973[0m     +  0.0000  15.9242
      3      0.9939        [32m0.1162[0m       [35m0.5540[0m      [31m0.8005[0m        [94m0.3767[0m     +  0.0000  16.0624
      4      [36m0.9954[0m        [32m0.1133[0m       0.5453      0.7967        0.3848        0.0000  15.7100
      5      [36m0.9955[0m        [32m0.1097[0m       0.5477      0.7943        0.3809        0.0000  15.9403
      6      [36m0.9955[0m        [32m0.1045[0m       [35m0.6082[0m      [31m0.8100[0m        [94m0.3518[0m     +  0.0000  15.8566
      7      0.9949        0.1045       [35m0.6094[0m      [31m0.8116[0m        [94m0.3455[0m     +  0.0000  16.0760
      8      [36m0.9962[0m        [32m0.1023[0m       [35m0.6134[0m      0.8111        0.3460        0.0000  15.9716
      9      [36m0.9965[0m        [32m0.0979[0m       0.6102      [31m0.8134[0m        [94m0.3455[0m     +  0.0000  15.7232
     10      0.9965        [32m0.0966[0m       0.6094      0.8109        [94m0.3437[0m     +  0.0000  15.8904
     11      0.9960        0.0968       [35m0.6170[0m      0.8125        [94m0.3384[0m     +  0.0000  15.8018
     12      0.9965        [32m0.0957[0m       0.6113      0.8109        0.3413        0.0000  15.9046
     13      [36m0.9971[0m        [32m0.0955[0m       0.6158      0.8113        [94m0.3378[0m     +  0.0000  15.8174
     14      0.9966        [32m0.0951[0m       0.6106      0.8100        0.3416        0.0000  15.6050
     15      0.9965        0.0956       0.6120      0.8115        0.3409        0.0000  15.7832
     16      [36m0.9973[0m        [32m0.0935[0m       0.6130      0.8108        0.3402        0.0000  15.7502
     17      0.9966        0.0937       0.6151      0.8108        0.3389        0.0000  15.4501
     18      0.9968        [32m0.0916[0m       0.6149      0.8110        0.3390        0.0000  15.9656
     19      0.9973        0.0929       0.6163      0.8113        0.3387        0.0000  16.4124
     20      0.9969        0.0944       0.6139      0.8099        0.3388        0.0000  16.2416
     21      0.9969        0.0920       0.6155      0.8106        0.3384        0.0000  15.7750
     22      0.9968        0.0921       0.6156      0.8106        0.3385        0.0000  15.7233
     23      0.9969        [32m0.0915[0m       0.6149      0.8104        0.3386        0.0000  15.5537
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.8539094650205762
F1 Macro Score after query 7: 0.8452753165705239
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9937[0m        [32m0.1043[0m       [35m0.4585[0m      [31m0.7482[0m        [94m0.4708[0m     +  0.0000  19.4222
      2      [36m0.9947[0m        [32m0.0944[0m       [35m0.4969[0m      [31m0.7631[0m        [94m0.4416[0m     +  0.0000  19.7470
      3      [36m0.9950[0m        [32m0.0893[0m       [35m0.5179[0m      [31m0.7709[0m        [94m0.4289[0m     +  0.0000  19.4283
      4      [36m0.9951[0m        [32m0.0836[0m       [35m0.5583[0m      [31m0.7969[0m        [94m0.3740[0m     +  0.0000  19.7033
      5      [36m0.9954[0m        [32m0.0788[0m       [35m0.5993[0m      [31m0.8091[0m        [94m0.3704[0m     +  0.0000  19.6326
      6      [36m0.9971[0m        [32m0.0723[0m       [35m0.6349[0m      [31m0.8210[0m        [94m0.3484[0m     +  0.0000  19.6746
      7      0.9966        [32m0.0703[0m       [35m0.6372[0m      [31m0.8230[0m        [94m0.3390[0m     +  0.0000  19.5176
      8      [36m0.9972[0m        [32m0.0673[0m       [35m0.6401[0m      0.8224        [94m0.3376[0m     +  0.0000  19.7903
      9      [36m0.9975[0m        [32m0.0665[0m       0.6215      0.8155        0.3488        0.0000  19.5623
     10      0.9973        [32m0.0656[0m       0.6217      0.8144        0.3469        0.0000  19.9331
     11      [36m0.9976[0m        [32m0.0624[0m       0.6139      0.8126        0.3500        0.0000  19.3210
     12      [36m0.9978[0m        0.0625       0.6026      0.8086        0.3557        0.0000  19.8323
     13      0.9977        [32m0.0608[0m       0.6078      0.8094        0.3500        0.0000  19.6237
     14      [36m0.9981[0m        [32m0.0597[0m       0.6135      0.8117        0.3484        0.0000  19.7266
     15      0.9979        [32m0.0597[0m       0.6019      0.8068        0.3526        0.0000  19.5578
     16      0.9981        [32m0.0588[0m       0.6005      0.8082        0.3606        0.0000  19.9157
     17      [36m0.9982[0m        [32m0.0577[0m       0.6024      0.8078        0.3572        0.0000  19.7377
     18      [36m0.9984[0m        0.0580       0.6019      0.8079        0.3605        0.0000  19.9264
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8346580737558181
F1 Macro Score after query 8: 0.8295710132011621
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9935[0m        [32m0.0814[0m       [35m0.5439[0m      [31m0.7803[0m        [94m0.4061[0m     +  0.0000  26.8339
      2      [36m0.9947[0m        [32m0.0708[0m       0.4311      0.7289        0.5283        0.0000  26.9784
      3      [36m0.9950[0m        [32m0.0652[0m       0.4736      0.7523        0.4839        0.0000  26.5709
      4      [36m0.9952[0m        [32m0.0585[0m       0.4556      0.7492        0.5130        0.0000  26.6864
      5      [36m0.9954[0m        [32m0.0541[0m       0.4741      0.7500        0.4914        0.0000  27.2908
      6      [36m0.9960[0m        [32m0.0494[0m       0.5347      0.7767        0.4524        0.0000  26.8636
      7      [36m0.9967[0m        [32m0.0467[0m       0.5365      0.7783        0.4557        0.0000  27.1138
      8      [36m0.9967[0m        [32m0.0440[0m       [35m0.5597[0m      [31m0.7880[0m        0.4365        0.0000  26.5023
      9      0.9965        [32m0.0437[0m       [35m0.5615[0m      0.7876        0.4390        0.0000  26.7683
     10      [36m0.9970[0m        [32m0.0421[0m       0.5332      0.7743        0.4720        0.0000  26.6292
     11      [36m0.9972[0m        [32m0.0387[0m       0.5514      0.7828        0.4515        0.0000  26.9880
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8133261397356354
F1 Macro Score after query 9: 0.8124404976937741
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9784[0m        [32m0.1252[0m       [35m0.4976[0m      [31m0.7969[0m        [94m0.3761[0m     +  0.0000  39.1518
      2      [36m0.9846[0m        [32m0.0999[0m       [35m0.5130[0m      [31m0.7993[0m        0.3820        0.0000  39.0421
      3      [36m0.9869[0m        [32m0.0879[0m       0.4707      0.7768        0.4588        0.0000  39.4635
      4      [36m0.9885[0m        [32m0.0791[0m       0.4785      0.7722        0.4678        0.0000  39.1052
      5      [36m0.9895[0m        [32m0.0728[0m       [35m0.5205[0m      0.7970        0.4191        0.0000  39.1667
      6      [36m0.9911[0m        [32m0.0647[0m       [35m0.5569[0m      [31m0.8139[0m        [94m0.3527[0m     +  0.0000  39.4309
      7      [36m0.9920[0m        [32m0.0617[0m       0.5498      0.8121        0.3590        0.0000  39.0772
      8      0.9919        [32m0.0579[0m       [35m0.5611[0m      [31m0.8142[0m        [94m0.3502[0m     +  0.0000  39.7145
      9      [36m0.9923[0m        [32m0.0566[0m       [35m0.5630[0m      [31m0.8160[0m        [94m0.3485[0m     +  0.0000  39.4834
     10      [36m0.9931[0m        [32m0.0549[0m       0.5628      0.8148        0.3549        0.0000  39.1152
     11      [36m0.9932[0m        [32m0.0508[0m       [35m0.5984[0m      [31m0.8253[0m        [94m0.3249[0m     +  0.0000  40.0712
     12      [36m0.9939[0m        [32m0.0493[0m       [35m0.6023[0m      [31m0.8257[0m        [94m0.3219[0m     +  0.0000  39.2900
     13      [36m0.9944[0m        [32m0.0477[0m       0.5920      0.8236        0.3316        0.0000  39.0274
     14      [36m0.9945[0m        [32m0.0470[0m       0.5946      0.8251        0.3327        0.0000  40.4006
     15      [36m0.9945[0m        [32m0.0458[0m       0.5885      0.8230        0.3360        0.0000  39.3827
     16      [36m0.9951[0m        [32m0.0444[0m       [35m0.6071[0m      [31m0.8269[0m        0.3287        0.0000  39.8048
     17      [36m0.9952[0m        [32m0.0435[0m       [35m0.6078[0m      [31m0.8273[0m        0.3282        0.0000  39.0884
     18      [36m0.9954[0m        [32m0.0430[0m       0.6040      0.8262        0.3316        0.0000  38.4609
     19      [36m0.9955[0m        [32m0.0426[0m       0.6012      0.8252        0.3355        0.0000  39.5384
     20      [36m0.9958[0m        [32m0.0420[0m       0.6002      0.8257        0.3369        0.0000  39.4299
     21      [36m0.9959[0m        [32m0.0413[0m       0.6052      0.8267        0.3329        0.0000  39.3228
     22      0.9958        [32m0.0413[0m       0.6052      0.8264        0.3342        0.0000  39.3063
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.85454031916396
F1 Macro Score after query 10: 0.8562669026788924
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9743[0m        [32m0.1114[0m       [35m0.8021[0m      [31m0.8872[0m        [94m0.2114[0m     +  0.0000  61.5754
      2      [36m0.9802[0m        [32m0.0908[0m       0.7977      [31m0.8880[0m        0.2150        0.0000  61.3700
      3      [36m0.9824[0m        [32m0.0803[0m       [35m0.8156[0m      0.8871        [94m0.1972[0m     +  0.0000  61.7144
      4      [36m0.9842[0m        [32m0.0727[0m       [35m0.8307[0m      [31m0.8939[0m        [94m0.1863[0m     +  0.0000  61.7293
      5      [36m0.9853[0m        [32m0.0664[0m       [35m0.8309[0m      0.8913        [94m0.1825[0m     +  0.0000  61.4675
      6      [36m0.9884[0m        [32m0.0574[0m       0.8115      0.8843        0.2049        0.0000  61.7484
      7      [36m0.9888[0m        [32m0.0532[0m       0.8141      0.8849        0.2074        0.0000  61.2909
      8      [36m0.9901[0m        [32m0.0507[0m       0.8127      0.8837        0.2162        0.0000  61.8036
      9      [36m0.9904[0m        [32m0.0480[0m       0.8115      0.8843        0.2166        0.0000  61.6562
     10      [36m0.9913[0m        [32m0.0452[0m       0.8090      0.8836        0.2199        0.0000  61.6482
     11      [36m0.9923[0m        [32m0.0407[0m       0.8059      0.8839        0.2307        0.0000  61.8247
     12      [36m0.9928[0m        [32m0.0403[0m       0.8042      0.8833        0.2305        0.0000  61.5214
     13      [36m0.9931[0m        [32m0.0382[0m       0.8007      0.8824        0.2366        0.0000  61.3587
     14      [36m0.9937[0m        [32m0.0370[0m       0.8009      0.8821        0.2372        0.0000  61.6494
     15      [36m0.9942[0m        [32m0.0363[0m       0.7993      0.8816        0.2408        0.0000  61.2924
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.9149470798751237
F1 Macro Score after query 11: 0.9060625189143613
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9800[0m        [32m0.0659[0m       [35m0.8323[0m      [31m0.9008[0m        [94m0.2162[0m     +  0.0000  101.0391
      2      [36m0.9833[0m        [32m0.0524[0m       0.8219      0.8743        [94m0.1938[0m     +  0.0000  100.0966
      3      [36m0.9849[0m        [32m0.0450[0m       0.8295      0.8854        [94m0.1870[0m     +  0.0000  101.7081
      4      [36m0.9861[0m        [32m0.0398[0m       [35m0.8375[0m      0.8905        0.1925        0.0000  101.2513
      5      [36m0.9866[0m        [32m0.0356[0m       0.8255      0.8896        0.2018        0.0000  101.9189
      6      [36m0.9896[0m        [32m0.0295[0m       0.8245      0.8926        0.2132        0.0000  101.9580
      7      [36m0.9913[0m        [32m0.0260[0m       0.8132      0.8904        0.2415        0.0000  101.3205
      8      [36m0.9923[0m        [32m0.0239[0m       0.8130      0.8897        0.2527        0.0000  101.0520
      9      [36m0.9931[0m        [32m0.0218[0m       0.8031      0.8884        0.2627        0.0000  101.2896
     10      [36m0.9935[0m        [32m0.0202[0m       0.8035      0.8863        0.2645        0.0000  100.9630
     11      [36m0.9951[0m        [32m0.0178[0m       0.8010      0.8861        0.2737        0.0000  101.2370
     12      [36m0.9958[0m        [32m0.0167[0m       0.8023      0.8855        0.2737        0.0000  101.2241
     13      [36m0.9963[0m        [32m0.0155[0m       0.7948      0.8833        0.2849        0.0000  102.1169
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.9123386370459321
F1 Macro Score after query 12: 0.90314468380365
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9848[0m        [32m0.0389[0m       [35m0.8354[0m      [31m0.8838[0m        [94m0.1873[0m     +  0.0000  116.6596
      2      [36m0.9861[0m        [32m0.0343[0m       0.8212      [31m0.8884[0m        0.1912        0.0000  116.5040
      3      [36m0.9879[0m        [32m0.0298[0m       0.8297      0.8840        0.2176        0.0000  111.2547
      4      [36m0.9887[0m        [32m0.0270[0m       0.8260      0.8788        0.2381        0.0000  110.8166
      5      [36m0.9901[0m        [32m0.0238[0m       0.8186      0.8827        0.2700        0.0000  110.8947
      6      [36m0.9916[0m        [32m0.0199[0m       0.8200      0.8847        0.2442        0.0000  110.8756
      7      [36m0.9935[0m        [32m0.0174[0m       0.8135      0.8790        0.2704        0.0000  110.8027
      8      [36m0.9939[0m        [32m0.0155[0m       0.8135      0.8825        0.2662        0.0000  110.8666
      9      [36m0.9947[0m        [32m0.0142[0m       0.8156      [31m0.8891[0m        0.2731        0.0000  110.9844
     10      [36m0.9956[0m        [32m0.0128[0m       0.8099      0.8878        0.2894        0.0000  110.6771
     11      [36m0.9966[0m        [32m0.0111[0m       0.8123      0.8870        0.2800        0.0000  110.9351
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.9222034678533068
F1 Macro Score after query 13: 0.9120145734269581
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed45_lowLR\AL_average_score_results_for_multilabel_classification_s45.pickle
