Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5460[0m        [32m0.7305[0m       [35m0.1863[0m      [31m0.4349[0m        [94m0.7025[0m     +  0.0000  12.8139
      2      [36m0.7190[0m        [32m0.6576[0m       [35m0.2182[0m      0.2878        [94m0.6934[0m     +  0.0000  10.4830
      3      0.6389        [32m0.6449[0m       [35m0.2687[0m      [31m0.4495[0m        [94m0.6918[0m     +  0.0000  10.4041
      4      0.5913        [32m0.6354[0m       [35m0.2983[0m      0.4066        [94m0.6754[0m     +  0.0000  10.7027
      5      [36m0.9048[0m        [32m0.5740[0m       0.2793      [31m0.4647[0m        0.6930        0.0000  10.8724
      6      [36m0.9259[0m        [32m0.5448[0m       0.2785      [31m0.4678[0m        0.6885        0.0000  10.7600
      7      0.8201        [32m0.5390[0m       0.2720      0.4648        0.6880        0.0000  10.7659
      8      0.8320        0.5509       0.2694      [31m0.4776[0m        0.6883        0.0000  10.8596
      9      0.8130        0.5648       0.2823      0.4742        0.6833        0.0000  10.8554
     10      [36m0.9630[0m        [32m0.5210[0m       0.2793      [31m0.4887[0m        0.6835        0.0000  10.7823
     11      0.8796        0.5431       0.2795      0.4866        0.6838        0.0000  10.8020
     12      0.8519        [32m0.5153[0m       0.2839      0.4838        0.6831        0.0000  11.1399
     13      0.9259        [32m0.4990[0m       0.2877      [31m0.4894[0m        0.6845        0.0000  10.9217
     14      0.9259        [32m0.4931[0m       0.2835      [31m0.4896[0m        0.6848        0.0000  11.0159
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.5246
Pre F1 macro score = 0.5115
Pre Accuracy = 0.3703

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9051[0m        [32m0.4961[0m       [35m0.2090[0m      [31m0.5427[0m        [94m0.7671[0m     +  0.0000  11.1409
      2      [36m0.9511[0m        [32m0.4095[0m       0.1825      0.4959        [94m0.7598[0m     +  0.0000  11.0438
      3      [36m0.9581[0m        [32m0.3733[0m       0.1851      0.4980        0.7720        0.0000  10.9217
      4      0.9567        [32m0.3470[0m       0.1844      0.5103        0.7844        0.0000  11.1092
      5      0.9581        [32m0.3354[0m       0.1960      0.4953        0.7729        0.0000  11.0240
      6      0.9581        [32m0.3174[0m       0.1962      0.4838        0.7712        0.0000  10.9863
      7      0.9487        0.3321       0.1882      0.4801        0.7694        0.0000  10.8863
      8      0.9581        [32m0.3058[0m       0.1861      0.4816        0.7649        0.0000  11.0183
      9      [36m0.9662[0m        0.3061       0.1804      0.4772        0.7643        0.0000  11.1310
     10      0.9581        [32m0.3047[0m       0.1802      0.4779        0.7626        0.0000  10.9734
     11      0.9581        [32m0.2920[0m       0.1830      0.4788        0.7616        0.0000  11.1704
     12      0.9662        [32m0.2815[0m       0.1811      0.4779        0.7622        0.0000  11.0590
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.5169984686064318
F1 Macro Score after query 1: 0.49860295555861517
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9839[0m        [32m0.2882[0m       [35m0.2080[0m      [31m0.5201[0m        [94m0.8635[0m     +  0.0000  11.2356
      2      0.9808        [32m0.2251[0m       0.1960      0.5135        [94m0.8591[0m     +  0.0000  11.2473
      3      0.9808        [32m0.2115[0m       0.1823      0.4961        0.8620        0.0000  11.1590
      4      0.9808        [32m0.2065[0m       0.1837      0.4749        [94m0.8326[0m     +  0.0000  11.2044
      5      0.9839        [32m0.1765[0m       0.2031      0.4702        [94m0.8206[0m     +  0.0000  11.0159
      6      0.9839        0.1794       0.2036      0.4704        [94m0.8152[0m     +  0.0000  11.1310
      7      [36m0.9871[0m        [32m0.1693[0m       0.2019      0.4723        [94m0.8060[0m     +  0.0000  10.9818
      8      0.9808        0.1709       0.2014      0.4710        [94m0.8006[0m     +  0.0000  11.0761
      9      0.9839        0.1714       0.2035      0.4729        [94m0.7956[0m     +  0.0000  11.1717
     10      0.9840        [32m0.1631[0m       0.2040      0.4740        [94m0.7913[0m     +  0.0000  11.0047
     11      0.9871        0.1649       0.2047      0.4754        [94m0.7891[0m     +  0.0000  11.1434
     12      0.9871        [32m0.1610[0m       0.2031      0.4765        [94m0.7883[0m     +  0.0000  10.9985
     13      0.9871        0.1652       0.2066      0.4778        [94m0.7856[0m     +  0.0000  11.3396
     14      0.9871        0.1662       0.2069      0.4789        [94m0.7837[0m     +  0.0000  11.2527
     15      0.9871        0.1634       0.2068      0.4798        [94m0.7817[0m     +  0.0000  11.0416
     16      0.9871        0.1687       0.2066      0.4800        [94m0.7801[0m     +  0.0000  11.0463
     17      0.9871        0.1636       0.2069      0.4804        [94m0.7798[0m     +  0.0000  10.9881
     18      0.9840        [32m0.1565[0m       0.2068      0.4806        [94m0.7789[0m     +  0.0000  11.0783
     19      0.9871        0.1675       0.2071      0.4813        [94m0.7777[0m     +  0.0000  11.0335
     20      0.9871        0.1655       0.2062      0.4809        [94m0.7775[0m     +  0.0000  10.9998
     21      0.9871        [32m0.1489[0m       0.2062      0.4810        [94m0.7772[0m     +  0.0000  11.0924
     22      0.9871        0.1524       0.2064      0.4812        [94m0.7770[0m     +  0.0000  11.1610
     23      0.9871        0.1644       0.2061      0.4809        0.7770        0.0000  11.0784
     24      0.9871        0.1570       0.2061      0.4812        [94m0.7763[0m     +  0.0000  11.4407
     25      0.9871        0.1706       0.2061      0.4813        [94m0.7761[0m     +  0.0000  11.2034
     26      0.9871        0.1587       0.2064      0.4815        [94m0.7757[0m     +  0.0000  11.1601
     27      0.9871        0.1674       0.2062      0.4814        [94m0.7755[0m     +  0.0000  11.1653
     28      0.9871        0.1709       0.2062      0.4816        [94m0.7753[0m     +  0.0000  11.0624
     29      0.9871        0.1628       0.2061      0.4816        [94m0.7751[0m     +  0.0000  10.9687
     30      0.9871        0.1585       0.2059      0.4818        [94m0.7749[0m     +  0.0000  11.0782
     31      0.9871        0.1531       0.2059      0.4818        [94m0.7749[0m     +  0.0000  10.9162
     32      0.9871        0.1612       0.2059      0.4818        [94m0.7748[0m     +  0.0000  11.2245
     33      0.9871        0.1557       0.2059      0.4818        0.7749        0.0000  11.1095
     34      0.9871        0.1544       0.2061      0.4819        [94m0.7748[0m     +  0.0000  11.1407
     35      0.9839        0.1597       0.2059      0.4818        [94m0.7748[0m     +  0.0000  11.3586
     36      0.9871        0.1659       0.2059      0.4818        [94m0.7748[0m     +  0.0000  11.1455
     37      0.9871        0.1606       0.2059      0.4818        [94m0.7748[0m     +  0.0000  11.1820
     38      0.9871        0.1522       0.2059      0.4818        [94m0.7747[0m     +  0.0000  11.0875
     39      0.9871        0.1630       0.2059      0.4818        [94m0.7747[0m     +  0.0000  11.0452
     40      0.9871        0.1614       0.2059      0.4818        [94m0.7747[0m     +  0.0000  11.1556
     41      0.9871        0.1561       0.2059      0.4818        [94m0.7747[0m     +  0.0000  11.0781
     42      0.9871        0.1703       0.2059      0.4818        [94m0.7747[0m     +  0.0000  11.2635
     43      0.9871        0.1619       0.2059      0.4818        [94m0.7747[0m     +  0.0000  11.1367
     44      0.9871        0.1583       0.2059      0.4818        [94m0.7747[0m     +  0.0000  11.1731
     45      0.9871        0.1646       0.2059      0.4818        [94m0.7746[0m     +  0.0000  11.0620
     46      0.9871        0.1624       0.2059      0.4818        [94m0.7746[0m     +  0.0000  11.1097
     47      [36m0.9903[0m        0.1497       0.2059      0.4818        0.7746        0.0000  11.2354
     48      0.9839        0.1602       0.2059      0.4818        [94m0.7746[0m     +  0.0000  11.0030
     49      0.9871        0.1563       0.2059      0.4819        [94m0.7746[0m     +  0.0000  11.1301
     50      0.9871        0.1554       0.2059      0.4819        [94m0.7746[0m     +  0.0000  11.1919
     51      0.9871        0.1613       0.2059      0.4819        [94m0.7746[0m     +  0.0000  11.1269
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.5167210691630227
F1 Macro Score after query 2: 0.4982660431252503
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9890[0m        [32m0.1663[0m       [35m0.2083[0m      [31m0.5468[0m        [94m0.7922[0m     +  0.0000  11.7975
      2      0.9890        [32m0.1448[0m       [35m0.2120[0m      0.4968        [94m0.7787[0m     +  0.0000  11.7183
      3      0.9890        [32m0.1443[0m       0.2066      0.4959        [94m0.7650[0m     +  0.0000  11.6181
      4      0.9890        [32m0.1372[0m       0.2042      0.4931        0.7662        0.0000  11.6082
      5      [36m0.9906[0m        [32m0.1351[0m       0.2068      0.4940        [94m0.7622[0m     +  0.0000  11.5937
      6      0.9890        [32m0.1209[0m       0.2057      0.4907        0.7673        0.0000  11.6248
      7      0.9890        0.1224       0.2031      0.4908        0.7642        0.0000  11.6169
      8      0.9890        0.1266       0.2047      0.4951        [94m0.7548[0m     +  0.0000  11.5439
      9      0.9890        0.1264       0.2038      0.4949        [94m0.7538[0m     +  0.0000  11.4228
     10      0.9890        [32m0.1185[0m       0.2056      0.4959        [94m0.7486[0m     +  0.0000  11.4524
     11      0.9906        0.1193       0.2047      0.4961        [94m0.7465[0m     +  0.0000  11.6394
     12      0.9906        0.1194       0.2056      0.4963        0.7477        0.0000  11.4550
     13      0.9890        [32m0.1185[0m       0.2030      0.4949        [94m0.7443[0m     +  0.0000  11.4932
     14      0.9890        [32m0.1174[0m       0.2031      0.4959        [94m0.7423[0m     +  0.0000  11.5884
     15      0.9890        [32m0.1171[0m       0.2028      0.4958        [94m0.7408[0m     +  0.0000  11.5954
     16      0.9906        0.1185       0.2028      0.4956        0.7419        0.0000  11.6384
     17      0.9906        [32m0.1125[0m       0.2035      0.4960        0.7432        0.0000  11.6388
     18      0.9890        0.1221       0.2031      0.4961        0.7427        0.0000  11.5813
     19      [36m0.9906[0m        0.1177       0.2030      0.4961        0.7419        0.0000  11.8587
     20      0.9890        0.1151       0.2023      0.4957        0.7412        0.0000  11.6402
     21      0.9906        0.1132       0.2026      0.4957        0.7411        0.0000  11.6982
     22      0.9890        0.1179       0.2024      0.4956        0.7411        0.0000  11.6112
     23      [36m0.9921[0m        0.1126       0.2024      0.4957        [94m0.7407[0m     +  0.0000  11.4579
     24      0.9906        0.1188       0.2024      0.4957        0.7409        0.0000  11.5492
     25      0.9906        0.1140       0.2026      0.4957        [94m0.7407[0m     +  0.0000  11.6713
     26      0.9890        0.1148       0.2030      0.4960        0.7407        0.0000  11.5986
     27      0.9906        0.1148       0.2030      0.4960        0.7408        0.0000  11.8440
     28      0.9906        0.1187       0.2028      0.4959        [94m0.7406[0m     +  0.0000  11.5206
     29      0.9890        0.1199       0.2026      0.4958        [94m0.7406[0m     +  0.0000  11.7021
     30      0.9906        0.1206       0.2023      0.4956        [94m0.7404[0m     +  0.0000  11.7179
     31      0.9906        [32m0.1120[0m       0.2024      0.4957        0.7405        0.0000  11.6759
     32      0.9890        0.1149       0.2023      0.4956        0.7405        0.0000  11.7780
     33      [36m0.9921[0m        0.1162       0.2024      0.4957        0.7405        0.0000  11.7535
     34      0.9906        [32m0.1119[0m       0.2024      0.4957        0.7405        0.0000  11.5286
     35      0.9906        0.1136       0.2024      0.4957        0.7405        0.0000  11.6751
     36      0.9890        0.1161       0.2024      0.4957        0.7405        0.0000  11.7500
     37      0.9890        [32m0.1107[0m       0.2024      0.4957        0.7405        0.0000  11.6256
     38      0.9890        0.1155       0.2024      0.4957        [94m0.7404[0m     +  0.0000  11.6402
     39      0.9890        0.1149       0.2024      0.4957        [94m0.7404[0m     +  0.0000  11.5898
     40      0.9890        0.1130       0.2024      0.4957        [94m0.7404[0m     +  0.0000  11.7968
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.5395233754395103
F1 Macro Score after query 3: 0.5257097333493658
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9766[0m        [32m0.1761[0m       [35m0.2280[0m      [31m0.5498[0m        [94m0.8582[0m     +  0.0000  12.0704
      2      [36m0.9776[0m        [32m0.1721[0m       0.2043      0.5136        [94m0.8056[0m     +  0.0000  11.9842
      3      [36m0.9785[0m        [32m0.1624[0m       0.1970      0.5121        [94m0.7738[0m     +  0.0000  11.8695
      4      0.9775        [32m0.1536[0m       0.1953      0.5143        [94m0.7723[0m     +  0.0000  11.9833
      5      [36m0.9791[0m        [32m0.1492[0m       0.1964      0.5066        [94m0.7685[0m     +  0.0000  12.1085
      6      [36m0.9817[0m        [32m0.1404[0m       0.1908      0.4955        [94m0.7491[0m     +  0.0000  12.0614
      7      0.9817        [32m0.1363[0m       0.1910      0.4925        [94m0.7439[0m     +  0.0000  12.0625
      8      [36m0.9834[0m        0.1364       0.1908      0.4911        [94m0.7386[0m     +  0.0000  12.0495
      9      [36m0.9859[0m        [32m0.1306[0m       0.1910      0.4918        [94m0.7358[0m     +  0.0000  12.0999
     10      0.9859        [32m0.1277[0m       0.1906      0.4918        [94m0.7323[0m     +  0.0000  12.0150
     11      0.9851        0.1312       0.1911      0.4914        [94m0.7284[0m     +  0.0000  12.0490
     12      0.9851        0.1305       0.1911      0.4913        [94m0.7254[0m     +  0.0000  11.9882
     13      [36m0.9885[0m        [32m0.1257[0m       0.1915      0.4914        [94m0.7247[0m     +  0.0000  11.9686
     14      0.9885        [32m0.1223[0m       0.1924      0.4920        [94m0.7247[0m     +  0.0000  11.8604
     15      0.9868        0.1248       0.1925      0.4921        [94m0.7239[0m     +  0.0000  11.7885
     16      [36m0.9894[0m        [32m0.1196[0m       0.1925      0.4920        [94m0.7228[0m     +  0.0000  12.0159
     17      0.9885        0.1209       0.1929      0.4921        [94m0.7220[0m     +  0.0000  12.0459
     18      0.9868        0.1207       0.1931      0.4922        [94m0.7216[0m     +  0.0000  12.0143
     19      [36m0.9894[0m        [32m0.1195[0m       0.1927      0.4923        [94m0.7211[0m     +  0.0000  11.8901
     20      [36m0.9903[0m        0.1197       0.1929      0.4924        [94m0.7202[0m     +  0.0000  11.9226
     21      0.9902        [32m0.1152[0m       0.1929      0.4924        0.7202        0.0000  11.9295
     22      [36m0.9920[0m        0.1170       0.1929      0.4923        0.7202        0.0000  11.9199
     23      0.9894        0.1186       0.1920      0.4921        0.7203        0.0000  12.0021
     24      0.9911        0.1229       0.1918      0.4920        0.7202        0.0000  11.9354
     25      0.9910        0.1188       0.1920      0.4919        0.7203        0.0000  11.9960
     26      0.9894        0.1195       0.1925      0.4922        [94m0.7200[0m     +  0.0000  12.0367
     27      0.9885        0.1175       0.1924      0.4922        0.7201        0.0000  11.8469
     28      0.9885        0.1189       0.1922      0.4921        0.7201        0.0000  11.9033
     29      0.9902        0.1200       0.1924      0.4921        [94m0.7200[0m     +  0.0000  11.8906
     30      0.9894        [32m0.1142[0m       0.1924      0.4921        [94m0.7199[0m     +  0.0000  12.0488
     31      0.9910        0.1182       0.1924      0.4921        [94m0.7199[0m     +  0.0000  11.9841
     32      0.9911        0.1205       0.1924      0.4921        [94m0.7198[0m     +  0.0000  12.0571
     33      0.9920        0.1158       0.1924      0.4921        0.7198        0.0000  11.9697
     34      0.9902        0.1170       0.1922      0.4919        0.7199        0.0000  11.9206
     35      0.9919        [32m0.1130[0m       0.1924      0.4920        0.7199        0.0000  11.9267
     36      0.9912        0.1171       0.1922      0.4919        0.7199        0.0000  11.9981
     37      0.9894        0.1206       0.1920      0.4919        0.7199        0.0000  11.9530
     38      0.9894        0.1169       0.1920      0.4919        0.7199        0.0000  12.1240
     39      0.9919        0.1166       0.1920      0.4919        0.7199        0.0000  12.1122
     40      0.9902        0.1189       0.1922      0.4921        0.7199        0.0000  11.9526
     41      0.9920        0.1204       0.1922      0.4921        0.7199        0.0000  11.8777
     42      0.9903        0.1183       0.1920      0.4919        0.7199        0.0000  11.8893
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.5370593754188447
F1 Macro Score after query 4: 0.522491327833583
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9805[0m        [32m0.1540[0m       [35m0.2283[0m      [31m0.5512[0m        [94m0.8999[0m     +  0.0000  12.8445
      2      0.9800        [32m0.1370[0m       0.2184      0.5434        [94m0.8524[0m     +  0.0000  12.6551
      3      [36m0.9844[0m        [32m0.1255[0m       0.2156      0.5338        [94m0.8239[0m     +  0.0000  12.7175
      4      [36m0.9867[0m        [32m0.1185[0m       0.2149      0.5304        [94m0.8175[0m     +  0.0000  12.7360
      5      0.9858        0.1198       0.2111      0.5171        [94m0.7995[0m     +  0.0000  12.8319
      6      [36m0.9871[0m        [32m0.1111[0m       0.2071      0.5113        [94m0.7736[0m     +  0.0000  12.9771
      7      [36m0.9885[0m        [32m0.1074[0m       0.2059      0.5063        [94m0.7624[0m     +  0.0000  12.7343
      8      0.9881        [32m0.1072[0m       0.2064      0.5093        0.7687        0.0000  12.7170
      9      [36m0.9918[0m        [32m0.1006[0m       0.2054      0.5093        0.7637        0.0000  12.7975
     10      0.9904        0.1046       0.2078      0.5101        0.7695        0.0000  12.7721
     11      [36m0.9933[0m        [32m0.0971[0m       0.2064      0.5082        [94m0.7585[0m     +  0.0000  12.6840
     12      0.9923        [32m0.0970[0m       0.2071      0.5074        [94m0.7538[0m     +  0.0000  12.6746
     13      0.9914        0.0984       0.2069      0.5078        [94m0.7533[0m     +  0.0000  12.7421
     14      0.9923        [32m0.0953[0m       0.2076      0.5080        0.7550        0.0000  12.5843
     15      0.9928        [32m0.0942[0m       0.2078      0.5083        0.7560        0.0000  12.6000
     16      0.9932        0.0945       0.2076      0.5079        0.7546        0.0000  12.6248
     17      0.9928        [32m0.0937[0m       0.2076      0.5085        [94m0.7533[0m     +  0.0000  12.7068
     18      [36m0.9947[0m        [32m0.0911[0m       0.2087      0.5095        0.7562        0.0000  12.8084
     19      0.9927        0.0940       0.2071      0.5077        [94m0.7523[0m     +  0.0000  12.5815
     20      0.9947        0.0936       0.2078      0.5089        0.7533        0.0000  12.5698
     21      0.9947        0.0912       0.2085      0.5095        0.7554        0.0000  12.7344
     22      0.9932        0.0916       0.2083      0.5094        0.7555        0.0000  12.7350
     23      [36m0.9952[0m        0.0915       0.2080      0.5094        0.7555        0.0000  12.6556
     24      0.9947        [32m0.0910[0m       0.2080      0.5096        0.7552        0.0000  12.5633
     25      0.9942        0.0939       0.2083      0.5097        0.7544        0.0000  12.5639
     26      0.9942        0.0911       0.2083      0.5096        0.7550        0.0000  12.7193
     27      0.9951        [32m0.0907[0m       0.2085      0.5097        0.7551        0.0000  12.5149
     28      0.9952        0.0918       0.2085      0.5098        0.7551        0.0000  12.6748
     29      0.9952        [32m0.0886[0m       0.2085      0.5100        0.7556        0.0000  12.5915
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.5293890675241159
F1 Macro Score after query 5: 0.5163915305552947
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9655[0m        [32m0.1910[0m       [35m0.1708[0m      [31m0.4661[0m        [94m0.6762[0m     +  0.0000  13.8482
      2      [36m0.9786[0m        [32m0.1421[0m       [35m0.1870[0m      [31m0.4801[0m        [94m0.6629[0m     +  0.0000  14.0695
      3      [36m0.9870[0m        [32m0.1230[0m       [35m0.1892[0m      [31m0.4917[0m        [94m0.6528[0m     +  0.0000  13.9369
      4      [36m0.9903[0m        [32m0.1123[0m       [35m0.1970[0m      [31m0.5139[0m        [94m0.6502[0m     +  0.0000  13.7525
      5      0.9892        [32m0.1049[0m       [35m0.2043[0m      [31m0.5215[0m        [94m0.6436[0m     +  0.0000  13.8126
      6      [36m0.9943[0m        [32m0.0968[0m       [35m0.2052[0m      [31m0.5230[0m        [94m0.6403[0m     +  0.0000  13.7084
      7      0.9943        [32m0.0964[0m       0.2040      0.5225        0.6409        0.0000  13.7445
      8      0.9938        [32m0.0916[0m       0.2024      0.5191        0.6416        0.0000  13.7032
      9      [36m0.9951[0m        [32m0.0880[0m       0.2038      0.5215        0.6421        0.0000  13.4647
     10      [36m0.9954[0m        [32m0.0866[0m       0.2049      [31m0.5310[0m        0.6432        0.0000  13.6965
     11      0.9954        [32m0.0835[0m       0.2033      0.5253        0.6420        0.0000  13.5995
     12      [36m0.9957[0m        [32m0.0824[0m       0.2030      0.5259        0.6418        0.0000  13.8645
     13      0.9951        [32m0.0810[0m       0.2026      0.5262        0.6420        0.0000  13.6114
     14      0.9954        0.0818       0.2028      0.5263        [94m0.6401[0m     +  0.0000  13.4401
     15      0.9957        [32m0.0802[0m       0.2040      0.5292        0.6414        0.0000  13.8134
     16      [36m0.9960[0m        [32m0.0788[0m       0.2042      0.5289        0.6411        0.0000  13.5307
     17      [36m0.9963[0m        [32m0.0775[0m       0.2050      0.5297        0.6411        0.0000  13.5000
     18      [36m0.9965[0m        [32m0.0765[0m       0.2036      0.5271        0.6410        0.0000  13.6499
     19      0.9963        0.0801       0.2031      0.5285        0.6415        0.0000  13.7212
     20      [36m0.9973[0m        0.0772       0.2047      [31m0.5332[0m        0.6417        0.0000  13.7007
     21      0.9960        0.0768       0.2042      0.5328        0.6409        0.0000  13.6880
     22      0.9971        [32m0.0763[0m       0.2038      0.5316        0.6409        0.0000  13.7192
     23      0.9968        0.0769       0.2043      0.5328        0.6409        0.0000  13.5299
     24      0.9968        [32m0.0757[0m       0.2047      [31m0.5342[0m        0.6416        0.0000  13.5360
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.5576808524720366
F1 Macro Score after query 6: 0.5473146751840209
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9778[0m        [32m0.1391[0m       [35m0.2167[0m      [31m0.5410[0m        [94m0.6442[0m     +  0.0000  15.8248
      2      [36m0.9916[0m        [32m0.0968[0m       [35m0.2509[0m      [31m0.5845[0m        [94m0.6269[0m     +  0.0000  15.9219
      3      [36m0.9925[0m        [32m0.0884[0m       [35m0.2694[0m      [31m0.6032[0m        [94m0.6226[0m     +  0.0000  15.8265
      4      [36m0.9945[0m        [32m0.0795[0m       0.2682      0.6021        0.6235        0.0000  15.6984
      5      [36m0.9952[0m        [32m0.0742[0m       [35m0.2804[0m      [31m0.6106[0m        0.6229        0.0000  15.6223
      6      [36m0.9960[0m        [32m0.0674[0m       0.2752      [31m0.6124[0m        [94m0.6167[0m     +  0.0000  15.6914
      7      [36m0.9966[0m        [32m0.0665[0m       0.2724      0.6081        0.6264        0.0000  16.0439
      8      0.9966        [32m0.0635[0m       0.2726      0.6123        0.6188        0.0000  15.9850
      9      [36m0.9969[0m        [32m0.0607[0m       [35m0.2814[0m      [31m0.6202[0m        0.6210        0.0000  15.6976
     10      0.9969        0.0618       0.2797      0.6194        0.6252        0.0000  15.7682
     11      [36m0.9974[0m        [32m0.0574[0m       0.2802      0.6185        0.6318        0.0000  15.6882
     12      [36m0.9980[0m        0.0578       0.2783      0.6169        0.6292        0.0000  15.9360
     13      0.9978        [32m0.0573[0m       0.2773      0.6170        0.6312        0.0000  15.8807
     14      [36m0.9981[0m        [32m0.0562[0m       0.2809      0.6193        0.6284        0.0000  15.8590
     15      0.9977        [32m0.0536[0m       [35m0.2816[0m      0.6192        0.6334        0.0000  15.6192
     16      0.9979        0.0544       [35m0.2861[0m      [31m0.6236[0m        0.6358        0.0000  15.7956
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.6129363449691991
F1 Macro Score after query 7: 0.6191695780666201
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9837[0m        [32m0.1071[0m       [35m0.3264[0m      [31m0.6923[0m        [94m0.6106[0m     +  0.0000  19.9189
      2      [36m0.9881[0m        [32m0.0868[0m       [35m0.3372[0m      [31m0.7089[0m        [94m0.5591[0m     +  0.0000  19.7619
      3      [36m0.9897[0m        [32m0.0794[0m       [35m0.3476[0m      [31m0.7106[0m        0.5617        0.0000  19.4882
      4      [36m0.9903[0m        [32m0.0740[0m       0.3476      0.7067        0.5739        0.0000  19.5299
      5      [36m0.9908[0m        [32m0.0696[0m       [35m0.3547[0m      [31m0.7138[0m        [94m0.5579[0m     +  0.0000  19.7643
      6      [36m0.9940[0m        [32m0.0624[0m       [35m0.3764[0m      [31m0.7183[0m        0.5646        0.0000  19.7518
      7      [36m0.9943[0m        [32m0.0586[0m       [35m0.3830[0m      [31m0.7191[0m        0.5606        0.0000  19.5121
      8      0.9942        [32m0.0551[0m       [35m0.3873[0m      [31m0.7193[0m        0.5606        0.0000  19.5183
      9      [36m0.9945[0m        [32m0.0546[0m       0.3856      0.7183        0.5600        0.0000  19.8596
     10      [36m0.9955[0m        [32m0.0499[0m       [35m0.3892[0m      [31m0.7215[0m        0.5640        0.0000  19.7500
     11      [36m0.9961[0m        [32m0.0478[0m       [35m0.3913[0m      0.7182        0.5778        0.0000  19.4526
     12      [36m0.9965[0m        [32m0.0455[0m       0.3898      0.7169        0.5730        0.0000  19.4380
     13      [36m0.9967[0m        [32m0.0448[0m       0.3911      0.7170        0.5781        0.0000  19.7816
     14      [36m0.9972[0m        [32m0.0437[0m       [35m0.3931[0m      0.7179        0.5702        0.0000  19.6969
     15      0.9971        [32m0.0424[0m       [35m0.3944[0m      0.7190        0.5729        0.0000  19.5357
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7055327747073156
F1 Macro Score after query 8: 0.7216108578424638
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9907[0m        [32m0.0715[0m       [35m0.2615[0m      [31m0.6785[0m        [94m0.7971[0m     +  0.0000  26.2334
      2      [36m0.9924[0m        [32m0.0593[0m       0.2583      0.6666        0.8416        0.0000  26.5003
      3      [36m0.9928[0m        [32m0.0541[0m       0.2592      0.6586        0.8229        0.0000  26.4595
      4      [36m0.9940[0m        [32m0.0481[0m       0.2583      0.6535        0.8481        0.0000  26.3591
      5      [36m0.9949[0m        [32m0.0442[0m       0.2589      0.6559        0.8408        0.0000  26.4324
      6      [36m0.9960[0m        [32m0.0381[0m       [35m0.2809[0m      0.6691        [94m0.7568[0m     +  0.0000  26.5633
      7      [36m0.9965[0m        [32m0.0351[0m       [35m0.2854[0m      0.6745        [94m0.7031[0m     +  0.0000  26.2552
      8      [36m0.9972[0m        [32m0.0321[0m       [35m0.2927[0m      [31m0.6791[0m        [94m0.6923[0m     +  0.0000  26.4101
      9      [36m0.9975[0m        [32m0.0302[0m       0.2865      0.6729        0.7090        0.0000  26.4047
     10      0.9974        [32m0.0282[0m       [35m0.3057[0m      [31m0.6812[0m        0.6934        0.0000  26.5167
     11      [36m0.9985[0m        [32m0.0255[0m       [35m0.3083[0m      [31m0.6852[0m        [94m0.6713[0m     +  0.0000  26.2913
     12      [36m0.9988[0m        [32m0.0242[0m       0.3050      0.6840        0.6775        0.0000  26.6142
     13      [36m0.9989[0m        [32m0.0233[0m       [35m0.3099[0m      [31m0.6856[0m        0.6768        0.0000  26.5476
     14      0.9989        [32m0.0227[0m       0.3089      0.6840        0.6843        0.0000  26.2289
     15      [36m0.9990[0m        [32m0.0213[0m       0.3090      0.6835        0.6827        0.0000  26.6080
     16      [36m0.9993[0m        [32m0.0210[0m       0.3090      0.6829        0.6964        0.0000  26.5012
     17      0.9992        [32m0.0206[0m       0.3094      0.6830        0.6981        0.0000  26.3311
     18      0.9992        [32m0.0203[0m       [35m0.3118[0m      0.6837        0.6962        0.0000  26.3910
     19      [36m0.9993[0m        [32m0.0197[0m       [35m0.3120[0m      0.6844        0.6988        0.0000  26.4888
     20      [36m0.9995[0m        [32m0.0197[0m       [35m0.3123[0m      0.6848        0.7009        0.0000  26.2188
     21      [36m0.9995[0m        [32m0.0192[0m       0.3109      0.6841        0.7055        0.0000  26.5976
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.6740228370663153
F1 Macro Score after query 9: 0.6958391665815418
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9811[0m        [32m0.0943[0m       [35m0.3280[0m      [31m0.7153[0m        [94m0.5840[0m     +  0.0000  38.2811
      2      [36m0.9867[0m        [32m0.0716[0m       0.3220      [31m0.7276[0m        [94m0.5752[0m     +  0.0000  39.0993
      3      [36m0.9889[0m        [32m0.0637[0m       0.3260      [31m0.7300[0m        [94m0.5734[0m     +  0.0000  38.6759
      4      [36m0.9904[0m        [32m0.0570[0m       [35m0.3332[0m      [31m0.7430[0m        [94m0.5659[0m     +  0.0000  38.6588
      5      [36m0.9918[0m        [32m0.0514[0m       [35m0.3387[0m      0.7352        0.5919        0.0000  38.6430
      6      [36m0.9946[0m        [32m0.0415[0m       [35m0.3677[0m      [31m0.7479[0m        [94m0.5497[0m     +  0.0000  38.6688
      7      [36m0.9954[0m        [32m0.0374[0m       [35m0.3759[0m      [31m0.7480[0m        0.5627        0.0000  38.5452
      8      [36m0.9961[0m        [32m0.0339[0m       0.3618      0.7378        0.5940        0.0000  38.7585
      9      [36m0.9965[0m        [32m0.0319[0m       [35m0.3804[0m      0.7447        0.5901        0.0000  38.7057
     10      [36m0.9973[0m        [32m0.0293[0m       [35m0.3866[0m      [31m0.7501[0m        0.5874        0.0000  38.6977
     11      [36m0.9979[0m        [32m0.0265[0m       [35m0.3870[0m      [31m0.7506[0m        0.6008        0.0000  38.7527
     12      [36m0.9980[0m        [32m0.0245[0m       [35m0.3910[0m      0.7483        0.6082        0.0000  38.5660
     13      [36m0.9983[0m        [32m0.0236[0m       0.3887      0.7481        0.6169        0.0000  38.7343
     14      [36m0.9987[0m        [32m0.0224[0m       [35m0.3911[0m      0.7485        0.6198        0.0000  38.7468
     15      0.9987        [32m0.0220[0m       [35m0.3950[0m      0.7478        0.6230        0.0000  38.7679
     16      [36m0.9989[0m        [32m0.0205[0m       [35m0.3988[0m      0.7478        0.6292        0.0000  38.7810
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.7294302839498699
F1 Macro Score after query 10: 0.7509495815043375
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9775[0m        [32m0.1059[0m       [35m0.7991[0m      [31m0.8932[0m        [94m0.2442[0m     +  0.0000  60.3742
      2      [36m0.9841[0m        [32m0.0817[0m       [35m0.7998[0m      [31m0.8947[0m        [94m0.2365[0m     +  0.0000  60.3251
      3      [36m0.9876[0m        [32m0.0682[0m       0.7931      0.8928        [94m0.2230[0m     +  0.0000  60.5344
      4      [36m0.9888[0m        [32m0.0600[0m       0.7880      0.8910        0.2283        0.0000  60.7682
      5      [36m0.9902[0m        [32m0.0536[0m       0.7899      0.8902        0.2433        0.0000  59.7596
      6      [36m0.9927[0m        [32m0.0443[0m       0.7995      [31m0.8956[0m        [94m0.2201[0m     +  0.0000  60.5309
      7      [36m0.9940[0m        [32m0.0398[0m       0.7856      0.8908        0.2475        0.0000  60.5451
      8      [36m0.9952[0m        [32m0.0356[0m       0.7868      0.8936        0.2408        0.0000  60.7690
      9      [36m0.9958[0m        [32m0.0331[0m       0.7849      0.8911        0.2470        0.0000  60.3463
     10      [36m0.9964[0m        [32m0.0308[0m       0.7793      0.8890        0.2616        0.0000  60.6894
     11      [36m0.9972[0m        [32m0.0282[0m       0.7807      0.8891        0.2572        0.0000  60.3882
     12      [36m0.9979[0m        [32m0.0262[0m       0.7781      0.8884        0.2611        0.0000  60.4207
     13      [36m0.9981[0m        [32m0.0250[0m       0.7757      0.8867        0.2713        0.0000  60.7185
     14      [36m0.9984[0m        [32m0.0236[0m       0.7799      0.8888        0.2665        0.0000  60.6121
     15      [36m0.9985[0m        [32m0.0231[0m       0.7781      0.8880        0.2721        0.0000  60.4950
     16      [36m0.9987[0m        [32m0.0220[0m       0.7806      0.8881        0.2645        0.0000  60.5833
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8964146471982264
F1 Macro Score after query 11: 0.891151621786762
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9809[0m        [32m0.0692[0m       [35m0.8259[0m      [31m0.9059[0m        [94m0.1822[0m     +  0.0000  99.1558
      2      [36m0.9843[0m        [32m0.0532[0m       [35m0.8271[0m      0.8978        [94m0.1775[0m     +  0.0000  99.5049
      3      [36m0.9861[0m        [32m0.0441[0m       [35m0.8321[0m      0.9039        [94m0.1764[0m     +  0.0000  99.3802
      4      [36m0.9883[0m        [32m0.0374[0m       0.8200      0.9014        0.1903        0.0000  99.2300
      5      [36m0.9890[0m        [32m0.0335[0m       0.8116      0.8902        0.1900        0.0000  99.0314
      6      [36m0.9920[0m        [32m0.0273[0m       0.8276      0.9009        0.1883        0.0000  99.1976
      7      [36m0.9945[0m        [32m0.0224[0m       0.8236      0.9006        0.1975        0.0000  99.6928
      8      [36m0.9958[0m        [32m0.0198[0m       0.8198      0.9012        0.2188        0.0000  99.1306
      9      [36m0.9962[0m        [32m0.0183[0m       [35m0.8415[0m      [31m0.9090[0m        0.1902        0.0000  99.3851
     10      [36m0.9965[0m        [32m0.0173[0m       0.8198      0.8991        0.2338        0.0000  99.2238
     11      [36m0.9974[0m        [32m0.0148[0m       0.8286      0.9046        0.2226        0.0000  99.3594
     12      [36m0.9983[0m        [32m0.0135[0m       0.8283      0.9044        0.2235        0.0000  99.5632
     13      [36m0.9984[0m        [32m0.0124[0m       0.8276      0.9045        0.2285        0.0000  99.4631
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.9201834149374368
F1 Macro Score after query 12: 0.9118893311032424
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9859[0m        [32m0.0412[0m       [35m0.8241[0m      [31m0.8892[0m        [94m0.1748[0m     +  0.0000  114.8037
      2      [36m0.9875[0m        [32m0.0350[0m       [35m0.8384[0m      [31m0.9004[0m        0.1817        0.0000  115.1801
      3      [36m0.9891[0m        [32m0.0301[0m       0.8259      0.8946        0.2007        0.0000  115.5088
      4      [36m0.9903[0m        [32m0.0264[0m       0.8196      0.8927        0.2168        0.0000  115.1343
      5      [36m0.9907[0m        [32m0.0248[0m       0.8304      [31m0.9050[0m        0.1850        0.0000  115.0524
      6      [36m0.9938[0m        [32m0.0188[0m       0.8333      [31m0.9082[0m        0.2033        0.0000  115.2266
      7      [36m0.9965[0m        [32m0.0150[0m       0.8302      0.9036        0.2121        0.0000  114.8902
      8      [36m0.9969[0m        [32m0.0135[0m       [35m0.8399[0m      0.9056        0.1936        0.0000  115.5002
      9      [36m0.9974[0m        [32m0.0122[0m       0.8394      0.9053        0.2121        0.0000  115.2525
     10      [36m0.9977[0m        [32m0.0111[0m       [35m0.8439[0m      [31m0.9086[0m        0.1978        0.0000  115.5951
     11      [36m0.9981[0m        [32m0.0097[0m       0.8392      [31m0.9092[0m        0.2222        0.0000  115.6896
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.9281025320412628
F1 Macro Score after query 13: 0.92005622820423
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_lowLR\AL_average_score_results_for_multilabel_classification_s44.pickle
