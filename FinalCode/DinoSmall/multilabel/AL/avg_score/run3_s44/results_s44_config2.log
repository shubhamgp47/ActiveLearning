Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5460[0m        [32m0.7305[0m       [35m0.0606[0m      [31m0.1748[0m        [94m0.6982[0m     +  0.0001  12.1830
      2      0.5000        [32m0.6546[0m       [35m0.3118[0m      [31m0.5036[0m        [94m0.6765[0m     +  0.0001  10.3494
      3      [36m0.6984[0m        [32m0.6165[0m       0.3059      [31m0.5187[0m        [94m0.6743[0m     +  0.0001  10.3573
      4      0.5675        0.6462       [35m0.3158[0m      0.4720        0.6783        0.0001  10.4802
      5      [36m0.8214[0m        [32m0.5715[0m       0.2073      0.4845        0.6887        0.0001  10.2978
      6      0.7667        [32m0.5593[0m       0.2906      0.4912        0.6802        0.0000  10.4933
      7      [36m0.8320[0m        [32m0.5395[0m       0.2708      0.4806        0.6846        0.0000  10.4946
      8      0.7667        0.5659       0.2970      0.4869        0.6792        0.0000  10.4945
      9      0.7667        0.5557       0.3035      0.4821        0.6774        0.0000  10.8478
     10      0.7963        [32m0.5302[0m       0.3089      0.4837        0.6771        0.0000  10.7590
     11      0.7857        [32m0.5224[0m       0.3080      0.4812        0.6779        0.0000  10.8244
     12      [36m0.8519[0m        [32m0.5205[0m       0.3073      0.4780        0.6762        0.0000  10.9664
     13      0.8333        [32m0.5047[0m       0.3082      0.4801        0.6753        0.0000  10.8703
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4935
Pre F1 macro score = 0.5063
Pre Accuracy = 0.3436

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9491[0m        [32m0.3863[0m       [35m0.2229[0m      [31m0.5497[0m        [94m0.9385[0m     +  0.0001  10.8559
      2      0.9151        [32m0.3476[0m       0.2068      0.5251        [94m0.8726[0m     +  0.0001  10.8562
      3      0.9279        [32m0.3288[0m       [35m0.3174[0m      0.5408        [94m0.8204[0m     +  0.0001  10.8693
      4      0.9410        [32m0.2531[0m       0.2995      0.5191        0.8343        0.0001  10.9730
      5      [36m0.9500[0m        [32m0.2483[0m       [35m0.3189[0m      0.5227        [94m0.8060[0m     +  0.0001  10.9114
      6      0.9410        [32m0.2433[0m       0.3092      0.5207        0.8081        0.0000  10.9828
      7      [36m0.9585[0m        [32m0.2427[0m       0.3057      0.5155        [94m0.8059[0m     +  0.0000  10.9654
      8      0.9585        [32m0.2197[0m       0.3135      0.5150        [94m0.7900[0m     +  0.0000  10.9218
      9      0.9491        [32m0.2133[0m       0.3049      0.5143        [94m0.7796[0m     +  0.0000  10.7729
     10      [36m0.9667[0m        0.2228       0.2988      0.5174        [94m0.7781[0m     +  0.0000  10.8367
     11      0.9500        0.2134       0.2984      0.5158        [94m0.7731[0m     +  0.0000  10.9674
     12      0.9585        [32m0.2099[0m       0.2983      0.5147        [94m0.7652[0m     +  0.0000  11.0764
     13      0.9581        0.2185       0.2946      0.5148        [94m0.7623[0m     +  0.0000  10.8116
     14      0.9500        0.2161       0.2967      0.5142        [94m0.7568[0m     +  0.0000  10.8044
     15      0.9667        [32m0.1866[0m       0.2939      0.5140        [94m0.7549[0m     +  0.0000  10.8565
     16      0.9500        0.2071       0.2964      0.5150        [94m0.7527[0m     +  0.0000  10.9032
     17      0.9667        [32m0.1824[0m       0.2924      0.5135        0.7531        0.0000  10.9193
     18      0.9581        0.2128       0.2911      0.5133        0.7531        0.0000  10.8561
     19      0.9500        0.2072       0.2908      0.5133        [94m0.7522[0m     +  0.0000  10.9166
     20      0.9581        0.1999       0.2901      0.5132        [94m0.7519[0m     +  0.0000  10.9738
     21      0.9581        0.1954       0.2903      0.5133        [94m0.7512[0m     +  0.0000  10.8750
     22      0.9667        0.2086       0.2903      0.5133        [94m0.7511[0m     +  0.0000  10.8422
     23      0.9500        0.2066       0.2906      0.5135        [94m0.7508[0m     +  0.0000  10.8332
     24      0.9667        0.2024       0.2908      0.5136        [94m0.7502[0m     +  0.0000  10.7767
     25      0.9500        0.2010       0.2913      0.5144        [94m0.7491[0m     +  0.0000  10.7768
     26      0.9500        0.2060       0.2913      0.5144        [94m0.7490[0m     +  0.0000  10.9366
     27      0.9500        0.2072       0.2911      0.5144        [94m0.7489[0m     +  0.0000  10.9333
     28      0.9667        0.2138       0.2910      0.5143        [94m0.7489[0m     +  0.0000  10.9374
     29      0.9581        0.2058       0.2910      0.5143        [94m0.7487[0m     +  0.0000  10.7191
     30      0.9581        0.1966       0.2910      0.5144        [94m0.7485[0m     +  0.0000  10.7773
     31      0.9496        0.2015       0.2910      0.5144        [94m0.7484[0m     +  0.0000  10.9633
     32      0.9581        0.2095       0.2910      0.5144        [94m0.7484[0m     +  0.0000  10.8606
     33      0.9581        [32m0.1744[0m       0.2906      0.5143        0.7484        0.0000  10.7475
     34      0.9667        0.1915       0.2906      0.5144        [94m0.7484[0m     +  0.0000  10.9219
     35      0.9581        0.1784       0.2906      0.5144        [94m0.7484[0m     +  0.0000  10.7367
     36      0.9667        0.1756       0.2906      0.5144        [94m0.7484[0m     +  0.0000  10.7990
     37      0.9500        0.1965       0.2906      0.5144        [94m0.7483[0m     +  0.0000  10.8406
     38      0.9667        0.1909       0.2906      0.5144        [94m0.7483[0m     +  0.0000  10.8149
     39      0.9581        0.1914       0.2906      0.5144        0.7483        0.0000  10.7964
     40      0.9581        0.2008       0.2906      0.5146        [94m0.7483[0m     +  0.0000  10.8603
     41      0.9667        0.1965       0.2906      0.5146        [94m0.7483[0m     +  0.0000  11.0464
     42      0.9581        0.1917       0.2906      0.5146        [94m0.7482[0m     +  0.0000  10.8549
     43      0.9667        0.1864       0.2906      0.5146        [94m0.7482[0m     +  0.0000  10.8748
     44      0.9667        0.1837       0.2906      0.5146        [94m0.7482[0m     +  0.0000  10.8628
     45      0.9581        0.2043       0.2906      0.5146        [94m0.7482[0m     +  0.0000  10.8594
     46      0.9581        0.1921       0.2906      0.5146        [94m0.7482[0m     +  0.0000  10.8593
     47      0.9667        0.2070       0.2906      0.5146        [94m0.7482[0m     +  0.0000  10.7290
     48      0.9500        0.2007       0.2906      0.5146        [94m0.7482[0m     +  0.0000  10.7893
     49      0.9581        0.1906       0.2906      0.5146        0.7482        0.0000  11.0155
     50      [36m0.9748[0m        0.1976       0.2906      0.5146        0.7482        0.0000  10.9531
     51      0.9581        0.2000       0.2906      0.5146        0.7482        0.0000  10.7289
     52      0.9662        0.1762       0.2906      0.5146        0.7482        0.0000  10.7004
     53      0.9500        0.2006       0.2906      0.5146        0.7482        0.0000  10.9359
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.5165206594467822
F1 Macro Score after query 1: 0.5134661757841944
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9839[0m        [32m0.1357[0m       [35m0.2333[0m      [31m0.5657[0m        [94m0.9910[0m     +  0.0001  10.9312
      2      0.9750        [32m0.1251[0m       [35m0.3054[0m      0.5188        [94m0.7584[0m     +  0.0001  10.8435
      3      0.9839        [32m0.0924[0m       0.2837      0.5180        [94m0.7327[0m     +  0.0001  11.0248
      4      [36m0.9871[0m        [32m0.0806[0m       0.2858      0.5308        [94m0.7029[0m     +  0.0001  10.9581
      5      [36m0.9904[0m        [32m0.0756[0m       0.2627      0.5280        [94m0.6906[0m     +  0.0001  10.9843
      6      [36m0.9904[0m        [32m0.0684[0m       0.2646      0.5253        [94m0.6813[0m     +  0.0000  10.9198
      7      [36m0.9936[0m        [32m0.0678[0m       0.2635      0.5231        [94m0.6648[0m     +  0.0000  11.0415
      8      0.9936        [32m0.0564[0m       0.2648      0.5216        [94m0.6564[0m     +  0.0000  10.9487
      9      0.9904        [32m0.0563[0m       0.2632      0.5215        [94m0.6503[0m     +  0.0000  10.9544
     10      0.9904        0.0638       0.2620      0.5266        [94m0.6450[0m     +  0.0000  11.0186
     11      0.9936        0.0606       0.2634      0.5273        [94m0.6446[0m     +  0.0000  11.0464
     12      0.9936        [32m0.0502[0m       0.2646      0.5284        [94m0.6434[0m     +  0.0000  10.9377
     13      0.9935        0.0545       0.2668      0.5293        [94m0.6409[0m     +  0.0000  11.0782
     14      0.9936        [32m0.0498[0m       0.2689      0.5308        [94m0.6387[0m     +  0.0000  10.7762
     15      0.9936        0.0531       0.2686      0.5354        [94m0.6387[0m     +  0.0000  11.1068
     16      0.9936        [32m0.0495[0m       0.2689      0.5338        [94m0.6369[0m     +  0.0000  10.9534
     17      0.9936        0.0526       0.2710      0.5347        [94m0.6366[0m     +  0.0000  11.0884
     18      0.9904        0.0542       0.2712      0.5351        0.6370        0.0000  10.8527
     19      0.9904        0.0537       0.2710      0.5353        [94m0.6365[0m     +  0.0000  10.8587
     20      0.9936        0.0512       0.2715      0.5357        [94m0.6350[0m     +  0.0000  10.9688
     21      0.9936        0.0505       0.2719      0.5356        [94m0.6349[0m     +  0.0000  10.8075
     22      0.9936        [32m0.0450[0m       0.2720      0.5366        0.6356        0.0000  10.7661
     23      0.9936        0.0476       0.2720      0.5364        0.6353        0.0000  10.8607
     24      0.9936        0.0513       0.2719      0.5358        0.6354        0.0000  11.1564
     25      [36m0.9968[0m        [32m0.0440[0m       0.2720      0.5359        0.6353        0.0000  11.0105
     26      0.9968        0.0509       0.2722      0.5360        0.6353        0.0000  10.8077
     27      0.9936        0.0441       0.2724      0.5360        0.6352        0.0000  10.9208
     28      0.9936        0.0496       0.2722      0.5362        0.6352        0.0000  11.1182
     29      0.9968        0.0448       0.2722      0.5362        0.6352        0.0000  10.9228
     30      0.9968        0.0460       0.2726      0.5362        0.6352        0.0000  10.8709
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.5648023862788963
F1 Macro Score after query 2: 0.5462394281144561
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9906[0m        [32m0.1092[0m       [35m0.2898[0m      [31m0.6097[0m        [94m0.9506[0m     +  0.0001  11.0406
      2      0.9815        [32m0.1071[0m       0.2677      0.5440        [94m0.6727[0m     +  0.0001  11.2411
      3      0.9875        [32m0.0735[0m       0.2628      0.5442        [94m0.6507[0m     +  0.0001  11.1308
      4      0.9889        0.0783       0.2622      0.5494        [94m0.6506[0m     +  0.0001  11.1524
      5      0.9889        0.0735       0.2677      0.5579        [94m0.6381[0m     +  0.0001  11.1215
      6      0.9906        [32m0.0591[0m       0.2628      0.5509        [94m0.6369[0m     +  0.0000  11.0780
      7      [36m0.9921[0m        [32m0.0584[0m       0.2536      0.5430        0.6383        0.0000  11.1889
      8      0.9906        [32m0.0519[0m       0.2642      0.5371        [94m0.6361[0m     +  0.0000  11.1094
      9      0.9921        0.0525       0.2700      0.5200        0.6365        0.0000  11.0811
     10      0.9920        [32m0.0506[0m       0.2707      0.5244        [94m0.6347[0m     +  0.0000  11.0822
     11      0.9920        [32m0.0477[0m       0.2719      0.5295        0.6351        0.0000  11.1746
     12      0.9921        0.0493       0.2731      0.5263        0.6360        0.0000  11.2564
     13      [36m0.9937[0m        [32m0.0474[0m       0.2747      0.5239        0.6367        0.0000  11.0619
     14      0.9921        0.0478       0.2726      0.5262        0.6377        0.0000  11.0538
     15      0.9937        [32m0.0449[0m       0.2733      0.5233        0.6386        0.0000  11.0844
     16      0.9937        [32m0.0411[0m       0.2731      0.5233        0.6388        0.0000  11.1420
     17      0.9905        0.0481       0.2733      0.5226        0.6393        0.0000  11.1078
     18      0.9937        0.0454       0.2724      0.5253        0.6395        0.0000  11.1202
     19      0.9937        0.0448       0.2738      0.5257        0.6399        0.0000  11.0129
     20      0.9937        0.0470       0.2734      0.5264        0.6397        0.0000  11.2345
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.5855735120220733
F1 Macro Score after query 3: 0.5600732469627889
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9856[0m        [32m0.1040[0m       [35m0.2830[0m      [31m0.6277[0m        [94m0.9225[0m     +  0.0001  11.4045
      2      0.9842        [32m0.0991[0m       0.2672      0.5493        [94m0.6970[0m     +  0.0001  11.3381
      3      [36m0.9882[0m        [32m0.0828[0m       0.2519      0.5558        [94m0.6875[0m     +  0.0001  11.3436
      4      0.9873        0.0839       0.2651      0.5535        [94m0.6651[0m     +  0.0001  11.4688
      5      0.9873        [32m0.0814[0m       0.2656      0.5554        [94m0.6517[0m     +  0.0001  11.2342
      6      [36m0.9890[0m        [32m0.0696[0m       0.2700      0.5449        [94m0.6510[0m     +  0.0000  11.3753
      7      0.9882        [32m0.0651[0m       [35m0.2939[0m      0.5396        [94m0.6507[0m     +  0.0000  11.2618
      8      0.9881        0.0655       0.2884      0.5256        0.6551        0.0000  11.3833
      9      0.9881        [32m0.0634[0m       0.2911      0.5164        0.6599        0.0000  11.2028
     10      0.9890        [32m0.0592[0m       0.2823      0.5170        0.6651        0.0000  11.2500
     11      0.9889        [32m0.0570[0m       0.2882      0.5193        0.6636        0.0000  11.3434
     12      [36m0.9906[0m        [32m0.0541[0m       0.2903      0.5166        0.6647        0.0000  11.3007
     13      [36m0.9915[0m        [32m0.0492[0m       0.2936      0.5154        0.6653        0.0000  11.3062
     14      0.9881        0.0503       [35m0.2941[0m      0.5166        0.6670        0.0000  11.2498
     15      0.9889        0.0527       [35m0.2953[0m      0.5107        0.6702        0.0000  11.3283
     16      0.9889        0.0509       [35m0.2964[0m      0.5138        0.6696        0.0000  11.4086
     17      0.9889        0.0509       0.2962      0.5141        0.6696        0.0000  11.0937
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.5923812720255076
F1 Macro Score after query 4: 0.565990945391297
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9859[0m        [32m0.1030[0m       [35m0.2845[0m      [31m0.6256[0m        [94m0.9616[0m     +  0.0001  11.5950
      2      0.9837        [32m0.0959[0m       [35m0.2891[0m      0.5857        [94m0.6622[0m     +  0.0001  11.6220
      3      [36m0.9863[0m        [32m0.0839[0m       0.2786      0.5805        [94m0.6533[0m     +  0.0001  11.4878
      4      0.9858        [32m0.0808[0m       0.2873      0.5674        0.6558        0.0001  11.7166
      5      0.9858        [32m0.0746[0m       [35m0.2967[0m      0.5656        [94m0.6527[0m     +  0.0001  11.7813
      6      0.9858        [32m0.0661[0m       [35m0.3069[0m      0.5540        0.6636        0.0000  11.6094
      7      [36m0.9872[0m        [32m0.0645[0m       [35m0.3229[0m      0.5467        0.6760        0.0000  11.6050
      8      0.9848        0.0670       0.3163      0.5460        0.6786        0.0000  11.5297
      9      [36m0.9880[0m        [32m0.0599[0m       0.3089      0.5455        0.6788        0.0000  11.6408
     10      0.9866        0.0599       0.3071      0.5469        0.6754        0.0000  11.6281
     11      [36m0.9889[0m        [32m0.0533[0m       0.3069      0.5399        0.6819        0.0000  11.7750
     12      [36m0.9903[0m        [32m0.0513[0m       0.3047      0.5402        0.6861        0.0000  11.7344
     13      0.9894        0.0513       0.3082      0.5400        0.6858        0.0000  11.5625
     14      0.9898        0.0513       0.3054      0.5400        0.6881        0.0000  11.6251
     15      0.9902        [32m0.0478[0m       0.3064      0.5391        0.6891        0.0000  11.6558
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.5959711758925645
F1 Macro Score after query 5: 0.5776267245695784
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9754[0m        [32m0.1277[0m       [35m0.2622[0m      [31m0.6104[0m        [94m0.7008[0m     +  0.0001  12.3592
      2      [36m0.9775[0m        [32m0.1104[0m       0.2538      0.5747        [94m0.6393[0m     +  0.0001  12.2810
      3      0.9767        [32m0.1011[0m       [35m0.2740[0m      0.5665        0.6768        0.0001  12.3280
      4      [36m0.9779[0m        [32m0.0908[0m       [35m0.2875[0m      0.5403        0.6851        0.0001  12.1229
      5      [36m0.9816[0m        [32m0.0858[0m       0.2799      0.5468        0.6967        0.0001  12.1833
      6      [36m0.9835[0m        [32m0.0728[0m       0.2873      0.5723        0.6943        0.0000  12.2863
      7      [36m0.9848[0m        [32m0.0687[0m       [35m0.2981[0m      0.5799        0.6935        0.0000  12.2392
      8      0.9843        0.0697       [35m0.2991[0m      0.5758        0.6955        0.0000  12.2340
      9      [36m0.9853[0m        0.0694       0.2908      0.5685        0.7023        0.0000  12.3330
     10      0.9849        [32m0.0668[0m       0.2898      0.5676        0.7085        0.0000  12.3280
     11      [36m0.9855[0m        [32m0.0665[0m       0.2941      0.5925        0.7051        0.0000  12.0626
     12      [36m0.9864[0m        [32m0.0655[0m       0.2957      0.5946        0.7052        0.0000  12.2972
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6508247947096868
F1 Macro Score after query 6: 0.6394590514463929
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9698[0m        [32m0.1279[0m       [35m0.3089[0m      [31m0.6729[0m        [94m0.6445[0m     +  0.0001  13.5781
      2      [36m0.9746[0m        [32m0.0979[0m       [35m0.3214[0m      0.6453        [94m0.5654[0m     +  0.0001  13.3295
      3      [36m0.9795[0m        [32m0.0868[0m       [35m0.3748[0m      0.6518        [94m0.5223[0m     +  0.0001  13.2815
      4      [36m0.9802[0m        [32m0.0821[0m       [35m0.4280[0m      0.6503        [94m0.5090[0m     +  0.0001  13.4527
      5      [36m0.9821[0m        [32m0.0756[0m       [35m0.4396[0m      0.6679        [94m0.5012[0m     +  0.0001  13.4351
      6      [36m0.9849[0m        [32m0.0649[0m       [35m0.4674[0m      0.6691        [94m0.4965[0m     +  0.0000  13.2802
      7      0.9845        0.0656       [35m0.4797[0m      0.6692        [94m0.4943[0m     +  0.0000  13.3133
      8      [36m0.9859[0m        [32m0.0643[0m       0.4778      [31m0.6761[0m        [94m0.4890[0m     +  0.0000  13.4741
      9      0.9843        [32m0.0625[0m       [35m0.5014[0m      [31m0.6778[0m        0.4907        0.0000  13.3471
     10      [36m0.9861[0m        [32m0.0600[0m       [35m0.5182[0m      [31m0.6854[0m        [94m0.4838[0m     +  0.0000  13.3400
     11      [36m0.9870[0m        [32m0.0564[0m       [35m0.5382[0m      [31m0.6929[0m        0.4861        0.0000  13.2293
     12      [36m0.9873[0m        [32m0.0559[0m       [35m0.5470[0m      [31m0.6939[0m        0.4917        0.0000  13.2348
     13      0.9866        [32m0.0558[0m       0.5469      0.6934        0.4940        0.0000  13.3314
     14      0.9872        [32m0.0557[0m       0.5450      0.6928        0.4932        0.0000  13.1718
     15      [36m0.9874[0m        [32m0.0530[0m       [35m0.5477[0m      0.6918        0.4987        0.0000  13.3409
     16      [36m0.9880[0m        [32m0.0529[0m       [35m0.5486[0m      [31m0.7053[0m        0.4865        0.0000  13.3350
     17      [36m0.9884[0m        0.0532       0.5476      0.7000        0.4912        0.0000  13.2033
     18      [36m0.9896[0m        [32m0.0524[0m       [35m0.5493[0m      0.7045        0.4883        0.0000  13.3796
     19      0.9886        0.0532       [35m0.5530[0m      0.7015        0.4913        0.0000  13.2838
     20      0.9878        0.0528       [35m0.5566[0m      [31m0.7071[0m        0.4873        0.0000  13.1875
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.7479504902748754
F1 Macro Score after query 7: 0.7440492313912394
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9890[0m        [32m0.0642[0m       [35m0.4094[0m      [31m0.7441[0m        [94m0.4442[0m     +  0.0001  15.4355
      2      [36m0.9897[0m        [32m0.0579[0m       [35m0.4693[0m      [31m0.7551[0m        [94m0.3908[0m     +  0.0001  15.5015
      3      [36m0.9901[0m        [32m0.0525[0m       [35m0.4835[0m      0.7369        [94m0.3896[0m     +  0.0001  15.4968
      4      [36m0.9905[0m        [32m0.0507[0m       [35m0.5278[0m      0.7432        [94m0.3837[0m     +  0.0001  15.5461
      5      [36m0.9909[0m        [32m0.0466[0m       [35m0.5405[0m      0.7528        [94m0.3793[0m     +  0.0001  15.5200
      6      [36m0.9917[0m        [32m0.0399[0m       [35m0.5441[0m      0.7131        0.4261        0.0000  15.2554
      7      [36m0.9923[0m        [32m0.0390[0m       [35m0.5448[0m      0.7146        0.4323        0.0000  15.3655
      8      0.9921        [32m0.0385[0m       [35m0.5483[0m      0.7220        0.4254        0.0000  15.4722
      9      0.9919        0.0391       0.5382      0.7134        0.4389        0.0000  15.1699
     10      [36m0.9927[0m        [32m0.0376[0m       0.5378      0.7093        0.4478        0.0000  15.4156
     11      [36m0.9931[0m        [32m0.0345[0m       [35m0.5495[0m      0.7090        0.4482        0.0000  15.3187
     12      [36m0.9933[0m        [32m0.0343[0m       [35m0.5559[0m      0.7092        0.4571        0.0000  15.2994
     13      0.9932        [32m0.0332[0m       0.5502      0.7090        0.4597        0.0000  15.4487
     14      0.9930        0.0349       0.5484      0.7077        0.4583        0.0000  15.0780
     15      [36m0.9935[0m        [32m0.0328[0m       0.5509      0.7061        0.4647        0.0000  15.1767
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7672642495377443
F1 Macro Score after query 8: 0.7578622439016147
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9773[0m        [32m0.1003[0m       [35m0.4309[0m      [31m0.7480[0m        [94m0.5068[0m     +  0.0001  19.1876
      2      [36m0.9808[0m        [32m0.0863[0m       [35m0.5118[0m      [31m0.7668[0m        [94m0.4632[0m     +  0.0001  19.2087
      3      [36m0.9822[0m        [32m0.0800[0m       [35m0.5155[0m      0.7585        0.4727        0.0001  19.1366
      4      [36m0.9837[0m        [32m0.0754[0m       0.5130      0.7523        0.4792        0.0001  19.1126
      5      [36m0.9845[0m        [32m0.0719[0m       0.5073      0.7439        0.5133        0.0001  19.3237
      6      [36m0.9872[0m        [32m0.0622[0m       [35m0.5184[0m      0.7315        0.5105        0.0000  19.0928
      7      [36m0.9873[0m        [32m0.0602[0m       0.5082      0.7307        0.5243        0.0000  19.2055
      8      0.9873        [32m0.0594[0m       0.5165      0.7338        0.5126        0.0000  19.2004
      9      0.9873        [32m0.0581[0m       0.5099      0.7309        0.5270        0.0000  19.1172
     10      [36m0.9875[0m        [32m0.0576[0m       0.5163      0.7292        0.5212        0.0000  19.0455
     11      [36m0.9886[0m        [32m0.0539[0m       0.5160      0.7260        0.5160        0.0000  19.0475
     12      0.9885        0.0539       0.5137      0.7244        0.5137        0.0000  19.1106
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.7640778119058066
F1 Macro Score after query 9: 0.7659933353523493
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9578[0m        [32m0.1628[0m       [35m0.5644[0m      [31m0.7982[0m        [94m0.3507[0m     +  0.0001  25.6992
      2      [36m0.9652[0m        [32m0.1372[0m       0.5226      0.7912        0.3852        0.0001  25.6099
      3      [36m0.9705[0m        [32m0.1233[0m       0.5111      0.7805        0.3807        0.0001  25.7704
      4      [36m0.9721[0m        [32m0.1147[0m       0.4854      0.7815        0.4223        0.0001  25.6742
      5      [36m0.9738[0m        [32m0.1085[0m       0.4724      0.7748        0.4332        0.0001  25.7018
      6      [36m0.9767[0m        [32m0.0950[0m       0.4684      0.7811        0.4555        0.0000  25.5502
      7      [36m0.9783[0m        [32m0.0921[0m       0.4700      0.7838        0.4586        0.0000  25.7815
      8      [36m0.9790[0m        [32m0.0891[0m       0.4714      0.7865        0.4693        0.0000  25.8747
      9      [36m0.9791[0m        [32m0.0870[0m       0.4681      0.7858        0.4865        0.0000  26.0303
     10      [36m0.9804[0m        [32m0.0854[0m       0.4552      0.7827        0.5049        0.0000  25.6553
     11      [36m0.9806[0m        [32m0.0814[0m       0.4694      0.7892        0.4815        0.0000  25.8261
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.7919246298788696
F1 Macro Score after query 10: 0.806501519000454
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9410[0m        [32m0.1667[0m       [35m0.7198[0m      [31m0.8277[0m        [94m0.2455[0m     +  0.0001  37.2992
      2      [36m0.9513[0m        [32m0.1377[0m       [35m0.7345[0m      [31m0.8356[0m        [94m0.2422[0m     +  0.0001  37.2987
      3      [36m0.9568[0m        [32m0.1234[0m       [35m0.7411[0m      [31m0.8404[0m        0.2493        0.0001  36.8882
      4      [36m0.9603[0m        [32m0.1136[0m       [35m0.7439[0m      0.8368        0.2517        0.0001  37.3457
      5      [36m0.9632[0m        [32m0.1075[0m       0.7351      0.8280        0.2688        0.0001  37.3597
      6      [36m0.9679[0m        [32m0.0933[0m       0.7424      [31m0.8491[0m        0.2740        0.0000  37.3979
      7      [36m0.9689[0m        [32m0.0906[0m       0.7408      [31m0.8503[0m        0.2838        0.0000  37.3515
      8      [36m0.9706[0m        [32m0.0874[0m       [35m0.7472[0m      [31m0.8522[0m        0.2786        0.0000  37.1406
      9      0.9704        [32m0.0862[0m       0.7465      0.8507        0.2732        0.0000  37.3752
     10      [36m0.9719[0m        [32m0.0845[0m       [35m0.7519[0m      0.8514        0.2657        0.0000  37.3254
     11      [36m0.9733[0m        [32m0.0803[0m       0.7503      [31m0.8570[0m        0.2749        0.0000  37.4287
     12      0.9729        [32m0.0791[0m       0.7453      [31m0.8572[0m        0.2807        0.0000  37.3893
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8968762051677593
F1 Macro Score after query 11: 0.8858192332876379
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9385[0m        [32m0.1238[0m       [35m0.7660[0m      [31m0.8228[0m        [94m0.2251[0m     +  0.0001  57.5637
      2      [36m0.9443[0m        [32m0.1079[0m       [35m0.7726[0m      [31m0.8342[0m        [94m0.2197[0m     +  0.0001  58.4059
      3      [36m0.9491[0m        [32m0.0982[0m       [35m0.7767[0m      [31m0.8459[0m        [94m0.2138[0m     +  0.0001  58.4678
      4      [36m0.9528[0m        [32m0.0912[0m       0.7686      0.8414        0.2333        0.0001  58.1929
      5      [36m0.9557[0m        [32m0.0873[0m       0.7575      0.8099        0.2471        0.0001  58.0454
      6      [36m0.9608[0m        [32m0.0755[0m       0.7512      0.8379        0.2760        0.0000  58.4228
      7      [36m0.9628[0m        [32m0.0724[0m       0.7415      0.8333        0.2908        0.0000  58.3917
      8      [36m0.9634[0m        [32m0.0704[0m       0.7594      0.8444        0.2560        0.0000  58.3887
      9      [36m0.9643[0m        [32m0.0685[0m       0.7451      0.8383        0.2755        0.0000  58.1212
     10      [36m0.9652[0m        [32m0.0675[0m       0.7634      0.8451        0.2409        0.0000  58.1058
     11      [36m0.9674[0m        [32m0.0624[0m       0.7497      [31m0.8473[0m        0.2916        0.0000  58.0309
     12      [36m0.9678[0m        [32m0.0621[0m       0.7524      0.8460        0.2849        0.0000  58.1996
     13      0.9673        [32m0.0620[0m       0.7540      [31m0.8474[0m        0.2728        0.0000  58.4217
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8989531178880291
F1 Macro Score after query 12: 0.8846094464730493
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9449[0m        [32m0.0987[0m       [35m0.7460[0m      [31m0.8316[0m        [94m0.2824[0m     +  0.0001  65.9975
      2      [36m0.9490[0m        [32m0.0902[0m       [35m0.7698[0m      [31m0.8389[0m        [94m0.2468[0m     +  0.0001  66.7018
      3      [36m0.9520[0m        [32m0.0849[0m       0.7538      0.8354        0.2884        0.0001  66.6096
      4      [36m0.9545[0m        [32m0.0803[0m       0.7665      [31m0.8467[0m        0.2693        0.0001  66.7808
      5      [36m0.9566[0m        [32m0.0773[0m       0.7535      0.8303        0.2825        0.0001  66.6867
      6      [36m0.9618[0m        [32m0.0656[0m       0.7549      [31m0.8485[0m        0.3043        0.0000  66.5515
      7      [36m0.9633[0m        [32m0.0643[0m       0.7538      0.8447        0.2930        0.0000  66.5414
      8      [36m0.9643[0m        [32m0.0623[0m       0.7488      0.8436        0.3156        0.0000  66.9841
      9      [36m0.9651[0m        [32m0.0613[0m       0.7505      0.8413        0.2966        0.0000  66.7225
     10      [36m0.9653[0m        [32m0.0609[0m       0.7467      0.8469        0.3184        0.0000  66.5910
     11      [36m0.9667[0m        [32m0.0566[0m       0.7481      [31m0.8516[0m        0.3336        0.0000  66.7128
     12      [36m0.9678[0m        [32m0.0558[0m       0.7523      [31m0.8518[0m        0.3207        0.0000  66.7654
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.9010526315789473
F1 Macro Score after query 13: 0.8893174417774262
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed44_config2\AL_average_score_results_for_multilabel_classification.pickle
