Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2434[0m        [32m0.6979[0m       [35m0.1743[0m      [31m0.4814[0m        [94m0.6974[0m     +  0.0001  12.7854
      2      [36m0.8320[0m        [32m0.6060[0m       0.1276      0.4306        0.7038        0.0001  10.8778
      3      0.7667        0.6264       0.1323      0.4351        0.7086        0.0001  10.8920
      4      0.5985        0.6300       [35m0.2733[0m      0.4432        [94m0.6808[0m     +  0.0001  10.8105
      5      0.7368        [32m0.5420[0m       0.2479      0.4483        0.6907        0.0001  11.0882
      6      0.7963        0.5478       0.2483      0.4404        0.6928        0.0000  10.9841
      7      0.6905        0.5752       0.2500      0.4425        0.6925        0.0000  10.9831
      8      0.7857        0.5549       0.2576      0.4437        0.6927        0.0000  11.0381
      9      0.7222        0.5526       0.2585      0.4446        0.6912        0.0000  10.8962
     10      0.7500        0.5567       0.2540      0.4484        0.6946        0.0000  11.2048
     11      0.6111        0.5854       0.2481      0.4463        0.6956        0.0000  10.9235
     12      [36m0.8690[0m        [32m0.4682[0m       0.2500      0.4457        0.6959        0.0000  11.0668
     13      0.8333        0.5104       0.2587      0.4473        0.6939        0.0000  11.1748
     14      0.6111        0.5341       0.2528      0.4475        0.6950        0.0000  11.1203
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4688
Pre F1 macro score = 0.4682
Pre Accuracy = 0.2630

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9491[0m        [32m0.3998[0m       [35m0.1811[0m      [31m0.5460[0m        [94m0.9222[0m     +  0.0001  11.1388
      2      0.9299        [32m0.3538[0m       0.1722      0.4772        [94m0.8806[0m     +  0.0001  11.0313
      3      0.9423        [32m0.2842[0m       [35m0.2170[0m      0.4794        [94m0.8730[0m     +  0.0001  11.0270
      4      0.9423        [32m0.2787[0m       [35m0.2233[0m      0.4829        0.8857        0.0001  11.1981
      5      0.9423        [32m0.2761[0m       [35m0.2503[0m      0.4789        0.8813        0.0001  11.2308
      6      [36m0.9500[0m        [32m0.2574[0m       [35m0.2601[0m      0.4836        [94m0.8601[0m     +  0.0000  11.0262
      7      [36m0.9671[0m        [32m0.2330[0m       0.2601      0.4812        [94m0.8493[0m     +  0.0000  11.0764
      8      0.9585        [32m0.2232[0m       0.2550      0.4788        0.8500        0.0000  11.1320
      9      0.9581        0.2270       [35m0.2615[0m      0.4810        [94m0.8372[0m     +  0.0000  11.0526
     10      0.9581        0.2368       0.2597      0.4898        [94m0.8297[0m     +  0.0000  10.9799
     11      0.9667        0.2280       0.2562      0.4862        [94m0.8283[0m     +  0.0000  11.1104
     12      0.9667        [32m0.2221[0m       0.2564      0.4851        [94m0.8264[0m     +  0.0000  11.1237
     13      0.9667        0.2260       0.2599      0.4861        [94m0.8215[0m     +  0.0000  11.1275
     14      0.9581        [32m0.2184[0m       0.2566      0.4890        [94m0.8212[0m     +  0.0000  10.9158
     15      [36m0.9752[0m        [32m0.1998[0m       0.2569      0.4873        [94m0.8186[0m     +  0.0000  11.0649
     16      0.9752        [32m0.1805[0m       0.2568      0.4873        [94m0.8181[0m     +  0.0000  11.0933
     17      0.9671        0.2148       0.2573      0.4877        [94m0.8158[0m     +  0.0000  11.0636
     18      0.9752        0.2126       0.2594      0.4876        [94m0.8144[0m     +  0.0000  11.0499
     19      0.9667        0.2218       0.2609      0.4871        [94m0.8135[0m     +  0.0000  11.0312
     20      0.9752        0.2105       0.2608      0.4864        [94m0.8124[0m     +  0.0000  11.1457
     21      0.9667        0.1875       0.2608      0.4865        [94m0.8122[0m     +  0.0000  11.0944
     22      0.9581        0.2112       0.2611      0.4869        [94m0.8121[0m     +  0.0000  11.0307
     23      0.9752        0.1847       [35m0.2616[0m      0.4870        [94m0.8118[0m     +  0.0000  11.0415
     24      0.9500        0.1852       0.2613      0.4872        [94m0.8113[0m     +  0.0000  10.9520
     25      0.9667        0.2050       [35m0.2620[0m      0.4874        [94m0.8110[0m     +  0.0000  11.0213
     26      0.9752        0.2213       0.2618      0.4874        [94m0.8108[0m     +  0.0000  11.1386
     27      0.9752        [32m0.1799[0m       0.2616      0.4875        [94m0.8108[0m     +  0.0000  11.0725
     28      0.9500        0.2050       0.2620      0.4874        [94m0.8106[0m     +  0.0000  11.1375
     29      0.9667        0.2008       [35m0.2625[0m      0.4874        [94m0.8104[0m     +  0.0000  11.0880
     30      0.9667        0.1998       [35m0.2627[0m      0.4873        [94m0.8103[0m     +  0.0000  11.0264
     31      0.9752        0.2040       0.2625      0.4872        [94m0.8102[0m     +  0.0000  11.0650
     32      0.9585        0.2276       0.2625      0.4872        [94m0.8102[0m     +  0.0000  11.0289
     33      0.9667        0.2180       0.2625      0.4872        [94m0.8101[0m     +  0.0000  11.1593
     34      0.9667        0.2000       0.2623      0.4872        [94m0.8101[0m     +  0.0000  10.9669
     35      0.9752        0.1937       0.2625      0.4872        [94m0.8100[0m     +  0.0000  11.1723
     36      0.9667        0.2031       0.2625      0.4873        0.8101        0.0000  11.0729
     37      0.9752        0.1918       0.2625      0.4873        0.8100        0.0000  11.0595
     38      0.9585        0.2268       0.2625      0.4873        0.8101        0.0000  10.9714
     39      0.9585        0.2044       0.2625      0.4872        [94m0.8100[0m     +  0.0000  11.0317
     40      0.9752        0.1959       0.2625      0.4872        [94m0.8100[0m     +  0.0000  11.1151
     41      0.9752        [32m0.1759[0m       0.2625      0.4873        0.8100        0.0000  11.1117
     42      0.9752        0.2012       0.2625      0.4873        [94m0.8100[0m     +  0.0000  11.0037
     43      0.9667        0.1864       0.2625      0.4873        [94m0.8100[0m     +  0.0000  11.0681
     44      0.9581        0.1888       0.2625      0.4873        [94m0.8100[0m     +  0.0000  11.0832
     45      0.9752        0.1979       0.2625      0.4873        [94m0.8100[0m     +  0.0000  11.0307
     46      0.9500        0.2171       0.2625      0.4873        [94m0.8100[0m     +  0.0000  10.9996
     47      0.9667        0.2002       0.2625      0.4873        [94m0.8100[0m     +  0.0000  11.1587
     48      0.9491        0.2048       0.2625      0.4873        [94m0.8100[0m     +  0.0000  11.1469
     49      0.9667        0.2126       0.2625      0.4873        [94m0.8100[0m     +  0.0000  11.0791
     50      0.9500        0.2182       0.2625      0.4873        0.8100        0.0000  11.0929
     51      0.9585        0.2078       0.2625      0.4873        0.8100        0.0000  11.2156
     52      0.9667        0.1938       0.2625      0.4873        0.8100        0.0000  11.1230
     53      0.9585        0.2143       0.2625      0.4873        [94m0.8100[0m     +  0.0000  11.0214
     54      0.9585        0.1925       0.2625      0.4873        0.8100        0.0000  11.0287
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.49923633707417486
F1 Macro Score after query 1: 0.4899851325798326
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9771[0m        [32m0.1543[0m       [35m0.2925[0m      [31m0.5813[0m        [94m0.9819[0m     +  0.0001  11.1786
      2      [36m0.9872[0m        [32m0.1141[0m       0.2686      0.4865        [94m0.9124[0m     +  0.0001  11.1737
      3      0.9840        [32m0.1028[0m       0.2894      0.4997        [94m0.8644[0m     +  0.0001  11.1553
      4      0.9871        [32m0.0975[0m       0.2491      0.5059        [94m0.8480[0m     +  0.0001  11.0460
      5      [36m0.9904[0m        [32m0.0769[0m       0.2684      0.5071        [94m0.8079[0m     +  0.0001  11.0772
      6      [36m0.9936[0m        [32m0.0672[0m       0.2668      0.5081        [94m0.7781[0m     +  0.0000  11.1916
      7      0.9936        [32m0.0622[0m       0.2625      0.5083        [94m0.7719[0m     +  0.0000  11.1407
      8      0.9936        0.0700       0.2641      0.5068        [94m0.7542[0m     +  0.0000  11.1803
      9      0.9936        0.0623       0.2609      0.5067        [94m0.7459[0m     +  0.0000  11.2491
     10      0.9904        0.0641       0.2552      0.5076        [94m0.7414[0m     +  0.0000  11.0934
     11      0.9936        0.0664       0.2561      0.5077        [94m0.7363[0m     +  0.0000  11.1266
     12      0.9936        [32m0.0586[0m       0.2549      0.5079        [94m0.7325[0m     +  0.0000  11.3709
     13      0.9936        [32m0.0503[0m       0.2536      0.5081        [94m0.7304[0m     +  0.0000  11.1066
     14      0.9936        0.0566       0.2542      0.5079        [94m0.7255[0m     +  0.0000  11.1405
     15      0.9936        0.0572       0.2535      0.5090        [94m0.7207[0m     +  0.0000  11.1088
     16      0.9904        0.0517       0.2535      0.5078        [94m0.7196[0m     +  0.0000  11.1382
     17      0.9936        0.0607       0.2530      0.5084        [94m0.7176[0m     +  0.0000  11.2676
     18      0.9936        0.0534       0.2526      0.5085        [94m0.7165[0m     +  0.0000  11.0473
     19      0.9936        0.0510       0.2526      0.5084        [94m0.7152[0m     +  0.0000  11.1589
     20      0.9936        [32m0.0498[0m       0.2519      0.5086        [94m0.7134[0m     +  0.0000  11.1193
     21      0.9936        [32m0.0488[0m       0.2526      0.5089        [94m0.7125[0m     +  0.0000  11.0258
     22      0.9936        0.0529       0.2521      0.5090        [94m0.7122[0m     +  0.0000  11.1505
     23      0.9936        0.0515       0.2521      0.5090        [94m0.7120[0m     +  0.0000  11.1563
     24      0.9936        0.0518       0.2507      0.5083        [94m0.7120[0m     +  0.0000  11.0958
     25      0.9936        0.0519       0.2500      0.5084        [94m0.7117[0m     +  0.0000  11.1157
     26      0.9904        0.0554       0.2500      0.5084        [94m0.7113[0m     +  0.0000  11.1845
     27      0.9936        0.0544       0.2498      0.5083        [94m0.7110[0m     +  0.0000  11.0779
     28      0.9936        0.0525       0.2502      0.5084        0.7111        0.0000  11.2019
     29      0.9936        [32m0.0468[0m       0.2500      0.5082        0.7113        0.0000  11.0159
     30      [36m0.9968[0m        0.0487       0.2500      0.5083        0.7116        0.0000  11.1716
     31      0.9936        0.0570       0.2502      0.5084        0.7114        0.0000  11.1346
     32      0.9968        0.0516       0.2502      0.5084        0.7114        0.0000  11.2577
     33      0.9936        [32m0.0465[0m       0.2500      0.5083        0.7114        0.0000  11.3160
     34      0.9936        0.0543       0.2500      0.5083        0.7114        0.0000  11.2106
     35      0.9936        0.0577       0.2500      0.5083        0.7113        0.0000  11.3588
     36      0.9936        0.0548       0.2498      0.5083        0.7112        0.0000  11.1746
     37      0.9936        0.0567       0.2498      0.5083        0.7112        0.0000  11.2384
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.5371557371275621
F1 Macro Score after query 2: 0.5167260988558415
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9889[0m        [32m0.1159[0m       [35m0.2684[0m      [31m0.5984[0m        [94m1.1674[0m     +  0.0001  11.2402
      2      0.9784        0.1247       0.2533      0.5119        [94m0.7947[0m     +  0.0001  11.2335
      3      0.9874        [32m0.1068[0m       0.2623      0.5138        [94m0.7718[0m     +  0.0001  11.3734
      4      0.9889        [32m0.0869[0m       0.2566      0.5090        [94m0.7520[0m     +  0.0001  11.4150
      5      0.9889        [32m0.0745[0m       0.2644      0.5132        [94m0.7437[0m     +  0.0001  11.2352
      6      0.9889        [32m0.0593[0m       [35m0.2694[0m      0.5142        [94m0.7284[0m     +  0.0000  11.1853
      7      0.9889        0.0649       [35m0.2724[0m      0.5137        [94m0.7120[0m     +  0.0000  11.2261
      8      [36m0.9905[0m        [32m0.0588[0m       0.2674      0.5184        [94m0.7042[0m     +  0.0000  11.2143
      9      0.9905        [32m0.0558[0m       0.2705      0.5166        [94m0.6933[0m     +  0.0000  11.2379
     10      0.9905        [32m0.0478[0m       0.2696      0.5160        [94m0.6834[0m     +  0.0000  11.3321
     11      0.9905        0.0503       [35m0.2727[0m      0.5159        [94m0.6776[0m     +  0.0000  11.3293
     12      [36m0.9936[0m        [32m0.0460[0m       0.2710      0.5162        [94m0.6744[0m     +  0.0000  11.4026
     13      0.9920        0.0487       0.2682      0.5148        0.6768        0.0000  11.2949
     14      0.9920        0.0470       0.2689      0.5159        0.6753        0.0000  11.2304
     15      0.9905        0.0462       0.2715      0.5149        [94m0.6717[0m     +  0.0000  11.2782
     16      0.9936        [32m0.0441[0m       0.2714      0.5142        [94m0.6710[0m     +  0.0000  11.3811
     17      0.9905        0.0457       0.2726      0.5133        [94m0.6695[0m     +  0.0000  11.2612
     18      [36m0.9952[0m        [32m0.0396[0m       0.2715      0.5146        0.6703        0.0000  11.3731
     19      0.9919        0.0426       0.2717      0.5150        0.6702        0.0000  11.1746
     20      0.9952        0.0459       0.2701      0.5148        0.6714        0.0000  11.2443
     21      0.9936        0.0481       0.2705      0.5147        0.6708        0.0000  11.3430
     22      0.9935        [32m0.0393[0m       0.2698      0.5145        0.6707        0.0000  11.2017
     23      0.9952        0.0435       0.2698      0.5144        0.6705        0.0000  11.2010
     24      0.9935        0.0417       0.2700      0.5142        0.6700        0.0000  11.5293
     25      0.9952        [32m0.0376[0m       0.2696      0.5143        0.6700        0.0000  11.2546
     26      0.9919        0.0403       0.2696      0.5143        0.6700        0.0000  11.2876
     27      0.9935        0.0400       0.2696      0.5143        0.6700        0.0000  11.1923
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.573621103117506
F1 Macro Score after query 3: 0.5465087291098365
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9726[0m        [32m0.1419[0m       [35m0.2821[0m      [31m0.6108[0m        [94m1.1446[0m     +  0.0001  11.5794
      2      0.9722        0.1437       0.2495      0.5638        [94m0.8535[0m     +  0.0001  11.4484
      3      [36m0.9765[0m        [32m0.1277[0m       0.2547      0.5577        [94m0.8445[0m     +  0.0001  11.3928
      4      0.9764        [32m0.1173[0m       0.2696      0.5615        [94m0.7882[0m     +  0.0001  11.4497
      5      [36m0.9771[0m        [32m0.1058[0m       0.2677      0.5686        [94m0.7733[0m     +  0.0001  11.6113
      6      [36m0.9772[0m        [32m0.1005[0m       0.2582      0.5406        [94m0.7247[0m     +  0.0000  11.6241
      7      0.9770        0.1055       0.2703      0.5309        [94m0.7076[0m     +  0.0000  11.6092
      8      [36m0.9812[0m        [32m0.0907[0m       0.2604      0.5357        [94m0.7063[0m     +  0.0000  11.4952
      9      0.9777        [32m0.0899[0m       0.2646      0.5308        [94m0.6983[0m     +  0.0000  11.4536
     10      [36m0.9812[0m        [32m0.0802[0m       0.2609      0.5299        [94m0.6977[0m     +  0.0000  11.3937
     11      [36m0.9829[0m        0.0821       0.2701      0.5251        [94m0.6927[0m     +  0.0000  11.5900
     12      0.9792        0.0886       0.2679      0.5242        [94m0.6877[0m     +  0.0000  11.4254
     13      0.9802        [32m0.0800[0m       0.2677      0.5267        [94m0.6850[0m     +  0.0000  11.5310
     14      0.9811        0.0801       0.2708      0.5239        [94m0.6835[0m     +  0.0000  11.3781
     15      0.9792        0.0817       0.2705      0.5233        [94m0.6804[0m     +  0.0000  11.4411
     16      0.9809        [32m0.0786[0m       0.2715      0.5239        [94m0.6796[0m     +  0.0000  11.5475
     17      0.9818        [32m0.0780[0m       0.2719      0.5239        [94m0.6785[0m     +  0.0000  11.4287
     18      0.9828        [32m0.0732[0m       0.2738      0.5242        [94m0.6781[0m     +  0.0000  11.6282
     19      0.9809        0.0785       0.2740      0.5242        [94m0.6765[0m     +  0.0000  11.6430
     20      0.9808        0.0793       0.2760      0.5226        [94m0.6765[0m     +  0.0000  11.5412
     21      [36m0.9855[0m        0.0766       0.2769      0.5228        0.6765        0.0000  11.5022
     22      0.9799        0.0780       0.2776      0.5230        [94m0.6762[0m     +  0.0000  11.4740
     23      0.9854        [32m0.0724[0m       0.2762      0.5233        0.6766        0.0000  11.4204
     24      0.9810        0.0811       0.2764      0.5231        [94m0.6761[0m     +  0.0000  11.3393
     25      0.9809        0.0753       0.2769      0.5233        0.6762        0.0000  11.4720
     26      0.9844        0.0754       0.2767      0.5234        0.6762        0.0000  11.5905
     27      0.9818        0.0767       0.2766      0.5234        [94m0.6761[0m     +  0.0000  11.4729
     28      0.9818        0.0724       0.2762      0.5232        0.6762        0.0000  11.5991
     29      0.9808        0.0775       0.2755      0.5232        0.6763        0.0000  11.5533
     30      0.9809        0.0724       0.2760      0.5236        0.6763        0.0000  11.6876
     31      0.9836        0.0747       0.2757      0.5234        0.6763        0.0000  11.4838
     32      0.9818        0.0741       0.2757      0.5237        0.6763        0.0000  11.5454
     33      0.9818        0.0788       0.2760      0.5237        0.6764        0.0000  11.2711
     34      0.9817        [32m0.0721[0m       0.2759      0.5237        0.6764        0.0000  11.5207
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.5881204231082181
F1 Macro Score after query 4: 0.5596973037371367
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9828[0m        [32m0.0961[0m       [35m0.3167[0m      [31m0.6239[0m        [94m1.1734[0m     +  0.0001  11.8621
      2      [36m0.9844[0m        [32m0.0858[0m       0.2981      0.5849        [94m0.7854[0m     +  0.0001  11.9015
      3      0.9837        [32m0.0754[0m       0.2951      0.5861        [94m0.7523[0m     +  0.0001  11.8054
      4      0.9841        0.0768       0.2929      0.5747        [94m0.7358[0m     +  0.0001  11.8054
      5      [36m0.9865[0m        [32m0.0685[0m       0.2780      0.5764        [94m0.7181[0m     +  0.0001  11.8706
      6      0.9860        [32m0.0600[0m       0.2892      0.5583        [94m0.7012[0m     +  0.0000  11.8032
      7      [36m0.9887[0m        [32m0.0577[0m       0.2970      0.5521        [94m0.6935[0m     +  0.0000  11.9531
      8      0.9882        [32m0.0559[0m       0.2951      0.5516        0.6956        0.0000  11.8882
      9      0.9887        [32m0.0548[0m       0.2977      0.5537        [94m0.6856[0m     +  0.0000  11.8577
     10      0.9882        0.0551       0.2911      0.5549        0.6870        0.0000  11.8629
     11      0.9873        [32m0.0521[0m       0.2997      0.5471        [94m0.6836[0m     +  0.0000  11.9256
     12      0.9878        [32m0.0491[0m       0.2979      0.5477        0.6836        0.0000  11.8453
     13      [36m0.9892[0m        0.0497       0.2943      0.5467        [94m0.6813[0m     +  0.0000  11.7134
     14      0.9891        [32m0.0475[0m       0.2936      0.5493        0.6828        0.0000  11.8508
     15      0.9886        0.0476       0.3000      0.5477        0.6836        0.0000  11.7669
     16      0.9882        0.0490       0.3014      0.5466        0.6823        0.0000  11.9339
     17      0.9887        [32m0.0463[0m       0.3017      0.5472        0.6829        0.0000  11.8733
     18      0.9891        [32m0.0451[0m       0.3000      0.5470        0.6841        0.0000  11.9521
     19      [36m0.9900[0m        0.0463       0.3005      0.5477        0.6829        0.0000  11.8909
     20      [36m0.9901[0m        [32m0.0440[0m       0.3026      0.5489        0.6827        0.0000  11.9219
     21      0.9896        [32m0.0427[0m       0.3016      0.5492        0.6826        0.0000  11.8130
     22      0.9896        0.0447       0.3016      0.5490        0.6826        0.0000  11.7987
     23      0.9891        0.0464       0.3016      0.5480        0.6822        0.0000  11.8655
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.6159268272216162
F1 Macro Score after query 5: 0.59041009515405
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9776[0m        [32m0.1299[0m       [35m0.3184[0m      [31m0.6469[0m        [94m0.7139[0m     +  0.0001  12.4843
      2      [36m0.9803[0m        [32m0.1067[0m       0.3170      0.5748        [94m0.6217[0m     +  0.0001  12.4685
      3      [36m0.9821[0m        [32m0.0925[0m       [35m0.3233[0m      0.5972        [94m0.6053[0m     +  0.0001  12.3908
      4      [36m0.9856[0m        [32m0.0829[0m       0.2870      0.6014        0.6185        0.0001  12.5463
      5      0.9844        [32m0.0804[0m       0.3177      0.6043        0.6103        0.0001  12.3539
      6      [36m0.9869[0m        [32m0.0658[0m       0.2720      0.6144        0.6682        0.0000  12.6517
      7      [36m0.9876[0m        0.0665       0.2793      0.6132        0.6652        0.0000  12.5435
      8      [36m0.9883[0m        [32m0.0628[0m       0.2858      0.6091        0.6572        0.0000  12.4522
      9      0.9864        [32m0.0617[0m       0.2759      0.6146        0.6662        0.0000  12.5613
     10      0.9879        [32m0.0602[0m       0.2769      0.6121        0.6683        0.0000  12.5159
     11      0.9872        [32m0.0560[0m       0.2757      0.6130        0.6766        0.0000  12.4528
     12      [36m0.9886[0m        [32m0.0555[0m       0.2724      0.6124        0.6812        0.0000  12.5070
     13      [36m0.9889[0m        0.0557       0.2750      0.6132        0.6825        0.0000  12.7703
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6553508590353964
F1 Macro Score after query 6: 0.6395494710751378
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9838[0m        [32m0.0923[0m       [35m0.3148[0m      [31m0.6496[0m        [94m0.8852[0m     +  0.0001  13.6773
      2      [36m0.9839[0m        [32m0.0774[0m       [35m0.3330[0m      [31m0.6586[0m        [94m0.6594[0m     +  0.0001  13.6266
      3      [36m0.9859[0m        [32m0.0718[0m       [35m0.3347[0m      0.6557        [94m0.5766[0m     +  0.0001  13.5004
      4      [36m0.9864[0m        [32m0.0669[0m       [35m0.3656[0m      0.6546        [94m0.5697[0m     +  0.0001  13.8970
      5      [36m0.9880[0m        [32m0.0627[0m       [35m0.3710[0m      [31m0.6587[0m        [94m0.5562[0m     +  0.0001  13.6107
      6      [36m0.9885[0m        [32m0.0543[0m       0.3656      0.6495        0.5681        0.0000  13.6556
      7      [36m0.9894[0m        [32m0.0527[0m       0.3549      0.6498        0.5756        0.0000  13.5782
      8      [36m0.9902[0m        [32m0.0505[0m       [35m0.3753[0m      0.6480        0.5712        0.0000  13.9098
      9      0.9896        [32m0.0499[0m       0.3576      0.6477        0.5825        0.0000  13.5799
     10      [36m0.9903[0m        [32m0.0490[0m       [35m0.3774[0m      0.6507        0.5769        0.0000  13.4550
     11      0.9902        [32m0.0454[0m       0.3724      0.6523        0.5828        0.0000  13.7368
     12      [36m0.9916[0m        [32m0.0450[0m       0.3720      0.6513        0.5821        0.0000  13.7966
     13      0.9907        0.0454       0.3710      0.6516        0.5844        0.0000  13.4981
     14      0.9914        [32m0.0435[0m       0.3648      0.6505        0.5905        0.0000  13.7769
     15      0.9909        0.0443       0.3701      0.6518        0.5856        0.0000  13.6541
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.7249237915517492
F1 Macro Score after query 7: 0.7150802108985511
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9864[0m        [32m0.0809[0m       [35m0.3125[0m      [31m0.6731[0m        [94m0.6473[0m     +  0.0001  15.8544
      2      [36m0.9882[0m        [32m0.0662[0m       [35m0.3543[0m      [31m0.6930[0m        [94m0.6012[0m     +  0.0001  15.6549
      3      [36m0.9890[0m        [32m0.0601[0m       0.3497      0.6914        0.6291        0.0001  15.7188
      4      [36m0.9893[0m        [32m0.0568[0m       0.3425      0.6860        0.6909        0.0001  15.6090
      5      0.9890        [32m0.0551[0m       0.3337      0.6818        0.7071        0.0001  15.8591
      6      [36m0.9906[0m        [32m0.0461[0m       [35m0.3700[0m      [31m0.6935[0m        [94m0.5818[0m     +  0.0000  15.6884
      7      0.9905        0.0468       0.3696      [31m0.6947[0m        0.5884        0.0000  15.9353
      8      [36m0.9908[0m        [32m0.0447[0m       [35m0.3759[0m      0.6926        [94m0.5691[0m     +  0.0000  15.7185
      9      [36m0.9909[0m        [32m0.0426[0m       0.3714      0.6940        0.5698        0.0000  15.6055
     10      0.9908        0.0437       0.3670      0.6914        0.5745        0.0000  15.9531
     11      0.9905        [32m0.0396[0m       [35m0.3764[0m      0.6856        [94m0.5560[0m     +  0.0000  15.6346
     12      [36m0.9915[0m        [32m0.0392[0m       0.3755      0.6874        0.5584        0.0000  15.7453
     13      0.9914        [32m0.0381[0m       [35m0.3800[0m      0.6859        0.5706        0.0000  15.7015
     14      [36m0.9918[0m        [32m0.0377[0m       0.3747      0.6850        0.5714        0.0000  15.5683
     15      0.9916        0.0385       0.3743      0.6855        0.5712        0.0000  15.9064
     16      [36m0.9923[0m        [32m0.0362[0m       0.3792      0.6866        0.5620        0.0000  15.7374
     17      0.9916        0.0366       0.3776      0.6868        0.5669        0.0000  15.6198
     18      0.9920        0.0369       0.3774      0.6855        0.5662        0.0000  15.8940
     19      0.9916        0.0362       0.3785      0.6865        0.5662        0.0000  15.5068
     20      0.9923        0.0365       0.3799      0.6855        0.5653        0.0000  15.8775
     21      0.9922        [32m0.0358[0m       0.3797      0.6854        0.5640        0.0000  15.9364
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7254274232000545
F1 Macro Score after query 8: 0.7197111353440416
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9751[0m        [32m0.1201[0m       [35m0.4571[0m      [31m0.7650[0m        [94m0.4274[0m     +  0.0001  19.5430
      2      [36m0.9781[0m        [32m0.0987[0m       [35m0.5340[0m      [31m0.7806[0m        [94m0.3800[0m     +  0.0001  19.5123
      3      [36m0.9809[0m        [32m0.0873[0m       [35m0.5679[0m      [31m0.7866[0m        [94m0.3669[0m     +  0.0001  19.5666
      4      [36m0.9817[0m        [32m0.0812[0m       [35m0.6057[0m      [31m0.7942[0m        [94m0.3448[0m     +  0.0001  19.3698
      5      [36m0.9835[0m        [32m0.0772[0m       [35m0.6092[0m      [31m0.7993[0m        0.3474        0.0001  19.5620
      6      [36m0.9857[0m        [32m0.0667[0m       [35m0.6280[0m      0.7904        [94m0.3420[0m     +  0.0000  19.2851
      7      [36m0.9862[0m        [32m0.0645[0m       0.6158      0.7887        0.3444        0.0000  19.5905
      8      [36m0.9865[0m        [32m0.0633[0m       0.6061      0.7831        0.3528        0.0000  19.3431
      9      [36m0.9876[0m        [32m0.0602[0m       0.5967      0.7815        0.3604        0.0000  19.6700
     10      0.9875        [32m0.0601[0m       0.5941      0.7830        0.3623        0.0000  19.3286
     11      [36m0.9878[0m        [32m0.0579[0m       0.5929      0.7807        0.3663        0.0000  19.6657
     12      [36m0.9880[0m        [32m0.0573[0m       0.5868      0.7781        0.3723        0.0000  19.5151
     13      0.9879        [32m0.0551[0m       0.5917      0.7807        0.3682        0.0000  19.7288
     14      [36m0.9882[0m        [32m0.0548[0m       0.5880      0.7773        0.3700        0.0000  19.4064
     15      0.9879        0.0561       0.5872      0.7773        0.3722        0.0000  19.5778
     16      [36m0.9884[0m        [32m0.0535[0m       0.5882      0.7793        0.3732        0.0000  19.4858
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8207423412300332
F1 Macro Score after query 9: 0.8153881870984883
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9664[0m        [32m0.1265[0m       [35m0.6191[0m      [31m0.8139[0m        [94m0.3087[0m     +  0.0001  26.6567
      2      [36m0.9699[0m        [32m0.1098[0m       [35m0.6672[0m      [31m0.8300[0m        [94m0.2865[0m     +  0.0001  26.1995
      3      [36m0.9733[0m        [32m0.1013[0m       0.6554      0.8282        0.3077        0.0001  26.1249
      4      [36m0.9745[0m        [32m0.0971[0m       [35m0.6682[0m      [31m0.8337[0m        0.3002        0.0001  26.5027
      5      [36m0.9763[0m        [32m0.0923[0m       0.6587      0.8282        0.3024        0.0001  26.3279
      6      [36m0.9794[0m        [32m0.0795[0m       0.6396      0.8278        0.3287        0.0000  26.1156
      7      [36m0.9806[0m        [32m0.0785[0m       0.6424      0.8299        0.3380        0.0000  26.6602
      8      [36m0.9809[0m        [32m0.0769[0m       0.6438      0.8306        0.3359        0.0000  26.4908
      9      [36m0.9811[0m        [32m0.0753[0m       0.6382      0.8303        0.3495        0.0000  25.9942
     10      [36m0.9817[0m        [32m0.0728[0m       0.6408      0.8293        0.3401        0.0000  26.3879
     11      [36m0.9825[0m        [32m0.0692[0m       0.6148      0.8208        0.3784        0.0000  26.5148
     12      [36m0.9833[0m        [32m0.0683[0m       0.6189      0.8233        0.3728        0.0000  26.2282
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8495976591075347
F1 Macro Score after query 10: 0.8473971107817629
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9455[0m        [32m0.1569[0m       [35m0.7132[0m      [31m0.8237[0m        [94m0.2365[0m     +  0.0001  39.0724
      2      [36m0.9552[0m        [32m0.1323[0m       [35m0.7321[0m      [31m0.8414[0m        0.2390        0.0001  38.8645
      3      [36m0.9582[0m        [32m0.1209[0m       0.7250      0.8276        [94m0.2335[0m     +  0.0001  38.8342
      4      [36m0.9624[0m        [32m0.1125[0m       [35m0.7352[0m      0.8342        0.2355        0.0001  38.7089
      5      [36m0.9653[0m        [32m0.1065[0m       [35m0.7484[0m      [31m0.8486[0m        [94m0.2297[0m     +  0.0001  38.7132
      6      [36m0.9699[0m        [32m0.0936[0m       0.7408      0.8468        0.2405        0.0000  38.7161
      7      [36m0.9699[0m        [32m0.0915[0m       0.7408      0.8471        0.2465        0.0000  38.7269
      8      [36m0.9701[0m        [32m0.0906[0m       0.7444      [31m0.8510[0m        0.2461        0.0000  38.0249
      9      [36m0.9709[0m        [32m0.0880[0m       0.7398      0.8476        0.2441        0.0000  38.8876
     10      [36m0.9714[0m        [32m0.0866[0m       0.7443      [31m0.8519[0m        0.2533        0.0000  38.6989
     11      [36m0.9732[0m        [32m0.0814[0m       0.7455      [31m0.8525[0m        0.2589        0.0000  38.2753
     12      0.9732        [32m0.0811[0m       0.7399      0.8509        0.2596        0.0000  38.7901
     13      [36m0.9737[0m        [32m0.0802[0m       0.7401      0.8520        0.2604        0.0000  38.4709
     14      0.9731        0.0807       0.7396      0.8497        0.2632        0.0000  38.0455
     15      0.9730        0.0802       0.7382      0.8489        0.2624        0.0000  38.8634
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8968832377112731
F1 Macro Score after query 11: 0.8834826870008089
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9469[0m        [32m0.1074[0m       [35m0.7790[0m      [31m0.8713[0m        [94m0.2336[0m     +  0.0001  60.2991
      2      [36m0.9502[0m        [32m0.0966[0m       0.7594      0.8657        0.2699        0.0001  60.2624
      3      [36m0.9535[0m        [32m0.0904[0m       0.7514      0.8604        0.2653        0.0001  59.9814
      4      [36m0.9556[0m        [32m0.0858[0m       0.7484      0.8541        0.2689        0.0001  59.8932
      5      [36m0.9575[0m        [32m0.0814[0m       0.7503      0.8516        0.2678        0.0001  59.9690
      6      [36m0.9630[0m        [32m0.0712[0m       0.7655      0.8608        0.2625        0.0000  59.9056
      7      [36m0.9649[0m        [32m0.0688[0m       0.7582      0.8592        0.2859        0.0000  59.8277
      8      [36m0.9652[0m        [32m0.0675[0m       0.7613      0.8626        0.2849        0.0000  59.8476
      9      [36m0.9656[0m        [32m0.0660[0m       0.7575      0.8607        0.2799        0.0000  59.8594
     10      [36m0.9659[0m        [32m0.0657[0m       0.7535      0.8589        0.2967        0.0000  59.8112
     11      [36m0.9676[0m        [32m0.0616[0m       0.7611      0.8596        0.2789        0.0000  59.9234
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.9025850958987187
F1 Macro Score after query 12: 0.8906533532105326
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9410[0m        [32m0.1044[0m       [35m0.7490[0m      [31m0.8345[0m        [94m0.2682[0m     +  0.0001  68.7345
      2      [36m0.9465[0m        [32m0.0930[0m       [35m0.7554[0m      [31m0.8413[0m        [94m0.2679[0m     +  0.0001  68.6415
      3      [36m0.9512[0m        [32m0.0861[0m       0.7549      0.8378        0.2775        0.0001  68.6568
      4      [36m0.9532[0m        [32m0.0813[0m       [35m0.7611[0m      0.8362        0.2732        0.0001  68.8273
      5      [36m0.9554[0m        [32m0.0768[0m       [35m0.7618[0m      0.8366        0.2784        0.0001  68.9516
      6      [36m0.9617[0m        [32m0.0670[0m       [35m0.7625[0m      [31m0.8560[0m        0.2998        0.0000  69.1190
      7      [36m0.9632[0m        [32m0.0649[0m       0.7495      0.8496        0.3282        0.0000  69.0830
      8      [36m0.9642[0m        [32m0.0630[0m       0.7608      [31m0.8593[0m        0.2990        0.0000  69.4534
      9      [36m0.9644[0m        [32m0.0619[0m       0.7571      0.8551        0.3109        0.0000  69.2612
     10      [36m0.9650[0m        [32m0.0611[0m       0.7571      0.8574        0.3138        0.0000  63.5037
     11      [36m0.9680[0m        [32m0.0570[0m       0.7484      0.8552        0.3502        0.0000  62.4789
     12      [36m0.9683[0m        [32m0.0565[0m       0.7432      0.8502        0.3514        0.0000  62.5052
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.9040765579082208
F1 Macro Score after query 13: 0.8924670184614243
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed43_config2\AL_average_score_results_for_multilabel_classification.pickle
