Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6963[0m        [32m0.6694[0m       [35m0.0502[0m      [31m0.2983[0m        [94m0.7190[0m     +  0.0001  12.0569
      2      0.6498        [32m0.6421[0m       [35m0.1720[0m      [31m0.4558[0m        [94m0.6983[0m     +  0.0001  10.2667
      3      [36m0.7963[0m        [32m0.6193[0m       [35m0.2663[0m      0.4267        [94m0.6873[0m     +  0.0001  10.3724
      4      0.7368        [32m0.5757[0m       0.1826      0.4468        0.7050        0.0001  10.4234
      5      0.7222        0.5919       0.2655      0.4145        0.6883        0.0001  10.3873
      6      0.7222        [32m0.5485[0m       0.2269      0.4425        0.6966        0.0000  10.3465
      7      0.6627        0.5662       0.2170      0.4459        0.7001        0.0000  10.2761
      8      0.7963        [32m0.5172[0m       0.2314      0.4487        0.7015        0.0000  10.2969
      9      0.7963        0.5277       0.2486      0.4525        0.7004        0.0000  10.7138
     10      [36m0.8333[0m        [32m0.5022[0m       0.2611      0.4518        0.7003        0.0000  10.3159
     11      0.6333        0.5754       0.2531      0.4541        0.7040        0.0000  10.3507
     12      0.7963        0.5327       0.2524      0.4526        0.7032        0.0000  10.4940
     13      0.8333        0.5051       0.2481      0.4518        0.7033        0.0000  10.5176
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4573
Pre F1 macro score = 0.4548
Pre Accuracy = 0.2510

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9585[0m        [32m0.3434[0m       [35m0.2411[0m      [31m0.5485[0m        [94m0.9503[0m     +  0.0001  10.6540
      2      0.9454        [32m0.3160[0m       [35m0.2802[0m      0.5282        [94m0.8702[0m     +  0.0001  10.3876
      3      0.9500        [32m0.2439[0m       0.2455      0.5018        0.8863        0.0001  10.5603
      4      0.9500        [32m0.2373[0m       0.2694      0.4928        0.8758        0.0001  10.9572
      5      0.9500        0.2470       [35m0.2812[0m      0.4845        [94m0.8418[0m     +  0.0001  10.8631
      6      0.9508        [32m0.2078[0m       0.2681      0.4731        [94m0.8353[0m     +  0.0000  10.7962
      7      [36m0.9667[0m        0.2095       0.2627      0.4678        [94m0.8285[0m     +  0.0000  10.7813
      8      [36m0.9671[0m        [32m0.1992[0m       0.2759      0.4696        [94m0.8125[0m     +  0.0000  10.7382
      9      0.9500        [32m0.1981[0m       0.2727      0.4711        [94m0.8119[0m     +  0.0000  10.8642
     10      0.9667        [32m0.1724[0m       0.2665      0.4690        0.8162        0.0000  10.8001
     11      0.9667        0.1976       0.2649      0.4702        0.8128        0.0000  10.7512
     12      0.9667        0.1841       0.2644      0.4703        [94m0.8090[0m     +  0.0000  10.8237
     13      0.9671        0.1864       0.2635      0.4697        [94m0.8034[0m     +  0.0000  10.7647
     14      [36m0.9752[0m        [32m0.1693[0m       0.2663      0.4691        [94m0.7990[0m     +  0.0000  10.8506
     15      [36m0.9837[0m        0.1742       0.2642      0.4685        [94m0.7966[0m     +  0.0000  10.8935
     16      0.9667        0.1916       0.2639      0.4677        [94m0.7941[0m     +  0.0000  11.0295
     17      0.9752        [32m0.1605[0m       0.2635      0.4683        [94m0.7929[0m     +  0.0000  10.7651
     18      0.9752        [32m0.1603[0m       0.2658      0.4686        [94m0.7897[0m     +  0.0000  10.9676
     19      0.9667        0.1772       0.2644      0.4679        [94m0.7895[0m     +  0.0000  10.6090
     20      0.9752        0.1678       0.2637      0.4682        0.7899        0.0000  11.2002
     21      0.9752        0.1795       0.2634      0.4682        0.7899        0.0000  11.0000
     22      0.9752        0.1770       0.2630      0.4685        0.7895        0.0000  10.8612
     23      0.9585        0.1722       0.2630      0.4683        [94m0.7894[0m     +  0.0000  11.0127
     24      0.9752        0.1729       0.2644      0.4689        [94m0.7886[0m     +  0.0000  10.9036
     25      0.9581        [32m0.1509[0m       0.2630      0.4688        0.7890        0.0000  10.7819
     26      0.9667        0.1699       0.2627      0.4687        0.7894        0.0000  10.7924
     27      0.9667        0.1648       0.2627      0.4688        0.7893        0.0000  10.9825
     28      0.9667        0.1586       0.2622      0.4686        0.7893        0.0000  10.8291
     29      0.9585        0.1785       0.2628      0.4689        0.7890        0.0000  10.7641
     30      0.9667        0.1713       0.2628      0.4689        0.7889        0.0000  10.8511
     31      0.9667        0.1773       0.2628      0.4689        0.7888        0.0000  10.7942
     32      0.9752        0.1646       0.2628      0.4687        0.7887        0.0000  10.9709
     33      0.9752        0.1627       0.2627      0.4687        0.7887        0.0000  10.8632
     34      0.9662        0.1679       0.2627      0.4687        0.7887        0.0000  10.8682
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.47531034482758616
F1 Macro Score after query 1: 0.47005527748760917
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9872[0m        [32m0.1149[0m       [35m0.2460[0m      [31m0.5615[0m        [94m1.0062[0m     +  0.0001  10.7785
      2      [36m0.9874[0m        [32m0.0882[0m       [35m0.3047[0m      0.4704        [94m0.8260[0m     +  0.0001  10.7019
      3      0.9871        [32m0.0744[0m       0.2582      0.5096        0.8565        0.0001  10.8763
      4      [36m0.9937[0m        [32m0.0583[0m       0.2646      0.4918        [94m0.7994[0m     +  0.0001  10.9795
      5      0.9937        0.0590       0.2575      0.5131        0.8099        0.0001  10.9392
      6      [36m0.9968[0m        [32m0.0534[0m       0.2552      0.4995        [94m0.7887[0m     +  0.0000  10.8630
      7      0.9968        0.0587       0.2595      0.4973        [94m0.7726[0m     +  0.0000  10.8875
      8      0.9968        [32m0.0481[0m       0.2578      0.4964        [94m0.7611[0m     +  0.0000  10.9649
      9      0.9968        0.0496       0.2597      0.4994        [94m0.7488[0m     +  0.0000  10.8933
     10      0.9936        0.0485       0.2554      0.4983        [94m0.7375[0m     +  0.0000  10.9646
     11      0.9968        [32m0.0351[0m       0.2542      0.5007        0.7402        0.0000  10.8451
     12      0.9968        0.0389       0.2533      0.5022        0.7378        0.0000  10.7997
     13      0.9968        0.0366       0.2514      0.5048        0.7414        0.0000  10.7339
     14      0.9968        0.0394       0.2500      0.5044        0.7406        0.0000  10.8785
     15      0.9968        0.0393       0.2500      0.5053        0.7422        0.0000  10.8000
     16      0.9968        [32m0.0342[0m       0.2493      0.5041        0.7392        0.0000  10.7951
     17      0.9968        [32m0.0328[0m       0.2497      0.5052        0.7417        0.0000  10.7869
     18      0.9968        0.0396       0.2505      0.5057        0.7407        0.0000  10.7061
     19      0.9968        0.0444       0.2498      0.5050        0.7401        0.0000  10.9204
     20      0.9968        0.0360       0.2481      0.5051        0.7394        0.0000  10.8811
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.5332046065788566
F1 Macro Score after query 2: 0.5149125745274793
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9953[0m        [32m0.0629[0m       [35m0.2604[0m      [31m0.5758[0m        [94m1.0365[0m     +  0.0001  11.0788
      2      0.9893        0.0644       [35m0.2649[0m      0.5044        [94m0.7905[0m     +  0.0001  10.8088
      3      0.9938        [32m0.0581[0m       0.2547      0.5141        [94m0.7548[0m     +  0.0001  11.0260
      4      0.9953        [32m0.0498[0m       0.2514      0.5237        [94m0.7544[0m     +  0.0001  11.0164
      5      0.9953        [32m0.0478[0m       0.2521      0.5124        [94m0.7082[0m     +  0.0001  10.8885
      6      0.9953        [32m0.0407[0m       0.2422      0.5194        0.7313        0.0000  10.8457
      7      0.9953        0.0429       0.2439      0.5143        0.7106        0.0000  11.0328
      8      [36m0.9969[0m        [32m0.0398[0m       0.2443      0.5179        0.7222        0.0000  10.9090
      9      0.9953        [32m0.0373[0m       0.2410      0.5179        0.7150        0.0000  11.0574
     10      0.9953        0.0374       0.2408      0.5195        0.7123        0.0000  10.8334
     11      0.9953        [32m0.0323[0m       0.2420      0.5196        0.7098        0.0000  10.9513
     12      0.9953        [32m0.0320[0m       0.2410      0.5223        0.7155        0.0000  10.9975
     13      0.9953        [32m0.0296[0m       0.2422      0.5235        0.7130        0.0000  10.8306
     14      0.9953        0.0372       0.2418      0.5199        [94m0.7065[0m     +  0.0000  10.9147
     15      0.9953        0.0323       0.2405      0.5185        [94m0.7044[0m     +  0.0000  11.1074
     16      0.9969        0.0343       0.2410      0.5192        0.7055        0.0000  10.8042
     17      0.9969        0.0343       0.2410      0.5188        [94m0.7041[0m     +  0.0000  10.8413
     18      0.9953        0.0299       0.2418      0.5178        0.7047        0.0000  10.7689
     19      0.9969        0.0321       0.2432      0.5174        [94m0.7040[0m     +  0.0000  10.9531
     20      0.9969        0.0329       0.2424      0.5175        0.7046        0.0000  10.9796
     21      0.9969        0.0339       0.2424      0.5173        0.7044        0.0000  11.0469
     22      0.9969        0.0311       0.2429      0.5172        0.7041        0.0000  11.1632
     23      0.9953        0.0306       0.2431      0.5172        0.7041        0.0000  10.7356
     24      0.9969        0.0342       0.2429      0.5175        0.7044        0.0000  10.8716
     25      0.9969        [32m0.0291[0m       0.2429      0.5166        [94m0.7039[0m     +  0.0000  10.9148
     26      0.9953        0.0339       0.2425      0.5161        [94m0.7037[0m     +  0.0000  10.8604
     27      0.9953        0.0316       0.2425      0.5160        [94m0.7037[0m     +  0.0000  11.0762
     28      0.9969        0.0310       0.2424      0.5161        [94m0.7035[0m     +  0.0000  10.9575
     29      0.9953        0.0326       0.2424      0.5158        [94m0.7033[0m     +  0.0000  10.7976
     30      0.9969        [32m0.0278[0m       0.2424      0.5163        0.7036        0.0000  10.9215
     31      0.9969        0.0320       0.2422      0.5163        0.7036        0.0000  10.8393
     32      0.9953        0.0295       0.2420      0.5162        0.7036        0.0000  11.1332
     33      0.9969        0.0298       0.2422      0.5162        0.7036        0.0000  11.1561
     34      0.9953        0.0321       0.2420      0.5164        0.7037        0.0000  11.1249
     35      0.9969        0.0350       0.2420      0.5161        0.7036        0.0000  11.1230
     36      0.9969        0.0327       0.2418      0.5160        0.7035        0.0000  11.0903
     37      0.9969        0.0309       0.2420      0.5160        0.7036        0.0000  11.0062
     38      0.9969        0.0298       0.2418      0.5160        0.7036        0.0000  10.9704
     39      0.9953        0.0355       0.2417      0.5158        0.7036        0.0000  10.9548
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.552339855665501
F1 Macro Score after query 3: 0.5271632966811041
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9846[0m        [32m0.1204[0m       [35m0.1878[0m      [31m0.5724[0m        [94m1.1994[0m     +  0.0001  11.2729
      2      0.9772        0.1335       [35m0.2604[0m      [31m0.5817[0m        [94m0.8177[0m     +  0.0001  11.1895
      3      0.9830        [32m0.1150[0m       0.2297      0.5406        [94m0.7641[0m     +  0.0001  11.1733
      4      0.9821        [32m0.1091[0m       0.2365      0.5353        [94m0.7437[0m     +  0.0001  11.3212
      5      0.9829        [32m0.0973[0m       0.2531      0.5161        [94m0.7191[0m     +  0.0001  11.2561
      6      0.9838        [32m0.0945[0m       0.2526      0.5173        0.7223        0.0000  11.1748
      7      0.9821        0.0955       0.2488      0.5162        [94m0.7066[0m     +  0.0000  11.1685
      8      0.9829        [32m0.0886[0m       0.2481      0.5150        [94m0.7034[0m     +  0.0000  11.2426
      9      [36m0.9846[0m        [32m0.0858[0m       0.2497      0.5138        [94m0.6977[0m     +  0.0000  11.3062
     10      0.9820        [32m0.0836[0m       0.2434      0.5121        [94m0.6976[0m     +  0.0000  11.2826
     11      0.9836        0.0853       0.2443      0.5164        0.6984        0.0000  11.3148
     12      0.9828        [32m0.0821[0m       0.2502      0.5155        [94m0.6938[0m     +  0.0000  11.2141
     13      0.9845        [32m0.0801[0m       0.2550      0.5175        [94m0.6922[0m     +  0.0000  11.3877
     14      0.9820        0.0815       0.2536      0.5161        [94m0.6911[0m     +  0.0000  11.1954
     15      0.9845        [32m0.0765[0m       0.2602      0.5121        [94m0.6877[0m     +  0.0000  11.3724
     16      [36m0.9854[0m        [32m0.0731[0m       0.2578      0.5136        0.6898        0.0000  11.2838
     17      [36m0.9862[0m        0.0774       0.2590      0.5128        0.6890        0.0000  11.1583
     18      0.9854        0.0781       0.2595      0.5129        0.6884        0.0000  11.2517
     19      0.9854        [32m0.0713[0m       0.2578      0.5141        0.6902        0.0000  11.2181
     20      0.9845        [32m0.0689[0m       [35m0.2606[0m      0.5129        0.6892        0.0000  11.3726
     21      0.9828        0.0766       [35m0.2618[0m      0.5126        0.6890        0.0000  11.2687
     22      [36m0.9878[0m        0.0695       0.2618      0.5127        0.6892        0.0000  11.0456
     23      0.9845        0.0735       0.2618      0.5131        0.6891        0.0000  11.0488
     24      0.9862        [32m0.0676[0m       0.2618      0.5125        0.6892        0.0000  11.3062
     25      0.9845        0.0719       0.2615      0.5138        0.6899        0.0000  11.1257
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.5756523144034251
F1 Macro Score after query 4: 0.5498833399642727
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9810[0m        [32m0.1155[0m       [35m0.3017[0m      [31m0.6192[0m        [94m0.9932[0m     +  0.0001  11.4906
      2      [36m0.9816[0m        [32m0.1126[0m       0.2953      0.5473        [94m0.7405[0m     +  0.0001  11.6331
      3      [36m0.9825[0m        [32m0.1002[0m       0.2745      0.5471        [94m0.7150[0m     +  0.0001  11.3667
      4      [36m0.9833[0m        [32m0.0947[0m       0.2623      0.5457        [94m0.6918[0m     +  0.0001  11.4766
      5      0.9828        [32m0.0912[0m       0.2830      0.5528        [94m0.6637[0m     +  0.0001  11.6165
      6      0.9824        [32m0.0876[0m       0.2981      0.5418        [94m0.6607[0m     +  0.0000  11.5543
      7      0.9828        [32m0.0828[0m       [35m0.3200[0m      0.5335        [94m0.6570[0m     +  0.0000  11.3045
      8      0.9818        [32m0.0793[0m       0.3054      0.5327        0.6642        0.0000  11.6016
      9      [36m0.9842[0m        [32m0.0769[0m       0.2955      0.5381        0.6665        0.0000  11.4747
     10      0.9842        [32m0.0714[0m       0.3016      0.5380        0.6657        0.0000  11.7113
     11      [36m0.9860[0m        [32m0.0707[0m       0.3076      0.5354        0.6694        0.0000  11.5375
     12      [36m0.9864[0m        [32m0.0696[0m       0.3108      0.5342        0.6675        0.0000  11.3809
     13      0.9850        0.0730       0.3179      0.5341        0.6671        0.0000  11.4283
     14      0.9860        [32m0.0660[0m       0.3168      0.5342        0.6681        0.0000  11.6784
     15      0.9850        0.0690       0.3141      0.5373        0.6704        0.0000  11.5998
     16      0.9860        [32m0.0626[0m       0.3144      0.5350        0.6713        0.0000  11.4838
     17      0.9864        0.0675       0.3168      0.5351        0.6707        0.0000  11.7421
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.5904295721157904
F1 Macro Score after query 5: 0.5701188303947573
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9759[0m        [32m0.1309[0m       [35m0.3109[0m      [31m0.6306[0m        [94m0.9428[0m     +  0.0001  11.9610
      2      [36m0.9766[0m        [32m0.1161[0m       0.3014      0.6137        [94m0.7291[0m     +  0.0001  12.0868
      3      [36m0.9771[0m        [32m0.1082[0m       [35m0.3158[0m      0.5901        [94m0.6719[0m     +  0.0001  12.2891
      4      [36m0.9785[0m        [32m0.1009[0m       0.3068      0.5865        [94m0.6640[0m     +  0.0001  11.9297
      5      [36m0.9795[0m        [32m0.0943[0m       0.3073      0.5992        [94m0.6625[0m     +  0.0001  12.3513
      6      [36m0.9820[0m        [32m0.0844[0m       [35m0.3361[0m      0.5881        [94m0.6306[0m     +  0.0000  12.0855
      7      [36m0.9823[0m        [32m0.0809[0m       0.3351      0.5867        0.6339        0.0000  12.1173
      8      [36m0.9825[0m        [32m0.0792[0m       [35m0.3406[0m      0.5770        0.6420        0.0000  12.0234
      9      [36m0.9829[0m        0.0792       [35m0.3432[0m      0.5787        0.6452        0.0000  12.2113
     10      0.9827        [32m0.0783[0m       [35m0.3446[0m      0.5861        0.6394        0.0000  11.9144
     11      [36m0.9844[0m        [32m0.0716[0m       [35m0.3563[0m      0.5746        0.6429        0.0000  12.2729
     12      [36m0.9848[0m        [32m0.0703[0m       0.3561      0.5747        0.6466        0.0000  12.1316
     13      0.9846        0.0708       [35m0.3575[0m      0.5737        0.6471        0.0000  12.1476
     14      0.9848        0.0711       [35m0.3595[0m      0.5696        0.6499        0.0000  12.0701
     15      [36m0.9853[0m        [32m0.0701[0m       [35m0.3611[0m      0.5719        0.6504        0.0000  12.0547
     16      [36m0.9863[0m        [32m0.0652[0m       [35m0.3653[0m      0.5654        0.6543        0.0000  12.1001
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6006639993189751
F1 Macro Score after query 6: 0.590205847944853
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9658[0m        [32m0.1348[0m       [35m0.3193[0m      [31m0.6600[0m        [94m0.6888[0m     +  0.0001  13.0866
      2      [36m0.9714[0m        [32m0.1120[0m       0.3111      0.6318        [94m0.5860[0m     +  0.0001  13.3230
      3      [36m0.9757[0m        [32m0.1010[0m       [35m0.3208[0m      0.6271        [94m0.5660[0m     +  0.0001  13.2393
      4      [36m0.9782[0m        [32m0.0947[0m       [35m0.3257[0m      0.6173        [94m0.5625[0m     +  0.0001  13.3052
      5      [36m0.9801[0m        [32m0.0871[0m       [35m0.3451[0m      0.6219        0.5679        0.0001  13.6436
      6      [36m0.9833[0m        [32m0.0771[0m       [35m0.3460[0m      0.6084        0.5876        0.0000  13.0393
      7      [36m0.9836[0m        [32m0.0730[0m       [35m0.3519[0m      0.6173        0.5900        0.0000  13.1000
      8      [36m0.9845[0m        0.0742       [35m0.3615[0m      0.6000        0.5908        0.0000  13.3219
      9      [36m0.9848[0m        [32m0.0711[0m       0.3330      0.5961        0.5979        0.0000  13.0387
     10      0.9827        [32m0.0710[0m       0.3411      0.5979        0.5932        0.0000  13.3062
     11      [36m0.9854[0m        [32m0.0663[0m       0.3286      0.5981        0.6060        0.0000  13.4472
     12      [36m0.9858[0m        [32m0.0650[0m       0.3273      0.5997        0.6094        0.0000  13.1342
     13      0.9847        0.0661       0.3245      0.5980        0.6095        0.0000  13.4137
     14      0.9856        [32m0.0644[0m       0.3236      0.5956        0.6132        0.0000  13.1803
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.669105274709196
F1 Macro Score after query 7: 0.6593141454684159
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9844[0m        [32m0.0812[0m       [35m0.3179[0m      [31m0.6527[0m        [94m0.7962[0m     +  0.0001  15.5088
      2      [36m0.9862[0m        [32m0.0720[0m       [35m0.3441[0m      [31m0.6675[0m        [94m0.6404[0m     +  0.0001  15.5871
      3      [36m0.9865[0m        [32m0.0703[0m       [35m0.3476[0m      0.6661        0.6638        0.0001  15.5241
      4      [36m0.9866[0m        [32m0.0648[0m       [35m0.3637[0m      [31m0.6731[0m        [94m0.6275[0m     +  0.0001  15.4466
      5      [36m0.9879[0m        [32m0.0632[0m       [35m0.3684[0m      [31m0.6735[0m        [94m0.6235[0m     +  0.0001  15.4933
      6      [36m0.9886[0m        [32m0.0563[0m       [35m0.3792[0m      0.6715        [94m0.5911[0m     +  0.0000  15.5885
      7      [36m0.9889[0m        [32m0.0556[0m       0.3753      0.6694        [94m0.5822[0m     +  0.0000  15.5581
      8      [36m0.9892[0m        [32m0.0527[0m       0.3766      0.6668        [94m0.5799[0m     +  0.0000  15.5877
      9      [36m0.9899[0m        [32m0.0512[0m       0.3674      0.6604        0.5871        0.0000  15.5098
     10      [36m0.9906[0m        0.0515       0.3655      0.6586        0.6020        0.0000  15.0709
     11      0.9900        [32m0.0496[0m       0.3688      0.6613        0.5814        0.0000  15.3475
     12      0.9905        [32m0.0477[0m       0.3738      0.6568        0.5824        0.0000  15.1956
     13      0.9906        0.0482       0.3724      0.6556        0.5821        0.0000  15.3688
     14      0.9904        0.0482       0.3672      0.6525        0.5885        0.0000  15.4618
     15      [36m0.9907[0m        0.0478       0.3672      0.6544        0.5850        0.0000  15.1020
     16      [36m0.9909[0m        [32m0.0470[0m       0.3705      0.6539        [94m0.5790[0m     +  0.0000  15.1645
     17      [36m0.9911[0m        [32m0.0466[0m       0.3766      0.6545        [94m0.5768[0m     +  0.0000  15.4784
     18      0.9908        0.0471       0.3771      0.6543        0.5795        0.0000  15.5898
     19      [36m0.9912[0m        [32m0.0457[0m       0.3785      0.6557        0.5804        0.0000  15.1824
     20      0.9906        0.0462       0.3781      0.6563        0.5787        0.0000  15.4148
     21      0.9909        0.0466       0.3790      0.6546        0.5770        0.0000  15.1488
     22      [36m0.9915[0m        [32m0.0454[0m       0.3792      0.6541        0.5785        0.0000  15.1637
     23      [36m0.9916[0m        [32m0.0447[0m       [35m0.3795[0m      0.6539        0.5796        0.0000  15.2764
     24      0.9911        0.0463       0.3792      0.6537        0.5799        0.0000  15.2754
     25      0.9909        0.0461       0.3785      0.6536        0.5793        0.0000  15.1332
     26      0.9915        [32m0.0446[0m       0.3780      0.6529        0.5805        0.0000  15.0566
     27      0.9910        0.0449       0.3785      0.6527        0.5805        0.0000  15.3521
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7203443652529815
F1 Macro Score after query 8: 0.7183648470621541
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9756[0m        [32m0.1197[0m       [35m0.4201[0m      [31m0.7220[0m        [94m0.4446[0m     +  0.0001  19.1508
      2      [36m0.9808[0m        [32m0.0937[0m       [35m0.4431[0m      0.7142        [94m0.4292[0m     +  0.0001  19.1841
      3      [36m0.9830[0m        [32m0.0840[0m       [35m0.5179[0m      [31m0.7497[0m        [94m0.4040[0m     +  0.0001  18.7930
      4      [36m0.9837[0m        [32m0.0783[0m       [35m0.5660[0m      [31m0.7655[0m        [94m0.3952[0m     +  0.0001  18.7458
      5      [36m0.9842[0m        [32m0.0773[0m       [35m0.5972[0m      [31m0.7796[0m        [94m0.3905[0m     +  0.0001  19.1996
      6      [36m0.9861[0m        [32m0.0665[0m       0.5450      0.7630        0.4114        0.0000  19.0440
      7      [36m0.9864[0m        [32m0.0634[0m       0.5536      0.7614        0.4141        0.0000  18.7468
      8      [36m0.9866[0m        [32m0.0623[0m       0.5620      0.7661        0.4139        0.0000  19.0433
      9      [36m0.9870[0m        [32m0.0616[0m       0.5759      0.7699        0.4089        0.0000  19.2133
     10      [36m0.9873[0m        [32m0.0604[0m       0.5759      0.7717        0.4138        0.0000  19.0261
     11      [36m0.9879[0m        [32m0.0578[0m       0.5792      0.7767        0.4138        0.0000  18.6040
     12      [36m0.9881[0m        [32m0.0559[0m       0.5816      0.7784        0.4144        0.0000  18.4867
     13      [36m0.9885[0m        0.0562       0.5771      0.7759        0.4156        0.0000  19.2147
     14      0.9884        [32m0.0553[0m       0.5783      0.7750        0.4146        0.0000  18.7924
     15      0.9880        0.0554       0.5726      0.7745        0.4172        0.0000  19.0898
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.83613350410608
F1 Macro Score after query 9: 0.8277321736838587
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9647[0m        [32m0.1404[0m       [35m0.4530[0m      [31m0.7700[0m        [94m0.4359[0m     +  0.0001  26.1234
      2      [36m0.9692[0m        [32m0.1206[0m       [35m0.4543[0m      [31m0.7741[0m        0.4389        0.0001  25.4848
      3      [36m0.9717[0m        [32m0.1111[0m       0.4408      0.7693        0.4543        0.0001  25.0456
      4      [36m0.9741[0m        [32m0.1038[0m       0.4295      [31m0.7822[0m        0.4926        0.0001  25.8147
      5      [36m0.9752[0m        [32m0.0979[0m       0.4351      0.7788        0.4809        0.0001  25.3575
      6      [36m0.9787[0m        [32m0.0857[0m       [35m0.4594[0m      [31m0.7885[0m        0.4739        0.0000  25.2959
      7      [36m0.9791[0m        [32m0.0833[0m       0.4361      0.7800        0.4894        0.0000  25.8540
      8      [36m0.9795[0m        [32m0.0812[0m       0.4358      0.7810        0.4943        0.0000  25.4672
      9      [36m0.9799[0m        [32m0.0787[0m       0.4340      0.7806        0.4923        0.0000  25.1100
     10      [36m0.9803[0m        [32m0.0776[0m       0.4293      0.7825        0.5205        0.0000  25.9054
     11      [36m0.9808[0m        [32m0.0744[0m       0.4302      0.7827        0.5099        0.0000  24.8381
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.7892564779108314
F1 Macro Score after query 10: 0.8119032870858005
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9363[0m        [32m0.1826[0m       [35m0.7101[0m      [31m0.8187[0m        [94m0.2330[0m     +  0.0001  37.9150
      2      [36m0.9497[0m        [32m0.1494[0m       [35m0.7368[0m      [31m0.8356[0m        [94m0.2177[0m     +  0.0001  36.9759
      3      [36m0.9545[0m        [32m0.1344[0m       [35m0.7556[0m      [31m0.8453[0m        [94m0.2169[0m     +  0.0001  37.6182
      4      [36m0.9592[0m        [32m0.1237[0m       0.7498      0.8397        0.2188        0.0001  37.9684
      5      [36m0.9609[0m        [32m0.1167[0m       [35m0.7616[0m      [31m0.8528[0m        [94m0.2153[0m     +  0.0001  37.0678
      6      [36m0.9665[0m        [32m0.1015[0m       [35m0.7656[0m      [31m0.8593[0m        0.2235        0.0000  37.8669
      7      [36m0.9677[0m        [32m0.0977[0m       0.7653      0.8583        0.2271        0.0000  37.4453
      8      [36m0.9690[0m        [32m0.0946[0m       0.7595      0.8541        0.2326        0.0000  37.2426
      9      [36m0.9691[0m        [32m0.0931[0m       0.7594      0.8563        0.2347        0.0000  37.6005
     10      [36m0.9701[0m        [32m0.0909[0m       0.7587      [31m0.8599[0m        0.2402        0.0000  37.2538
     11      [36m0.9713[0m        [32m0.0869[0m       0.7514      0.8557        0.2560        0.0000  36.9789
     12      [36m0.9726[0m        [32m0.0849[0m       0.7467      0.8511        0.2607        0.0000  37.8252
     13      [36m0.9729[0m        0.0852       0.7467      0.8515        0.2589        0.0000  36.8356
     14      [36m0.9733[0m        [32m0.0839[0m       0.7481      0.8546        0.2613        0.0000  37.2249
     15      0.9730        [32m0.0829[0m       0.7476      0.8544        0.2579        0.0000  37.4755
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.9005155035777488
F1 Macro Score after query 11: 0.8856118617850136
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9487[0m        [32m0.1065[0m       [35m0.7486[0m      [31m0.8047[0m        [94m0.2752[0m     +  0.0001  58.7249
      2      [36m0.9524[0m        [32m0.0952[0m       [35m0.7623[0m      [31m0.8232[0m        [94m0.2655[0m     +  0.0001  58.6296
      3      [36m0.9551[0m        [32m0.0886[0m       0.7497      [31m0.8233[0m        [94m0.2641[0m     +  0.0001  58.9089
      4      [36m0.9564[0m        [32m0.0856[0m       0.7444      0.8058        0.2750        0.0001  58.4955
      5      [36m0.9579[0m        [32m0.0822[0m       0.7483      0.8218        0.2668        0.0001  58.7047
      6      [36m0.9635[0m        [32m0.0704[0m       0.7495      [31m0.8369[0m        0.2780        0.0000  58.0474
      7      [36m0.9651[0m        [32m0.0685[0m       0.7465      [31m0.8397[0m        0.2777        0.0000  58.2080
      8      [36m0.9655[0m        [32m0.0666[0m       0.7403      0.8356        0.2945        0.0000  58.0036
      9      [36m0.9661[0m        [32m0.0656[0m       0.7460      0.8327        0.2779        0.0000  58.4867
     10      [36m0.9665[0m        [32m0.0646[0m       0.7472      [31m0.8407[0m        0.2874        0.0000  58.7836
     11      [36m0.9679[0m        [32m0.0615[0m       0.7417      [31m0.8440[0m        0.3051        0.0000  59.1950
     12      [36m0.9694[0m        [32m0.0601[0m       0.7431      0.8414        0.2969        0.0000  58.6768
     13      0.9691        [32m0.0599[0m       0.7446      0.8425        0.2970        0.0000  58.5034
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8927722848164329
F1 Macro Score after query 12: 0.8789658849762662
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9485[0m        [32m0.0908[0m       [35m0.7710[0m      [31m0.8581[0m        [94m0.2496[0m     +  0.0001  60.2404
      2      [36m0.9523[0m        [32m0.0840[0m       0.7689      0.8541        [94m0.2461[0m     +  0.0001  60.2359
      3      [36m0.9540[0m        [32m0.0793[0m       0.7575      0.8541        0.2961        0.0001  60.0465
      4      [36m0.9559[0m        [32m0.0767[0m       0.7670      [31m0.8640[0m        0.3095        0.0001  60.1227
      5      [36m0.9578[0m        [32m0.0737[0m       0.7642      0.8488        0.2650        0.0001  60.0896
      6      [36m0.9634[0m        [32m0.0642[0m       0.7524      0.8553        0.3404        0.0000  60.1387
      7      [36m0.9647[0m        [32m0.0617[0m       0.7521      0.8518        0.3230        0.0000  60.1813
      8      [36m0.9651[0m        [32m0.0606[0m       0.7540      0.8544        0.3240        0.0000  60.2142
      9      [36m0.9653[0m        [32m0.0597[0m       0.7540      0.8587        0.3444        0.0000  60.0134
     10      [36m0.9662[0m        [32m0.0587[0m       0.7443      0.8518        0.3814        0.0000  60.0795
     11      [36m0.9678[0m        [32m0.0554[0m       0.7465      0.8515        0.3233        0.0000  60.1060
     12      [36m0.9679[0m        [32m0.0549[0m       0.7425      0.8482        0.3434        0.0000  60.0811
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8971878515185602
F1 Macro Score after query 13: 0.8847414098145507
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed42_config2\AL_average_score_results_for_multilabel_classification.pickle
