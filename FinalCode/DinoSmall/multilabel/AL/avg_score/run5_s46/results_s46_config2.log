Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5556[0m        [32m0.6869[0m       [35m0.2349[0m      [31m0.5648[0m        [94m0.6892[0m     +  0.0001  11.9219
      2      [36m0.6313[0m        0.6994       0.0997      0.3476        [94m0.6785[0m     +  0.0001  10.4788
      3      0.5945        [32m0.6623[0m       0.1566      0.4336        [94m0.6757[0m     +  0.0001  10.7968
      4      [36m0.7130[0m        [32m0.5900[0m       [35m0.2663[0m      0.3519        [94m0.6747[0m     +  0.0001  10.5565
      5      [36m0.8796[0m        0.6231       0.1536      0.5009        0.7018        0.0001  10.7693
      6      0.6985        0.6312       0.1727      0.4538        0.6888        0.0000  10.6391
      7      0.8130        0.6034       0.2568      0.4692        0.6791        0.0000  10.8761
      8      0.7857        [32m0.5544[0m       0.2562      0.4766        0.6772        0.0000  10.7673
      9      0.7424        [32m0.5443[0m       0.2564      0.4699        [94m0.6719[0m     +  0.0000  10.7643
     10      0.7857        [32m0.5361[0m       [35m0.2686[0m      0.4721        [94m0.6710[0m     +  0.0000  10.2152
     11      0.7500        0.5526       [35m0.2759[0m      0.4746        [94m0.6704[0m     +  0.0000  10.0788
     12      0.8333        [32m0.5334[0m       0.2747      0.4741        0.6718        0.0000  10.1109
     13      0.6905        0.5616       0.2738      0.4740        0.6723        0.0000  10.0353
     14      0.7500        0.5547       0.2736      0.4726        0.6712        0.0000  9.9977
     15      0.7857        [32m0.5206[0m       [35m0.2766[0m      0.4738        0.6714        0.0000  9.8710
     16      0.8426        [32m0.4995[0m       0.2759      0.4721        0.6707        0.0000  9.9123
     17      0.7857        0.5310       0.2759      0.4730        0.6708        0.0000  10.0811
     18      0.8333        0.5341       0.2760      0.4723        [94m0.6704[0m     +  0.0000  9.9949
     19      0.7857        0.5084       [35m0.2767[0m      0.4746        [94m0.6703[0m     +  0.0000  9.9016
     20      0.7963        [32m0.4736[0m       0.2767      0.4747        [94m0.6702[0m     +  0.0000  9.9218
     21      0.7857        0.5279       0.2753      0.4744        0.6703        0.0000  9.9668
     22      0.8796        0.5139       0.2759      0.4732        [94m0.6700[0m     +  0.0000  10.0965
     23      0.7685        0.5104       0.2757      0.4727        [94m0.6700[0m     +  0.0000  9.8214
     24      0.7222        0.5279       0.2752      0.4741        0.6703        0.0000  9.9344
     25      0.7857        0.5278       0.2755      0.4739        0.6702        0.0000  9.9620
     26      0.7857        0.5162       0.2753      0.4739        0.6701        0.0000  9.9053
     27      0.8333        0.5214       0.2752      0.4736        0.6701        0.0000  9.9423
     28      0.8333        0.4963       0.2752      0.4741        0.6701        0.0000  9.9842
     29      0.7667        0.5383       0.2748      0.4741        0.6701        0.0000  10.0179
     30      0.8426        0.5036       0.2748      0.4744        0.6701        0.0000  9.9124
     31      0.7857        0.4833       0.2748      0.4744        0.6701        0.0000  9.8907
     32      0.7963        0.5281       0.2750      0.4744        0.6701        0.0000  9.9079
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4928
Pre F1 macro score = 0.4914
Pre Accuracy = 0.3075

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9585[0m        [32m0.3963[0m       [35m0.1769[0m      [31m0.5445[0m        [94m0.9163[0m     +  0.0001  10.4056
      2      0.9364        [32m0.3294[0m       [35m0.2418[0m      0.5198        [94m0.8669[0m     +  0.0001  10.4528
      3      0.9364        [32m0.2864[0m       0.2396      0.4964        [94m0.8561[0m     +  0.0001  10.5468
      4      0.9508        [32m0.2609[0m       [35m0.3000[0m      0.5149        [94m0.8348[0m     +  0.0001  10.5115
      5      [36m0.9593[0m        [32m0.2168[0m       0.2880      0.5221        0.8409        0.0001  10.3587
      6      [36m0.9671[0m        0.2235       0.2865      0.4982        [94m0.8233[0m     +  0.0000  10.4498
      7      0.9593        0.2204       0.2946      0.4972        [94m0.8094[0m     +  0.0000  10.4276
      8      0.9500        0.2242       0.2806      0.4929        [94m0.8035[0m     +  0.0000  10.3844
      9      [36m0.9756[0m        0.2187       0.2927      0.4893        [94m0.7928[0m     +  0.0000  10.4272
     10      0.9581        [32m0.1924[0m       0.2797      0.4872        0.7955        0.0000  10.3749
     11      0.9585        0.2002       0.2837      0.4912        [94m0.7900[0m     +  0.0000  10.3695
     12      0.9667        [32m0.1853[0m       0.2830      0.4917        [94m0.7870[0m     +  0.0000  10.5148
     13      0.9585        0.2024       0.2799      0.4911        [94m0.7862[0m     +  0.0000  10.4127
     14      0.9585        0.1950       0.2776      0.4915        [94m0.7831[0m     +  0.0000  10.4693
     15      0.9756        0.1889       0.2840      0.4924        [94m0.7779[0m     +  0.0000  10.4692
     16      0.9585        0.1976       0.2840      0.4920        [94m0.7769[0m     +  0.0000  10.4684
     17      0.9671        [32m0.1802[0m       0.2835      0.4924        [94m0.7762[0m     +  0.0000  10.3906
     18      0.9752        [32m0.1683[0m       0.2819      0.4924        0.7767        0.0000  10.2658
     19      [36m0.9837[0m        0.1771       0.2825      0.4927        [94m0.7755[0m     +  0.0000  10.2721
     20      0.9671        0.1797       0.2823      0.4925        [94m0.7753[0m     +  0.0000  10.2912
     21      0.9756        0.1695       0.2826      0.4922        [94m0.7747[0m     +  0.0000  10.3661
     22      0.9667        0.1812       0.2828      0.4924        [94m0.7741[0m     +  0.0000  10.3231
     23      0.9671        [32m0.1653[0m       0.2837      0.4927        [94m0.7733[0m     +  0.0000  10.3663
     24      0.9756        0.1790       0.2839      0.4926        [94m0.7730[0m     +  0.0000  10.4172
     25      0.9585        0.1953       0.2840      0.4927        [94m0.7719[0m     +  0.0000  10.5828
     26      0.9667        0.1830       0.2840      0.4927        [94m0.7718[0m     +  0.0000  10.2896
     27      0.9671        0.1844       0.2840      0.4928        [94m0.7715[0m     +  0.0000  10.4922
     28      0.9671        0.1789       0.2840      0.4928        [94m0.7714[0m     +  0.0000  10.3981
     29      0.9671        0.1887       0.2840      0.4927        [94m0.7711[0m     +  0.0000  10.3134
     30      0.9671        0.1908       0.2842      0.4926        [94m0.7708[0m     +  0.0000  10.3100
     31      0.9756        0.1680       0.2842      0.4925        [94m0.7708[0m     +  0.0000  10.7245
     32      0.9585        0.1793       0.2844      0.4923        [94m0.7707[0m     +  0.0000  10.7986
     33      0.9671        0.1902       0.2844      0.4923        [94m0.7706[0m     +  0.0000  10.7086
     34      0.9671        0.1918       0.2844      0.4925        [94m0.7705[0m     +  0.0000  10.9544
     35      0.9585        0.1776       0.2844      0.4925        [94m0.7705[0m     +  0.0000  10.5829
     36      0.9671        0.1729       0.2844      0.4925        [94m0.7705[0m     +  0.0000  10.7287
     37      0.9585        0.1669       0.2844      0.4925        [94m0.7705[0m     +  0.0000  10.8284
     38      0.9756        0.1815       0.2844      0.4925        [94m0.7704[0m     +  0.0000  10.7509
     39      0.9756        0.1730       0.2844      0.4926        [94m0.7704[0m     +  0.0000  10.7626
     40      0.9585        0.1945       0.2844      0.4926        [94m0.7704[0m     +  0.0000  10.8022
     41      0.9671        0.1861       0.2844      0.4926        [94m0.7704[0m     +  0.0000  10.4788
     42      0.9671        0.1838       0.2844      0.4926        [94m0.7703[0m     +  0.0000  10.9858
     43      0.9585        0.1906       0.2844      0.4925        [94m0.7703[0m     +  0.0000  10.8838
     44      0.9752        0.1758       0.2844      0.4925        [94m0.7703[0m     +  0.0000  10.7493
     45      0.9756        0.1759       0.2844      0.4925        [94m0.7703[0m     +  0.0000  10.7921
     46      0.9585        0.1825       0.2844      0.4925        [94m0.7703[0m     +  0.0000  11.0259
     47      0.9756        0.1803       0.2844      0.4925        [94m0.7703[0m     +  0.0000  10.6877
     48      0.9585        0.1777       0.2844      0.4925        0.7703        0.0000  10.9061
     49      0.9756        0.1834       0.2844      0.4925        0.7703        0.0000  10.9481
     50      0.9671        0.1783       0.2844      0.4925        [94m0.7703[0m     +  0.0000  10.8457
     51      0.9756        0.1725       0.2844      0.4925        [94m0.7703[0m     +  0.0000  10.9012
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.5170295178309069
F1 Macro Score after query 1: 0.5052241472155274
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9840[0m        [32m0.1288[0m       [35m0.2913[0m      [31m0.5744[0m        [94m0.8827[0m     +  0.0001  11.0357
      2      [36m0.9872[0m        [32m0.0898[0m       [35m0.3189[0m      0.5059        [94m0.7811[0m     +  0.0001  10.8592
      3      0.9807        [32m0.0853[0m       0.2708      0.5078        [94m0.7577[0m     +  0.0001  11.0040
      4      [36m0.9968[0m        [32m0.0685[0m       0.2977      0.5197        [94m0.7160[0m     +  0.0001  10.8594
      5      0.9936        [32m0.0647[0m       0.2767      0.5293        0.7230        0.0001  10.9686
      6      0.9968        [32m0.0534[0m       0.2870      0.5272        [94m0.7111[0m     +  0.0000  11.0054
      7      0.9968        0.0536       0.2922      0.5285        [94m0.6922[0m     +  0.0000  10.9010
      8      0.9968        [32m0.0438[0m       0.3000      0.5303        [94m0.6858[0m     +  0.0000  10.8331
      9      0.9968        0.0482       0.2993      0.5340        [94m0.6756[0m     +  0.0000  10.8353
     10      0.9968        0.0470       0.3021      0.5351        [94m0.6683[0m     +  0.0000  11.0521
     11      0.9968        [32m0.0389[0m       0.3016      0.5354        [94m0.6653[0m     +  0.0000  11.0714
     12      0.9968        [32m0.0382[0m       0.2983      0.5354        0.6665        0.0000  10.8454
     13      0.9968        [32m0.0380[0m       0.2951      0.5347        0.6678        0.0000  11.0534
     14      0.9968        [32m0.0361[0m       0.2891      0.5363        0.6707        0.0000  11.0418
     15      0.9968        0.0418       0.2910      0.5372        0.6674        0.0000  10.9642
     16      0.9968        0.0384       0.2892      0.5369        0.6680        0.0000  11.1285
     17      0.9968        [32m0.0352[0m       0.2882      0.5372        0.6671        0.0000  10.9711
     18      0.9968        0.0406       0.2920      0.5378        [94m0.6650[0m     +  0.0000  11.0702
     19      0.9968        0.0379       0.2901      0.5367        [94m0.6638[0m     +  0.0000  10.9133
     20      0.9968        0.0360       0.2880      0.5372        0.6649        0.0000  10.8831
     21      0.9968        [32m0.0333[0m       0.2875      0.5372        0.6651        0.0000  10.9292
     22      0.9968        0.0356       0.2884      0.5370        0.6648        0.0000  10.8678
     23      0.9968        0.0355       0.2875      0.5368        0.6646        0.0000  10.9764
     24      0.9968        0.0338       0.2859      0.5372        0.6656        0.0000  10.9276
     25      0.9968        0.0350       0.2859      0.5371        0.6652        0.0000  10.7880
     26      0.9968        [32m0.0321[0m       0.2859      0.5368        0.6652        0.0000  10.7882
     27      0.9968        0.0330       0.2854      0.5366        0.6652        0.0000  10.7721
     28      0.9968        0.0326       0.2854      0.5365        0.6651        0.0000  10.7257
     29      0.9968        0.0352       0.2861      0.5366        0.6646        0.0000  10.6473
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.5863843552418763
F1 Macro Score after query 2: 0.5639634256168969
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9906[0m        [32m0.0858[0m       [35m0.2917[0m      [31m0.5888[0m        [94m0.9990[0m     +  0.0001  10.8041
      2      0.9876        0.0948       [35m0.3069[0m      0.5348        [94m0.7179[0m     +  0.0001  11.0860
      3      [36m0.9922[0m        [32m0.0778[0m       0.2693      0.5364        0.7232        0.0001  10.9747
      4      0.9922        [32m0.0648[0m       0.2845      0.5435        [94m0.6907[0m     +  0.0001  10.8028
      5      0.9922        0.0689       0.2748      0.5508        [94m0.6779[0m     +  0.0001  10.7882
      6      0.9922        [32m0.0599[0m       0.2762      0.5517        [94m0.6651[0m     +  0.0000  10.8036
      7      0.9922        [32m0.0557[0m       0.3009      0.5403        [94m0.6535[0m     +  0.0000  10.5843
      8      0.9922        [32m0.0555[0m       0.2988      0.5373        [94m0.6484[0m     +  0.0000  10.6012
      9      [36m0.9937[0m        [32m0.0472[0m       0.2964      0.5380        0.6491        0.0000  11.2578
     10      0.9937        0.0516       0.2866      0.5495        0.6538        0.0000  10.9748
     11      0.9937        0.0521       0.2861      0.5460        0.6519        0.0000  10.4944
     12      0.9921        0.0554       0.2849      0.5501        0.6537        0.0000  10.8977
     13      0.9937        0.0510       0.2887      0.5470        0.6514        0.0000  11.1156
     14      0.9922        0.0549       0.2931      0.5414        [94m0.6480[0m     +  0.0000  10.8801
     15      0.9921        0.0526       0.2880      0.5458        0.6507        0.0000  10.9131
     16      0.9937        0.0524       0.2882      0.5450        0.6504        0.0000  10.8182
     17      0.9937        0.0526       0.2877      0.5435        0.6505        0.0000  10.8498
     18      0.9937        0.0541       0.2899      0.5457        0.6506        0.0000  10.4294
     19      0.9937        0.0500       0.2877      0.5454        0.6509        0.0000  10.9441
     20      0.9937        [32m0.0441[0m       0.2894      0.5449        0.6510        0.0000  10.8348
     21      0.9921        0.0524       0.2889      0.5447        0.6512        0.0000  11.0695
     22      0.9937        0.0470       0.2892      0.5442        0.6511        0.0000  10.8012
     23      0.9937        0.0487       0.2906      0.5429        0.6508        0.0000  10.7409
     24      0.9921        0.0551       0.2913      0.5420        0.6505        0.0000  11.0054
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.5892857142857143
F1 Macro Score after query 3: 0.5597843483397547
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9916[0m        [32m0.0787[0m       [35m0.2604[0m      [31m0.5811[0m        [94m1.3711[0m     +  0.0001  11.2410
      2      0.9843        0.0988       [35m0.2970[0m      0.5567        [94m0.7618[0m     +  0.0001  10.8245
      3      0.9908        [32m0.0737[0m       0.2708      0.5517        [94m0.7228[0m     +  0.0001  11.1316
      4      0.9908        [32m0.0692[0m       0.2771      0.5597        [94m0.6802[0m     +  0.0001  10.9305
      5      0.9908        [32m0.0688[0m       0.2802      0.5636        [94m0.6757[0m     +  0.0001  11.1632
      6      0.9908        [32m0.0634[0m       0.2924      0.5539        [94m0.6531[0m     +  0.0000  11.1787
      7      0.9908        [32m0.0600[0m       0.2944      0.5516        [94m0.6520[0m     +  0.0000  11.0068
      8      0.9908        0.0639       0.2962      0.5463        0.6566        0.0000  10.8814
      9      0.9908        0.0628       [35m0.3085[0m      0.5475        0.6529        0.0000  11.1320
     10      0.9916        [32m0.0587[0m       0.3052      0.5451        0.6550        0.0000  11.0854
     11      0.9908        [32m0.0566[0m       0.3075      0.5437        0.6565        0.0000  10.9127
     12      0.9908        [32m0.0553[0m       [35m0.3191[0m      0.5415        0.6557        0.0000  10.9589
     13      0.9908        0.0559       0.3151      0.5423        0.6575        0.0000  10.9903
     14      0.9916        0.0603       [35m0.3234[0m      0.5385        0.6558        0.0000  11.1630
     15      0.9908        0.0563       0.3160      0.5418        0.6553        0.0000  11.1172
     16      0.9916        [32m0.0542[0m       0.3189      0.5412        0.6563        0.0000  10.9903
     17      0.9916        [32m0.0512[0m       0.3179      0.5417        0.6573        0.0000  11.0235
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.5972655313024706
F1 Macro Score after query 4: 0.5670000270041555
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9853[0m        [32m0.0987[0m       [35m0.2811[0m      [31m0.6122[0m        [94m1.0184[0m     +  0.0001  11.2107
      2      0.9827        0.0993       0.2613      0.5423        [94m0.6947[0m     +  0.0001  11.5081
      3      0.9853        [32m0.0867[0m       [35m0.2880[0m      0.5508        [94m0.6527[0m     +  0.0001  11.4602
      4      0.9843        [32m0.0800[0m       0.2865      0.5528        0.6683        0.0001  11.2131
      5      0.9852        [32m0.0743[0m       [35m0.2899[0m      0.5535        0.6735        0.0001  11.4900
      6      [36m0.9866[0m        [32m0.0712[0m       [35m0.3050[0m      0.5408        0.6789        0.0000  11.5224
      7      [36m0.9870[0m        [32m0.0653[0m       [35m0.3177[0m      0.5406        0.6778        0.0000  11.1015
      8      0.9870        [32m0.0650[0m       [35m0.3438[0m      0.5350        0.6833        0.0000  11.3187
      9      0.9870        [32m0.0642[0m       0.3224      0.5395        0.6834        0.0000  11.3505
     10      0.9870        [32m0.0623[0m       0.3269      0.5359        0.6818        0.0000  11.2573
     11      [36m0.9879[0m        [32m0.0566[0m       0.3293      0.5303        0.6835        0.0000  11.5565
     12      [36m0.9893[0m        0.0570       0.3276      0.5298        0.6817        0.0000  11.5398
     13      0.9888        0.0582       0.3361      0.5287        0.6850        0.0000  11.3822
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.6114338637703124
F1 Macro Score after query 5: 0.5848259823216478
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9658[0m        [32m0.1465[0m       [35m0.2795[0m      [31m0.6163[0m        [94m0.7770[0m     +  0.0001  12.1639
      2      [36m0.9700[0m        [32m0.1254[0m       [35m0.3245[0m      0.5985        [94m0.6723[0m     +  0.0001  12.2576
      3      [36m0.9717[0m        [32m0.1162[0m       [35m0.3351[0m      0.6051        [94m0.6337[0m     +  0.0001  12.1188
      4      0.9709        [32m0.1124[0m       0.3262      0.6090        [94m0.6140[0m     +  0.0001  12.0222
      5      [36m0.9738[0m        [32m0.1040[0m       0.3273      0.6155        0.6152        0.0001  11.8836
      6      [36m0.9788[0m        [32m0.0909[0m       [35m0.3628[0m      0.5988        0.6146        0.0000  11.9451
      7      [36m0.9788[0m        [32m0.0871[0m       [35m0.3644[0m      0.5970        0.6231        0.0000  11.9457
      8      [36m0.9788[0m        [32m0.0852[0m       [35m0.3670[0m      0.5953        0.6208        0.0000  12.1495
      9      [36m0.9791[0m        0.0863       [35m0.3712[0m      0.5918        0.6205        0.0000  12.0375
     10      [36m0.9805[0m        [32m0.0830[0m       0.3609      0.5935        0.6299        0.0000  11.8366
     11      [36m0.9812[0m        [32m0.0787[0m       [35m0.3833[0m      0.5789        0.6346        0.0000  12.0222
     12      [36m0.9825[0m        [32m0.0777[0m       0.3750      0.5798        0.6330        0.0000  11.7893
     13      0.9823        [32m0.0754[0m       0.3830      0.5785        0.6360        0.0000  11.9894
     14      0.9823        0.0771       0.3740      0.5795        0.6363        0.0000  12.1474
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6341709387343475
F1 Macro Score after query 6: 0.6120658870195982
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9586[0m        [32m0.1449[0m       [35m0.3116[0m      [31m0.6510[0m        [94m0.7067[0m     +  0.0001  13.2568
      2      [36m0.9681[0m        [32m0.1149[0m       [35m0.3273[0m      0.6454        [94m0.6680[0m     +  0.0001  13.2589
      3      [36m0.9728[0m        [32m0.1054[0m       [35m0.3401[0m      0.6314        [94m0.6466[0m     +  0.0001  13.0239
      4      [36m0.9763[0m        [32m0.0970[0m       0.3170      0.6343        0.6876        0.0001  13.0137
      5      [36m0.9778[0m        [32m0.0908[0m       0.3222      0.6285        0.6853        0.0001  13.0239
      6      [36m0.9807[0m        [32m0.0815[0m       0.3266      0.6032        0.6744        0.0000  12.9465
      7      [36m0.9808[0m        [32m0.0798[0m       0.3220      0.5965        0.6817        0.0000  13.1344
      8      [36m0.9818[0m        [32m0.0774[0m       0.3123      0.5953        0.6868        0.0000  13.2729
      9      0.9818        [32m0.0752[0m       0.3132      0.5897        0.6980        0.0000  13.2426
     10      0.9818        0.0765       0.3043      0.5836        0.7020        0.0000  13.3698
     11      [36m0.9827[0m        [32m0.0704[0m       0.3089      0.5807        0.7026        0.0000  13.1493
     12      [36m0.9831[0m        0.0708       0.3068      0.5753        0.7067        0.0000  13.2428
     13      [36m0.9836[0m        0.0704       0.3050      0.5745        0.7051        0.0000  13.2269
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.6321701362887524
F1 Macro Score after query 7: 0.6237034547900342
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9700[0m        [32m0.1339[0m       [35m0.3547[0m      [31m0.6866[0m        [94m0.5404[0m     +  0.0001  15.2601
      2      [36m0.9740[0m        [32m0.1118[0m       0.3469      0.6728        0.5674        0.0001  15.3079
      3      [36m0.9767[0m        [32m0.1009[0m       0.3245      0.6549        0.6035        0.0001  15.2597
      4      [36m0.9784[0m        [32m0.0936[0m       0.3033      0.6664        0.6285        0.0001  14.8360
      5      [36m0.9797[0m        [32m0.0906[0m       0.2939      0.6533        0.6374        0.0001  15.1342
      6      [36m0.9823[0m        [32m0.0810[0m       0.3142      0.6716        0.6251        0.0000  15.1961
      7      [36m0.9828[0m        [32m0.0764[0m       0.3132      0.6711        0.6373        0.0000  15.2266
      8      [36m0.9835[0m        0.0766       0.3089      0.6699        0.6549        0.0000  15.2891
      9      0.9832        [32m0.0759[0m       0.3106      0.6648        0.6512        0.0000  15.4160
     10      0.9828        [32m0.0759[0m       0.3089      0.6628        0.6436        0.0000  15.2428
     11      [36m0.9836[0m        [32m0.0711[0m       0.3153      0.6683        0.6343        0.0000  15.0879
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7079893475366179
F1 Macro Score after query 8: 0.7172439119279538
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9723[0m        [32m0.1223[0m       [35m0.3665[0m      [31m0.7431[0m        [94m0.5474[0m     +  0.0001  19.0269
      2      [36m0.9763[0m        [32m0.1009[0m       [35m0.3674[0m      [31m0.7510[0m        [94m0.5393[0m     +  0.0001  19.0142
      3      [36m0.9794[0m        [32m0.0910[0m       [35m0.3694[0m      0.7494        0.5425        0.0001  19.1096
      4      [36m0.9804[0m        [32m0.0839[0m       [35m0.3908[0m      [31m0.7598[0m        [94m0.5329[0m     +  0.0001  18.9018
      5      [36m0.9820[0m        [32m0.0792[0m       [35m0.3997[0m      0.7482        0.5364        0.0001  19.1376
      6      [36m0.9836[0m        [32m0.0709[0m       [35m0.4010[0m      0.7584        0.5460        0.0000  19.2138
      7      [36m0.9855[0m        [32m0.0673[0m       0.4005      [31m0.7599[0m        0.5531        0.0000  19.0740
      8      [36m0.9857[0m        [32m0.0660[0m       [35m0.4024[0m      0.7591        0.5401        0.0000  18.7773
      9      [36m0.9861[0m        [32m0.0643[0m       [35m0.4069[0m      0.7597        0.5357        0.0000  19.2605
     10      0.9860        [32m0.0626[0m       [35m0.4137[0m      0.7593        [94m0.5101[0m     +  0.0000  18.8410
     11      [36m0.9871[0m        [32m0.0591[0m       0.4134      [31m0.7635[0m        0.5308        0.0000  18.9973
     12      [36m0.9871[0m        [32m0.0591[0m       0.4116      0.7630        0.5418        0.0000  18.9490
     13      [36m0.9876[0m        [32m0.0577[0m       0.4082      [31m0.7640[0m        0.5459        0.0000  18.7446
     14      0.9866        0.0583       [35m0.4153[0m      0.7627        0.5255        0.0000  18.8123
     15      0.9872        [32m0.0575[0m       0.4082      0.7608        0.5443        0.0000  18.7920
     16      0.9874        [32m0.0564[0m       0.4089      0.7594        0.5379        0.0000  18.7140
     17      0.9872        0.0566       0.4062      0.7589        0.5407        0.0000  18.9326
     18      0.9868        0.0570       0.4075      0.7596        0.5391        0.0000  18.6561
     19      [36m0.9876[0m        [32m0.0557[0m       0.4090      0.7598        0.5360        0.0000  18.8383
     20      [36m0.9877[0m        0.0560       0.4038      0.7579        0.5372        0.0000  18.9323
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.7674736698126111
F1 Macro Score after query 9: 0.7844294966532502
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9681[0m        [32m0.1289[0m       [35m0.4741[0m      [31m0.7891[0m        [94m0.4858[0m     +  0.0001  25.1232
      2      [36m0.9713[0m        [32m0.1103[0m       0.3833      0.7789        0.5534        0.0001  25.5642
      3      [36m0.9746[0m        [32m0.0987[0m       0.4043      0.7786        0.5663        0.0001  25.4208
      4      [36m0.9761[0m        [32m0.0938[0m       0.3788      0.7776        0.5997        0.0001  25.5611
      5      [36m0.9775[0m        [32m0.0894[0m       0.3578      0.7778        0.6833        0.0001  25.4812
      6      [36m0.9807[0m        [32m0.0781[0m       0.3582      0.7718        0.7166        0.0000  25.4666
      7      [36m0.9814[0m        [32m0.0755[0m       0.3622      0.7691        0.7349        0.0000  25.6099
      8      [36m0.9815[0m        [32m0.0744[0m       0.3651      0.7676        0.7282        0.0000  25.4068
      9      0.9814        [32m0.0726[0m       0.3748      0.7769        0.7310        0.0000  24.9394
     10      0.9813        [32m0.0724[0m       0.3648      0.7690        0.7505        0.0000  25.3900
     11      [36m0.9824[0m        [32m0.0684[0m       0.3627      0.7698        0.7864        0.0000  25.2031
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.7719230521778292
F1 Macro Score after query 10: 0.7987233574388389
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9459[0m        [32m0.1561[0m       [35m0.6889[0m      [31m0.8285[0m        [94m0.2745[0m     +  0.0001  37.6487
      2      [36m0.9556[0m        [32m0.1289[0m       [35m0.6965[0m      0.8184        [94m0.2631[0m     +  0.0001  37.5397
      3      [36m0.9606[0m        [32m0.1155[0m       [35m0.7016[0m      0.8265        [94m0.2629[0m     +  0.0001  37.3509
      4      [36m0.9630[0m        [32m0.1069[0m       [35m0.7115[0m      [31m0.8325[0m        [94m0.2460[0m     +  0.0001  36.9438
      5      [36m0.9650[0m        [32m0.1013[0m       0.7010      0.8239        0.2616        0.0001  36.5428
      6      [36m0.9703[0m        [32m0.0873[0m       [35m0.7224[0m      [31m0.8416[0m        0.2711        0.0000  37.0675
      7      [36m0.9712[0m        [32m0.0851[0m       0.7156      0.8345        0.2712        0.0000  37.2092
      8      [36m0.9719[0m        [32m0.0827[0m       0.7200      0.8387        0.2756        0.0000  37.3813
      9      [36m0.9720[0m        [32m0.0809[0m       [35m0.7252[0m      [31m0.8424[0m        0.2755        0.0000  37.2881
     10      [36m0.9727[0m        [32m0.0796[0m       [35m0.7259[0m      0.8418        0.2701        0.0000  37.5513
     11      [36m0.9748[0m        [32m0.0747[0m       [35m0.7321[0m      [31m0.8476[0m        0.2790        0.0000  37.4909
     12      0.9742        0.0748       [35m0.7326[0m      [31m0.8486[0m        0.2754        0.0000  37.5833
     13      0.9747        [32m0.0738[0m       0.7318      0.8455        0.2718        0.0000  37.6275
     14      0.9747        [32m0.0732[0m       0.7306      0.8465        0.2805        0.0000  37.6306
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.9022839651518718
F1 Macro Score after query 11: 0.8890782402298761
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9466[0m        [32m0.1079[0m       [35m0.7321[0m      [31m0.8173[0m        [94m0.2700[0m     +  0.0001  58.7091
      2      [36m0.9523[0m        [32m0.0958[0m       0.7259      0.8166        0.3006        0.0001  59.0516
      3      [36m0.9548[0m        [32m0.0881[0m       [35m0.7332[0m      0.8110        0.2881        0.0001  58.7229
      4      [36m0.9572[0m        [32m0.0843[0m       [35m0.7361[0m      [31m0.8266[0m        0.2754        0.0001  58.8611
      5      [36m0.9588[0m        [32m0.0805[0m       [35m0.7372[0m      [31m0.8356[0m        0.3158        0.0001  58.7368
      6      [36m0.9633[0m        [32m0.0701[0m       [35m0.7398[0m      0.8343        0.3019        0.0000  59.0636
      7      [36m0.9648[0m        [32m0.0677[0m       0.7257      0.8337        0.3413        0.0000  59.1590
      8      [36m0.9658[0m        [32m0.0665[0m       0.7326      0.8344        0.3105        0.0000  58.8326
      9      0.9656        [32m0.0641[0m       0.7330      [31m0.8389[0m        0.3230        0.0000  56.4644
     10      [36m0.9660[0m        [32m0.0631[0m       0.7307      0.8355        0.3235        0.0000  59.5358
     11      [36m0.9676[0m        [32m0.0612[0m       [35m0.7434[0m      [31m0.8451[0m        0.2994        0.0000  59.5050
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.895367473097764
F1 Macro Score after query 12: 0.8827299634825357
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9409[0m        [32m0.1059[0m       [35m0.7589[0m      [31m0.8379[0m        [94m0.2239[0m     +  0.0001  67.8227
      2      [36m0.9450[0m        [32m0.0957[0m       0.7569      [31m0.8473[0m        0.2444        0.0001  67.7577
      3      [36m0.9500[0m        [32m0.0878[0m       0.7465      0.8424        0.2505        0.0001  67.9418
      4      [36m0.9523[0m        [32m0.0836[0m       0.7512      0.8451        0.2706        0.0001  67.8068
      5      [36m0.9556[0m        [32m0.0787[0m       0.7460      0.8417        0.2713        0.0001  67.7590
      6      [36m0.9611[0m        [32m0.0684[0m       0.7408      0.8427        0.3235        0.0000  67.9615
      7      [36m0.9625[0m        [32m0.0651[0m       0.7316      0.8367        0.3361        0.0000  67.6944
      8      [36m0.9627[0m        0.0651       0.7252      0.8348        0.3421        0.0000  65.5438
      9      [36m0.9646[0m        [32m0.0630[0m       0.7410      0.8406        0.3154        0.0000  67.6502
     10      [36m0.9653[0m        [32m0.0612[0m       0.7347      0.8374        0.3425        0.0000  67.7574
     11      [36m0.9665[0m        [32m0.0583[0m       0.7326      0.8325        0.3289        0.0000  67.8793
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8929381521246031
F1 Macro Score after query 13: 0.8790706885793703
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_score_seed46_config2\AL_average_score_results_for_multilabel_classification.pickle
