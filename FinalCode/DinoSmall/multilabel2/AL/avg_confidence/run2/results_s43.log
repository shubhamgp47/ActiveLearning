Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2434[0m        [32m0.6979[0m       [35m0.2356[0m      [31m0.4635[0m        [94m0.6879[0m     +  0.0000  11.8791
      2      [36m0.8320[0m        [32m0.6229[0m       0.1953      0.4493        0.6886        0.0000  10.5959
      3      0.7460        0.6306       0.2273      0.4454        0.6916        0.0000  10.3786
      4      0.7054        0.6251       0.1556      0.4449        0.6932        0.0000  10.3581
      5      [36m0.8426[0m        [32m0.5746[0m       0.2014      [31m0.4773[0m        [94m0.6830[0m     +  0.0000  10.7558
      6      0.8426        [32m0.5676[0m       0.2083      0.4599        0.6870        0.0000  11.0536
      7      0.7963        [32m0.5644[0m       0.2033      0.4602        0.6952        0.0000  10.5165
      8      0.8333        [32m0.5369[0m       0.2113      0.4646        0.6927        0.0000  10.4578
      9      0.8320        [32m0.5339[0m       0.2056      0.4598        0.6932        0.0000  10.6243
     10      0.7857        [32m0.5283[0m       0.2073      0.4740        0.6929        0.0000  10.6353
     11      0.8130        0.5537       0.2066      0.4687        0.6947        0.0000  10.5683
     12      [36m0.9630[0m        [32m0.4794[0m       0.2083      0.4677        0.6938        0.0000  10.5707
     13      0.8796        0.4997       0.2122      0.4698        0.6929        0.0000  10.8463
     14      0.8889        0.5241       0.2115      0.4708        0.6932        0.0000  10.6854
     15      0.9167        0.4934       0.2125      0.4701        0.6944        0.0000  10.6576
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4810
Pre F1 macro score = 0.4786
Pre Accuracy = 0.2436

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6208[0m        [32m0.6535[0m       [35m0.3615[0m      [31m0.2970[0m        [94m0.6368[0m     +  0.0000  10.5945
      2      [36m0.6500[0m        [32m0.6154[0m       0.3545      [31m0.3006[0m        [94m0.6085[0m     +  0.0000  10.8731
      3      0.5525        [32m0.5701[0m       [35m0.3983[0m      [31m0.4606[0m        [94m0.5871[0m     +  0.0000  10.8750
      4      [36m0.6627[0m        [32m0.5446[0m       [35m0.5036[0m      [31m0.4755[0m        [94m0.5829[0m     +  0.0000  10.7968
      5      [36m0.7104[0m        [32m0.5150[0m       [35m0.5191[0m      [31m0.4982[0m        [94m0.5702[0m     +  0.0000  10.5469
      6      [36m0.7996[0m        [32m0.4806[0m       [35m0.5214[0m      [31m0.5890[0m        [94m0.5519[0m     +  0.0000  10.5470
      7      [36m0.8665[0m        [32m0.4649[0m       [35m0.5385[0m      [31m0.6066[0m        [94m0.5475[0m     +  0.0000  10.9574
      8      0.8520        [32m0.4559[0m       [35m0.5425[0m      [31m0.6137[0m        [94m0.5431[0m     +  0.0000  10.6370
      9      [36m0.8832[0m        [32m0.4470[0m       [35m0.5592[0m      [31m0.6244[0m        [94m0.5398[0m     +  0.0000  10.5842
     10      [36m0.8971[0m        [32m0.4312[0m       0.5566      0.6183        [94m0.5356[0m     +  0.0000  10.6415
     11      [36m0.9630[0m        [32m0.4228[0m       0.5583      [31m0.6280[0m        [94m0.5349[0m     +  0.0000  10.9365
     12      0.8824        0.4386       0.5568      [31m0.6324[0m        [94m0.5343[0m     +  0.0000  10.5299
     13      0.9259        0.4238       0.5580      [31m0.6375[0m        [94m0.5326[0m     +  0.0000  10.7483
     14      0.9167        [32m0.4215[0m       0.5589      [31m0.6413[0m        [94m0.5318[0m     +  0.0000  10.6779
     15      0.9008        0.4227       [35m0.5660[0m      [31m0.6594[0m        [94m0.5286[0m     +  0.0000  10.6458
     16      0.9630        0.4252       0.5651      0.6549        0.5287        0.0000  10.6537
     17      0.8971        [32m0.4079[0m       0.5628      0.6527        0.5291        0.0000  10.6339
     18      0.9485        [32m0.4037[0m       0.5622      0.6490        0.5290        0.0000  10.8922
     19      0.8971        0.4162       0.5628      0.6480        [94m0.5285[0m     +  0.0000  10.6383
     20      0.8554        0.4128       0.5632      0.6501        [94m0.5275[0m     +  0.0000  10.5167
     21      0.9063        0.4068       0.5634      0.6495        [94m0.5275[0m     +  0.0000  10.9419
     22      0.9278        0.4175       0.5634      0.6500        [94m0.5272[0m     +  0.0000  10.8194
     23      0.9434        0.4042       0.5628      0.6504        [94m0.5271[0m     +  0.0000  10.5778
     24      0.9275        [32m0.4001[0m       0.5634      0.6508        [94m0.5269[0m     +  0.0000  10.6132
     25      0.9434        [32m0.3985[0m       0.5627      0.6498        0.5269        0.0000  10.9870
     26      0.9100        0.4157       0.5628      0.6500        [94m0.5268[0m     +  0.0000  10.7008
     27      0.9474        0.4182       0.5628      0.6501        [94m0.5268[0m     +  0.0000  10.8717
     28      0.8971        0.4105       0.5628      0.6511        [94m0.5267[0m     +  0.0000  10.5917
     29      0.9259        0.4194       0.5627      0.6500        0.5268        0.0000  10.5843
     30      0.9471        0.4049       0.5627      0.6503        0.5267        0.0000  10.5820
     31      0.9216        0.4271       0.5630      0.6505        [94m0.5267[0m     +  0.0000  10.6254
     32      0.8971        0.4227       0.5632      0.6506        [94m0.5266[0m     +  0.0000  10.8711
     33      0.8971        0.4185       0.5632      0.6508        [94m0.5266[0m     +  0.0000  10.7635
     34      0.9630        0.3996       0.5632      0.6508        [94m0.5266[0m     +  0.0000  10.6205
     35      0.9412        0.4135       0.5634      0.6511        [94m0.5266[0m     +  0.0000  10.5635
     36      0.9434        0.3992       0.5632      0.6510        0.5266        0.0000  10.5771
     37      [36m0.9825[0m        [32m0.3909[0m       0.5634      0.6511        [94m0.5266[0m     +  0.0000  10.6105
     38      0.8898        0.4228       0.5634      0.6511        [94m0.5265[0m     +  0.0000  10.6928
     39      0.9628        0.3955       0.5634      0.6511        [94m0.5265[0m     +  0.0000  10.5643
     40      0.8824        0.4131       0.5635      0.6514        [94m0.5265[0m     +  0.0000  10.5282
     41      0.9412        0.4144       0.5635      0.6514        0.5265        0.0000  10.5580
     42      0.9259        0.4194       0.5635      0.6514        0.5265        0.0000  10.5761
     43      0.9216        0.4176       0.5635      0.6514        [94m0.5265[0m     +  0.0000  10.5935
     44      0.8971        0.4003       0.5635      0.6514        [94m0.5265[0m     +  0.0000  10.6161
     45      0.9063        0.4222       0.5635      0.6514        [94m0.5265[0m     +  0.0000  10.5278
     46      0.9167        0.4033       0.5635      0.6514        0.5265        0.0000  10.5832
     47      0.9063        [32m0.3882[0m       0.5635      0.6514        0.5265        0.0000  10.5941
     48      0.9434        0.4094       0.5635      0.6514        [94m0.5265[0m     +  0.0000  10.6253
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.6962469957478277
F1 Macro Score after query 1: 0.6752375425560091
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6648[0m        [32m0.5060[0m       [35m0.5295[0m      [31m0.6076[0m        [94m0.4742[0m     +  0.0000  10.7063
      2      [36m0.8012[0m        [32m0.4250[0m       [35m0.5858[0m      [31m0.7208[0m        [94m0.4404[0m     +  0.0000  10.8276
      3      [36m0.8311[0m        [32m0.4008[0m       [35m0.6224[0m      [31m0.7284[0m        [94m0.4246[0m     +  0.0000  10.6996
      4      [36m0.9031[0m        [32m0.3634[0m       [35m0.6682[0m      [31m0.7855[0m        [94m0.4113[0m     +  0.0000  11.1122
      5      [36m0.9077[0m        [32m0.3536[0m       0.6566      0.7685        [94m0.4044[0m     +  0.0000  10.7940
      6      [36m0.9166[0m        [32m0.3398[0m       0.6535      0.7708        0.4049        0.0000  10.7378
      7      [36m0.9190[0m        [32m0.3298[0m       0.6368      0.7530        0.4070        0.0000  10.8173
      8      0.9125        [32m0.3286[0m       0.6318      0.7495        0.4064        0.0000  10.7498
      9      [36m0.9280[0m        [32m0.3151[0m       0.6486      0.7644        [94m0.4007[0m     +  0.0000  10.8911
     10      [36m0.9384[0m        0.3174       0.6286      0.7401        0.4027        0.0000  11.2209
     11      [36m0.9434[0m        0.3176       0.6418      0.7567        [94m0.3998[0m     +  0.0000  10.7310
     12      0.9262        [32m0.3075[0m       0.6417      0.7591        [94m0.3993[0m     +  0.0000  10.6718
     13      [36m0.9496[0m        0.3150       0.6389      0.7547        0.3995        0.0000  10.6912
     14      0.8977        0.3170       0.6545      0.7690        [94m0.3957[0m     +  0.0000  10.6942
     15      0.9177        0.3202       0.6403      0.7578        0.3983        0.0000  11.0147
     16      0.9384        0.3171       0.6408      0.7579        0.3983        0.0000  10.7055
     17      0.9312        0.3108       0.6418      0.7588        0.3979        0.0000  10.7261
     18      0.9205        0.3099       0.6372      0.7547        0.3988        0.0000  10.8392
     19      0.9432        [32m0.3012[0m       0.6389      0.7568        0.3986        0.0000  10.6872
     20      0.9238        0.3196       0.6415      0.7588        0.3977        0.0000  10.7627
     21      0.9227        0.3131       0.6424      0.7595        0.3973        0.0000  10.9042
     22      0.9314        0.3150       0.6429      0.7601        0.3971        0.0000  10.8124
     23      0.9314        0.3070       0.6431      0.7614        0.3969        0.0000  10.7346
     24      0.9238        0.3082       0.6424      0.7604        0.3972        0.0000  10.8413
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.8096093015303069
F1 Macro Score after query 2: 0.7855094323246941
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8348[0m        [32m0.3741[0m       [35m0.7078[0m      [31m0.8417[0m        [94m0.3654[0m     +  0.0000  10.9559
      2      [36m0.8697[0m        [32m0.3221[0m       [35m0.7085[0m      0.8409        [94m0.3521[0m     +  0.0000  11.0613
      3      [36m0.9152[0m        [32m0.3026[0m       0.6950      0.8326        [94m0.3449[0m     +  0.0000  10.8844
      4      0.8969        [32m0.2907[0m       [35m0.7099[0m      [31m0.8432[0m        [94m0.3400[0m     +  0.0000  10.9049
      5      [36m0.9302[0m        [32m0.2828[0m       0.7038      0.8396        [94m0.3336[0m     +  0.0000  10.9307
      6      [36m0.9467[0m        [32m0.2669[0m       0.7017      0.8384        [94m0.3327[0m     +  0.0000  11.0061
      7      0.9329        0.2720       0.6932      0.8317        [94m0.3324[0m     +  0.0000  10.8886
      8      0.9467        [32m0.2639[0m       0.6918      0.8304        [94m0.3303[0m     +  0.0000  10.8888
      9      0.9388        [32m0.2611[0m       0.6939      0.8326        [94m0.3294[0m     +  0.0000  10.9222
     10      [36m0.9512[0m        [32m0.2561[0m       0.6929      0.8318        [94m0.3291[0m     +  0.0000  10.9058
     11      0.9426        [32m0.2540[0m       0.6920      0.8312        [94m0.3288[0m     +  0.0000  11.2312
     12      0.9406        0.2578       0.6898      0.8299        0.3292        0.0000  10.8715
     13      [36m0.9574[0m        [32m0.2522[0m       0.6882      0.8284        0.3292        0.0000  10.9387
     14      0.9482        [32m0.2475[0m       0.6889      0.8295        0.3292        0.0000  10.8867
     15      0.9506        0.2534       0.6944      0.8340        [94m0.3274[0m     +  0.0000  10.9490
     16      0.9531        [32m0.2470[0m       0.6911      0.8309        0.3277        0.0000  11.2816
     17      0.9349        0.2521       0.6915      0.8307        0.3275        0.0000  11.0158
     18      0.9546        0.2476       0.6882      0.8285        0.3280        0.0000  10.9179
     19      0.9368        0.2506       0.6896      0.8294        0.3276        0.0000  10.9041
     20      0.9476        [32m0.2462[0m       0.6896      0.8295        0.3275        0.0000  10.9173
     21      0.9534        0.2545       0.6901      0.8299        [94m0.3274[0m     +  0.0000  11.1106
     22      0.9493        [32m0.2437[0m       0.6905      0.8300        [94m0.3273[0m     +  0.0000  10.9992
     23      0.9508        0.2467       0.6896      0.8296        0.3274        0.0000  10.8881
     24      [36m0.9590[0m        0.2479       0.6875      0.8284        0.3278        0.0000  11.0000
     25      0.9417        0.2507       0.6887      0.8293        0.3275        0.0000  10.9341
     26      0.9533        0.2531       0.6898      0.8299        0.3274        0.0000  10.8576
     27      [36m0.9623[0m        0.2486       0.6905      0.8303        0.3273        0.0000  11.3877
     28      [36m0.9666[0m        0.2518       0.6905      0.8302        [94m0.3272[0m     +  0.0000  10.8883
     29      0.9574        0.2455       0.6903      0.8302        0.3273        0.0000  10.9413
     30      0.9465        0.2462       0.6901      0.8301        0.3273        0.0000  10.8531
     31      0.9553        0.2509       0.6901      0.8301        0.3273        0.0000  10.9217
     32      0.9565        0.2500       0.6896      0.8299        0.3274        0.0000  11.2856
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.8619741100323625
F1 Macro Score after query 3: 0.8483521748750764
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8838[0m        [32m0.2950[0m       [35m0.7368[0m      [31m0.8664[0m        [94m0.3030[0m     +  0.0000  11.4898
      2      [36m0.8880[0m        [32m0.2700[0m       0.7219      0.8554        [94m0.2953[0m     +  0.0000  11.3252
      3      [36m0.9209[0m        [32m0.2575[0m       0.7366      0.8635        [94m0.2888[0m     +  0.0000  11.2934
      4      [36m0.9319[0m        [32m0.2433[0m       [35m0.7401[0m      0.8633        [94m0.2873[0m     +  0.0000  11.6106
      5      0.9287        [32m0.2345[0m       [35m0.7457[0m      0.8623        [94m0.2845[0m     +  0.0000  11.2959
      6      [36m0.9516[0m        [32m0.2261[0m       0.7300      0.8519        0.2857        0.0000  11.3592
      7      0.9447        [32m0.2211[0m       0.7319      0.8521        [94m0.2842[0m     +  0.0000  11.3120
      8      [36m0.9558[0m        [32m0.2198[0m       0.7328      0.8515        0.2853        0.0000  11.2498
      9      [36m0.9592[0m        [32m0.2127[0m       0.7307      0.8494        0.2852        0.0000  11.4218
     10      0.9592        0.2151       0.7358      0.8532        [94m0.2812[0m     +  0.0000  11.3121
     11      0.9586        [32m0.2089[0m       0.7318      0.8514        [94m0.2810[0m     +  0.0000  11.2466
     12      0.9551        [32m0.2088[0m       0.7361      0.8556        [94m0.2797[0m     +  0.0000  11.6954
     13      0.9539        [32m0.2067[0m       0.7368      0.8550        [94m0.2791[0m     +  0.0000  11.3601
     14      [36m0.9649[0m        0.2113       0.7302      0.8516        0.2806        0.0000  11.3748
     15      0.9627        [32m0.2053[0m       0.7326      0.8527        0.2797        0.0000  11.4747
     16      0.9639        0.2075       0.7413      0.8604        [94m0.2772[0m     +  0.0000  11.3920
     17      [36m0.9679[0m        0.2070       0.7377      0.8570        0.2780        0.0000  11.4156
     18      0.9593        [32m0.2042[0m       0.7399      0.8588        0.2772        0.0000  11.3584
     19      0.9655        0.2048       0.7380      0.8571        0.2775        0.0000  11.3321
     20      [36m0.9691[0m        0.2060       0.7375      0.8571        0.2776        0.0000  11.3594
     21      0.9587        0.2072       0.7382      0.8578        0.2776        0.0000  11.4375
     22      [36m0.9701[0m        [32m0.2020[0m       0.7385      0.8586        [94m0.2769[0m     +  0.0000  11.2799
     23      0.9651        0.2086       0.7394      0.8593        [94m0.2766[0m     +  0.0000  11.3459
     24      0.9679        0.2045       0.7391      0.8588        0.2768        0.0000  11.3101
     25      0.9685        0.2025       0.7384      0.8583        0.2771        0.0000  11.2337
     26      [36m0.9766[0m        0.2088       0.7389      0.8586        0.2769        0.0000  11.3688
     27      0.9634        0.2062       0.7387      0.8588        0.2768        0.0000  11.2939
     28      0.9680        0.2075       0.7392      0.8591        0.2766        0.0000  11.3306
     29      0.9715        0.2074       0.7389      0.8588        0.2766        0.0000  11.4364
     30      0.9715        0.2090       0.7391      0.8586        0.2767        0.0000  11.4118
     31      0.9638        0.2055       0.7391      0.8586        0.2768        0.0000  11.2969
     32      0.9651        0.2054       0.7389      0.8585        0.2767        0.0000  11.2217
     33      0.9634        0.2061       0.7391      0.8586        0.2767        0.0000  11.2680
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.9006376624424893
F1 Macro Score after query 4: 0.8899961033299366
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9095[0m        [32m0.2426[0m       [35m0.7568[0m      [31m0.8735[0m        [94m0.2685[0m     +  0.0000  11.9151
      2      [36m0.9244[0m        [32m0.2205[0m       [35m0.7639[0m      [31m0.8758[0m        [94m0.2643[0m     +  0.0000  11.8449
      3      [36m0.9475[0m        [32m0.2109[0m       0.7615      0.8737        [94m0.2595[0m     +  0.0000  11.9581
      4      [36m0.9480[0m        [32m0.1968[0m       [35m0.7686[0m      0.8755        [94m0.2537[0m     +  0.0000  11.9405
      5      0.9477        [32m0.1938[0m       0.7668      0.8752        0.2539        0.0000  11.9512
      6      [36m0.9545[0m        [32m0.1855[0m       0.7628      0.8689        [94m0.2498[0m     +  0.0000  12.2075
      7      [36m0.9619[0m        [32m0.1803[0m       0.7681      0.8735        [94m0.2484[0m     +  0.0000  11.8876
      8      0.9584        0.1839       0.7677      0.8729        [94m0.2481[0m     +  0.0000  12.0743
      9      [36m0.9677[0m        0.1806       0.7615      0.8643        0.2484        0.0000  11.9870
     10      [36m0.9709[0m        [32m0.1740[0m       0.7648      0.8663        0.2481        0.0000  11.9403
     11      [36m0.9713[0m        [32m0.1679[0m       0.7613      0.8652        0.2486        0.0000  11.9260
     12      [36m0.9726[0m        0.1696       0.7639      0.8642        0.2489        0.0000  12.0014
     13      0.9697        0.1718       0.7630      0.8627        0.2494        0.0000  11.9217
     14      0.9713        0.1707       0.7649      0.8626        0.2490        0.0000  12.1708
     15      [36m0.9736[0m        0.1685       0.7649      0.8649        [94m0.2480[0m     +  0.0000  12.0431
     16      [36m0.9764[0m        [32m0.1641[0m       0.7618      0.8630        0.2484        0.0000  12.0942
     17      0.9749        [32m0.1633[0m       0.7632      0.8649        [94m0.2478[0m     +  0.0000  11.9985
     18      0.9745        [32m0.1624[0m       0.7642      0.8646        0.2484        0.0000  11.8716
     19      0.9740        0.1669       0.7630      0.8642        0.2485        0.0000  11.9304
     20      0.9728        0.1653       0.7627      0.8646        [94m0.2475[0m     +  0.0000  11.9632
     21      0.9714        0.1638       0.7632      0.8636        0.2484        0.0000  11.9316
     22      0.9753        [32m0.1618[0m       0.7635      0.8642        0.2484        0.0000  12.0011
     23      0.9760        0.1630       0.7634      0.8636        0.2486        0.0000  11.9459
     24      0.9760        0.1639       0.7641      0.8647        0.2483        0.0000  11.9428
     25      [36m0.9824[0m        0.1619       0.7641      0.8649        0.2480        0.0000  11.9525
     26      0.9736        [32m0.1586[0m       0.7641      0.8643        0.2483        0.0000  11.8749
     27      0.9754        [32m0.1581[0m       0.7642      0.8648        0.2481        0.0000  11.9556
     28      0.9768        0.1617       0.7641      0.8648        0.2482        0.0000  11.9982
     29      0.9815        0.1638       0.7635      0.8645        0.2481        0.0000  11.9846
     30      0.9749        0.1635       0.7634      0.8642        0.2482        0.0000  12.1254
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.9099609219235982
F1 Macro Score after query 5: 0.8988468880811831
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9294[0m        [32m0.2028[0m       [35m0.7592[0m      [31m0.8739[0m        [94m0.2464[0m     +  0.0000  13.4990
      2      [36m0.9510[0m        [32m0.1802[0m       [35m0.7693[0m      [31m0.8773[0m        [94m0.2403[0m     +  0.0000  13.3909
      3      [36m0.9580[0m        [32m0.1705[0m       [35m0.7719[0m      0.8748        [94m0.2342[0m     +  0.0000  13.4817
      4      [36m0.9668[0m        [32m0.1613[0m       [35m0.7762[0m      0.8768        [94m0.2324[0m     +  0.0000  13.3884
      5      [36m0.9711[0m        [32m0.1560[0m       0.7759      0.8723        [94m0.2300[0m     +  0.0000  13.4966
      6      [36m0.9799[0m        [32m0.1457[0m       [35m0.7816[0m      0.8750        [94m0.2275[0m     +  0.0000  13.4544
      7      [36m0.9827[0m        0.1459       [35m0.7878[0m      0.8766        [94m0.2247[0m     +  0.0000  13.4046
      8      0.9780        [32m0.1433[0m       0.7870      [31m0.8774[0m        0.2262        0.0000  13.4501
      9      0.9815        [32m0.1390[0m       0.7875      0.8759        [94m0.2230[0m     +  0.0000  13.4711
     10      [36m0.9858[0m        [32m0.1355[0m       0.7852      0.8770        0.2259        0.0000  13.4214
     11      0.9834        0.1363       [35m0.7915[0m      0.8771        [94m0.2211[0m     +  0.0000  13.4077
     12      [36m0.9859[0m        [32m0.1318[0m       [35m0.7922[0m      [31m0.8785[0m        0.2219        0.0000  13.3538
     13      0.9855        0.1320       [35m0.7948[0m      [31m0.8796[0m        [94m0.2209[0m     +  0.0000  13.4031
     14      [36m0.9864[0m        0.1324       0.7948      0.8793        0.2211        0.0000  13.3737
     15      [36m0.9874[0m        [32m0.1311[0m       [35m0.7953[0m      0.8794        0.2212        0.0000  13.3896
     16      0.9858        [32m0.1288[0m       0.7946      0.8790        [94m0.2203[0m     +  0.0000  13.5384
     17      0.9863        [32m0.1267[0m       0.7951      [31m0.8800[0m        [94m0.2200[0m     +  0.0000  13.4721
     18      0.9871        0.1293       0.7946      0.8796        [94m0.2199[0m     +  0.0000  13.3898
     19      0.9867        0.1273       0.7953      0.8798        [94m0.2197[0m     +  0.0000  13.4029
     20      0.9872        [32m0.1251[0m       0.7951      0.8797        [94m0.2193[0m     +  0.0000  13.4204
     21      0.9869        0.1266       [35m0.7958[0m      0.8797        [94m0.2192[0m     +  0.0000  13.4900
     22      [36m0.9881[0m        0.1288       0.7946      0.8793        0.2194        0.0000  13.4021
     23      [36m0.9888[0m        0.1255       [35m0.7965[0m      [31m0.8800[0m        [94m0.2191[0m     +  0.0000  13.8035
     24      0.9880        0.1255       0.7948      0.8795        [94m0.2191[0m     +  0.0000  13.4100
     25      [36m0.9897[0m        0.1261       0.7964      0.8798        [94m0.2189[0m     +  0.0000  13.3720
     26      0.9884        0.1258       0.7953      0.8797        [94m0.2188[0m     +  0.0000  13.5156
     27      0.9869        0.1258       0.7948      0.8792        [94m0.2188[0m     +  0.0000  13.4058
     28      0.9891        [32m0.1234[0m       0.7948      0.8793        [94m0.2187[0m     +  0.0000  13.3449
     29      0.9893        0.1264       0.7944      0.8792        0.2188        0.0000  13.4175
     30      0.9873        0.1270       0.7950      0.8793        0.2188        0.0000  13.6207
     31      0.9872        0.1263       0.7948      0.8792        0.2188        0.0000  13.6091
     32      0.9888        0.1259       0.7951      0.8793        [94m0.2187[0m     +  0.0000  13.5651
     33      0.9881        0.1266       0.7948      0.8792        [94m0.2187[0m     +  0.0000  13.3751
     34      0.9886        0.1254       0.7951      0.8791        [94m0.2186[0m     +  0.0000  13.3804
     35      0.9881        [32m0.1234[0m       0.7951      0.8791        [94m0.2186[0m     +  0.0000  13.5160
     36      0.9881        0.1235       0.7953      0.8792        [94m0.2186[0m     +  0.0000  13.4016
     37      0.9888        0.1240       0.7955      0.8792        [94m0.2186[0m     +  0.0000  13.8457
     38      0.9888        0.1260       0.7955      0.8792        [94m0.2186[0m     +  0.0000  13.4390
     39      0.9879        0.1246       0.7955      0.8792        [94m0.2186[0m     +  0.0000  13.4242
     40      0.9863        0.1263       0.7953      0.8791        [94m0.2186[0m     +  0.0000  13.7624
     41      0.9878        0.1244       0.7955      0.8792        [94m0.2186[0m     +  0.0000  13.2932
     42      0.9881        0.1279       0.7957      0.8792        [94m0.2186[0m     +  0.0000  13.3626
     43      0.9890        0.1258       0.7955      0.8792        0.2186        0.0000  13.5177
     44      0.9878        0.1264       0.7955      0.8792        0.2186        0.0000  13.4854
     45      0.9883        0.1284       0.7955      0.8792        0.2186        0.0000  13.4842
     46      0.9888        0.1252       0.7955      0.8792        0.2186        0.0000  13.4813
     47      0.9884        0.1267       0.7955      0.8792        0.2186        0.0000  13.4418
     48      0.9881        0.1235       0.7955      0.8792        [94m0.2186[0m     +  0.0000  13.6724
     49      0.9872        0.1259       0.7955      0.8792        0.2186        0.0000  13.3321
     50      0.9872        0.1257       0.7955      0.8792        [94m0.2186[0m     +  0.0000  13.4063
     51      0.9877        0.1246       0.7955      0.8792        [94m0.2186[0m     +  0.0000  13.3719
     52      0.9893        0.1255       0.7955      0.8792        [94m0.2186[0m     +  0.0000  13.4535
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.9132034123816232
F1 Macro Score after query 6: 0.8994482906673897
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9521[0m        [32m0.1640[0m       [35m0.7969[0m      [31m0.8724[0m        [94m0.2176[0m     +  0.0000  15.5789
      2      [36m0.9635[0m        [32m0.1464[0m       [35m0.7984[0m      0.8681        [94m0.2131[0m     +  0.0000  15.5891
      3      [36m0.9695[0m        [32m0.1391[0m       [35m0.8104[0m      [31m0.8796[0m        [94m0.2081[0m     +  0.0000  15.6605
      4      [36m0.9727[0m        [32m0.1312[0m       [35m0.8214[0m      [31m0.8886[0m        [94m0.2007[0m     +  0.0000  15.5001
      5      [36m0.9739[0m        [32m0.1244[0m       0.8111      0.8808        0.2009        0.0000  15.5823
      6      [36m0.9806[0m        [32m0.1160[0m       [35m0.8316[0m      [31m0.8910[0m        [94m0.1932[0m     +  0.0000  16.0367
      7      [36m0.9839[0m        [32m0.1130[0m       [35m0.8339[0m      [31m0.8915[0m        [94m0.1909[0m     +  0.0000  15.7032
      8      [36m0.9869[0m        [32m0.1105[0m       0.8326      [31m0.8915[0m        0.1912        0.0000  15.6253
      9      0.9848        [32m0.1084[0m       0.8339      0.8886        [94m0.1907[0m     +  0.0000  15.6731
     10      0.9848        [32m0.1058[0m       0.8335      0.8890        [94m0.1888[0m     +  0.0000  15.6806
     11      [36m0.9902[0m        [32m0.1024[0m       [35m0.8380[0m      [31m0.8933[0m        [94m0.1866[0m     +  0.0000  15.5185
     12      [36m0.9918[0m        [32m0.1003[0m       0.8309      0.8915        [94m0.1860[0m     +  0.0000  15.5644
     13      0.9905        0.1007       0.8347      0.8932        [94m0.1851[0m     +  0.0000  16.0460
     14      [36m0.9926[0m        [32m0.0996[0m       0.8328      0.8924        0.1854        0.0000  15.5700
     15      0.9907        [32m0.0982[0m       0.8328      0.8923        0.1851        0.0000  15.5827
     16      0.9922        [32m0.0970[0m       0.8337      [31m0.8941[0m        [94m0.1845[0m     +  0.0000  15.5268
     17      [36m0.9938[0m        0.0980       0.8330      0.8938        0.1846        0.0000  15.7147
     18      0.9931        [32m0.0964[0m       0.8328      0.8936        0.1846        0.0000  15.5200
     19      [36m0.9943[0m        0.0972       0.8337      0.8936        [94m0.1845[0m     +  0.0000  15.5596
     20      0.9939        [32m0.0947[0m       0.8321      0.8930        0.1847        0.0000  15.7569
     21      0.9931        0.0967       0.8295      0.8923        0.1851        0.0000  15.4667
     22      0.9932        0.0967       0.8292      0.8925        0.1852        0.0000  15.6281
     23      0.9929        [32m0.0937[0m       0.8292      0.8924        0.1853        0.0000  15.6274
     24      [36m0.9951[0m        0.0961       0.8280      0.8923        0.1857        0.0000  15.8306
     25      0.9944        0.0940       0.8278      0.8921        0.1856        0.0000  15.5991
     26      0.9934        0.0949       0.8273      0.8922        0.1864        0.0000  15.7168
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.9068352059925093
F1 Macro Score after query 7: 0.8884765607058475
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9689[0m        [32m0.1180[0m       [35m0.7898[0m      [31m0.8735[0m        [94m0.1991[0m     +  0.0000  19.4177
      2      [36m0.9773[0m        [32m0.1069[0m       [35m0.8036[0m      [31m0.8763[0m        [94m0.1891[0m     +  0.0000  19.2619
      3      [36m0.9820[0m        [32m0.0980[0m       [35m0.8151[0m      [31m0.8796[0m        [94m0.1851[0m     +  0.0000  19.3614
      4      [36m0.9851[0m        [32m0.0906[0m       0.8151      [31m0.8826[0m        [94m0.1798[0m     +  0.0000  19.4164
      5      [36m0.9869[0m        [32m0.0851[0m       [35m0.8316[0m      [31m0.8924[0m        [94m0.1782[0m     +  0.0000  19.3042
      6      [36m0.9912[0m        [32m0.0778[0m       [35m0.8332[0m      [31m0.8952[0m        [94m0.1745[0m     +  0.0000  19.3560
      7      [36m0.9918[0m        [32m0.0744[0m       0.8274      0.8921        0.1754        0.0000  19.5623
      8      [36m0.9942[0m        [32m0.0723[0m       0.8321      0.8938        [94m0.1727[0m     +  0.0000  19.5618
      9      0.9938        [32m0.0696[0m       0.8290      0.8907        0.1728        0.0000  19.2809
     10      [36m0.9945[0m        [32m0.0681[0m       0.8245      0.8904        0.1764        0.0000  19.3596
     11      [36m0.9954[0m        [32m0.0663[0m       0.8247      0.8860        [94m0.1726[0m     +  0.0000  19.3294
     12      [36m0.9963[0m        [32m0.0646[0m       0.8234      0.8855        0.1727        0.0000  19.5003
     13      0.9961        [32m0.0639[0m       0.8231      0.8854        0.1731        0.0000  19.4970
     14      [36m0.9968[0m        [32m0.0634[0m       0.8227      0.8852        0.1732        0.0000  19.2840
     15      0.9964        [32m0.0629[0m       0.8240      0.8870        0.1740        0.0000  19.1881
     16      0.9966        [32m0.0607[0m       0.8208      0.8851        0.1743        0.0000  19.3554
     17      0.9964        0.0608       0.8217      0.8861        0.1746        0.0000  19.4685
     18      [36m0.9970[0m        [32m0.0598[0m       0.8200      0.8843        0.1744        0.0000  19.2809
     19      [36m0.9972[0m        0.0608       0.8205      0.8846        0.1747        0.0000  19.3451
     20      0.9966        [32m0.0597[0m       0.8227      0.8860        0.1748        0.0000  19.7690
     21      0.9972        [32m0.0594[0m       0.8229      0.8869        0.1750        0.0000  19.1993
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.9077571406274387
F1 Macro Score after query 8: 0.8892751051230667
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9747[0m        [32m0.0886[0m       [35m0.8205[0m      [31m0.8920[0m        [94m0.1714[0m     +  0.0000  26.2193
      2      [36m0.9782[0m        [32m0.0784[0m       0.8135      0.8870        0.1727        0.0000  26.5926
      3      [36m0.9840[0m        [32m0.0704[0m       0.8163      [31m0.8937[0m        0.1740        0.0000  26.0660
      4      [36m0.9870[0m        [32m0.0632[0m       0.8168      0.8880        0.1794        0.0000  26.4512
      5      [36m0.9881[0m        [32m0.0594[0m       [35m0.8335[0m      [31m0.8956[0m        [94m0.1655[0m     +  0.0000  26.2241
      6      [36m0.9916[0m        [32m0.0518[0m       0.8122      0.8880        0.1856        0.0000  25.7316
      7      [36m0.9937[0m        [32m0.0485[0m       0.8205      0.8906        0.1811        0.0000  24.9853
      8      0.9937        [32m0.0467[0m       0.8187      0.8903        0.1863        0.0000  24.9459
      9      [36m0.9950[0m        [32m0.0444[0m       0.8252      0.8912        0.1904        0.0000  24.9329
     10      0.9944        [32m0.0430[0m       0.8241      0.8949        0.1824        0.0000  24.9537
     11      [36m0.9963[0m        [32m0.0402[0m       0.8299      0.8906        0.1766        0.0000  24.9212
     12      [36m0.9966[0m        [32m0.0392[0m       0.8311      0.8919        0.1782        0.0000  24.9410
     13      [36m0.9971[0m        [32m0.0384[0m       0.8318      0.8915        0.1763        0.0000  24.9663
     14      [36m0.9972[0m        [32m0.0373[0m       0.8269      0.8847        0.1802        0.0000  25.0133
     15      [36m0.9972[0m        [32m0.0369[0m       0.8278      0.8868        0.1775        0.0000  25.0806
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.9062401512763946
F1 Macro Score after query 9: 0.8860006706051159
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9759[0m        [32m0.0711[0m       [35m0.8321[0m      [31m0.8961[0m        [94m0.1608[0m     +  0.0000  36.7671
      2      [36m0.9806[0m        [32m0.0621[0m       0.8292      0.8945        [94m0.1590[0m     +  0.0000  36.8448
      3      [36m0.9829[0m        [32m0.0556[0m       [35m0.8375[0m      [31m0.8994[0m        0.1625        0.0000  36.8163
      4      [36m0.9855[0m        [32m0.0501[0m       0.8278      0.8905        0.1658        0.0000  36.7635
      5      [36m0.9869[0m        [32m0.0446[0m       0.8182      0.8843        0.1854        0.0000  36.8469
      6      [36m0.9889[0m        [32m0.0388[0m       0.8293      0.8952        0.1753        0.0000  36.8272
      7      [36m0.9917[0m        [32m0.0355[0m       0.8259      0.8954        0.1847        0.0000  36.8416
      8      [36m0.9930[0m        [32m0.0331[0m       [35m0.8427[0m      [31m0.9031[0m        0.1695        0.0000  36.7989
      9      [36m0.9947[0m        [32m0.0308[0m       0.8347      0.8992        0.1832        0.0000  37.0386
     10      [36m0.9949[0m        [32m0.0286[0m       0.8399      0.8982        0.1746        0.0000  37.5120
     11      [36m0.9964[0m        [32m0.0265[0m       0.8332      0.8993        0.1888        0.0000  37.5912
     12      [36m0.9972[0m        [32m0.0249[0m       0.8326      0.8982        0.1925        0.0000  37.3406
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.9077673662200882
F1 Macro Score after query 10: 0.8918052989632689
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9761[0m        [32m0.0638[0m       [35m0.8302[0m      [31m0.8949[0m        [94m0.1626[0m     +  0.0000  58.3350
      2      [36m0.9797[0m        [32m0.0559[0m       [35m0.8342[0m      0.8948        0.1639        0.0000  60.0503
      3      [36m0.9818[0m        [32m0.0497[0m       [35m0.8368[0m      [31m0.8958[0m        0.1665        0.0000  60.0641
      4      [36m0.9837[0m        [32m0.0446[0m       0.8326      0.8930        0.1748        0.0000  60.2178
      5      [36m0.9861[0m        [32m0.0398[0m       0.8177      0.8836        0.1958        0.0000  59.9226
      6      [36m0.9883[0m        [32m0.0338[0m       [35m0.8436[0m      [31m0.9003[0m        0.1717        0.0000  59.8731
      7      [36m0.9910[0m        [32m0.0300[0m       [35m0.8451[0m      [31m0.9018[0m        0.1702        0.0000  59.5916
      8      [36m0.9923[0m        [32m0.0274[0m       0.8389      0.8965        0.1763        0.0000  59.5784
      9      [36m0.9930[0m        [32m0.0253[0m       0.8378      0.8949        0.1825        0.0000  60.1466
     10      [36m0.9936[0m        [32m0.0238[0m       [35m0.8497[0m      [31m0.9043[0m        0.1768        0.0000  60.3495
     11      [36m0.9953[0m        [32m0.0215[0m       0.8401      0.9000        0.1878        0.0000  59.8856
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.9070435660479925
F1 Macro Score after query 11: 0.8900353729579468
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9761[0m        [32m0.0591[0m       [35m0.8394[0m      [31m0.8941[0m        [94m0.1595[0m     +  0.0000  99.4746
      2      [36m0.9790[0m        [32m0.0502[0m       0.8335      0.8867        0.1654        0.0000  98.8801
      3      [36m0.9821[0m        [32m0.0443[0m       [35m0.8547[0m      [31m0.9066[0m        [94m0.1502[0m     +  0.0000  99.0948
      4      [36m0.9833[0m        [32m0.0393[0m       0.8385      0.8994        0.1737        0.0000  98.9009
      5      [36m0.9846[0m        [32m0.0358[0m       0.8509      [31m0.9073[0m        0.1689        0.0000  98.6417
      6      [36m0.9880[0m        [32m0.0291[0m       0.8503      0.9036        0.1689        0.0000  98.4970
      7      [36m0.9900[0m        [32m0.0260[0m       0.8519      [31m0.9077[0m        0.1723        0.0000  99.0177
      8      [36m0.9908[0m        [32m0.0242[0m       0.8495      0.9064        0.1772        0.0000  99.2842
      9      [36m0.9921[0m        [32m0.0221[0m       0.8490      0.9065        0.1857        0.0000  98.6375
     10      [36m0.9925[0m        [32m0.0201[0m       0.8375      0.9008        0.2010        0.0000  98.7760
     11      [36m0.9934[0m        [32m0.0183[0m       0.8391      0.9033        0.2041        0.0000  99.0022
     12      [36m0.9946[0m        [32m0.0169[0m       0.8387      0.9035        0.2084        0.0000  98.6555
     13      [36m0.9951[0m        [32m0.0160[0m       0.8365      0.9021        0.2122        0.0000  98.4999
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.9226404968182168
F1 Macro Score after query 12: 0.9122925235379239
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9805[0m        [32m0.0429[0m       [35m0.8441[0m      [31m0.9070[0m        [94m0.1735[0m     +  0.0000  113.6181
      2      [36m0.9834[0m        [32m0.0373[0m       [35m0.8465[0m      [31m0.9081[0m        [94m0.1701[0m     +  0.0000  114.1080
      3      [36m0.9847[0m        [32m0.0339[0m       [35m0.8564[0m      0.9076        0.1754        0.0000  113.9425
      4      [36m0.9861[0m        [32m0.0306[0m       0.8368      0.9010        0.2030        0.0000  114.3596
      5      [36m0.9867[0m        [32m0.0284[0m       0.8484      0.9042        0.1861        0.0000  114.3765
      6      [36m0.9900[0m        [32m0.0229[0m       0.8542      [31m0.9092[0m        0.1797        0.0000  114.3583
      7      [36m0.9912[0m        [32m0.0203[0m       0.8444      0.9040        0.1907        0.0000  114.2637
      8      [36m0.9927[0m        [32m0.0188[0m       0.8458      0.9048        0.1906        0.0000  114.4373
      9      [36m0.9933[0m        [32m0.0169[0m       0.8382      0.9025        0.2078        0.0000  114.1887
     10      [36m0.9938[0m        [32m0.0158[0m       0.8439      0.9039        0.2029        0.0000  114.7610
     11      [36m0.9946[0m        [32m0.0138[0m       0.8410      0.9040        0.2131        0.0000  114.1871
     12      [36m0.9959[0m        [32m0.0123[0m       0.8392      0.9034        0.2191        0.0000  114.3260
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.9204294525241757
F1 Macro Score after query 13: 0.9080924737690269
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed43_lowLR\AL_average_confidence_results_for_multilabel_classification.pickle
