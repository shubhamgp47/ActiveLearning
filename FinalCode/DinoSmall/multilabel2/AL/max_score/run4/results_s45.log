Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5152[0m        [32m0.7299[0m       [35m0.0061[0m      [31m0.6298[0m        [94m0.7097[0m     +  0.0000  14.5484
      2      0.4924        [32m0.6640[0m       [35m0.0769[0m      0.5615        [94m0.6983[0m     +  0.0000  10.2599
      3      [36m0.5556[0m        [32m0.6529[0m       [35m0.2003[0m      0.2952        [94m0.6960[0m     +  0.0000  10.7354
      4      [36m0.7146[0m        [32m0.6185[0m       [35m0.2849[0m      0.3663        [94m0.6905[0m     +  0.0000  10.7616
      5      [36m0.7685[0m        [32m0.6058[0m       [35m0.2988[0m      0.3867        [94m0.6894[0m     +  0.0000  10.4671
      6      [36m0.8690[0m        [32m0.5623[0m       [35m0.3146[0m      0.3911        [94m0.6892[0m     +  0.0000  10.7311
      7      0.7024        0.5662       0.3095      0.3967        0.6905        0.0000  10.6059
      8      [36m0.9153[0m        0.5654       [35m0.3160[0m      0.3987        [94m0.6871[0m     +  0.0000  10.8303
      9      0.8519        [32m0.5385[0m       [35m0.3201[0m      0.4022        0.6875        0.0000  10.6920
     10      0.7500        0.5809       0.2981      0.3964        0.6919        0.0000  10.7390
     11      0.8056        [32m0.5338[0m       0.2977      0.3974        0.6923        0.0000  10.7377
     12      0.9153        0.5491       0.3028      0.3984        0.6925        0.0000  10.6094
     13      0.8889        [32m0.5282[0m       0.3064      0.3979        0.6915        0.0000  10.7161
     14      0.8333        0.5388       0.3099      0.3976        0.6910        0.0000  10.9408
     15      0.8413        0.5354       0.3071      0.3975        0.6921        0.0000  10.5158
     16      [36m0.9630[0m        [32m0.5129[0m       0.3071      0.3974        0.6922        0.0000  10.9383
     17      0.8571        0.5212       0.3083      0.3974        0.6920        0.0000  10.7990
     18      0.9524        0.5348       0.3036      0.3958        0.6930        0.0000  10.8146
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4454
Pre F1 macro score = 0.4359
Pre Accuracy = 0.3345

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6545[0m        [32m0.6128[0m       [35m0.2543[0m      [31m0.2480[0m        [94m0.6633[0m     +  0.0000  10.6716
      2      [36m0.7989[0m        [32m0.5528[0m       [35m0.3115[0m      0.2021        [94m0.6608[0m     +  0.0000  10.8492
      3      0.5984        [32m0.5072[0m       [35m0.3307[0m      [31m0.5266[0m        [94m0.6495[0m     +  0.0000  10.9863
      4      0.6065        [32m0.4801[0m       0.3003      0.2270        0.6671        0.0000  11.0141
      5      0.6720        [32m0.4443[0m       0.3161      0.2067        0.6605        0.0000  10.9512
      6      0.5379        0.4521       0.3141      0.2166        0.6646        0.0000  10.9302
      7      0.6790        0.4476       0.3144      0.2167        0.6633        0.0000  10.7859
      8      0.6218        [32m0.4181[0m       0.3094      0.2252        0.6614        0.0000  10.7019
      9      0.7556        0.4198       0.3092      0.2280        0.6624        0.0000  10.7512
     10      0.7238        0.4328       0.3104      0.2317        0.6643        0.0000  10.6406
     11      0.7714        [32m0.4009[0m       0.3101      0.2320        0.6635        0.0000  10.5468
     12      0.6481        0.4226       0.3116      0.2376        0.6633        0.0000  10.8281
     13      0.6481        0.4313       0.3115      0.2403        0.6643        0.0000  10.9896
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.39919799498746866
F1 Macro Score after query 1: 0.27432384391767456
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6650[0m        [32m0.4664[0m       [35m0.1870[0m      [31m0.3537[0m        [94m0.7078[0m     +  0.0000  10.9221
      2      0.5836        [32m0.4497[0m       [35m0.2776[0m      [31m0.6767[0m        [94m0.6897[0m     +  0.0000  10.8412
      3      0.6190        [32m0.4133[0m       [35m0.2842[0m      0.3559        [94m0.6802[0m     +  0.0000  10.8570
      4      [36m0.6873[0m        [32m0.3903[0m       [35m0.2965[0m      0.6684        [94m0.6659[0m     +  0.0000  11.1092
      5      [36m0.7513[0m        [32m0.3689[0m       [35m0.3007[0m      0.3673        [94m0.6640[0m     +  0.0000  10.7187
      6      [36m0.7686[0m        [32m0.3597[0m       [35m0.3026[0m      0.3791        [94m0.6603[0m     +  0.0000  10.9279
      7      [36m0.7936[0m        [32m0.3405[0m       [35m0.3045[0m      0.4022        [94m0.6574[0m     +  0.0000  10.7745
      8      [36m0.8468[0m        [32m0.3258[0m       0.3038      0.4128        [94m0.6558[0m     +  0.0000  10.9671
      9      0.7665        0.3358       [35m0.3050[0m      0.4330        [94m0.6553[0m     +  0.0000  11.0604
     10      0.8111        [32m0.3086[0m       0.3024      0.4387        [94m0.6543[0m     +  0.0000  10.8475
     11      0.8380        [32m0.3059[0m       0.3023      0.4517        [94m0.6540[0m     +  0.0000  10.8787
     12      [36m0.8477[0m        0.3134       0.3028      0.4521        0.6542        0.0000  11.1612
     13      0.8333        [32m0.2999[0m       0.3014      0.4581        0.6540        0.0000  11.0935
     14      [36m0.8908[0m        [32m0.2987[0m       0.3002      0.4635        [94m0.6537[0m     +  0.0000  11.0157
     15      [36m0.9310[0m        [32m0.2956[0m       0.2981      0.4648        [94m0.6532[0m     +  0.0000  10.9989
     16      0.7984        [32m0.2898[0m       0.3005      0.4645        [94m0.6529[0m     +  0.0000  10.8881
     17      0.8485        0.2918       0.2970      0.4655        0.6529        0.0000  10.7832
     18      0.8694        [32m0.2875[0m       0.2969      0.4655        [94m0.6527[0m     +  0.0000  10.7764
     19      0.8581        0.3005       0.2962      0.4672        [94m0.6524[0m     +  0.0000  11.0431
     20      0.8639        [32m0.2838[0m       0.2948      0.4686        0.6525        0.0000  10.7814
     21      0.8856        0.2916       0.2948      0.4683        0.6524        0.0000  10.7344
     22      0.9144        0.2865       0.2946      0.4690        0.6525        0.0000  10.7831
     23      0.8908        0.2977       0.2936      0.4689        0.6524        0.0000  11.2210
     24      0.9203        [32m0.2785[0m       0.2929      0.4695        0.6524        0.0000  11.0407
     25      0.8850        0.2939       0.2927      0.4693        [94m0.6523[0m     +  0.0000  10.9425
     26      0.8876        0.2896       0.2929      0.4692        0.6523        0.0000  11.0310
     27      0.8639        0.2853       0.2931      0.4695        0.6523        0.0000  11.1001
     28      [36m0.9363[0m        0.2961       0.2924      0.4693        0.6523        0.0000  10.7548
     29      0.9037        0.2885       0.2924      0.4693        0.6523        0.0000  10.9051
     30      0.8458        0.3008       0.2924      0.4695        [94m0.6523[0m     +  0.0000  10.9260
     31      0.9148        0.2901       0.2924      0.4695        [94m0.6522[0m     +  0.0000  10.7040
     32      0.8694        0.2893       0.2922      0.4694        [94m0.6522[0m     +  0.0000  10.7465
     33      0.8805        0.3052       0.2918      0.4695        [94m0.6522[0m     +  0.0000  10.7811
     34      0.9090        0.2844       0.2920      0.4695        0.6523        0.0000  10.9406
     35      0.8986        0.2927       0.2920      0.4695        0.6523        0.0000  10.9819
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.5274508189974484
F1 Macro Score after query 2: 0.47435930870009946
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6307[0m        [32m0.4436[0m       [35m0.4562[0m      [31m0.0556[0m        [94m0.6634[0m     +  0.0000  11.1187
      2      [36m0.6489[0m        [32m0.3865[0m       [35m0.4630[0m      [31m0.1384[0m        [94m0.6447[0m     +  0.0000  11.2783
      3      [36m0.8077[0m        [32m0.3395[0m       0.4500      [31m0.3497[0m        [94m0.6280[0m     +  0.0000  11.2280
      4      [36m0.9067[0m        [32m0.2858[0m       0.3927      [31m0.4187[0m        [94m0.6173[0m     +  0.0000  11.0311
      5      [36m0.9277[0m        [32m0.2558[0m       0.3717      [31m0.4321[0m        [94m0.6101[0m     +  0.0000  11.1311
      6      [36m0.9496[0m        [32m0.2430[0m       0.3599      [31m0.4532[0m        [94m0.6074[0m     +  0.0000  11.1745
      7      0.9475        0.2451       0.3634      [31m0.4534[0m        [94m0.6067[0m     +  0.0000  11.6447
      8      [36m0.9565[0m        [32m0.2362[0m       0.3592      [31m0.4595[0m        [94m0.6048[0m     +  0.0000  11.6321
      9      [36m0.9635[0m        [32m0.2343[0m       0.3606      [31m0.4621[0m        [94m0.6033[0m     +  0.0000  11.7293
     10      0.9325        0.2393       0.3512      [31m0.4711[0m        [94m0.6023[0m     +  0.0000  11.8206
     11      0.9451        [32m0.2311[0m       0.3563      0.4644        [94m0.6017[0m     +  0.0000  11.2272
     12      0.9527        [32m0.2244[0m       0.3554      0.4685        [94m0.6012[0m     +  0.0000  11.5548
     13      0.9521        [32m0.2178[0m       0.3557      0.4693        [94m0.6006[0m     +  0.0000  11.2258
     14      0.9610        0.2181       0.3512      [31m0.4741[0m        [94m0.5998[0m     +  0.0000  11.3819
     15      0.9635        0.2180       0.3530      0.4694        [94m0.5994[0m     +  0.0000  11.1642
     16      0.9475        0.2210       0.3554      0.4718        0.5996        0.0000  11.5873
     17      0.9635        0.2231       0.3564      0.4712        0.5997        0.0000  11.1666
     18      0.9496        0.2240       0.3545      0.4710        0.5997        0.0000  11.1027
     19      [36m0.9678[0m        [32m0.2144[0m       0.3543      0.4739        0.5995        0.0000  11.5711
     20      0.9610        [32m0.2141[0m       0.3530      0.4735        [94m0.5994[0m     +  0.0000  11.2913
     21      0.9608        0.2261       0.3535      [31m0.4746[0m        [94m0.5993[0m     +  0.0000  11.5074
     22      0.9610        [32m0.2133[0m       0.3526      [31m0.4761[0m        [94m0.5992[0m     +  0.0000  11.2104
     23      0.9589        0.2180       0.3542      [31m0.4762[0m        [94m0.5992[0m     +  0.0000  11.3657
     24      0.9678        0.2149       0.3538      [31m0.4771[0m        [94m0.5990[0m     +  0.0000  11.3362
     25      0.9678        [32m0.2059[0m       0.3530      0.4769        0.5990        0.0000  11.1025
     26      0.9408        0.2219       0.3526      0.4767        [94m0.5990[0m     +  0.0000  10.7256
     27      0.9592        0.2129       0.3528      0.4765        0.5990        0.0000  11.3355
     28      0.9678        0.2152       0.3528      0.4769        [94m0.5990[0m     +  0.0000  11.1809
     29      0.9521        0.2279       0.3533      0.4770        [94m0.5989[0m     +  0.0000  11.1471
     30      0.9565        0.2230       0.3535      0.4770        0.5989        0.0000  11.5701
     31      0.9678        0.2207       0.3538      0.4770        [94m0.5989[0m     +  0.0000  11.6949
     32      0.9477        0.2138       0.3535      [31m0.4773[0m        [94m0.5989[0m     +  0.0000  11.4618
     33      0.9635        0.2115       0.3538      0.4772        [94m0.5989[0m     +  0.0000  11.3527
     34      0.9678        0.2164       0.3542      [31m0.4774[0m        [94m0.5989[0m     +  0.0000  11.2729
     35      0.9632        0.2127       0.3533      [31m0.4776[0m        [94m0.5989[0m     +  0.0000  11.0862
     36      0.9678        0.2178       0.3535      [31m0.4780[0m        [94m0.5989[0m     +  0.0000  11.1801
     37      0.9635        0.2223       0.3533      0.4776        0.5989        0.0000  11.2734
     38      0.9678        0.2186       0.3535      0.4775        0.5989        0.0000  11.1035
     39      0.9678        0.2169       0.3535      0.4774        [94m0.5989[0m     +  0.0000  11.0544
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.5595586967764179
F1 Macro Score after query 3: 0.4851115901846508
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8801[0m        [32m0.2899[0m       [35m0.2578[0m      [31m0.5494[0m        [94m0.5960[0m     +  0.0000  11.7101
      2      [36m0.9527[0m        [32m0.2255[0m       [35m0.2740[0m      [31m0.5597[0m        [94m0.5866[0m     +  0.0000  11.4310
      3      [36m0.9690[0m        [32m0.2117[0m       [35m0.2811[0m      [31m0.5651[0m        [94m0.5825[0m     +  0.0000  11.6122
      4      [36m0.9727[0m        [32m0.2017[0m       [35m0.2925[0m      [31m0.5771[0m        [94m0.5763[0m     +  0.0000  11.5240
      5      0.9714        [32m0.1949[0m       [35m0.3043[0m      [31m0.5870[0m        [94m0.5736[0m     +  0.0000  12.0090
      6      [36m0.9820[0m        0.1953       0.3010      0.5643        [94m0.5647[0m     +  0.0000  11.2414
      7      0.9758        [32m0.1911[0m       [35m0.3125[0m      0.5678        [94m0.5634[0m     +  0.0000  11.9003
      8      0.9790        [32m0.1866[0m       [35m0.3160[0m      0.5788        [94m0.5619[0m     +  0.0000  11.6632
      9      [36m0.9849[0m        [32m0.1820[0m       0.3122      0.5660        [94m0.5618[0m     +  0.0000  12.0053
     10      0.9818        0.1880       [35m0.3191[0m      0.5792        [94m0.5602[0m     +  0.0000  11.3365
     11      0.9820        [32m0.1793[0m       [35m0.3253[0m      0.5612        [94m0.5584[0m     +  0.0000  12.1343
     12      0.9820        [32m0.1776[0m       [35m0.3262[0m      0.5606        0.5585        0.0000  11.6014
     13      0.9820        0.1788       [35m0.3269[0m      0.5600        [94m0.5579[0m     +  0.0000  11.5548
     14      0.9820        [32m0.1718[0m       [35m0.3330[0m      0.5676        0.5580        0.0000  11.7117
     15      [36m0.9879[0m        0.1733       0.3311      0.5692        [94m0.5578[0m     +  0.0000  11.8833
     16      0.9820        0.1744       [35m0.3347[0m      0.5581        [94m0.5574[0m     +  0.0000  11.5547
     17      0.9792        [32m0.1717[0m       [35m0.3378[0m      0.5547        [94m0.5573[0m     +  0.0000  11.3050
     18      0.9849        [32m0.1685[0m       [35m0.3384[0m      0.5585        [94m0.5571[0m     +  0.0000  11.4793
     19      0.9849        0.1727       0.3377      0.5592        [94m0.5571[0m     +  0.0000  11.5249
     20      0.9879        0.1762       0.3368      0.5596        [94m0.5567[0m     +  0.0000  11.2885
     21      0.9879        0.1731       [35m0.3389[0m      0.5582        0.5568        0.0000  11.5236
     22      0.9820        0.1760       [35m0.3391[0m      0.5586        0.5568        0.0000  11.3347
     23      0.9820        0.1722       [35m0.3406[0m      0.5575        0.5567        0.0000  11.3352
     24      0.9879        0.1714       0.3394      0.5587        [94m0.5566[0m     +  0.0000  11.6178
     25      0.9849        0.1749       0.3394      0.5592        [94m0.5566[0m     +  0.0000  11.6342
     26      0.9849        0.1714       0.3403      0.5594        [94m0.5565[0m     +  0.0000  11.6183
     27      0.9849        0.1694       0.3405      0.5591        0.5566        0.0000  11.8834
     28      0.9879        [32m0.1668[0m       [35m0.3410[0m      0.5603        0.5566        0.0000  11.8680
     29      0.9849        0.1743       [35m0.3413[0m      0.5589        0.5566        0.0000  11.4762
     30      0.9879        0.1706       0.3405      0.5587        0.5566        0.0000  11.6798
     31      0.9849        0.1716       0.3403      0.5587        0.5566        0.0000  11.7918
     32      0.9849        0.1685       0.3405      0.5585        0.5566        0.0000  11.6328
     33      0.9849        0.1685       0.3406      0.5583        0.5567        0.0000  11.8351
     34      0.9849        0.1714       0.3405      0.5574        0.5567        0.0000  11.3501
     35      0.9879        0.1716       0.3408      0.5576        0.5567        0.0000  11.6491
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.610484193677471
F1 Macro Score after query 4: 0.565032340296494
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9338[0m        [32m0.2427[0m       [35m0.3387[0m      [31m0.6181[0m        [94m0.5593[0m     +  0.0000  12.3677
      2      [36m0.9687[0m        [32m0.2075[0m       [35m0.3556[0m      [31m0.6350[0m        [94m0.5370[0m     +  0.0000  12.6654
      3      [36m0.9706[0m        [32m0.1949[0m       0.3474      [31m0.6367[0m        [94m0.5303[0m     +  0.0000  12.3204
      4      [36m0.9728[0m        [32m0.1931[0m       [35m0.3682[0m      [31m0.6535[0m        [94m0.5191[0m     +  0.0000  12.4612
      5      [36m0.9775[0m        [32m0.1846[0m       0.3627      0.6510        0.5220        0.0000  12.1796
      6      0.9774        [32m0.1773[0m       [35m0.3750[0m      [31m0.6601[0m        [94m0.5151[0m     +  0.0000  12.1019
      7      [36m0.9785[0m        [32m0.1762[0m       [35m0.3809[0m      [31m0.6643[0m        [94m0.5132[0m     +  0.0000  12.5380
      8      0.9746        0.1768       0.3778      0.6632        [94m0.5131[0m     +  0.0000  12.1041
      9      [36m0.9833[0m        [32m0.1710[0m       0.3807      0.6641        [94m0.5119[0m     +  0.0000  12.0551
     10      0.9787        [32m0.1664[0m       0.3785      0.6641        0.5127        0.0000  12.1573
     11      0.9810        [32m0.1654[0m       [35m0.3875[0m      [31m0.6692[0m        [94m0.5098[0m     +  0.0000  12.5249
     12      [36m0.9844[0m        0.1676       [35m0.3891[0m      [31m0.6707[0m        [94m0.5082[0m     +  0.0000  12.5721
     13      [36m0.9869[0m        [32m0.1598[0m       0.3875      0.6700        0.5089        0.0000  12.3987
     14      0.9869        0.1627       0.3877      [31m0.6713[0m        [94m0.5076[0m     +  0.0000  12.0875
     15      0.9856        0.1644       0.3889      [31m0.6724[0m        0.5080        0.0000  12.3982
     16      0.9843        0.1600       [35m0.3905[0m      [31m0.6733[0m        [94m0.5063[0m     +  0.0000  12.3834
     17      0.9869        [32m0.1589[0m       [35m0.3936[0m      [31m0.6754[0m        [94m0.5055[0m     +  0.0000  12.3688
     18      0.9831        0.1606       0.3917      0.6742        0.5055        0.0000  12.1188
     19      0.9869        0.1597       [35m0.3943[0m      0.6753        [94m0.5052[0m     +  0.0000  12.3851
     20      [36m0.9905[0m        0.1619       0.3929      0.6747        0.5052        0.0000  12.2858
     21      0.9881        [32m0.1569[0m       0.3934      0.6747        [94m0.5051[0m     +  0.0000  12.3839
     22      0.9822        0.1599       0.3941      [31m0.6755[0m        [94m0.5045[0m     +  0.0000  12.5245
     23      0.9869        0.1630       0.3941      0.6749        [94m0.5043[0m     +  0.0000  12.3207
     24      0.9850        0.1597       [35m0.3944[0m      0.6753        [94m0.5042[0m     +  0.0000  12.2582
     25      0.9881        [32m0.1561[0m       [35m0.3948[0m      0.6753        [94m0.5042[0m     +  0.0000  11.8355
     26      0.9870        0.1570       [35m0.3953[0m      0.6754        [94m0.5039[0m     +  0.0000  12.6019
     27      0.9868        0.1614       [35m0.3957[0m      [31m0.6757[0m        [94m0.5038[0m     +  0.0000  12.1507
     28      0.9885        0.1567       0.3953      0.6754        [94m0.5038[0m     +  0.0000  12.2747
     29      0.9893        0.1592       0.3957      [31m0.6757[0m        [94m0.5037[0m     +  0.0000  12.1334
     30      0.9881        0.1581       0.3957      0.6756        [94m0.5036[0m     +  0.0000  12.1956
     31      0.9856        0.1628       0.3957      0.6756        0.5037        0.0000  12.1504
     32      0.9884        0.1580       0.3957      0.6757        0.5037        0.0000  12.4151
     33      0.9846        0.1577       0.3957      0.6754        [94m0.5036[0m     +  0.0000  12.4005
     34      [36m0.9906[0m        0.1567       [35m0.3958[0m      [31m0.6760[0m        [94m0.5036[0m     +  0.0000  12.3194
     35      0.9872        0.1572       0.3955      0.6754        0.5037        0.0000  12.1788
     36      0.9894        [32m0.1533[0m       0.3957      0.6754        0.5036        0.0000  12.6816
     37      0.9857        0.1592       0.3957      0.6754        0.5037        0.0000  12.4614
     38      0.9894        0.1595       0.3958      0.6754        0.5037        0.0000  12.0561
     39      0.9856        0.1582       0.3958      0.6755        0.5036        0.0000  12.2736
     40      0.9868        0.1558       0.3958      0.6756        0.5036        0.0000  12.2737
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.6837977874247305
F1 Macro Score after query 5: 0.6877316976698468
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9711[0m        [32m0.2039[0m       [35m0.3972[0m      [31m0.7229[0m        [94m0.4796[0m     +  0.0000  13.3526
      2      [36m0.9818[0m        [32m0.1785[0m       [35m0.4085[0m      0.7214        [94m0.4737[0m     +  0.0000  13.4313
      3      [36m0.9849[0m        [32m0.1671[0m       0.4061      0.7190        [94m0.4727[0m     +  0.0000  13.8362
      4      [36m0.9872[0m        [32m0.1605[0m       [35m0.4219[0m      0.7224        0.4830        0.0000  13.2741
      5      0.9860        0.1606       0.4175      0.7185        0.4761        0.0000  13.5737
      6      [36m0.9889[0m        [32m0.1480[0m       0.4141      0.7169        0.4753        0.0000  13.4787
      7      [36m0.9900[0m        0.1499       [35m0.4224[0m      0.7209        0.4743        0.0000  13.8224
      8      0.9889        [32m0.1466[0m       0.4182      0.7195        0.4750        0.0000  13.5252
      9      0.9896        [32m0.1447[0m       0.4193      0.7183        0.4763        0.0000  13.4605
     10      0.9897        [32m0.1435[0m       0.4156      0.7158        0.4795        0.0000  13.1490
     11      [36m0.9914[0m        [32m0.1401[0m       0.4210      0.7178        0.4769        0.0000  13.3680
     12      [36m0.9919[0m        0.1406       0.4167      0.7166        0.4772        0.0000  13.4099
     13      0.9914        0.1404       0.4189      0.7168        0.4765        0.0000  13.8787
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.7415105580194612
F1 Macro Score after query 6: 0.7613786812467103
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9793[0m        [32m0.1808[0m       [35m0.3384[0m      [31m0.7066[0m        [94m0.5107[0m     +  0.0000  15.7121
      2      [36m0.9859[0m        [32m0.1647[0m       0.3271      0.7032        0.5200        0.0000  16.0113
      3      [36m0.9866[0m        [32m0.1557[0m       0.3196      0.6996        0.5310        0.0000  15.6056
      4      0.9865        [32m0.1473[0m       0.3215      0.7007        0.5327        0.0000  15.5747
      5      [36m0.9886[0m        [32m0.1422[0m       0.3179      0.6945        0.5342        0.0000  15.5105
      6      [36m0.9910[0m        [32m0.1345[0m       0.3182      0.6958        0.5416        0.0000  16.0095
      7      [36m0.9915[0m        [32m0.1327[0m       0.3174      0.6938        0.5410        0.0000  15.7305
      8      0.9914        [32m0.1279[0m       0.3168      0.6946        0.5446        0.0000  15.5887
      9      [36m0.9920[0m        [32m0.1267[0m       0.3163      0.6943        0.5443        0.0000  15.7605
     10      [36m0.9926[0m        [32m0.1252[0m       0.3161      0.6938        0.5504        0.0000  15.7289
     11      [36m0.9938[0m        [32m0.1215[0m       0.3207      0.6957        0.5413        0.0000  15.6979
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.7263934228025631
F1 Macro Score after query 7: 0.7473924706307331
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9758[0m        [32m0.1868[0m       [35m0.3389[0m      [31m0.7166[0m        [94m0.5038[0m     +  0.0000  19.3712
      2      [36m0.9815[0m        [32m0.1669[0m       0.3280      0.7054        0.5289        0.0000  19.4226
      3      [36m0.9832[0m        [32m0.1543[0m       0.3210      0.6996        0.5434        0.0000  19.3163
      4      [36m0.9838[0m        [32m0.1451[0m       0.3163      0.6913        0.5629        0.0000  19.2672
      5      [36m0.9861[0m        [32m0.1365[0m       0.3203      0.6919        0.5667        0.0000  19.2030
      6      [36m0.9869[0m        [32m0.1288[0m       0.3314      0.7016        0.5452        0.0000  19.5823
      7      [36m0.9878[0m        [32m0.1240[0m       0.3240      0.6954        0.5531        0.0000  19.4625
      8      0.9875        [32m0.1212[0m       0.3260      0.6957        0.5579        0.0000  19.6095
      9      [36m0.9893[0m        [32m0.1185[0m       0.3240      0.6939        0.5597        0.0000  19.5066
     10      [36m0.9901[0m        [32m0.1151[0m       0.3278      0.6950        0.5627        0.0000  19.7407
     11      [36m0.9906[0m        [32m0.1120[0m       0.3285      0.6984        0.5602        0.0000  19.5091
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.6928911624625155
F1 Macro Score after query 8: 0.7116072214338064
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9783[0m        [32m0.1714[0m       [35m0.3134[0m      [31m0.7109[0m        [94m0.5664[0m     +  0.0000  26.3071
      2      [36m0.9803[0m        [32m0.1531[0m       [35m0.3161[0m      [31m0.7173[0m        [94m0.5643[0m     +  0.0000  26.0470
      3      [36m0.9828[0m        [32m0.1384[0m       [35m0.3293[0m      [31m0.7213[0m        [94m0.5611[0m     +  0.0000  26.1554
      4      [36m0.9847[0m        [32m0.1270[0m       [35m0.3307[0m      [31m0.7277[0m        0.5617        0.0000  26.4069
      5      [36m0.9864[0m        [32m0.1165[0m       0.3156      0.7193        0.5951        0.0000  26.4234
      6      [36m0.9892[0m        [32m0.1050[0m       0.3207      0.7172        0.5838        0.0000  26.5219
      7      [36m0.9896[0m        [32m0.1021[0m       0.3224      0.7163        0.5848        0.0000  26.6088
      8      [36m0.9907[0m        [32m0.0961[0m       0.3234      0.7169        0.5869        0.0000  26.3852
      9      [36m0.9911[0m        [32m0.0940[0m       0.3198      0.7145        0.5942        0.0000  26.3620
     10      [36m0.9917[0m        [32m0.0909[0m       0.3120      0.7096        0.6102        0.0000  26.3377
     11      [36m0.9926[0m        [32m0.0867[0m       0.3179      0.7094        0.6032        0.0000  26.2902
     12      [36m0.9929[0m        [32m0.0842[0m       0.3215      0.7108        0.5967        0.0000  26.2550
     13      [36m0.9931[0m        [32m0.0819[0m       0.3205      0.7105        0.6002        0.0000  26.1493
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.7024272956262881
F1 Macro Score after query 9: 0.7250179120820152
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9808[0m        [32m0.1387[0m       [35m0.2582[0m      [31m0.6997[0m        [94m0.6531[0m     +  0.0000  38.8763
      2      [36m0.9843[0m        [32m0.1192[0m       [35m0.3021[0m      [31m0.7306[0m        [94m0.5626[0m     +  0.0000  38.4928
      3      [36m0.9871[0m        [32m0.1039[0m       [35m0.3418[0m      [31m0.7562[0m        [94m0.5254[0m     +  0.0000  38.2966
      4      [36m0.9881[0m        [32m0.0933[0m       0.3337      0.7504        0.5462        0.0000  38.2912
      5      [36m0.9892[0m        [32m0.0848[0m       0.3241      0.7373        0.5723        0.0000  38.5451
      6      [36m0.9910[0m        [32m0.0734[0m       0.3363      0.7434        0.5453        0.0000  38.4291
      7      [36m0.9918[0m        [32m0.0697[0m       [35m0.3530[0m      [31m0.7566[0m        [94m0.5152[0m     +  0.0000  38.6144
      8      [36m0.9925[0m        [32m0.0663[0m       0.3396      0.7474        0.5459        0.0000  38.4163
      9      [36m0.9929[0m        [32m0.0629[0m       0.3443      0.7479        0.5378        0.0000  38.4585
     10      [36m0.9938[0m        [32m0.0590[0m       0.3339      0.7431        0.5658        0.0000  38.4461
     11      [36m0.9943[0m        [32m0.0555[0m       0.3337      0.7407        0.5630        0.0000  38.7028
     12      [36m0.9947[0m        [32m0.0536[0m       0.3340      0.7405        0.5657        0.0000  38.8584
     13      [36m0.9953[0m        [32m0.0518[0m       0.3332      0.7398        0.5743        0.0000  38.1785
     14      [36m0.9955[0m        [32m0.0505[0m       0.3307      0.7370        0.5815        0.0000  38.5709
     15      [36m0.9958[0m        [32m0.0488[0m       0.3295      0.7336        0.5947        0.0000  38.6530
     16      [36m0.9959[0m        [32m0.0469[0m       0.3167      0.7219        0.6260        0.0000  38.6317
     17      [36m0.9962[0m        0.0472       0.3205      0.7237        0.6192        0.0000  38.6648
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.7187572996963326
F1 Macro Score after query 10: 0.7428699056425776
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9775[0m        [32m0.1157[0m       [35m0.7378[0m      [31m0.8493[0m        [94m0.2711[0m     +  0.0000  60.3379
      2      [36m0.9843[0m        [32m0.0876[0m       [35m0.7538[0m      [31m0.8645[0m        [94m0.2561[0m     +  0.0000  61.0621
      3      [36m0.9865[0m        [32m0.0757[0m       0.7493      0.8615        [94m0.2553[0m     +  0.0000  60.4065
      4      [36m0.9875[0m        [32m0.0679[0m       0.7427      0.8600        0.2618        0.0000  59.9046
      5      [36m0.9884[0m        [32m0.0619[0m       0.7335      0.8559        0.2581        0.0000  60.7300
      6      [36m0.9911[0m        [32m0.0517[0m       0.7196      0.8544        0.2722        0.0000  60.4003
      7      [36m0.9924[0m        [32m0.0476[0m       0.7021      0.8481        0.2921        0.0000  60.5546
      8      [36m0.9928[0m        [32m0.0445[0m       0.7059      0.8491        0.2814        0.0000  60.4307
      9      [36m0.9938[0m        [32m0.0415[0m       0.6760      0.8385        0.3181        0.0000  61.0603
     10      [36m0.9946[0m        [32m0.0379[0m       0.7073      0.8471        0.2947        0.0000  60.5901
     11      [36m0.9955[0m        [32m0.0348[0m       0.7043      0.8448        0.2925        0.0000  61.2986
     12      [36m0.9962[0m        [32m0.0331[0m       0.7087      0.8465        0.2917        0.0000  60.4457
     13      [36m0.9965[0m        [32m0.0314[0m       0.7009      0.8437        0.3052        0.0000  61.3527
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8757448686824101
F1 Macro Score after query 11: 0.8739273516238434
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9758[0m        [32m0.0848[0m       [35m0.8102[0m      [31m0.8828[0m        [94m0.2102[0m     +  0.0000  99.1832
      2      [36m0.9812[0m        [32m0.0644[0m       [35m0.8130[0m      [31m0.8861[0m        [94m0.2038[0m     +  0.0000  99.9250
      3      [36m0.9840[0m        [32m0.0528[0m       0.8007      0.8801        0.2127        0.0000  98.9095
      4      [36m0.9860[0m        [32m0.0457[0m       [35m0.8177[0m      0.8833        [94m0.1973[0m     +  0.0000  99.6785
      5      [36m0.9873[0m        [32m0.0401[0m       0.8085      [31m0.8882[0m        0.2298        0.0000  99.8794
      6      [36m0.9897[0m        [32m0.0332[0m       0.8000      0.8785        0.2359        0.0000  100.5854
      7      [36m0.9915[0m        [32m0.0292[0m       0.8017      0.8803        0.2506        0.0000  99.7602
      8      [36m0.9927[0m        [32m0.0264[0m       0.7937      0.8751        0.2612        0.0000  100.1889
      9      [36m0.9936[0m        [32m0.0242[0m       0.7934      0.8766        0.2757        0.0000  100.1007
     10      [36m0.9941[0m        [32m0.0227[0m       0.8000      0.8762        0.2672        0.0000  100.0519
     11      [36m0.9953[0m        [32m0.0198[0m       0.7972      0.8698        0.2718        0.0000  99.8644
     12      [36m0.9963[0m        [32m0.0183[0m       0.7937      0.8697        0.2843        0.0000  99.5492
     13      [36m0.9967[0m        [32m0.0172[0m       0.7927      0.8683        0.2901        0.0000  100.1290
     14      [36m0.9973[0m        [32m0.0161[0m       0.7946      0.8696        0.2935        0.0000  97.9424
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.9157543287522323
F1 Macro Score after query 12: 0.9047622325523821
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9862[0m        [32m0.0373[0m       [35m0.7898[0m      [31m0.8555[0m        [94m0.2299[0m     +  0.0000  115.2447
      2      [36m0.9871[0m        [32m0.0333[0m       [35m0.8038[0m      [31m0.8737[0m        [94m0.2185[0m     +  0.0000  116.4281
      3      [36m0.9886[0m        [32m0.0294[0m       [35m0.8059[0m      [31m0.8796[0m        0.2380        0.0000  116.3137
      4      [36m0.9894[0m        [32m0.0265[0m       [35m0.8097[0m      0.8744        0.2431        0.0000  116.0932
      5      [36m0.9901[0m        [32m0.0243[0m       0.8014      0.8741        0.2369        0.0000  116.3601
      6      [36m0.9927[0m        [32m0.0197[0m       0.8005      0.8733        0.2693        0.0000  115.8634
      7      [36m0.9944[0m        [32m0.0166[0m       0.8082      0.8744        0.2681        0.0000  115.9730
      8      [36m0.9954[0m        [32m0.0146[0m       0.8057      0.8759        0.2815        0.0000  116.2941
      9      [36m0.9960[0m        [32m0.0135[0m       0.8064      0.8756        0.2901        0.0000  115.8895
     10      [36m0.9966[0m        [32m0.0119[0m       [35m0.8170[0m      0.8765        0.2770        0.0000  116.6266
     11      [36m0.9969[0m        [32m0.0109[0m       0.8104      0.8733        0.2826        0.0000  116.6987
     12      [36m0.9979[0m        [32m0.0094[0m       0.8085      0.8732        0.2910        0.0000  115.7548
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.9220344263571929
F1 Macro Score after query 13: 0.9094318571136544
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/max_score_seed45_lowLR\AL_max_score_results_for_multilabel_classification_s45.pickle
