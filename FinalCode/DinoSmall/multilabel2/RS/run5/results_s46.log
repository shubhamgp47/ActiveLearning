Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)

Iteration 1: Using initial samples.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5556[0m        [32m0.6869[0m       [35m0.1859[0m      [31m0.5403[0m        [94m0.6979[0m     +  0.0000  12.5189
      2      [36m0.6833[0m        [32m0.6858[0m       0.1476      0.4470        [94m0.6882[0m     +  0.0000  10.5938
      3      0.6722        [32m0.6446[0m       [35m0.1981[0m      0.4584        0.6915        0.0000  10.7380
      4      [36m0.8350[0m        [32m0.6036[0m       [35m0.2899[0m      0.4102        [94m0.6826[0m     +  0.0000  10.6277
      5      0.7222        0.6210       0.2344      0.4254        0.6899        0.0000  10.7178
      6      0.8350        [32m0.5965[0m       0.2651      0.4395        0.6858        0.0000  10.6453
      7      0.8148        [32m0.5547[0m       0.2773      0.4432        0.6834        0.0000  10.7246
      8      0.7593        [32m0.5228[0m       0.2642      0.4369        0.6838        0.0000  10.7340
      9      [36m0.9630[0m        0.5230       0.2616      0.4589        0.6835        0.0000  10.7213
     10      0.9259        [32m0.4998[0m       0.2655      0.4598        [94m0.6817[0m     +  0.0000  10.8560
     11      0.8426        0.5413       0.2724      0.4593        [94m0.6814[0m     +  0.0000  10.7343
     12      0.9153        0.5251       0.2658      0.4609        0.6814        0.0000  10.9373
     13      0.9153        0.5339       0.2634      0.4553        0.6827        0.0000  10.9688
     14      0.9259        0.5187       0.2644      0.4610        0.6825        0.0000  10.8569
     15      0.9630        [32m0.4953[0m       0.2726      0.4624        0.6815        0.0000  10.9505
     16      0.9333        [32m0.4932[0m       0.2736      0.4620        [94m0.6811[0m     +  0.0000  10.8754
     17      0.9630        [32m0.4929[0m       0.2734      0.4633        0.6813        0.0000  10.8141
     18      0.8487        0.5119       0.2719      0.4635        0.6816        0.0000  10.7870
     19      0.9630        0.4939       0.2708      0.4634        0.6817        0.0000  10.8173
     20      0.9630        [32m0.4892[0m       0.2694      0.4647        0.6819        0.0000  10.7034
     21      0.9167        0.5014       0.2681      0.4648        0.6820        0.0000  10.7209
     22      0.9630        [32m0.4857[0m       0.2677      0.4650        0.6819        0.0000  10.8287
     23      0.9259        0.4931       0.2681      0.4656        0.6819        0.0000  10.9444
     24      0.9630        0.5094       0.2682      0.4662        0.6819        0.0000  10.8588
     25      0.9630        0.4895       0.2684      0.4665        0.6819        0.0000  10.7598
     26      0.9259        [32m0.4809[0m       0.2684      0.4665        0.6819        0.0000  10.7332
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 1: Test F1 Micro Score: 0.5200477960701009
Iteration 1: Test F1 Macro Score: 0.5084738365022237
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_0.pt

Iteration 2: Requesting 16 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6746[0m        [32m0.5701[0m       [35m0.3464[0m      [31m0.2234[0m        [94m0.6272[0m     +  0.0000  10.7417
      2      [36m0.8354[0m        [32m0.5629[0m       [35m0.3524[0m      [31m0.2604[0m        [94m0.6251[0m     +  0.0000  10.8615
      3      0.5000        [32m0.5429[0m       0.3460      0.2288        [94m0.6198[0m     +  0.0000  10.7144
      4      0.4917        [32m0.5076[0m       0.3460      0.2208        [94m0.6175[0m     +  0.0000  10.8256
      5      0.4990        0.5180       0.3472      [31m0.3095[0m        [94m0.6028[0m     +  0.0000  10.8039
      6      0.6518        [32m0.4546[0m       0.3309      [31m0.3252[0m        [94m0.6005[0m     +  0.0000  10.7142
      7      0.6690        0.4546       0.3340      0.3228        [94m0.5975[0m     +  0.0000  10.8207
      8      0.7037        [32m0.4503[0m       0.3316      0.3241        [94m0.5967[0m     +  0.0000  10.8261
      9      0.8072        [32m0.4310[0m       [35m0.3557[0m      0.3174        [94m0.5918[0m     +  0.0000  10.8984
     10      0.7531        0.4386       [35m0.3578[0m      0.3236        [94m0.5896[0m     +  0.0000  10.9371
     11      0.7899        [32m0.4209[0m       [35m0.3618[0m      [31m0.3288[0m        [94m0.5882[0m     +  0.0000  10.7771
     12      0.6867        0.4281       0.3569      [31m0.3361[0m        [94m0.5870[0m     +  0.0000  10.7248
     13      0.7023        [32m0.4148[0m       0.3590      [31m0.3403[0m        [94m0.5855[0m     +  0.0000  10.6638
     14      0.8313        0.4348       [35m0.3663[0m      [31m0.3406[0m        [94m0.5852[0m     +  0.0000  10.8141
     15      [36m0.8737[0m        0.4149       [35m0.3701[0m      [31m0.3453[0m        [94m0.5841[0m     +  0.0000  10.7134
     16      0.7778        [32m0.4099[0m       0.3665      [31m0.3470[0m        [94m0.5836[0m     +  0.0000  10.7808
     17      0.8333        0.4151       0.3665      [31m0.3481[0m        [94m0.5832[0m     +  0.0000  10.7816
     18      [36m0.9003[0m        [32m0.4076[0m       0.3661      [31m0.3498[0m        [94m0.5829[0m     +  0.0000  10.7300
     19      0.7285        0.4157       0.3674      [31m0.3501[0m        [94m0.5824[0m     +  0.0000  10.8127
     20      [36m0.9056[0m        0.4134       0.3682      [31m0.3526[0m        [94m0.5822[0m     +  0.0000  10.7969
     21      0.8056        [32m0.4006[0m       0.3675      [31m0.3537[0m        [94m0.5820[0m     +  0.0000  10.8798
     22      0.8859        0.4104       0.3674      [31m0.3544[0m        [94m0.5819[0m     +  0.0000  10.8504
     23      0.8933        0.4021       0.3672      [31m0.3555[0m        [94m0.5817[0m     +  0.0000  10.0235
     24      0.8333        [32m0.3966[0m       0.3675      0.3553        [94m0.5815[0m     +  0.0000  10.0012
     25      0.7685        0.4057       0.3675      [31m0.3566[0m        [94m0.5813[0m     +  0.0000  9.9791
     26      0.7818        0.4074       0.3679      [31m0.3574[0m        [94m0.5812[0m     +  0.0000  9.9641
     27      0.8374        0.3969       0.3686      0.3569        [94m0.5812[0m     +  0.0000  9.9266
     28      0.7357        0.4186       0.3681      0.3572        [94m0.5811[0m     +  0.0000  9.9330
     29      0.7404        0.4139       0.3684      0.3571        [94m0.5811[0m     +  0.0000  9.9977
     30      0.8084        0.4206       0.3684      [31m0.3580[0m        [94m0.5809[0m     +  0.0000  9.9508
     31      0.6693        0.4320       0.3684      [31m0.3581[0m        [94m0.5809[0m     +  0.0000  9.9271
     32      0.7044        0.4052       0.3686      0.3578        [94m0.5809[0m     +  0.0000  9.9652
     33      0.8188        0.4057       0.3688      0.3580        [94m0.5809[0m     +  0.0000  9.8646
     34      0.8241        0.4093       0.3686      [31m0.3582[0m        [94m0.5808[0m     +  0.0000  9.8806
     35      0.7667        0.4124       0.3686      0.3582        [94m0.5808[0m     +  0.0000  9.9788
     36      0.7880        0.4137       0.3686      0.3582        [94m0.5808[0m     +  0.0000  9.8190
     37      0.7859        0.4057       0.3684      0.3582        [94m0.5808[0m     +  0.0000  9.9534
     38      0.8548        0.3968       0.3684      0.3582        [94m0.5808[0m     +  0.0000  9.8859
     39      0.8548        0.4009       0.3684      0.3582        [94m0.5808[0m     +  0.0000  9.8582
     40      0.7341        0.4050       0.3684      0.3582        [94m0.5808[0m     +  0.0000  9.8855
     41      0.8158        0.4237       0.3684      0.3582        [94m0.5808[0m     +  0.0000  9.8890
     42      0.7120        0.4090       0.3684      0.3582        [94m0.5808[0m     +  0.0000  9.9056
     43      0.8880        0.4002       0.3684      0.3582        [94m0.5808[0m     +  0.0000  10.3180
     44      0.6756        0.4225       0.3684      0.3582        [94m0.5808[0m     +  0.0000  9.9691
     45      0.8489        0.4075       0.3684      0.3582        [94m0.5808[0m     +  0.0000  9.8783
     46      0.8056        0.4019       0.3684      0.3582        [94m0.5808[0m     +  0.0000  9.9219
     47      0.8339        [32m0.3940[0m       0.3684      0.3582        [94m0.5808[0m     +  0.0000  9.8587
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 2: Test F1 Micro Score: 0.4632210607820364
Iteration 2: Test F1 Macro Score: 0.35752940114480575
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_1.pt

Iteration 3: Requesting 32 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6268[0m        [32m0.5320[0m       [35m0.3396[0m      [31m0.6423[0m        [94m0.5487[0m     +  0.0000  10.1905
      2      [36m0.6794[0m        [32m0.4492[0m       [35m0.6450[0m      [31m0.7834[0m        [94m0.4457[0m     +  0.0000  10.1065
      3      [36m0.8510[0m        [32m0.3981[0m       0.6293      0.6772        [94m0.4376[0m     +  0.0000  10.1183
      4      [36m0.8641[0m        [32m0.3708[0m       [35m0.7024[0m      [31m0.8141[0m        [94m0.4025[0m     +  0.0000  10.1152
      5      [36m0.9398[0m        [32m0.3412[0m       [35m0.7142[0m      [31m0.8384[0m        [94m0.3867[0m     +  0.0000  10.1158
      6      0.9329        [32m0.3259[0m       0.7108      0.8373        [94m0.3831[0m     +  0.0000  10.1495
      7      0.9336        0.3321       0.7116      0.8375        [94m0.3799[0m     +  0.0000  10.0625
      8      0.9021        [32m0.3214[0m       0.7116      0.8373        [94m0.3776[0m     +  0.0000  10.0400
      9      0.9366        [32m0.3122[0m       0.7122      0.8376        [94m0.3752[0m     +  0.0000  10.2703
     10      0.9110        0.3331       0.7104      0.8366        [94m0.3730[0m     +  0.0000  10.1198
     11      [36m0.9577[0m        [32m0.2979[0m       [35m0.7168[0m      0.8363        [94m0.3721[0m     +  0.0000  10.0947
     12      0.9158        0.3137       [35m0.7175[0m      0.8367        [94m0.3714[0m     +  0.0000  10.2303
     13      0.9166        0.3225       0.7168      0.8347        [94m0.3707[0m     +  0.0000  10.1600
     14      0.9577        0.3009       [35m0.7179[0m      0.8353        [94m0.3698[0m     +  0.0000  10.0917
     15      0.9373        0.3183       0.7151      0.8330        [94m0.3696[0m     +  0.0000  10.0754
     16      0.9459        [32m0.2952[0m       0.7167      0.8342        [94m0.3693[0m     +  0.0000  10.1760
     17      0.9452        0.2953       0.7142      0.8318        0.3694        0.0000  10.1730
     18      0.9455        0.3017       0.7168      0.8340        [94m0.3689[0m     +  0.0000  10.1700
     19      0.9455        0.2986       0.7165      0.8341        [94m0.3684[0m     +  0.0000  10.1256
     20      0.9566        0.2999       0.7172      0.8349        [94m0.3679[0m     +  0.0000  10.1192
     21      0.9359        0.3078       0.7165      0.8338        0.3680        0.0000  10.1840
     22      0.9577        0.2984       0.7163      0.8334        0.3680        0.0000  10.0089
     23      0.9225        0.3106       0.7163      0.8332        [94m0.3678[0m     +  0.0000  10.0105
     24      0.9355        0.3127       0.7163      0.8334        [94m0.3676[0m     +  0.0000  10.0408
     25      0.9553        0.2969       0.7163      0.8332        [94m0.3676[0m     +  0.0000  10.1567
     26      0.9459        0.2982       0.7163      0.8332        [94m0.3675[0m     +  0.0000  10.2139
     27      0.9577        0.2968       0.7158      0.8330        [94m0.3675[0m     +  0.0000  10.2013
     28      0.9270        0.3051       0.7155      0.8329        [94m0.3675[0m     +  0.0000  10.1808
     29      0.9236        0.3012       0.7156      0.8328        [94m0.3675[0m     +  0.0000  10.2409
     30      0.9323        0.2989       0.7158      0.8327        [94m0.3675[0m     +  0.0000  10.1715
     31      0.9270        0.3002       0.7156      0.8326        [94m0.3675[0m     +  0.0000  10.0270
     32      0.9196        0.3020       0.7155      0.8324        [94m0.3674[0m     +  0.0000  10.0117
     33      0.9286        0.2988       0.7155      0.8324        [94m0.3674[0m     +  0.0000  10.1402
     34      0.9421        [32m0.2940[0m       0.7149      0.8319        [94m0.3674[0m     +  0.0000  10.0061
     35      0.9458        0.3095       0.7149      0.8319        [94m0.3674[0m     +  0.0000  10.1771
     36      0.9140        [32m0.2905[0m       0.7149      0.8319        0.3674        0.0000  9.9997
     37      0.9388        0.3075       0.7149      0.8319        [94m0.3674[0m     +  0.0000  9.9484
     38      0.9511        0.2987       0.7149      0.8319        [94m0.3674[0m     +  0.0000  10.2087
     39      [36m0.9660[0m        0.2920       0.7151      0.8321        [94m0.3674[0m     +  0.0000  10.0740
     40      0.9274        0.2928       0.7153      0.8322        [94m0.3673[0m     +  0.0000  9.9789
     41      0.9421        0.2947       0.7153      0.8322        [94m0.3673[0m     +  0.0000  10.0766
     42      0.9392        0.2974       0.7151      0.8320        0.3673        0.0000  9.9950
     43      0.9492        0.3067       0.7151      0.8320        0.3673        0.0000  10.0509
     44      0.9083        0.3091       0.7151      0.8320        [94m0.3673[0m     +  0.0000  10.0861
     45      0.9374        0.2978       0.7151      0.8320        [94m0.3673[0m     +  0.0000  10.1929
     46      0.9458        0.2976       0.7151      0.8320        [94m0.3673[0m     +  0.0000  10.3708
     47      0.9538        0.2909       0.7151      0.8320        [94m0.3673[0m     +  0.0000  10.0621
     48      0.9429        0.3020       0.7151      0.8320        [94m0.3673[0m     +  0.0000  10.0068
     49      0.9344        0.2911       0.7151      0.8320        [94m0.3673[0m     +  0.0000  10.1677
     50      0.9358        0.3050       0.7151      0.8320        [94m0.3673[0m     +  0.0000  10.1411
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 3: Test F1 Micro Score: 0.8596788509642539
Iteration 3: Test F1 Macro Score: 0.8339275994820262
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_2.pt

Iteration 4: Requesting 56 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8560[0m        [32m0.3564[0m       [35m0.5543[0m      [31m0.5484[0m        [94m0.4371[0m     +  0.0000  10.2361
      2      [36m0.8892[0m        [32m0.3074[0m       [35m0.7382[0m      [31m0.8539[0m        [94m0.3227[0m     +  0.0000  10.2658
      3      [36m0.9172[0m        [32m0.2887[0m       0.7326      0.8489        [94m0.3125[0m     +  0.0000  10.2770
      4      [36m0.9321[0m        [32m0.2659[0m       0.7106      0.8020        0.3222        0.0000  10.2631
      5      0.9193        0.2689       0.7007      0.7860        0.3259        0.0000  10.4060
      6      [36m0.9373[0m        [32m0.2525[0m       [35m0.7533[0m      [31m0.8645[0m        [94m0.3000[0m     +  0.0000  10.3288
      7      0.9278        0.2588       0.7472      0.8569        [94m0.2983[0m     +  0.0000  10.1677
      8      [36m0.9559[0m        [32m0.2479[0m       0.7464      0.8589        [94m0.2970[0m     +  0.0000  10.3068
      9      0.9517        [32m0.2370[0m       0.7455      0.8585        [94m0.2962[0m     +  0.0000  10.2500
     10      0.9543        0.2464       0.7474      0.8616        [94m0.2960[0m     +  0.0000  10.3243
     11      0.9557        0.2371       0.7505      0.8637        [94m0.2953[0m     +  0.0000  10.3226
     12      0.9388        0.2397       0.7512      0.8645        [94m0.2947[0m     +  0.0000  10.2587
     13      0.9545        0.2386       0.7483      0.8625        [94m0.2940[0m     +  0.0000  10.2750
     14      [36m0.9569[0m        [32m0.2313[0m       0.7467      0.8596        [94m0.2931[0m     +  0.0000  10.2501
     15      0.9490        0.2376       0.7505      [31m0.8645[0m        [94m0.2930[0m     +  0.0000  10.2540
     16      0.9460        0.2372       0.7498      0.8638        [94m0.2928[0m     +  0.0000  10.2037
     17      0.9418        0.2333       0.7483      0.8623        [94m0.2925[0m     +  0.0000  10.2084
     18      [36m0.9599[0m        0.2360       0.7465      0.8603        [94m0.2922[0m     +  0.0000  10.2529
     19      0.9525        0.2407       0.7465      0.8598        [94m0.2920[0m     +  0.0000  10.3014
     20      0.9528        0.2330       0.7479      0.8615        [94m0.2920[0m     +  0.0000  10.2294
     21      0.9545        0.2318       0.7470      0.8605        [94m0.2918[0m     +  0.0000  10.3052
     22      0.9485        0.2345       0.7470      0.8604        [94m0.2917[0m     +  0.0000  10.4944
     23      0.9374        [32m0.2285[0m       0.7470      0.8603        [94m0.2916[0m     +  0.0000  10.5773
     24      [36m0.9626[0m        0.2318       0.7474      0.8604        [94m0.2915[0m     +  0.0000  10.3031
     25      0.9556        [32m0.2265[0m       0.7477      0.8607        [94m0.2914[0m     +  0.0000  10.5317
     26      [36m0.9713[0m        0.2304       0.7469      0.8602        [94m0.2914[0m     +  0.0000  10.2660
     27      0.9527        [32m0.2255[0m       0.7469      0.8600        [94m0.2914[0m     +  0.0000  10.2624
     28      0.9556        0.2339       0.7469      0.8599        [94m0.2913[0m     +  0.0000  10.2181
     29      0.9570        0.2363       0.7460      0.8592        [94m0.2913[0m     +  0.0000  10.2348
     30      0.9620        0.2271       0.7464      0.8595        [94m0.2912[0m     +  0.0000  10.2768
     31      0.9584        [32m0.2215[0m       0.7464      0.8595        [94m0.2912[0m     +  0.0000  10.2736
     32      0.9557        0.2309       0.7464      0.8595        [94m0.2912[0m     +  0.0000  10.2455
     33      0.9706        0.2247       0.7457      0.8590        [94m0.2912[0m     +  0.0000  10.2290
     34      0.9641        0.2329       0.7462      0.8593        [94m0.2912[0m     +  0.0000  10.3802
     35      0.9612        0.2260       0.7464      0.8596        [94m0.2912[0m     +  0.0000  10.2263
     36      0.9654        0.2329       0.7464      0.8595        [94m0.2912[0m     +  0.0000  10.1915
     37      0.9555        0.2245       0.7464      0.8595        [94m0.2912[0m     +  0.0000  10.2184
     38      0.9541        0.2429       0.7464      0.8596        [94m0.2912[0m     +  0.0000  10.2502
     39      0.9364        0.2350       0.7464      0.8596        [94m0.2912[0m     +  0.0000  10.2343
     40      0.9544        0.2286       0.7464      0.8596        [94m0.2912[0m     +  0.0000  10.2689
     41      0.9559        0.2265       0.7464      0.8596        [94m0.2912[0m     +  0.0000  10.2516
     42      0.9340        0.2340       0.7464      0.8596        [94m0.2912[0m     +  0.0000  10.2336
     43      0.9598        0.2236       0.7464      0.8595        [94m0.2912[0m     +  0.0000  10.1843
     44      0.9489        0.2354       0.7464      0.8595        [94m0.2912[0m     +  0.0000  10.3137
     45      0.9557        0.2322       0.7464      0.8595        [94m0.2912[0m     +  0.0000  10.2168
     46      0.9639        0.2311       0.7464      0.8595        [94m0.2912[0m     +  0.0000  10.2412
     47      0.9557        0.2280       0.7464      0.8595        [94m0.2912[0m     +  0.0000  10.2433
     48      0.9625        0.2241       0.7462      0.8594        [94m0.2912[0m     +  0.0000  10.2570
     49      0.9617        0.2351       0.7462      0.8594        [94m0.2912[0m     +  0.0000  10.3966
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 4: Test F1 Micro Score: 0.8878951910253393
Iteration 4: Test F1 Macro Score: 0.8683700627638613
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_3.pt

Iteration 5: Requesting 96 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8613[0m        [32m0.2937[0m       [35m0.7646[0m      [31m0.8759[0m        [94m0.2885[0m     +  0.0000  10.5345
      2      [36m0.9044[0m        [32m0.2573[0m       0.7549      0.8686        0.2921        0.0000  10.5465
      3      [36m0.9293[0m        [32m0.2416[0m       0.7601      0.8757        [94m0.2798[0m     +  0.0000  10.5475
      4      [36m0.9375[0m        [32m0.2301[0m       0.7594      0.8747        0.2819        0.0000  10.5756
      5      [36m0.9508[0m        [32m0.2244[0m       0.7587      0.8726        0.2820        0.0000  10.5813
      6      [36m0.9529[0m        [32m0.2129[0m       [35m0.7656[0m      [31m0.8783[0m        [94m0.2713[0m     +  0.0000  10.5570
      7      [36m0.9585[0m        [32m0.2109[0m       0.7649      0.8779        [94m0.2696[0m     +  0.0000  10.6463
      8      [36m0.9722[0m        [32m0.2070[0m       [35m0.7658[0m      0.8780        [94m0.2672[0m     +  0.0000  10.5884
      9      0.9568        0.2094       0.7634      0.8778        0.2705        0.0000  10.5675
     10      0.9582        [32m0.2041[0m       [35m0.7663[0m      0.8781        0.2681        0.0000  10.5544
     11      0.9595        [32m0.1970[0m       0.7634      0.8759        [94m0.2649[0m     +  0.0000  10.7033
     12      0.9718        0.1975       0.7653      0.8780        0.2667        0.0000  10.5943
     13      [36m0.9750[0m        [32m0.1948[0m       0.7632      0.8756        [94m0.2638[0m     +  0.0000  10.5543
     14      0.9599        [32m0.1934[0m       0.7615      0.8745        0.2644        0.0000  10.5367
     15      [36m0.9835[0m        [32m0.1925[0m       0.7609      0.8746        0.2648        0.0000  10.5724
     16      0.9679        0.1976       0.7613      0.8741        [94m0.2632[0m     +  0.0000  10.5582
     17      0.9712        [32m0.1904[0m       0.7604      0.8737        0.2636        0.0000  10.5783
     18      0.9781        0.1954       0.7613      0.8741        0.2637        0.0000  10.5577
     19      0.9701        [32m0.1878[0m       0.7611      0.8740        0.2637        0.0000  10.5664
     20      0.9732        0.1897       0.7608      0.8735        [94m0.2631[0m     +  0.0000  10.5781
     21      0.9794        0.1907       0.7602      0.8730        [94m0.2628[0m     +  0.0000  10.6154
     22      0.9822        0.1908       0.7613      0.8737        0.2629        0.0000  10.5931
     23      0.9750        [32m0.1866[0m       0.7609      0.8734        [94m0.2627[0m     +  0.0000  10.5261
     24      0.9754        0.1947       0.7611      0.8737        0.2630        0.0000  10.6386
     25      0.9795        0.1888       0.7609      0.8734        [94m0.2627[0m     +  0.0000  10.5644
     26      [36m0.9889[0m        [32m0.1835[0m       0.7606      0.8732        [94m0.2627[0m     +  0.0000  10.5628
     27      0.9755        0.1929       0.7606      0.8732        [94m0.2627[0m     +  0.0000  10.8022
     28      0.9780        0.1875       0.7604      0.8732        [94m0.2626[0m     +  0.0000  10.5993
     29      0.9823        0.1914       0.7602      0.8731        [94m0.2625[0m     +  0.0000  10.6125
     30      0.9790        0.1857       0.7608      0.8732        [94m0.2624[0m     +  0.0000  10.5779
     31      0.9827        0.1873       0.7604      0.8732        0.2625        0.0000  10.6179
     32      0.9875        0.1916       0.7606      0.8732        [94m0.2624[0m     +  0.0000  10.5858
     33      0.9819        0.1915       0.7608      0.8733        [94m0.2624[0m     +  0.0000  10.5099
     34      0.9838        [32m0.1806[0m       0.7609      0.8734        [94m0.2623[0m     +  0.0000  10.5384
     35      0.9822        0.1849       0.7609      0.8734        0.2623        0.0000  10.5566
     36      0.9807        0.1895       0.7611      0.8734        [94m0.2623[0m     +  0.0000  10.4910
     37      0.9826        0.1888       0.7613      0.8735        [94m0.2623[0m     +  0.0000  10.4911
     38      0.9792        0.1902       0.7613      0.8735        [94m0.2623[0m     +  0.0000  10.5111
     39      0.9787        0.1873       0.7611      0.8734        0.2623        0.0000  10.5080
     40      0.9745        0.1932       0.7613      0.8735        [94m0.2622[0m     +  0.0000  10.5549
     41      0.9787        0.1892       0.7613      0.8735        0.2622        0.0000  10.4908
     42      0.9797        0.1869       0.7613      0.8735        0.2622        0.0000  10.5376
     43      0.9763        0.1840       0.7613      0.8735        0.2623        0.0000  10.6163
     44      0.9787        0.1880       0.7613      0.8735        0.2623        0.0000  10.6488
     45      0.9827        0.1874       0.7613      0.8735        0.2622        0.0000  10.5692
     46      0.9777        0.1917       0.7613      0.8735        0.2622        0.0000  11.0069
     47      0.9855        0.1838       0.7613      0.8735        0.2622        0.0000  10.8701
     48      0.9776        0.1875       0.7611      0.8734        [94m0.2622[0m     +  0.0000  10.4909
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 5: Test F1 Micro Score: 0.9061973986228002
Iteration 5: Test F1 Macro Score: 0.8916907065601708
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_4.pt

Iteration 6: Requesting 176 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9294[0m        [32m0.2310[0m       [35m0.7389[0m      [31m0.8359[0m        [94m0.2731[0m     +  0.0000  11.1805
      2      [36m0.9320[0m        [32m0.2058[0m       [35m0.7575[0m      [31m0.8502[0m        [94m0.2614[0m     +  0.0000  11.1497
      3      [36m0.9427[0m        [32m0.1970[0m       [35m0.7644[0m      [31m0.8528[0m        [94m0.2560[0m     +  0.0000  11.1804
      4      [36m0.9608[0m        [32m0.1897[0m       0.7632      0.8520        [94m0.2556[0m     +  0.0000  11.1182
      5      [36m0.9708[0m        [32m0.1764[0m       0.7589      0.8460        [94m0.2550[0m     +  0.0000  11.1348
      6      [36m0.9735[0m        [32m0.1720[0m       [35m0.7684[0m      0.8440        [94m0.2461[0m     +  0.0000  11.1502
      7      [36m0.9757[0m        [32m0.1643[0m       0.7665      0.8434        0.2474        0.0000  11.3231
      8      [36m0.9818[0m        [32m0.1615[0m       [35m0.7701[0m      0.8478        [94m0.2451[0m     +  0.0000  11.1851
      9      [36m0.9820[0m        [32m0.1597[0m       0.7688      [31m0.8539[0m        [94m0.2416[0m     +  0.0000  11.1480
     10      [36m0.9893[0m        [32m0.1550[0m       [35m0.7710[0m      0.8522        0.2417        0.0000  11.2270
     11      [36m0.9897[0m        [32m0.1539[0m       [35m0.7731[0m      [31m0.8597[0m        [94m0.2384[0m     +  0.0000  11.1323
     12      0.9832        [32m0.1518[0m       [35m0.7778[0m      [31m0.8662[0m        [94m0.2372[0m     +  0.0000  11.2118
     13      0.9871        0.1550       0.7767      0.8651        [94m0.2371[0m     +  0.0000  11.1958
     14      [36m0.9911[0m        [32m0.1480[0m       0.7752      0.8632        0.2372        0.0000  11.1806
     15      0.9886        0.1530       0.7755      0.8599        0.2382        0.0000  11.1805
     16      0.9874        [32m0.1472[0m       [35m0.7783[0m      [31m0.8692[0m        [94m0.2357[0m     +  0.0000  11.3070
     17      0.9898        0.1493       0.7781      [31m0.8716[0m        [94m0.2352[0m     +  0.0000  11.2111
     18      0.9839        0.1525       0.7780      0.8699        0.2353        0.0000  11.1168
     19      0.9877        0.1490       0.7778      [31m0.8719[0m        [94m0.2350[0m     +  0.0000  11.2119
     20      0.9905        0.1473       [35m0.7792[0m      [31m0.8725[0m        [94m0.2348[0m     +  0.0000  11.1179
     21      0.9845        0.1486       [35m0.7799[0m      [31m0.8744[0m        [94m0.2346[0m     +  0.0000  11.2121
     22      0.9869        [32m0.1458[0m       0.7797      0.8741        0.2346        0.0000  11.1657
     23      [36m0.9915[0m        [32m0.1452[0m       [35m0.7800[0m      [31m0.8746[0m        [94m0.2345[0m     +  0.0000  11.1959
     24      0.9898        [32m0.1438[0m       [35m0.7807[0m      [31m0.8749[0m        [94m0.2344[0m     +  0.0000  11.1486
     25      0.9898        0.1470       0.7806      0.8747        [94m0.2343[0m     +  0.0000  11.1637
     26      0.9911        [32m0.1438[0m       [35m0.7809[0m      [31m0.8751[0m        [94m0.2343[0m     +  0.0000  11.2427
     27      0.9889        0.1473       0.7800      0.8746        0.2343        0.0000  11.2578
     28      0.9818        [32m0.1437[0m       0.7802      0.8748        [94m0.2342[0m     +  0.0000  11.1806
     29      0.9911        0.1461       0.7804      [31m0.8751[0m        [94m0.2342[0m     +  0.0000  11.2112
     30      [36m0.9935[0m        [32m0.1430[0m       0.7800      0.8750        [94m0.2342[0m     +  0.0000  11.1808
     31      0.9883        0.1476       0.7800      0.8749        0.2342        0.0000  11.1647
     32      0.9886        0.1491       0.7806      [31m0.8752[0m        0.2342        0.0000  11.1799
     33      [36m0.9944[0m        0.1459       0.7804      0.8750        0.2342        0.0000  11.2112
     34      0.9909        0.1433       0.7804      0.8750        [94m0.2342[0m     +  0.0000  11.1789
     35      0.9858        0.1434       0.7804      0.8751        [94m0.2342[0m     +  0.0000  11.1477
     36      0.9885        0.1449       0.7802      0.8750        [94m0.2342[0m     +  0.0000  11.2426
     37      0.9863        0.1455       0.7802      0.8750        [94m0.2341[0m     +  0.0000  11.2570
     38      0.9911        0.1467       0.7804      0.8751        0.2341        0.0000  11.2117
     39      0.9911        [32m0.1415[0m       0.7802      0.8750        0.2341        0.0000  11.1645
     40      0.9878        0.1494       0.7802      0.8750        [94m0.2341[0m     +  0.0000  11.1182
     41      0.9879        0.1441       0.7804      0.8751        0.2341        0.0000  11.1636
     42      0.9903        0.1435       0.7804      0.8751        0.2341        0.0000  11.1206
     43      0.9912        0.1432       0.7804      0.8751        0.2341        0.0000  11.1486
     44      0.9922        0.1487       0.7804      0.8751        0.2341        0.0000  11.0854
     45      0.9912        0.1457       0.7804      0.8751        0.2341        0.0000  11.1808
     46      0.9871        0.1449       0.7804      0.8751        0.2341        0.0000  11.2068
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 6: Test F1 Micro Score: 0.917689361369499
Iteration 6: Test F1 Macro Score: 0.9027149503942097
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_5.pt

Iteration 7: Requesting 320 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9376[0m        [32m0.1916[0m       [35m0.7608[0m      [31m0.8231[0m        [94m0.2474[0m     +  0.0000  12.2578
      2      [36m0.9567[0m        [32m0.1690[0m       0.7571      0.8162        0.2492        0.0000  12.3840
      3      [36m0.9619[0m        [32m0.1608[0m       0.7606      0.8220        [94m0.2466[0m     +  0.0000  12.3680
      4      [36m0.9707[0m        [32m0.1528[0m       0.7580      [31m0.8234[0m        0.2478        0.0000  12.4476
      5      [36m0.9787[0m        [32m0.1448[0m       [35m0.7620[0m      0.8221        0.2480        0.0000  12.3677
      6      [36m0.9847[0m        [32m0.1341[0m       [35m0.7660[0m      [31m0.8327[0m        [94m0.2397[0m     +  0.0000  12.4000
      7      [36m0.9871[0m        [32m0.1325[0m       [35m0.7708[0m      [31m0.8417[0m        [94m0.2365[0m     +  0.0000  12.5882
      8      0.9823        [32m0.1319[0m       0.7707      0.8394        0.2383        0.0000  12.3070
      9      [36m0.9890[0m        [32m0.1290[0m       [35m0.7738[0m      [31m0.8441[0m        [94m0.2351[0m     +  0.0000  12.2902
     10      0.9853        [32m0.1275[0m       0.7694      0.8359        0.2398        0.0000  12.4303
     11      0.9875        [32m0.1261[0m       [35m0.7910[0m      [31m0.8690[0m        [94m0.2256[0m     +  0.0000  12.8225
     12      [36m0.9905[0m        [32m0.1240[0m       0.7887      0.8660        0.2258        0.0000  12.4767
     13      [36m0.9912[0m        [32m0.1217[0m       0.7899      0.8656        0.2268        0.0000  12.4469
     14      0.9905        [32m0.1206[0m       [35m0.7911[0m      [31m0.8698[0m        [94m0.2243[0m     +  0.0000  12.6185
     15      0.9896        [32m0.1206[0m       0.7899      0.8669        0.2260        0.0000  12.3688
     16      0.9899        0.1213       [35m0.7946[0m      [31m0.8730[0m        [94m0.2232[0m     +  0.0000  12.2758
     17      [36m0.9912[0m        [32m0.1197[0m       0.7929      0.8728        [94m0.2223[0m     +  0.0000  12.5884
     18      [36m0.9937[0m        [32m0.1185[0m       0.7936      0.8728        0.2227        0.0000  12.6053
     19      0.9927        [32m0.1183[0m       0.7939      0.8719        0.2233        0.0000  12.3529
     20      0.9931        0.1188       [35m0.7951[0m      [31m0.8735[0m        0.2226        0.0000  12.3508
     21      0.9916        [32m0.1163[0m       0.7937      [31m0.8740[0m        [94m0.2217[0m     +  0.0000  12.4342
     22      0.9927        0.1164       0.7936      0.8737        0.2218        0.0000  12.4458
     23      0.9910        0.1181       0.7944      [31m0.8742[0m        0.2218        0.0000  12.3382
     24      0.9910        0.1177       0.7939      [31m0.8746[0m        [94m0.2216[0m     +  0.0000  12.3147
     25      0.9910        0.1163       0.7946      0.8741        0.2219        0.0000  12.3215
     26      0.9920        0.1189       0.7941      [31m0.8747[0m        [94m0.2216[0m     +  0.0000  12.6037
     27      0.9910        [32m0.1158[0m       0.7939      [31m0.8749[0m        [94m0.2214[0m     +  0.0000  12.3222
     28      0.9932        0.1161       0.7939      [31m0.8750[0m        [94m0.2214[0m     +  0.0000  12.3214
     29      0.9927        0.1164       0.7943      [31m0.8752[0m        [94m0.2213[0m     +  0.0000  12.6199
     30      0.9927        [32m0.1156[0m       0.7941      0.8747        0.2214        0.0000  12.3700
     31      0.9920        0.1181       0.7939      0.8746        0.2214        0.0000  12.3999
     32      0.9920        0.1169       0.7943      0.8746        0.2215        0.0000  12.3212
     33      0.9931        0.1161       0.7937      0.8744        0.2215        0.0000  12.4008
     34      0.9920        0.1166       0.7937      0.8743        0.2215        0.0000  12.4135
     35      0.9922        0.1157       0.7941      0.8746        0.2214        0.0000  12.4939
     36      0.9911        0.1175       0.7941      0.8746        0.2214        0.0000  13.0092
     37      0.9915        [32m0.1156[0m       0.7941      0.8746        0.2214        0.0000  12.6580
     38      0.9911        0.1165       0.7941      0.8746        0.2214        0.0000  12.8293
     39      0.9922        0.1173       0.7939      0.8749        0.2214        0.0000  12.6438
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 7: Test F1 Micro Score: 0.9215162000629129
Iteration 7: Test F1 Macro Score: 0.9085213125543383
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_6.pt

Iteration 8: Requesting 560 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9519[0m        [32m0.1555[0m       [35m0.7875[0m      [31m0.8842[0m        [94m0.2138[0m     +  0.0000  14.7187
      2      [36m0.9695[0m        [32m0.1324[0m       0.7856      0.8820        [94m0.2119[0m     +  0.0000  14.8445
      3      [36m0.9768[0m        [32m0.1243[0m       0.7773      0.8768        0.2199        0.0000  14.9263
      4      [36m0.9802[0m        [32m0.1169[0m       0.7872      0.8818        0.2137        0.0000  14.9523
      5      [36m0.9839[0m        [32m0.1132[0m       0.7776      0.8760        0.2182        0.0000  15.1508
      6      [36m0.9872[0m        [32m0.1059[0m       0.7859      0.8761        0.2168        0.0000  15.4215
      7      [36m0.9882[0m        [32m0.1022[0m       [35m0.7889[0m      0.8761        0.2136        0.0000  15.4242
      8      [36m0.9911[0m        [32m0.0992[0m       [35m0.7910[0m      0.8797        0.2147        0.0000  15.3321
      9      [36m0.9915[0m        [32m0.0970[0m       0.7885      0.8740        0.2161        0.0000  15.5169
     10      0.9907        [32m0.0948[0m       0.7884      0.8746        0.2180        0.0000  15.3436
     11      [36m0.9925[0m        [32m0.0937[0m       0.7856      0.8700        0.2211        0.0000  15.2850
     12      [36m0.9933[0m        [32m0.0909[0m       0.7844      0.8687        0.2204        0.0000  15.4780
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 8: Test F1 Micro Score: 0.9226497421658073
Iteration 8: Test F1 Macro Score: 0.9107496486607304
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_7.pt

Iteration 9: Requesting 1000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9505[0m        [32m0.1459[0m       [35m0.7898[0m      [31m0.8517[0m        [94m0.2134[0m     +  0.0000  19.2529
      2      [36m0.9633[0m        [32m0.1304[0m       [35m0.7943[0m      [31m0.8551[0m        [94m0.2112[0m     +  0.0000  19.0628
      3      [36m0.9682[0m        [32m0.1205[0m       [35m0.8023[0m      [31m0.8665[0m        [94m0.2072[0m     +  0.0000  19.1189
      4      [36m0.9746[0m        [32m0.1145[0m       0.7983      0.8652        [94m0.2050[0m     +  0.0000  19.2357
      5      [36m0.9754[0m        [32m0.1075[0m       [35m0.8078[0m      [31m0.8747[0m        [94m0.1999[0m     +  0.0000  19.2572
      6      [36m0.9824[0m        [32m0.0960[0m       [35m0.8252[0m      [31m0.8967[0m        [94m0.1888[0m     +  0.0000  19.3882
      7      [36m0.9827[0m        [32m0.0933[0m       0.8248      0.8954        0.1899        0.0000  19.1759
      8      [36m0.9845[0m        [32m0.0893[0m       [35m0.8260[0m      0.8948        [94m0.1881[0m     +  0.0000  19.2869
      9      [36m0.9858[0m        [32m0.0863[0m       0.8255      0.8955        0.1889        0.0000  19.3572
     10      [36m0.9874[0m        [32m0.0831[0m       0.8241      0.8941        0.1905        0.0000  19.2483
     11      [36m0.9888[0m        [32m0.0808[0m       0.8193      0.8927        0.1914        0.0000  18.9187
     12      0.9882        [32m0.0786[0m       0.8207      0.8943        0.1909        0.0000  19.0949
     13      [36m0.9893[0m        [32m0.0782[0m       0.8172      0.8922        0.1920        0.0000  19.0002
     14      [36m0.9910[0m        [32m0.0763[0m       0.8191      0.8931        0.1916        0.0000  19.3085
     15      0.9907        0.0766       0.8181      0.8922        0.1935        0.0000  19.4686
     16      [36m0.9917[0m        [32m0.0748[0m       0.8144      0.8887        0.1933        0.0000  19.9393
     17      [36m0.9922[0m        [32m0.0743[0m       0.8167      0.8898        0.1927        0.0000  20.1510
     18      0.9912        0.0751       0.8148      0.8880        0.1932        0.0000  20.0959
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 9: Test F1 Micro Score: 0.9277756135566809
Iteration 9: Test F1 Macro Score: 0.9128859854535462
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_8.pt

Iteration 10: Requesting 1776 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9631[0m        [32m0.1075[0m       [35m0.7672[0m      [31m0.8238[0m        [94m0.2145[0m     +  0.0000  26.6671
      2      [36m0.9709[0m        [32m0.0956[0m       0.7644      0.8077        0.2179        0.0000  26.5135
      3      [36m0.9779[0m        [32m0.0863[0m       [35m0.7839[0m      [31m0.8375[0m        [94m0.2059[0m     +  0.0000  26.7959
      4      [36m0.9786[0m        [32m0.0800[0m       0.7727      0.8202        0.2113        0.0000  26.7313
      5      [36m0.9820[0m        [32m0.0719[0m       0.7766      0.8312        0.2119        0.0000  27.0232
      6      [36m0.9863[0m        [32m0.0654[0m       [35m0.7953[0m      [31m0.8636[0m        [94m0.1953[0m     +  0.0000  26.8458
      7      [36m0.9873[0m        [32m0.0619[0m       [35m0.7967[0m      0.8619        [94m0.1942[0m     +  0.0000  26.8793
      8      [36m0.9899[0m        [32m0.0577[0m       0.7939      0.8566        0.1971        0.0000  26.6797
      9      [36m0.9910[0m        [32m0.0553[0m       [35m0.7974[0m      [31m0.8703[0m        0.1968        0.0000  27.0255
     10      0.9907        [32m0.0530[0m       [35m0.8071[0m      [31m0.8818[0m        [94m0.1917[0m     +  0.0000  26.9490
     11      [36m0.9927[0m        [32m0.0503[0m       0.8021      0.8732        0.1970        0.0000  26.5987
     12      [36m0.9941[0m        [32m0.0492[0m       0.8069      0.8792        0.1940        0.0000  27.0169
     13      [36m0.9948[0m        [32m0.0470[0m       [35m0.8122[0m      [31m0.8830[0m        0.1920        0.0000  26.7961
     14      [36m0.9952[0m        [32m0.0465[0m       0.8082      0.8780        0.1957        0.0000  26.6894
     15      0.9948        [32m0.0455[0m       0.8118      0.8814        0.1945        0.0000  26.7046
     16      [36m0.9954[0m        [32m0.0443[0m       0.8094      0.8812        0.1968        0.0000  26.5323
     17      [36m0.9963[0m        [32m0.0440[0m       0.8101      0.8808        0.1972        0.0000  26.8959
     18      [36m0.9964[0m        [32m0.0433[0m       0.8099      0.8814        0.1976        0.0000  27.2814
     19      [36m0.9966[0m        0.0434       0.8092      0.8810        0.1986        0.0000  26.8769
     20      [36m0.9971[0m        [32m0.0429[0m       0.8094      0.8807        0.1992        0.0000  26.7488
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 10: Test F1 Micro Score: 0.9246543420848221
Iteration 10: Test F1 Macro Score: 0.9125531741945972
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_9.pt

Iteration 11: Requesting 3160 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9745[0m        [32m0.0718[0m       [35m0.8411[0m      [31m0.8955[0m        [94m0.1672[0m     +  0.0000  38.9691
      2      [36m0.9794[0m        [32m0.0628[0m       0.8384      0.8944        0.1723        0.0000  38.8496
      3      [36m0.9831[0m        [32m0.0560[0m       0.8313      [31m0.8984[0m        0.1779        0.0000  39.0133
      4      [36m0.9836[0m        [32m0.0513[0m       0.8288      0.8868        0.1764        0.0000  38.8740
      5      [36m0.9866[0m        [32m0.0453[0m       0.8313      0.8936        0.1812        0.0000  38.9843
      6      [36m0.9894[0m        [32m0.0394[0m       0.8316      0.8920        0.1856        0.0000  38.9081
      7      [36m0.9927[0m        [32m0.0345[0m       0.8259      0.8886        0.1934        0.0000  39.1090
      8      [36m0.9932[0m        [32m0.0331[0m       0.8208      0.8870        0.2037        0.0000  39.1739
      9      [36m0.9945[0m        [32m0.0310[0m       0.8273      0.8938        0.2084        0.0000  39.1364
     10      0.9943        [32m0.0293[0m       0.8240      0.8929        0.2107        0.0000  39.0612
     11      [36m0.9954[0m        [32m0.0275[0m       0.8214      0.8875        0.2079        0.0000  39.2662
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 11: Test F1 Micro Score: 0.9205521472392638
Iteration 11: Test F1 Macro Score: 0.9058897097250092
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_10.pt

Iteration 12: Requesting 5624 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9730[0m        [32m0.0690[0m       [35m0.8378[0m      [31m0.9003[0m        [94m0.1650[0m     +  0.0000  60.7214
      2      [36m0.9776[0m        [32m0.0606[0m       [35m0.8474[0m      [31m0.9062[0m        [94m0.1640[0m     +  0.0000  60.7146
      3      [36m0.9814[0m        [32m0.0518[0m       0.8448      [31m0.9085[0m        0.1704        0.0000  61.1073
      4      [36m0.9830[0m        [32m0.0467[0m       0.8302      0.9014        0.1846        0.0000  60.8897
      5      [36m0.9839[0m        [32m0.0430[0m       0.8396      0.9054        0.1798        0.0000  60.9693
      6      [36m0.9879[0m        [32m0.0352[0m       0.8377      0.9040        0.1853        0.0000  61.3267
      7      [36m0.9902[0m        [32m0.0317[0m       0.8345      0.9020        0.1885        0.0000  61.1859
      8      [36m0.9915[0m        [32m0.0298[0m       0.8344      0.9019        0.1901        0.0000  61.3040
      9      [36m0.9921[0m        [32m0.0279[0m       0.8358      0.9024        0.2015        0.0000  61.1798
     10      [36m0.9937[0m        [32m0.0252[0m       0.8274      0.8940        0.2031        0.0000  61.5399
     11      [36m0.9952[0m        [32m0.0231[0m       0.8356      0.8983        0.2023        0.0000  61.1146
     12      [36m0.9957[0m        [32m0.0220[0m       0.8380      0.8996        0.2032        0.0000  61.0685
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 12: Test F1 Micro Score: 0.9261529033246515
Iteration 12: Test F1 Macro Score: 0.9129272469077073
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_11.pt

Iteration 13: Requesting 10000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9754[0m        [32m0.0594[0m       [35m0.8585[0m      [31m0.9129[0m        [94m0.1487[0m     +  0.0000  99.9047
      2      [36m0.9787[0m        [32m0.0513[0m       [35m0.8651[0m      [31m0.9173[0m        [94m0.1446[0m     +  0.0000  100.1949
      3      [36m0.9804[0m        [32m0.0462[0m       0.8599      0.9129        0.1522        0.0000  101.1384
      4      [36m0.9819[0m        [32m0.0414[0m       0.8481      0.9082        0.1675        0.0000  99.6559
      5      [36m0.9851[0m        [32m0.0365[0m       0.8472      0.9091        0.1710        0.0000  100.5890
      6      [36m0.9872[0m        [32m0.0315[0m       0.8394      0.9013        0.1831        0.0000  100.1249
      7      [36m0.9895[0m        [32m0.0279[0m       0.8472      0.9037        0.1769        0.0000  100.0969
      8      [36m0.9909[0m        [32m0.0257[0m       0.8372      0.8979        0.1900        0.0000  100.1215
      9      [36m0.9919[0m        [32m0.0232[0m       0.8382      0.8981        0.1959        0.0000  99.9271
     10      [36m0.9928[0m        [32m0.0220[0m       0.8316      0.8965        0.2046        0.0000  100.3769
     11      [36m0.9938[0m        [32m0.0196[0m       0.8330      0.9001        0.2189        0.0000  99.8777
     12      [36m0.9947[0m        [32m0.0184[0m       0.8358      0.9020        0.2212        0.0000  100.0153
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 13: Test F1 Micro Score: 0.9288280712483755
Iteration 13: Test F1 Macro Score: 0.9150385246362612
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_12.pt

Iteration 14: Requesting all remaining samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9793[0m        [32m0.0471[0m       [35m0.8316[0m      [31m0.9021[0m        [94m0.1748[0m     +  0.0000  115.7989
      2      [36m0.9815[0m        [32m0.0422[0m       [35m0.8467[0m      [31m0.9077[0m        [94m0.1592[0m     +  0.0000  116.6274
      3      [36m0.9830[0m        [32m0.0374[0m       0.8370      0.9030        0.1730        0.0000  116.2005
      4      [36m0.9845[0m        [32m0.0343[0m       0.8335      0.9009        0.1855        0.0000  116.6094
      5      [36m0.9859[0m        [32m0.0314[0m       0.8271      0.8987        0.1983        0.0000  116.4883
      6      [36m0.9890[0m        [32m0.0258[0m       0.8392      0.9039        0.1923        0.0000  116.5520
      7      [36m0.9910[0m        [32m0.0228[0m       0.8264      0.8984        0.2186        0.0000  116.3140
      8      [36m0.9924[0m        [32m0.0204[0m       0.8373      0.9038        0.2041        0.0000  116.0601
      9      [36m0.9933[0m        [32m0.0190[0m       0.8326      0.9028        0.2207        0.0000  117.0764
     10      [36m0.9939[0m        [32m0.0175[0m       0.8266      0.8982        0.2388        0.0000  117.4534
     11      [36m0.9951[0m        [32m0.0155[0m       0.8457      0.9076        0.2143        0.0000  116.4690
     12      [36m0.9964[0m        [32m0.0138[0m       [35m0.8491[0m      [31m0.9102[0m        0.2131        0.0000  117.4692
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 14: Test F1 Micro Score: 0.929154474048976
Iteration 14: Test F1 Macro Score: 0.9157183087437998
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR/model_checkpoint_iteration_13.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_46_config2_lowLR\random_sampling_results_for_multilabel_classification_s46.pickle
