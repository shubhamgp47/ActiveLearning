Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.3016[0m        [32m0.7095[0m       [35m0.1998[0m      [31m0.1464[0m        [94m0.6758[0m     +  49.0804
      2      [36m0.6349[0m        [32m0.6434[0m       [35m0.2005[0m      [31m0.2415[0m        0.6782        47.0016
      3      [36m0.7024[0m        [32m0.6029[0m       [35m0.2123[0m      [31m0.2963[0m        0.6777        46.6446
      4      [36m0.8796[0m        [32m0.5442[0m       [35m0.2290[0m      [31m0.3080[0m        0.6796        46.3796
      5      [36m0.9630[0m        [32m0.4719[0m       0.1953      [31m0.3704[0m        0.6821        46.8601
      6      [36m1.0000[0m        [32m0.4474[0m       0.1443      [31m0.3803[0m        0.6836        47.5160
      7      0.9524        [32m0.4455[0m       0.1078      0.3603        0.6834        46.5355
      8      1.0000        [32m0.3582[0m       0.0755      0.3259        0.6854        47.0255
Stopping since valid_loss has not improved in the last 8 epochs.
Pre F1 micro score = 0.4042
Pre F1 macro score = 0.3411
Pre Accuracy = 0.0866

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.6446[0m        [32m0.5965[0m       [35m0.1443[0m      [31m0.3795[0m        [94m0.6767[0m     +  47.3921
      2      [36m0.8787[0m        [32m0.4123[0m       [35m0.3247[0m      [31m0.4605[0m        [94m0.6446[0m     +  47.4360
      3      [36m0.9744[0m        [32m0.3351[0m       [35m0.3557[0m      0.4604        [94m0.6158[0m     +  47.8812
      4      [36m1.0000[0m        [32m0.2708[0m       [35m0.4050[0m      [31m0.5695[0m        [94m0.5959[0m     +  46.6867
      5      1.0000        [32m0.2226[0m       [35m0.4337[0m      [31m0.6184[0m        0.5998        46.8591
      6      1.0000        [32m0.1769[0m       [35m0.4408[0m      0.6177        0.6159        46.6807
      7      1.0000        [32m0.1447[0m       [35m0.4606[0m      [31m0.6429[0m        0.6391        46.7697
      8      1.0000        [32m0.1070[0m       [35m0.4781[0m      [31m0.6808[0m        0.6334        46.4981
      9      0.9825        [32m0.0966[0m       0.4714      0.6762        0.6772        47.3193
     10      1.0000        [32m0.0764[0m       0.4665      0.6741        0.7186        47.3460
     11      1.0000        [32m0.0630[0m       0.4510      0.6684        0.7421        46.8201
Stopping since valid_loss has not improved in the last 8 epochs.
[24]
F1 Micro Score after query 1: 0.6919148936170214
F1 Macro Score after query 1: 0.6980552786227937
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.8430[0m        [32m0.3744[0m       [35m0.6134[0m      [31m0.7463[0m        [94m0.3989[0m     +  48.3084
      2      [36m0.8655[0m        [32m0.2602[0m       [35m0.6757[0m      [31m0.8140[0m        [94m0.3214[0m     +  48.5634
      3      [36m0.9145[0m        [32m0.1932[0m       [35m0.6781[0m      [31m0.8311[0m        [94m0.3023[0m     +  48.8464
      4      [36m0.9612[0m        [32m0.1429[0m       0.6637      0.8157        0.3152        47.8949
      5      [36m0.9892[0m        [32m0.0873[0m       0.6580      0.8195        0.3317        48.4417
      6      0.9815        [32m0.0689[0m       0.6597      0.8100        0.3314        48.4413
      7      0.9731        [32m0.0673[0m       0.6628      0.8102        0.3405        48.7370
      8      [36m1.0000[0m        [32m0.0412[0m       0.6644      0.8096        0.3529        48.6679
      9      1.0000        [32m0.0391[0m       0.6632      0.8109        0.3919        48.6863
     10      1.0000        [32m0.0285[0m       0.6740      0.8167        0.3825        48.8123
Stopping since valid_loss has not improved in the last 8 epochs.
[24, 56]
F1 Micro Score after query 2: 0.857665067397761
F1 Macro Score after query 2: 0.8417860884900511
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.9004[0m        [32m0.2495[0m       [35m0.6783[0m      [31m0.8017[0m        [94m0.3001[0m     +  50.1666
      2      [36m0.9081[0m        [32m0.2008[0m       [35m0.6813[0m      [31m0.8331[0m        0.3431        50.6501
      3      [36m0.9537[0m        [32m0.1516[0m       0.6632      0.7993        0.3050        50.3809
      4      [36m0.9571[0m        [32m0.1015[0m       [35m0.6925[0m      0.8281        0.3219        51.7023
      5      [36m0.9776[0m        [32m0.0929[0m       0.6524      0.8216        0.3296        50.0170
      6      [36m0.9917[0m        [32m0.0439[0m       0.6689      0.8225        0.3520        50.5905
      7      [36m0.9925[0m        0.0479       0.6740      0.8081        0.3719        50.6971
      8      [36m0.9971[0m        [32m0.0295[0m       0.6894      0.8207        0.3629        50.8967
Stopping since valid_loss has not improved in the last 8 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.8609062170706007
F1 Macro Score after query 3: 0.8460410290773747
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.8679[0m        [32m0.2282[0m       [35m0.7470[0m      [31m0.8592[0m        [94m0.2608[0m     +  54.7368
      2      [36m0.9106[0m        [32m0.1890[0m       0.7208      0.8443        0.2854        54.1435
      3      [36m0.9507[0m        [32m0.1100[0m       0.7274      0.8372        0.3139        54.3504
      4      [36m0.9635[0m        [32m0.0891[0m       0.7273      0.8458        0.3345        54.1529
      5      [36m0.9760[0m        [32m0.0581[0m       0.7208      0.8360        0.3409        54.6746
      6      [36m0.9766[0m        0.0596       0.7177      0.8421        0.3320        54.4746
      7      [36m0.9895[0m        [32m0.0395[0m       0.7066      0.8409        0.3591        55.0294
      8      [36m0.9952[0m        [32m0.0206[0m       0.7127      0.8398        0.3871        54.4332
Stopping since valid_loss has not improved in the last 8 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.859451243900488
F1 Macro Score after query 4: 0.8421588827398935
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.8737[0m        [32m0.2492[0m       [35m0.7457[0m      [31m0.8438[0m        [94m0.2449[0m     +  61.1096
      2      [36m0.9143[0m        [32m0.1655[0m       0.7250      0.8049        0.2700        61.4939
      3      [36m0.9455[0m        [32m0.1000[0m       [35m0.7566[0m      [31m0.8506[0m        [94m0.2398[0m     +  62.0074
      4      [36m0.9626[0m        [32m0.0769[0m       0.7495      [31m0.8513[0m        0.2786        61.2957
      5      [36m0.9715[0m        [32m0.0574[0m       0.7319      0.8269        0.3081        60.7682
      6      [36m0.9775[0m        0.0614       0.6634      0.7267        0.5004        61.8331
      7      0.9746        [32m0.0462[0m       0.7378      0.8079        0.3539        60.7229
      8      0.9593        0.0675       0.6778      0.8363        0.4092        61.1423
      9      0.9746        0.0602       0.7526      [31m0.8650[0m        0.3198        61.0420
     10      [36m0.9863[0m        [32m0.0344[0m       [35m0.7875[0m      [31m0.8760[0m        0.3304        61.5994
Stopping since valid_loss has not improved in the last 8 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.8837105751391465
F1 Macro Score after query 5: 0.8667627903395453
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.9277[0m        [32m0.1633[0m       [35m0.7535[0m      [31m0.8606[0m        [94m0.2383[0m     +  74.8446
      2      [36m0.9342[0m        [32m0.1256[0m       [35m0.7811[0m      [31m0.8825[0m        0.2544        73.5164
      3      [36m0.9699[0m        [32m0.0680[0m       [35m0.7969[0m      0.8621        0.2450        74.8711
      4      [36m0.9779[0m        [32m0.0603[0m       0.7672      0.8808        0.3363        74.3153
      5      [36m0.9795[0m        [32m0.0431[0m       [35m0.8009[0m      [31m0.8852[0m        0.2941        73.9559
      6      [36m0.9821[0m        [32m0.0361[0m       0.7601      0.8380        0.3165        73.8252
      7      [36m0.9868[0m        [32m0.0319[0m       0.7899      0.8799        0.2926        74.1410
      8      0.9790        0.0484       [35m0.8111[0m      [31m0.8955[0m        0.3142        73.9774
Stopping since valid_loss has not improved in the last 8 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8973986339194885
F1 Macro Score after query 6: 0.8829754565810157
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.9096[0m        [32m0.1582[0m       [35m0.7604[0m      [31m0.8790[0m        [94m0.2535[0m     +  96.2640
      2      [36m0.9479[0m        [32m0.0973[0m       [35m0.7892[0m      [31m0.8864[0m        [94m0.2127[0m     +  96.9239
      3      [36m0.9659[0m        [32m0.0696[0m       0.7809      0.8735        0.2604        96.6900
      4      [36m0.9696[0m        [32m0.0607[0m       [35m0.8241[0m      [31m0.8983[0m        [94m0.1771[0m     +  96.5665
      5      [36m0.9780[0m        [32m0.0386[0m       0.8108      0.8970        0.2477        97.0000
      6      0.9766        [32m0.0372[0m       0.7785      0.8645        0.2703        96.1549
      7      [36m0.9811[0m        [32m0.0349[0m       0.8108      0.8905        0.2584        95.8935
      8      [36m0.9853[0m        [32m0.0325[0m       0.7953      0.8911        0.2992        96.7816
      9      [36m0.9898[0m        [32m0.0213[0m       0.7622      0.8787        0.6102        93.8558
     10      [36m0.9902[0m        [32m0.0196[0m       0.7910      0.8869        0.3728        87.0488
     11      0.9860        0.0319       0.7632      0.8742        0.5244        86.0569
Stopping since valid_loss has not improved in the last 8 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.9010614395289378
F1 Macro Score after query 7: 0.8822655577835716
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9474[0m        [32m0.0982[0m       [35m0.8307[0m      [31m0.8989[0m        [94m0.1511[0m     +  126.2979
      2      [36m0.9713[0m        [32m0.0542[0m       0.8186      0.8899        0.2246        126.5675
      3      [36m0.9775[0m        [32m0.0373[0m       [35m0.8458[0m      [31m0.9127[0m        [94m0.1508[0m     +  126.3572
      4      [36m0.9802[0m        [32m0.0363[0m       0.8028      0.8812        0.2972        126.1666
      5      0.9796        0.0433       0.8028      0.8791        0.2730        127.2029
      6      [36m0.9880[0m        [32m0.0229[0m       0.8250      0.8937        0.2964        126.5952
      7      [36m0.9905[0m        [32m0.0195[0m       0.8090      0.8808        0.2640        126.6359
      8      0.9888        [32m0.0170[0m       0.7911      0.8857        0.2866        137.7748
      9      0.9887        0.0223       0.7891      0.8675        0.2737        137.7809
     10      0.9827        0.0305       0.8444      0.8950        0.1981        135.8617
Stopping since valid_loss has not improved in the last 8 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.9248830015070992
F1 Macro Score after query 8: 0.9057334404288708
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9648[0m        [32m0.0667[0m       [35m0.7628[0m      [31m0.8699[0m        [94m0.2839[0m     +  439.2962
      2      [36m0.9731[0m        [32m0.0441[0m       [35m0.8144[0m      [31m0.8978[0m        [94m0.2763[0m     +  439.3903
      3      [36m0.9753[0m        [32m0.0408[0m       0.7875      0.8837        0.3266        434.9698
      4      [36m0.9811[0m        [32m0.0336[0m       [35m0.8181[0m      [31m0.9019[0m        [94m0.2613[0m     +  432.4248
      5      [36m0.9879[0m        [32m0.0248[0m       [35m0.8226[0m      [31m0.9058[0m        0.3410        439.0578
      6      0.9856        0.0251       0.8076      0.8949        0.2961        439.1510
      7      0.9853        0.0287       0.8219      0.8863        [94m0.2475[0m     +  442.0778
      8      0.9844        0.0269       0.8167      0.8906        0.2767        443.4865
      9      [36m0.9880[0m        [32m0.0211[0m       0.8113      0.8824        0.2811        439.6369
     10      [36m0.9887[0m        0.0215       0.8108      0.8904        0.3320        440.7941
     11      [36m0.9907[0m        [32m0.0156[0m       0.7712      0.8763        0.3996        442.9668
     12      [36m0.9917[0m        [32m0.0153[0m       0.7872      0.8740        0.3732        447.8076
     13      0.9908        [32m0.0139[0m       0.8163      0.9009        0.3032        446.8128
     14      [36m0.9919[0m        0.0165       0.8045      0.8917        0.3744        443.6545
Stopping since valid_loss has not improved in the last 8 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.9185161948082502
F1 Macro Score after query 9: 0.8993945074862814
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9755[0m        [32m0.0483[0m       [35m0.8314[0m      [31m0.9008[0m        [94m0.2056[0m     +  758.1091
      2      [36m0.9828[0m        [32m0.0324[0m       0.7833      0.8752        0.2792        760.6560
      3      [36m0.9839[0m        [32m0.0272[0m       0.7974      0.8723        0.2993        755.3888
      4      [36m0.9843[0m        [32m0.0253[0m       0.7809      0.8924        0.3507        741.3435
      5      [36m0.9855[0m        0.0257       0.8035      0.8795        0.2827        738.3815
      6      [36m0.9873[0m        [32m0.0196[0m       0.8033      0.8880        0.3591        737.1607
      7      [36m0.9903[0m        [32m0.0170[0m       0.7882      0.8663        0.4013        538.6806
      8      0.9902        0.0171       0.7429      0.8570        0.5345        319.8154
Stopping since valid_loss has not improved in the last 8 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.903544804503271
F1 Macro Score after query 10: 0.8877406510829692
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9738[0m        [32m0.0527[0m       [35m0.8113[0m      [31m0.8899[0m        [94m0.1802[0m     +  539.3215
      2      [36m0.9769[0m        [32m0.0391[0m       [35m0.8149[0m      0.8842        0.2097        542.1252
      3      [36m0.9805[0m        [32m0.0335[0m       0.7950      0.8761        0.2184        545.6425
      4      [36m0.9824[0m        [32m0.0274[0m       [35m0.8156[0m      [31m0.8910[0m        0.2565        542.3368
      5      [36m0.9837[0m        [32m0.0264[0m       0.8130      [31m0.8930[0m        0.2726        543.2344
      6      [36m0.9861[0m        [32m0.0222[0m       0.7894      0.8768        0.3390        542.1562
      7      [36m0.9876[0m        [32m0.0206[0m       0.8063      0.8809        0.3364        543.1120
      8      [36m0.9893[0m        [32m0.0180[0m       0.7910      0.8621        0.3424        542.0724
Stopping since valid_loss has not improved in the last 8 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.9241455521351329
F1 Macro Score after query 11: 0.9071288809251236
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9726[0m        [32m0.0480[0m       [35m0.8293[0m      [31m0.8914[0m        [94m0.2086[0m     +  933.8561
      2      [36m0.9772[0m        [32m0.0391[0m       0.7806      0.8825        0.2475        938.4996
      3      [36m0.9794[0m        [32m0.0333[0m       0.8189      [31m0.8955[0m        0.2525        939.0330
      4      [36m0.9818[0m        [32m0.0290[0m       0.7882      0.8825        0.3202        939.3743
      5      [36m0.9838[0m        [32m0.0257[0m       0.8082      0.8753        0.2789        934.8604
      6      [36m0.9853[0m        [32m0.0233[0m       0.8080      0.8720        0.3000        940.5137
      7      [36m0.9876[0m        [32m0.0191[0m       0.8010      0.8875        0.3231        940.2423
      8      [36m0.9884[0m        [32m0.0172[0m       0.8078      0.8891        0.3332        936.6721
Stopping since valid_loss has not improved in the last 8 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.9133078135555055
F1 Macro Score after query 12: 0.8980010626524907
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp        dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ---------
      1      [36m0.9752[0m        [32m0.0414[0m       [35m0.8297[0m      [31m0.9066[0m        [94m0.2361[0m     +  1099.0339
      2      [36m0.9785[0m        [32m0.0346[0m       [35m0.8319[0m      0.9057        [94m0.2266[0m     +  1103.1886
      3      [36m0.9810[0m        [32m0.0290[0m       0.8203      0.9018        0.2609        1095.2406
      4      [36m0.9835[0m        [32m0.0257[0m       0.8271      0.9059        0.3752        1097.0928
      5      [36m0.9850[0m        [32m0.0228[0m       0.7979      0.8850        0.3491        1098.2383
      6      [36m0.9866[0m        [32m0.0213[0m       0.8314      0.9048        0.3158        1093.9856
      7      [36m0.9882[0m        [32m0.0180[0m       [35m0.8378[0m      0.9061        0.2948        1093.9042
      8      [36m0.9894[0m        [32m0.0166[0m       0.8125      0.8932        0.3428        1094.5614
      9      [36m0.9914[0m        [32m0.0137[0m       0.8200      0.8963        0.3393        1094.6399
Stopping since valid_loss has not improved in the last 8 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.9133727093745266
F1 Macro Score after query 13: 0.8957989510706401
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/EffNet/average_confidence_seed42\AL_average_confidence_results_for_multilabel_classification.pickle
