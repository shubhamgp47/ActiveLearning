Train set shape: (26880, 5)
Val set shape:   (5760, 5)
Test set shape:  (5760, 5)
Selected images DataFrame (Random Sampling):
   Query_Iteration                                     Selected_Image
0                1  Spule035_Image0269.jpg,Spule020_Image0191.jpg,...
1                2  Spule038_Image0730.jpg,Spule003_Image0380.jpg,...
2                3  Spule008_Image0826.jpg,Spule036_Image0204.jpg,...
3                4  Spule013_Image0726.jpg,Spule015_Image0930.jpg,...
4                5  Spule030_Image0776.jpg,Spule005_Image0100.jpg,...

Query 1: Using the exact images and labels from the CSV for this iteration.

Query 1: Using images from iteration=1 (random sampling).
Number of samples used for training in Query 1 is 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.4889[0m        [32m0.7147[0m       [35m0.0043[0m      [31m0.3553[0m        [94m0.7135[0m     +  0.0000  7.9343
      2      [36m0.5407[0m        [32m0.6860[0m       [35m0.0611[0m      0.3443        [94m0.7031[0m     +  0.0000  7.3764
      3      [36m0.6869[0m        [32m0.6747[0m       [35m0.0757[0m      [31m0.3881[0m        0.7088        0.0000  7.3888
      4      0.6571        [32m0.6566[0m       [35m0.0868[0m      [31m0.4815[0m        [94m0.6940[0m     +  0.0000  7.4374
      5      0.6556        0.6593       [35m0.1030[0m      0.4437        0.7014        0.0000  7.4997
      6      [36m0.7833[0m        [32m0.6286[0m       [35m0.1050[0m      0.4355        0.7012        0.0000  7.5625
      7      0.7685        [32m0.6054[0m       [35m0.1090[0m      0.4444        0.6967        0.0000  7.5688
      8      [36m0.8487[0m        [32m0.5847[0m       [35m0.1099[0m      0.4448        [94m0.6934[0m     +  0.0000  7.6407
      9      0.8320        0.5978       0.1026      0.4512        [94m0.6907[0m     +  0.0000  7.6110
     10      0.6944        0.6178       0.1080      0.4482        [94m0.6904[0m     +  0.0000  7.6123
     11      [36m0.8796[0m        [32m0.5755[0m       0.1075      0.4491        [94m0.6903[0m     +  0.0000  7.6328
     12      0.8024        [32m0.5614[0m       0.1083      0.4495        [94m0.6894[0m     +  0.0000  7.6750
     13      0.8258        0.5746       0.1059      0.4511        [94m0.6884[0m     +  0.0000  7.6905
     14      0.7685        0.5952       0.1073      0.4558        [94m0.6879[0m     +  0.0000  7.6746
     15      0.7857        0.5727       0.1082      0.4546        0.6879        0.0000  7.6922
     16      [36m0.8889[0m        [32m0.5465[0m       0.1083      0.4533        0.6883        0.0000  7.6688
     17      0.7857        0.5623       0.1082      0.4545        0.6880        0.0000  7.7204
     18      0.8320        0.5548       0.1080      0.4544        0.6884        0.0000  7.7344
     19      [36m0.9153[0m        0.5681       0.1076      0.4553        0.6883        0.0000  7.7041
     20      0.8796        [32m0.5455[0m       0.1078      0.4566        0.6880        0.0000  7.6945
     21      0.7833        0.5698       0.1076      0.4561        0.6881        0.0000  7.7661
     22      0.8381        0.5664       0.1082      0.4567        0.6880        0.0000  7.7120
     23      0.8500        0.5522       0.1082      0.4567        0.6880        0.0000  7.6835
     24      0.8783        0.5501       0.1083      0.4573        0.6880        0.0000  7.7662
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 1 Test Accuracy: 0.1594
Iteration 1 Test F1 Score (micro): 0.4832
Iteration 1 Test F1 Score (macro): 0.4798
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_0.pt

Query 2: Using the exact images and labels from the CSV for this iteration.

Query 2: Using images from iteration=2 (random sampling).
Number of samples used for training in Query 2 is 24
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.6463[0m        [32m0.6289[0m       [35m0.3444[0m      [31m0.1649[0m        [94m0.6708[0m     +  0.0000  7.7910
      2      0.3881        [32m0.5994[0m       [35m0.4439[0m      0.1270        [94m0.6568[0m     +  0.0000  7.6718
      3      0.4325        [32m0.5752[0m       0.4186      [31m0.2487[0m        [94m0.6494[0m     +  0.0000  7.6908
      4      0.5032        [32m0.5355[0m       [35m0.4562[0m      [31m0.3570[0m        [94m0.6465[0m     +  0.0000  7.6970
      5      0.6222        [32m0.5282[0m       0.4446      0.2521        [94m0.6428[0m     +  0.0000  7.7662
      6      0.4127        0.5320       [35m0.4722[0m      [31m0.3854[0m        [94m0.6318[0m     +  0.0000  7.6523
      7      0.5712        [32m0.5120[0m       [35m0.4781[0m      0.2962        [94m0.6305[0m     +  0.0000  7.6730
      8      0.5966        [32m0.4973[0m       [35m0.4898[0m      [31m0.3965[0m        [94m0.6233[0m     +  0.0000  7.6749
      9      [36m0.6605[0m        0.5004       0.4821      0.3505        [94m0.6220[0m     +  0.0000  7.7499
     10      [36m0.7845[0m        [32m0.4781[0m       0.4811      0.3452        [94m0.6190[0m     +  0.0000  7.6715
     11      0.6786        [32m0.4758[0m       0.4891      0.3691        [94m0.6172[0m     +  0.0000  7.6563
     12      0.7037        [32m0.4731[0m       [35m0.4913[0m      0.3752        [94m0.6150[0m     +  0.0000  7.6355
     13      0.6755        [32m0.4612[0m       0.4894      0.3770        [94m0.6135[0m     +  0.0000  7.6790
     14      [36m0.8199[0m        [32m0.4568[0m       0.4911      0.3832        [94m0.6131[0m     +  0.0000  7.7391
     15      0.6903        0.4620       [35m0.4938[0m      [31m0.3991[0m        [94m0.6115[0m     +  0.0000  7.7540
     16      0.7421        0.4609       [35m0.4939[0m      0.3985        [94m0.6111[0m     +  0.0000  7.7590
     17      0.7845        0.4582       [35m0.4943[0m      [31m0.4005[0m        [94m0.6110[0m     +  0.0000  7.6885
     18      [36m0.8646[0m        [32m0.4460[0m       0.4938      0.3961        0.6112        0.0000  7.6550
     19      0.8099        0.4706       [35m0.4946[0m      0.3978        [94m0.6106[0m     +  0.0000  7.6691
     20      0.6962        0.4577       0.4943      0.3977        [94m0.6102[0m     +  0.0000  7.6904
     21      0.7845        [32m0.4433[0m       [35m0.4948[0m      0.3993        [94m0.6099[0m     +  0.0000  7.6601
     22      0.7238        0.4561       0.4944      0.4003        [94m0.6097[0m     +  0.0000  7.7370
     23      0.8099        0.4448       0.4946      0.3996        [94m0.6096[0m     +  0.0000  7.6534
     24      0.6786        0.4501       0.4943      0.3986        [94m0.6095[0m     +  0.0000  7.6379
     25      0.7421        0.4602       0.4946      0.3989        [94m0.6094[0m     +  0.0000  7.6727
     26      0.6720        0.4526       0.4948      0.3993        [94m0.6093[0m     +  0.0000  7.7671
     27      0.7421        0.4652       0.4948      0.4004        [94m0.6092[0m     +  0.0000  7.7206
     28      0.6731        0.4530       [35m0.4950[0m      [31m0.4015[0m        [94m0.6091[0m     +  0.0000  7.6549
     29      0.7675        0.4616       0.4950      [31m0.4015[0m        [94m0.6090[0m     +  0.0000  7.6770
     30      [36m0.8746[0m        0.4549       0.4950      0.4013        [94m0.6090[0m     +  0.0000  7.7487
     31      0.7556        0.4546       0.4950      [31m0.4018[0m        [94m0.6089[0m     +  0.0000  7.6457
     32      0.6903        0.4582       [35m0.4951[0m      [31m0.4019[0m        [94m0.6089[0m     +  0.0000  7.6556
     33      0.6903        0.4443       0.4951      0.4017        [94m0.6089[0m     +  0.0000  7.6997
     34      0.6509        0.4720       0.4951      0.4019        [94m0.6089[0m     +  0.0000  7.6991
     35      0.7037        0.4554       0.4951      0.4018        [94m0.6089[0m     +  0.0000  7.6731
     36      0.7421        0.4519       0.4951      [31m0.4020[0m        [94m0.6088[0m     +  0.0000  7.6383
     37      0.7504        0.4514       0.4950      0.4020        [94m0.6088[0m     +  0.0000  7.6962
     38      0.6889        0.4730       0.4950      [31m0.4021[0m        [94m0.6088[0m     +  0.0000  7.6877
     39      0.7079        0.4540       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.6738
     40      0.8322        [32m0.4417[0m       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.6523
     41      0.8453        0.4511       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.6715
     42      0.7157        0.4469       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.7532
     43      0.7845        0.4452       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.6874
     44      0.7128        0.4570       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.7042
     45      0.7128        0.4539       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.7026
     46      0.7239        0.4578       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.6556
     47      0.8302        0.4465       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.6544
     48      0.7897        0.4547       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.6854
     49      0.7421        0.4594       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.7227
     50      0.7421        0.4513       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.6334
     51      0.7552        [32m0.4414[0m       0.4950      0.4021        0.6088        0.0000  7.6667
     52      0.7128        0.4473       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.7068
     53      0.7675        [32m0.4368[0m       0.4950      0.4021        [94m0.6088[0m     +  0.0000  7.6547
     54      0.7845        0.4498       0.4950      0.4021        0.6088        0.0000  7.7345
     55      0.7231        0.4429       0.4950      0.4021        0.6088        0.0000  7.6727
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 2 Test Accuracy: 0.5318
Iteration 2 Test F1 Score (micro): 0.5219
Iteration 2 Test F1 Score (macro): 0.4859
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_1.pt

Query 3: Using the exact images and labels from the CSV for this iteration.

Query 3: Using images from iteration=3 (random sampling).
Number of samples used for training in Query 3 is 56
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.6463[0m        [32m0.4809[0m       [35m0.4479[0m      [31m0.0000[0m        [94m0.6443[0m     +  0.0000  7.8263
      2      0.0000        0.5161       [35m0.5137[0m      [31m0.5879[0m        [94m0.5456[0m     +  0.0000  7.8445
      3      0.6328        [32m0.4725[0m       0.4479      0.0045        0.6349        0.0000  7.7304
      4      0.1465        0.4776       [35m0.5151[0m      0.4896        [94m0.5184[0m     +  0.0000  7.7635
      5      0.6351        [32m0.4060[0m       0.4811      0.3567        0.5355        0.0000  7.7501
      6      0.6406        [32m0.3862[0m       0.5120      0.4684        [94m0.5147[0m     +  0.0000  7.7658
      7      [36m0.7238[0m        0.3876       [35m0.5238[0m      0.5056        [94m0.5039[0m     +  0.0000  7.7659
      8      [36m0.7351[0m        [32m0.3791[0m       [35m0.5250[0m      0.5152        [94m0.4994[0m     +  0.0000  7.7215
      9      [36m0.7424[0m        0.3823       [35m0.5276[0m      0.5376        [94m0.4915[0m     +  0.0000  7.7658
     10      [36m0.7478[0m        [32m0.3705[0m       0.5262      0.5350        [94m0.4891[0m     +  0.0000  7.7476
     11      0.7369        [32m0.3691[0m       0.5252      0.5369        [94m0.4882[0m     +  0.0000  7.7202
     12      [36m0.8371[0m        [32m0.3590[0m       0.5245      0.5333        0.4885        0.0000  7.7309
     13      0.8198        [32m0.3563[0m       0.5229      0.5362        [94m0.4870[0m     +  0.0000  7.7703
     14      [36m0.8427[0m        0.3611       0.5208      0.5379        [94m0.4867[0m     +  0.0000  7.7177
     15      0.7642        0.3588       0.5215      0.5437        [94m0.4850[0m     +  0.0000  7.8123
     16      0.8250        [32m0.3525[0m       0.5207      0.5439        [94m0.4848[0m     +  0.0000  7.7373
     17      [36m0.8615[0m        [32m0.3502[0m       0.5208      0.5425        0.4848        0.0000  7.7354
     18      0.8552        0.3532       0.5207      0.5424        [94m0.4845[0m     +  0.0000  7.7676
     19      0.8366        0.3513       0.5203      0.5455        [94m0.4836[0m     +  0.0000  7.7562
     20      0.8431        0.3546       0.5201      0.5445        [94m0.4836[0m     +  0.0000  7.7299
     21      0.8169        [32m0.3464[0m       0.5200      0.5455        [94m0.4833[0m     +  0.0000  7.7408
     22      0.8427        0.3468       0.5200      0.5460        [94m0.4829[0m     +  0.0000  7.7189
     23      0.8600        [32m0.3408[0m       0.5205      0.5482        [94m0.4825[0m     +  0.0000  7.7413
     24      0.8198        0.3486       0.5200      0.5482        [94m0.4824[0m     +  0.0000  7.7256
     25      0.8435        0.3541       0.5201      0.5491        [94m0.4822[0m     +  0.0000  7.8284
     26      0.7685        0.3593       0.5201      0.5496        [94m0.4821[0m     +  0.0000  7.7188
     27      0.7982        0.3508       0.5203      0.5497        [94m0.4820[0m     +  0.0000  7.7229
     28      0.8107        0.3498       0.5201      0.5500        [94m0.4820[0m     +  0.0000  7.8140
     29      0.7996        0.3569       0.5201      0.5499        [94m0.4819[0m     +  0.0000  7.7383
     30      0.7774        0.3517       0.5203      0.5504        [94m0.4818[0m     +  0.0000  7.7333
     31      0.7993        0.3452       0.5205      0.5505        [94m0.4818[0m     +  0.0000  7.7342
     32      0.8396        0.3466       0.5205      0.5506        [94m0.4817[0m     +  0.0000  7.7346
     33      0.8002        0.3493       0.5205      0.5506        [94m0.4817[0m     +  0.0000  7.7662
     34      0.8371        0.3567       0.5203      0.5505        [94m0.4817[0m     +  0.0000  7.7652
     35      0.8002        0.3553       0.5203      0.5505        [94m0.4817[0m     +  0.0000  7.7667
     36      0.7338        0.3480       0.5203      0.5505        [94m0.4817[0m     +  0.0000  7.7518
     37      0.8313        0.3488       0.5201      0.5505        [94m0.4817[0m     +  0.0000  7.7594
     38      0.8487        0.3462       0.5203      0.5506        [94m0.4816[0m     +  0.0000  7.7813
     39      0.7996        0.3568       0.5203      0.5506        [94m0.4816[0m     +  0.0000  7.8161
     40      0.7685        0.3642       0.5203      0.5506        [94m0.4816[0m     +  0.0000  7.7288
     41      0.8052        0.3494       0.5203      0.5506        [94m0.4816[0m     +  0.0000  7.7352
     42      0.8110        0.3475       0.5201      0.5505        [94m0.4816[0m     +  0.0000  7.7362
     43      0.8427        0.3428       0.5201      0.5505        [94m0.4816[0m     +  0.0000  7.7498
     44      [36m0.8665[0m        [32m0.3392[0m       0.5203      0.5506        [94m0.4816[0m     +  0.0000  7.7291
     45      [36m0.8725[0m        0.3522       0.5201      0.5505        [94m0.4816[0m     +  0.0000  7.7326
     46      0.8198        0.3557       0.5201      0.5505        [94m0.4816[0m     +  0.0000  7.8266
     47      0.7797        0.3479       0.5201      0.5505        [94m0.4816[0m     +  0.0000  7.7820
     48      0.8240        0.3460       0.5201      0.5505        [94m0.4816[0m     +  0.0000  7.7169
     49      0.8312        0.3500       0.5201      0.5505        [94m0.4816[0m     +  0.0000  7.7315
     50      0.7774        0.3497       0.5201      0.5505        [94m0.4816[0m     +  0.0000  7.7541
     51      0.8313        0.3523       0.5201      0.5505        [94m0.4816[0m     +  0.0000  7.8494
     52      0.8121        0.3591       0.5201      0.5505        [94m0.4816[0m     +  0.0000  7.7372
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 3 Test Accuracy: 0.5774
Iteration 3 Test F1 Score (micro): 0.6596
Iteration 3 Test F1 Score (macro): 0.6405
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_2.pt

Query 4: Using the exact images and labels from the CSV for this iteration.

Query 4: Using images from iteration=4 (random sampling).
Number of samples used for training in Query 4 is 112
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8162[0m        [32m0.3848[0m       [35m0.6033[0m      [31m0.7918[0m        [94m0.4964[0m     +  0.0000  8.0486
      2      0.7861        0.4919       0.4627      0.3179        0.5139        0.0000  7.9185
      3      0.6081        0.4157       [35m0.6870[0m      [31m0.8317[0m        [94m0.4131[0m     +  0.0000  7.8933
      4      [36m0.9052[0m        [32m0.3569[0m       0.6358      0.7656        [94m0.4116[0m     +  0.0000  7.8859
      5      0.8877        [32m0.3400[0m       0.6590      0.8069        [94m0.4018[0m     +  0.0000  7.8889
      6      [36m0.9348[0m        [32m0.3248[0m       0.6524      0.7982        [94m0.4016[0m     +  0.0000  7.9475
      7      0.9088        0.3271       0.6523      0.7965        [94m0.4006[0m     +  0.0000  7.9118
      8      0.9011        0.3284       0.6545      0.7972        [94m0.3988[0m     +  0.0000  7.9368
      9      0.9125        [32m0.3183[0m       0.6559      0.8010        [94m0.3964[0m     +  0.0000  7.9373
     10      0.9105        [32m0.3143[0m       0.6552      0.7988        [94m0.3961[0m     +  0.0000  7.9201
     11      0.9170        0.3156       0.6557      0.7993        [94m0.3959[0m     +  0.0000  7.9215
     12      0.9309        0.3173       0.6556      0.7986        [94m0.3957[0m     +  0.0000  7.9781
     13      0.9206        0.3218       0.6561      0.7988        [94m0.3953[0m     +  0.0000  7.8919
     14      0.9143        0.3151       0.6561      0.7990        [94m0.3946[0m     +  0.0000  7.9037
     15      0.9163        0.3215       0.6562      0.7998        [94m0.3941[0m     +  0.0000  7.9408
     16      0.9246        0.3169       0.6562      0.8000        [94m0.3939[0m     +  0.0000  7.9011
     17      0.9069        [32m0.3136[0m       0.6566      0.8003        [94m0.3937[0m     +  0.0000  7.9207
     18      0.9255        0.3150       0.6569      0.8008        [94m0.3935[0m     +  0.0000  7.9255
     19      [36m0.9365[0m        [32m0.3120[0m       0.6568      0.8006        [94m0.3933[0m     +  0.0000  7.9212
     20      0.9223        [32m0.3073[0m       0.6569      0.8008        [94m0.3932[0m     +  0.0000  7.9343
     21      0.9235        0.3082       0.6569      0.8009        [94m0.3931[0m     +  0.0000  7.9063
     22      0.9216        [32m0.3067[0m       0.6566      0.8006        [94m0.3930[0m     +  0.0000  7.9376
     23      0.8968        0.3142       0.6564      0.8004        [94m0.3930[0m     +  0.0000  7.9821
     24      0.9206        0.3154       0.6564      0.8004        [94m0.3929[0m     +  0.0000  8.0769
     25      0.9245        0.3103       0.6568      0.8006        [94m0.3928[0m     +  0.0000  7.9303
     26      0.8965        0.3118       0.6569      0.8008        [94m0.3928[0m     +  0.0000  7.9052
     27      0.9145        0.3153       0.6569      0.8008        [94m0.3928[0m     +  0.0000  7.9241
     28      0.9309        [32m0.3046[0m       0.6569      0.8008        [94m0.3928[0m     +  0.0000  7.9667
     29      0.9190        0.3156       0.6573      0.8011        [94m0.3928[0m     +  0.0000  7.9063
     30      0.9354        0.3171       0.6573      0.8012        [94m0.3927[0m     +  0.0000  7.8894
     31      0.9190        0.3195       0.6573      0.8012        [94m0.3927[0m     +  0.0000  7.9690
     32      0.9170        0.3164       0.6573      0.8012        [94m0.3927[0m     +  0.0000  7.9055
     33      [36m0.9390[0m        0.3173       0.6573      0.8012        [94m0.3927[0m     +  0.0000  7.9218
     34      0.9024        0.3163       0.6573      0.8012        [94m0.3927[0m     +  0.0000  7.8994
     35      0.8941        0.3161       0.6573      0.8012        [94m0.3927[0m     +  0.0000  7.9219
     36      0.9135        0.3127       0.6573      0.8012        [94m0.3926[0m     +  0.0000  7.9729
     37      0.9309        0.3135       0.6573      0.8012        [94m0.3926[0m     +  0.0000  7.9045
     38      0.9166        0.3117       0.6573      0.8012        0.3926        0.0000  7.9383
     39      0.9226        0.3147       0.6573      0.8012        [94m0.3926[0m     +  0.0000  7.9331
     40      0.9096        [32m0.3023[0m       0.6573      0.8012        [94m0.3926[0m     +  0.0000  7.9082
     41      0.9097        0.3155       0.6573      0.8012        [94m0.3926[0m     +  0.0000  7.9049
     42      0.9042        0.3139       0.6573      0.8012        [94m0.3926[0m     +  0.0000  7.9373
     43      0.9108        0.3106       0.6573      0.8012        [94m0.3926[0m     +  0.0000  7.9409
     44      0.9004        0.3148       0.6573      0.8012        [94m0.3926[0m     +  0.0000  7.9862
     45      0.9134        0.3182       0.6573      0.8012        [94m0.3926[0m     +  0.0000  7.9208
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 4 Test Accuracy: 0.7304
Iteration 4 Test F1 Score (micro): 0.8486
Iteration 4 Test F1 Score (macro): 0.8422
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_3.pt

Query 5: Using the exact images and labels from the CSV for this iteration.

Query 5: Using images from iteration=5 (random sampling).
Number of samples used for training in Query 5 is 208
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8861[0m        [32m0.3369[0m       [35m0.4915[0m      [31m0.3465[0m        [94m0.4927[0m     +  0.0000  8.2823
      2      0.6875        0.3843       [35m0.6811[0m      [31m0.8156[0m        [94m0.3597[0m     +  0.0000  8.2188
      3      0.8817        [32m0.3115[0m       0.6781      0.8112        [94m0.3516[0m     +  0.0000  8.1907
      4      0.8750        [32m0.2984[0m       0.6656      0.8055        [94m0.3474[0m     +  0.0000  8.1832
      5      0.8783        [32m0.2981[0m       0.6731      0.8130        [94m0.3410[0m     +  0.0000  8.1684
      6      0.8742        [32m0.2876[0m       0.6734      0.8129        [94m0.3400[0m     +  0.0000  8.1719
      7      [36m0.8961[0m        0.2905       0.6715      0.8110        [94m0.3394[0m     +  0.0000  8.2032
      8      0.8875        [32m0.2805[0m       0.6733      0.8129        [94m0.3379[0m     +  0.0000  8.1848
      9      0.8870        0.2878       0.6762      0.8151        [94m0.3361[0m     +  0.0000  8.2085
     10      0.8758        0.2815       0.6726      0.8111        [94m0.3358[0m     +  0.0000  8.1735
     11      [36m0.9025[0m        [32m0.2729[0m       0.6753      0.8140        [94m0.3353[0m     +  0.0000  8.1559
     12      0.8969        0.2757       0.6743      0.8130        [94m0.3352[0m     +  0.0000  8.1261
     13      0.9016        [32m0.2720[0m       0.6771      0.8147        [94m0.3341[0m     +  0.0000  8.1545
     14      0.8965        0.2743       0.6793      [31m0.8163[0m        [94m0.3334[0m     +  0.0000  8.2657
     15      0.8941        0.2763       0.6792      0.8161        [94m0.3332[0m     +  0.0000  8.1689
     16      [36m0.9071[0m        [32m0.2708[0m       0.6786      0.8158        [94m0.3331[0m     +  0.0000  8.1426
     17      0.9024        0.2734       0.6800      [31m0.8167[0m        [94m0.3328[0m     +  0.0000  8.2344
     18      0.8943        0.2716       0.6800      0.8166        [94m0.3327[0m     +  0.0000  8.1706
     19      0.8957        0.2715       0.6806      [31m0.8170[0m        [94m0.3325[0m     +  0.0000  8.2210
     20      0.8934        0.2775       0.6807      [31m0.8172[0m        [94m0.3324[0m     +  0.0000  8.1987
     21      0.9028        [32m0.2685[0m       0.6806      0.8170        0.3324        0.0000  8.1409
     22      0.8985        0.2722       0.6795      0.8162        0.3325        0.0000  8.2342
     23      0.8916        0.2739       0.6802      0.8166        [94m0.3324[0m     +  0.0000  8.1899
     24      0.9069        [32m0.2668[0m       0.6799      0.8163        [94m0.3324[0m     +  0.0000  8.1668
     25      [36m0.9159[0m        0.2672       0.6793      0.8160        0.3324        0.0000  8.1987
     26      0.8990        [32m0.2668[0m       0.6793      0.8158        0.3324        0.0000  8.2074
     27      0.9056        0.2696       0.6792      0.8156        0.3324        0.0000  8.1875
     28      0.9083        0.2676       0.6790      0.8155        0.3324        0.0000  8.1934
     29      0.9129        [32m0.2641[0m       0.6788      0.8154        0.3324        0.0000  8.1834
     30      0.8916        0.2718       0.6785      0.8153        0.3324        0.0000  8.2075
     31      0.8971        0.2739       0.6785      0.8153        0.3324        0.0000  8.2222
     32      0.8879        0.2651       0.6785      0.8154        0.3324        0.0000  8.2698
     33      0.8979        0.2746       0.6786      0.8155        0.3324        0.0000  8.2224
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 5 Test Accuracy: 0.7394
Iteration 5 Test F1 Score (micro): 0.8683
Iteration 5 Test F1 Score (macro): 0.8571
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_4.pt

Query 6: Using the exact images and labels from the CSV for this iteration.

Query 6: Using images from iteration=6 (random sampling).
Number of samples used for training in Query 6 is 384
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8813[0m        [32m0.3050[0m       [35m0.4939[0m      [31m0.3889[0m        [94m0.4913[0m     +  0.0000  8.7305
      2      0.8101        0.3243       [35m0.6783[0m      [31m0.8079[0m        [94m0.3142[0m     +  0.0000  8.6406
      3      [36m0.8973[0m        [32m0.2762[0m       [35m0.6880[0m      [31m0.8186[0m        [94m0.3088[0m     +  0.0000  8.6501
      4      0.8943        [32m0.2702[0m       [35m0.6932[0m      [31m0.8242[0m        [94m0.3057[0m     +  0.0000  8.6361
      5      [36m0.9035[0m        [32m0.2622[0m       [35m0.6974[0m      [31m0.8288[0m        [94m0.3028[0m     +  0.0000  8.6853
      6      0.9020        0.2647       0.6924      0.8238        [94m0.3025[0m     +  0.0000  8.6395
      7      0.9020        [32m0.2578[0m       0.6925      0.8232        0.3026        0.0000  8.6402
      8      [36m0.9051[0m        0.2596       0.6918      0.8233        [94m0.3017[0m     +  0.0000  8.6484
      9      [36m0.9125[0m        0.2583       0.6905      0.8217        [94m0.3011[0m     +  0.0000  8.5946
     10      0.9046        [32m0.2531[0m       0.6922      0.8234        [94m0.3006[0m     +  0.0000  8.6910
     11      [36m0.9173[0m        [32m0.2499[0m       0.6944      0.8262        [94m0.3001[0m     +  0.0000  8.6346
     12      0.9102        [32m0.2499[0m       0.6951      0.8269        [94m0.2999[0m     +  0.0000  8.6302
     13      0.9062        0.2527       0.6934      0.8248        [94m0.2998[0m     +  0.0000  8.6056
     14      0.9084        0.2508       0.6951      0.8265        [94m0.2996[0m     +  0.0000  8.6482
     15      [36m0.9197[0m        [32m0.2471[0m       0.6958      0.8272        [94m0.2993[0m     +  0.0000  8.6779
     16      0.9182        0.2503       0.6955      0.8267        [94m0.2992[0m     +  0.0000  8.7615
     17      0.9172        0.2486       0.6951      0.8263        [94m0.2991[0m     +  0.0000  8.6566
     18      0.9190        0.2533       0.6958      0.8269        [94m0.2991[0m     +  0.0000  8.6134
     19      0.9152        0.2476       0.6965      0.8276        [94m0.2990[0m     +  0.0000  8.6381
     20      [36m0.9232[0m        [32m0.2469[0m       0.6962      0.8269        [94m0.2990[0m     +  0.0000  8.6685
     21      0.9121        0.2504       0.6962      0.8269        0.2990        0.0000  8.6812
     22      0.9150        [32m0.2431[0m       0.6962      0.8271        [94m0.2989[0m     +  0.0000  8.6080
     23      0.9203        0.2510       0.6964      0.8272        [94m0.2989[0m     +  0.0000  8.6097
     24      0.9211        0.2502       0.6965      0.8273        0.2989        0.0000  8.7065
     25      0.9115        0.2477       0.6965      0.8277        [94m0.2988[0m     +  0.0000  8.7046
     26      0.9221        0.2475       0.6965      0.8277        [94m0.2988[0m     +  0.0000  8.6722
     27      0.9118        0.2490       0.6965      0.8277        [94m0.2988[0m     +  0.0000  8.6237
     28      0.9089        0.2511       0.6965      0.8276        [94m0.2988[0m     +  0.0000  8.6885
     29      0.9152        0.2486       0.6965      0.8276        [94m0.2987[0m     +  0.0000  8.6142
     30      0.9173        0.2460       0.6965      0.8276        [94m0.2987[0m     +  0.0000  8.6148
     31      0.9155        0.2487       0.6965      0.8277        0.2987        0.0000  8.6981
     32      0.9061        0.2514       0.6965      0.8276        0.2987        0.0000  8.6611
     33      0.9196        0.2487       0.6967      0.8275        0.2987        0.0000  8.6744
     34      0.9225        0.2473       0.6967      0.8275        0.2987        0.0000  8.5944
     35      0.9100        0.2456       0.6967      0.8275        0.2987        0.0000  8.6304
     36      0.9042        0.2495       0.6967      0.8275        0.2987        0.0000  8.6024
     37      0.9184        0.2519       0.6965      0.8276        [94m0.2987[0m     +  0.0000  8.5956
     38      0.9189        0.2481       0.6965      0.8276        [94m0.2987[0m     +  0.0000  8.6477
     39      0.9132        0.2507       0.6965      0.8275        0.2987        0.0000  8.6171
     40      0.9148        0.2520       0.6967      0.8278        [94m0.2987[0m     +  0.0000  8.6150
     41      0.9170        0.2458       0.6967      0.8278        [94m0.2987[0m     +  0.0000  8.6026
     42      0.9151        [32m0.2423[0m       0.6967      0.8278        [94m0.2987[0m     +  0.0000  8.7400
     43      0.9112        0.2449       0.6967      0.8278        0.2987        0.0000  8.7129
     44      0.9115        0.2482       0.6967      0.8278        [94m0.2987[0m     +  0.0000  8.6118
     45      0.9206        0.2470       0.6967      0.8278        [94m0.2987[0m     +  0.0000  8.6000
     46      0.9072        0.2472       0.6967      0.8278        [94m0.2987[0m     +  0.0000  8.6810
     47      0.9104        0.2478       0.6967      0.8278        [94m0.2987[0m     +  0.0000  8.6349
     48      0.9138        0.2483       0.6967      0.8278        [94m0.2987[0m     +  0.0000  8.6149
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 6 Test Accuracy: 0.7547
Iteration 6 Test F1 Score (micro): 0.8789
Iteration 6 Test F1 Score (macro): 0.8671
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_5.pt

Query 7: Using the exact images and labels from the CSV for this iteration.

Query 7: Using images from iteration=7 (random sampling).
Number of samples used for training in Query 7 is 704
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  ------
      1      [36m0.8500[0m        [32m0.3073[0m       [35m0.7089[0m      [31m0.8328[0m        [94m0.2911[0m     +  0.0000  9.6774
      2      [36m0.9047[0m        [32m0.2579[0m       0.7019      0.8245        [94m0.2869[0m     +  0.0000  9.4956
      3      [36m0.9143[0m        [32m0.2518[0m       0.6972      0.8156        [94m0.2845[0m     +  0.0000  9.3976
      4      [36m0.9156[0m        [32m0.2456[0m       0.7019      0.8171        [94m0.2820[0m     +  0.0000  9.4796
      5      [36m0.9187[0m        [32m0.2433[0m       [35m0.7113[0m      0.8276        [94m0.2798[0m     +  0.0000  9.4738
      6      0.9146        [32m0.2392[0m       [35m0.7115[0m      0.8245        [94m0.2773[0m     +  0.0000  9.4322
      7      [36m0.9213[0m        [32m0.2373[0m       [35m0.7141[0m      0.8276        [94m0.2765[0m     +  0.0000  9.4881
      8      [36m0.9221[0m        0.2380       [35m0.7200[0m      0.8314        [94m0.2757[0m     +  0.0000  9.4321
      9      [36m0.9273[0m        [32m0.2347[0m       [35m0.7227[0m      [31m0.8332[0m        [94m0.2750[0m     +  0.0000  9.4788
     10      0.9267        [32m0.2340[0m       [35m0.7231[0m      [31m0.8335[0m        [94m0.2745[0m     +  0.0000  9.4512
     11      [36m0.9294[0m        [32m0.2300[0m       [35m0.7276[0m      [31m0.8379[0m        [94m0.2738[0m     +  0.0000  9.4447
     12      [36m0.9306[0m        [32m0.2289[0m       [35m0.7283[0m      [31m0.8388[0m        [94m0.2735[0m     +  0.0000  9.4904
     13      [36m0.9356[0m        0.2301       [35m0.7286[0m      [31m0.8391[0m        [94m0.2735[0m     +  0.0000  9.5001
     14      0.9269        0.2311       0.7271      0.8381        [94m0.2733[0m     +  0.0000  9.5156
     15      0.9307        0.2305       [35m0.7293[0m      [31m0.8400[0m        [94m0.2728[0m     +  0.0000  9.4844
     16      0.9260        0.2327       0.7293      0.8400        0.2728        0.0000  9.4530
     17      0.9285        [32m0.2270[0m       [35m0.7300[0m      [31m0.8407[0m        [94m0.2726[0m     +  0.0000  9.5320
     18      0.9291        0.2316       0.7299      0.8404        [94m0.2726[0m     +  0.0000  9.5371
     19      0.9306        0.2270       [35m0.7304[0m      [31m0.8410[0m        [94m0.2724[0m     +  0.0000  9.5423
     20      0.9347        0.2270       0.7304      0.8408        0.2724        0.0000  9.5128
     21      0.9296        0.2286       [35m0.7306[0m      0.8407        [94m0.2724[0m     +  0.0000  9.4902
     22      0.9311        [32m0.2255[0m       0.7304      0.8410        [94m0.2723[0m     +  0.0000  9.4985
     23      0.9344        0.2268       0.7304      0.8406        0.2723        0.0000  9.4414
     24      0.9296        0.2275       [35m0.7307[0m      0.8408        0.2723        0.0000  9.5154
     25      [36m0.9399[0m        [32m0.2243[0m       [35m0.7312[0m      [31m0.8414[0m        0.2723        0.0000  9.4846
     26      0.9338        0.2275       0.7312      0.8414        0.2723        0.0000  9.5206
     27      0.9310        0.2312       [35m0.7316[0m      [31m0.8417[0m        [94m0.2723[0m     +  0.0000  9.4594
     28      0.9344        0.2262       0.7316      0.8417        [94m0.2723[0m     +  0.0000  9.4909
     29      0.9315        0.2249       0.7309      0.8411        0.2723        0.0000  9.4837
     30      0.9271        0.2274       0.7314      0.8415        0.2723        0.0000  9.5004
     31      0.9311        0.2243       0.7314      0.8415        0.2723        0.0000  9.4839
     32      0.9367        0.2248       0.7312      0.8414        0.2723        0.0000  9.4691
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 7 Test Accuracy: 0.7944
Iteration 7 Test F1 Score (micro): 0.9022
Iteration 7 Test F1 Score (macro): 0.8942
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_6.pt

Query 8: Using the exact images and labels from the CSV for this iteration.

Query 8: Using images from iteration=8 (random sampling).
Number of samples used for training in Query 8 is 1264
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8916[0m        [32m0.2633[0m       [35m0.7047[0m      [31m0.8223[0m        [94m0.2742[0m     +  0.0000  11.0384
      2      [36m0.9151[0m        [32m0.2346[0m       [35m0.7122[0m      [31m0.8231[0m        [94m0.2679[0m     +  0.0000  10.8794
      3      [36m0.9191[0m        [32m0.2278[0m       [35m0.7264[0m      [31m0.8362[0m        [94m0.2661[0m     +  0.0000  10.9408
      4      [36m0.9235[0m        [32m0.2247[0m       0.7198      0.8277        [94m0.2617[0m     +  0.0000  10.9428
      5      [36m0.9246[0m        [32m0.2188[0m       0.7214      0.8295        [94m0.2592[0m     +  0.0000  10.9213
      6      [36m0.9304[0m        [32m0.2135[0m       [35m0.7278[0m      0.8284        [94m0.2558[0m     +  0.0000  10.9066
      7      [36m0.9345[0m        [32m0.2125[0m       [35m0.7330[0m      0.8350        [94m0.2547[0m     +  0.0000  10.9222
      8      0.9315        [32m0.2091[0m       0.7292      0.8303        0.2551        0.0000  10.9683
      9      0.9297        0.2101       [35m0.7340[0m      0.8325        [94m0.2541[0m     +  0.0000  11.0103
     10      0.9331        [32m0.2077[0m       [35m0.7351[0m      0.8349        [94m0.2536[0m     +  0.0000  10.9738
     11      [36m0.9359[0m        [32m0.2066[0m       [35m0.7403[0m      [31m0.8401[0m        [94m0.2529[0m     +  0.0000  10.9599
     12      [36m0.9395[0m        0.2069       [35m0.7431[0m      [31m0.8427[0m        [94m0.2524[0m     +  0.0000  10.9287
     13      0.9390        [32m0.2049[0m       [35m0.7439[0m      [31m0.8440[0m        [94m0.2520[0m     +  0.0000  10.9256
     14      0.9372        0.2063       0.7432      0.8419        [94m0.2519[0m     +  0.0000  10.9268
     15      0.9388        [32m0.2038[0m       0.7431      0.8415        [94m0.2517[0m     +  0.0000  10.9531
     16      0.9380        [32m0.2038[0m       [35m0.7441[0m      0.8426        [94m0.2516[0m     +  0.0000  10.9644
     17      [36m0.9403[0m        [32m0.2038[0m       [35m0.7444[0m      0.8424        [94m0.2515[0m     +  0.0000  10.9385
     18      0.9351        0.2052       [35m0.7462[0m      [31m0.8447[0m        [94m0.2513[0m     +  0.0000  10.9373
     19      0.9374        0.2045       0.7457      0.8440        0.2514        0.0000  10.9280
     20      0.9380        [32m0.2029[0m       0.7457      0.8444        [94m0.2511[0m     +  0.0000  10.9695
     21      0.9396        [32m0.2015[0m       [35m0.7469[0m      [31m0.8457[0m        [94m0.2509[0m     +  0.0000  10.9937
     22      [36m0.9423[0m        0.2035       0.7464      0.8451        0.2510        0.0000  10.9101
     23      [36m0.9425[0m        0.2028       0.7469      0.8456        [94m0.2509[0m     +  0.0000  10.9792
     24      0.9408        [32m0.2011[0m       0.7467      0.8453        0.2509        0.0000  10.9778
     25      0.9417        0.2023       [35m0.7474[0m      [31m0.8460[0m        [94m0.2508[0m     +  0.0000  10.9772
     26      0.9418        0.2026       0.7474      0.8460        [94m0.2508[0m     +  0.0000  10.9754
     27      0.9403        0.2033       0.7474      0.8460        [94m0.2508[0m     +  0.0000  10.9788
     28      0.9402        [32m0.2008[0m       [35m0.7476[0m      [31m0.8460[0m        [94m0.2507[0m     +  0.0000  10.9120
     29      0.9406        0.2025       0.7474      0.8459        [94m0.2507[0m     +  0.0000  10.9895
     30      [36m0.9461[0m        0.2014       0.7474      0.8459        [94m0.2507[0m     +  0.0000  10.9159
     31      0.9416        0.2017       [35m0.7479[0m      [31m0.8463[0m        [94m0.2507[0m     +  0.0000  10.9388
     32      0.9410        0.2030       0.7477      0.8462        [94m0.2507[0m     +  0.0000  10.8904
     33      0.9362        0.2017       [35m0.7483[0m      [31m0.8467[0m        [94m0.2507[0m     +  0.0000  10.9840
     34      0.9420        0.2038       0.7481      0.8466        [94m0.2506[0m     +  0.0000  10.9220
     35      0.9423        0.2032       0.7483      [31m0.8470[0m        [94m0.2506[0m     +  0.0000  10.9322
     36      0.9421        0.2034       0.7483      0.8470        [94m0.2506[0m     +  0.0000  10.8947
     37      0.9412        [32m0.2006[0m       0.7483      0.8470        [94m0.2506[0m     +  0.0000  10.9639
     38      0.9446        0.2029       0.7483      0.8470        [94m0.2506[0m     +  0.0000  10.9137
     39      0.9402        0.2011       0.7483      0.8470        [94m0.2506[0m     +  0.0000  10.9494
     40      0.9380        0.2027       0.7483      0.8470        [94m0.2506[0m     +  0.0000  10.8999
     41      0.9397        0.2018       0.7483      0.8470        [94m0.2506[0m     +  0.0000  10.9466
     42      0.9367        0.2033       0.7483      0.8470        [94m0.2506[0m     +  0.0000  10.9416
     43      0.9415        0.2025       0.7483      0.8470        [94m0.2506[0m     +  0.0000  10.9482
     44      0.9459        [32m0.1996[0m       0.7483      0.8470        0.2506        0.0000  11.0208
     45      0.9389        0.2030       0.7483      0.8470        [94m0.2506[0m     +  0.0000  10.9540
     46      0.9430        0.2011       0.7483      0.8470        [94m0.2506[0m     +  0.0000  11.1253
     47      0.9459        0.2005       0.7483      0.8470        [94m0.2506[0m     +  0.0000  10.9538
     48      0.9359        0.2028       0.7483      0.8470        [94m0.2506[0m     +  0.0000  10.9370
     49      0.9441        0.2005       0.7483      0.8470        0.2506        0.0000  10.9540
     50      0.9388        0.2036       0.7483      0.8470        0.2506        0.0000  10.9605
     51      0.9381        [32m0.1987[0m       0.7483      0.8470        0.2506        0.0000  10.9309
     52      0.9418        0.2023       0.7483      0.8470        0.2506        0.0000  10.9141
     53      0.9437        0.2010       0.7483      0.8470        0.2506        0.0000  10.9634
     54      0.9426        0.2012       0.7483      0.8470        0.2506        0.0000  10.9183
     55      0.9434        0.2016       0.7483      0.8470        0.2506        0.0000  10.9218
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 8 Test Accuracy: 0.8139
Iteration 8 Test F1 Score (micro): 0.9127
Iteration 8 Test F1 Score (macro): 0.9070
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_7.pt

Query 9: Using the exact images and labels from the CSV for this iteration.

Query 9: Using images from iteration=9 (random sampling).
Number of samples used for training in Query 9 is 2264
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9077[0m        [32m0.2270[0m       [35m0.7727[0m      [31m0.8672[0m        [94m0.2412[0m     +  0.0000  13.7378
      2      [36m0.9350[0m        [32m0.2012[0m       [35m0.7819[0m      [31m0.8706[0m        [94m0.2377[0m     +  0.0000  13.5157
      3      [36m0.9359[0m        [32m0.1950[0m       [35m0.7927[0m      [31m0.8772[0m        [94m0.2325[0m     +  0.0000  13.5205
      4      [36m0.9368[0m        [32m0.1914[0m       0.7913      0.8744        [94m0.2307[0m     +  0.0000  13.5203
      5      [36m0.9433[0m        [32m0.1877[0m       [35m0.7943[0m      0.8749        [94m0.2289[0m     +  0.0000  13.5278
      6      [36m0.9490[0m        [32m0.1830[0m       0.7911      0.8748        [94m0.2279[0m     +  0.0000  13.5936
      7      0.9469        [32m0.1807[0m       0.7931      0.8762        [94m0.2269[0m     +  0.0000  13.6095
      8      0.9465        0.1825       0.7915      0.8753        [94m0.2268[0m     +  0.0000  13.5817
      9      [36m0.9519[0m        [32m0.1775[0m       0.7936      0.8771        [94m0.2262[0m     +  0.0000  13.6037
     10      0.9488        [32m0.1772[0m       0.7939      0.8750        [94m0.2254[0m     +  0.0000  13.5528
     11      [36m0.9547[0m        [32m0.1745[0m       0.7931      0.8771        [94m0.2251[0m     +  0.0000  13.5563
     12      0.9522        [32m0.1739[0m       0.7925      0.8765        [94m0.2248[0m     +  0.0000  13.6030
     13      [36m0.9554[0m        0.1750       0.7931      0.8769        [94m0.2246[0m     +  0.0000  13.5759
     14      0.9544        0.1750       0.7934      0.8770        [94m0.2246[0m     +  0.0000  13.5596
     15      0.9546        [32m0.1732[0m       0.7941      [31m0.8778[0m        [94m0.2242[0m     +  0.0000  13.5265
     16      0.9553        0.1739       0.7922      0.8766        [94m0.2240[0m     +  0.0000  13.5306
     17      0.9535        0.1735       0.7905      0.8746        0.2242        0.0000  13.5593
     18      [36m0.9564[0m        [32m0.1724[0m       0.7917      0.8763        0.2241        0.0000  13.6310
     19      [36m0.9569[0m        0.1728       0.7918      0.8763        [94m0.2239[0m     +  0.0000  13.9974
     20      0.9541        0.1740       0.7917      0.8761        [94m0.2238[0m     +  0.0000  13.5132
     21      0.9562        0.1727       0.7920      0.8767        [94m0.2237[0m     +  0.0000  13.5144
     22      0.9539        0.1731       0.7918      0.8765        0.2238        0.0000  13.4784
     23      0.9553        0.1729       0.7917      0.8766        0.2238        0.0000  13.5120
     24      0.9543        [32m0.1704[0m       0.7918      0.8766        0.2238        0.0000  13.5590
     25      0.9534        0.1709       0.7917      0.8766        0.2237        0.0000  13.5140
     26      0.9553        0.1731       0.7918      0.8766        0.2237        0.0000  13.5406
     27      0.9561        0.1720       0.7915      0.8763        0.2238        0.0000  13.5407
     28      0.9568        0.1719       0.7913      0.8763        0.2238        0.0000  13.5287
     29      0.9552        0.1711       0.7913      0.8761        0.2238        0.0000  13.5906
     30      [36m0.9570[0m        0.1717       0.7917      0.8764        [94m0.2237[0m     +  0.0000  13.5901
     31      [36m0.9570[0m        [32m0.1703[0m       0.7913      0.8761        0.2237        0.0000  13.5127
     32      0.9542        0.1713       0.7917      0.8763        [94m0.2237[0m     +  0.0000  13.5428
     33      0.9549        0.1713       0.7917      0.8764        [94m0.2237[0m     +  0.0000  13.6219
     34      [36m0.9583[0m        0.1705       0.7920      0.8767        0.2237        0.0000  13.4974
     35      0.9563        0.1706       0.7920      0.8767        0.2237        0.0000  13.5286
     36      0.9551        0.1724       0.7920      0.8767        0.2237        0.0000  13.5281
     37      0.9554        0.1717       0.7920      0.8767        0.2237        0.0000  13.5416
     38      0.9528        0.1705       0.7920      0.8767        0.2237        0.0000  13.5259
     39      0.9556        0.1715       0.7920      0.8767        0.2237        0.0000  13.5434
     40      0.9564        0.1719       0.7915      0.8763        0.2237        0.0000  13.5437
     41      0.9569        0.1711       0.7915      0.8763        0.2237        0.0000  13.5587
     42      0.9565        [32m0.1699[0m       0.7915      0.8763        0.2237        0.0000  13.5297
     43      0.9559        0.1723       0.7915      0.8763        0.2237        0.0000  13.6059
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 9 Test Accuracy: 0.8340
Iteration 9 Test F1 Score (micro): 0.9242
Iteration 9 Test F1 Score (macro): 0.9183
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_8.pt

Query 10: Using the exact images and labels from the CSV for this iteration.

Query 10: Using images from iteration=10 (random sampling).
Number of samples used for training in Query 10 is 4040
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9308[0m        [32m0.1928[0m       [35m0.7873[0m      [31m0.8827[0m        [94m0.2211[0m     +  0.0000  18.3447
      2      [36m0.9490[0m        [32m0.1711[0m       [35m0.7931[0m      [31m0.8832[0m        [94m0.2193[0m     +  0.0000  18.1070
      3      [36m0.9508[0m        [32m0.1657[0m       [35m0.7943[0m      [31m0.8840[0m        [94m0.2178[0m     +  0.0000  18.2048
      4      [36m0.9525[0m        [32m0.1608[0m       0.7906      0.8819        [94m0.2176[0m     +  0.0000  18.2193
      5      [36m0.9587[0m        [32m0.1566[0m       0.7941      0.8836        [94m0.2152[0m     +  0.0000  18.1882
      6      [36m0.9600[0m        [32m0.1525[0m       [35m0.7976[0m      [31m0.8858[0m        [94m0.2110[0m     +  0.0000  18.1721
      7      [36m0.9610[0m        [32m0.1508[0m       [35m0.7995[0m      [31m0.8864[0m        [94m0.2097[0m     +  0.0000  18.1978
      8      [36m0.9637[0m        [32m0.1494[0m       [35m0.8010[0m      [31m0.8871[0m        [94m0.2089[0m     +  0.0000  18.1892
      9      0.9632        [32m0.1477[0m       0.8002      0.8868        0.2098        0.0000  18.2502
     10      [36m0.9650[0m        [32m0.1473[0m       [35m0.8028[0m      [31m0.8879[0m        [94m0.2086[0m     +  0.0000  18.1870
     11      0.9648        [32m0.1457[0m       [35m0.8064[0m      [31m0.8893[0m        [94m0.2067[0m     +  0.0000  18.2037
     12      [36m0.9656[0m        [32m0.1449[0m       0.8061      0.8889        [94m0.2063[0m     +  0.0000  18.1698
     13      [36m0.9663[0m        [32m0.1449[0m       [35m0.8080[0m      [31m0.8895[0m        [94m0.2058[0m     +  0.0000  18.1866
     14      [36m0.9674[0m        [32m0.1438[0m       0.8073      0.8890        0.2060        0.0000  18.2667
     15      0.9667        [32m0.1426[0m       0.8063      0.8893        0.2060        0.0000  18.1865
     16      [36m0.9676[0m        0.1440       [35m0.8109[0m      [31m0.8907[0m        [94m0.2047[0m     +  0.0000  18.2658
     17      [36m0.9687[0m        [32m0.1412[0m       0.8099      0.8900        [94m0.2046[0m     +  0.0000  18.2912
     18      0.9678        0.1425       0.8104      0.8902        0.2046        0.0000  19.1888
     19      0.9670        0.1423       0.8099      0.8900        0.2047        0.0000  18.2505
     20      0.9684        0.1416       0.8094      0.8898        0.2048        0.0000  18.1252
     21      0.9684        0.1414       0.8109      0.8904        [94m0.2045[0m     +  0.0000  18.1884
     22      0.9686        0.1414       0.8109      0.8903        [94m0.2044[0m     +  0.0000  18.2494
     23      0.9673        [32m0.1404[0m       [35m0.8115[0m      0.8906        0.2044        0.0000  18.1880
     24      [36m0.9687[0m        0.1413       [35m0.8120[0m      [31m0.8908[0m        [94m0.2043[0m     +  0.0000  18.3112
     25      0.9687        0.1412       0.8120      0.8908        [94m0.2042[0m     +  0.0000  18.2351
     26      0.9683        0.1424       0.8113      0.8905        0.2042        0.0000  18.2340
     27      0.9686        [32m0.1403[0m       [35m0.8122[0m      0.8908        [94m0.2041[0m     +  0.0000  18.2670
     28      [36m0.9703[0m        [32m0.1398[0m       [35m0.8125[0m      [31m0.8910[0m        [94m0.2041[0m     +  0.0000  18.2180
     29      0.9695        0.1403       0.8125      0.8909        [94m0.2040[0m     +  0.0000  18.2363
     30      0.9696        0.1406       0.8122      0.8908        0.2041        0.0000  18.2516
     31      0.9678        0.1410       [35m0.8127[0m      0.8910        0.2040        0.0000  18.2198
     32      0.9689        0.1411       0.8127      0.8910        [94m0.2040[0m     +  0.0000  18.2187
     33      0.9687        0.1401       0.8123      0.8909        [94m0.2040[0m     +  0.0000  18.2044
     34      0.9680        0.1405       0.8123      0.8909        0.2040        0.0000  18.2492
     35      0.9688        0.1405       0.8122      0.8908        0.2040        0.0000  18.1888
     36      0.9697        0.1401       0.8120      0.8907        0.2040        0.0000  18.2021
     37      0.9697        0.1408       0.8118      0.8906        0.2040        0.0000  18.2326
     38      0.9673        0.1407       0.8122      0.8908        0.2040        0.0000  18.2341
     39      0.9695        0.1416       0.8123      0.8909        [94m0.2040[0m     +  0.0000  18.2797
     40      0.9692        [32m0.1397[0m       0.8122      0.8908        [94m0.2040[0m     +  0.0000  18.2501
     41      0.9692        0.1412       0.8122      0.8908        0.2040        0.0000  18.2338
     42      0.9692        0.1404       0.8122      0.8908        0.2040        0.0000  18.2002
     43      [36m0.9708[0m        0.1404       0.8120      0.8907        [94m0.2040[0m     +  0.0000  18.2180
     44      0.9685        0.1399       0.8122      0.8908        [94m0.2040[0m     +  0.0000  18.2027
     45      0.9694        0.1410       0.8123      0.8909        [94m0.2040[0m     +  0.0000  18.2334
     46      0.9691        0.1414       0.8123      0.8909        [94m0.2040[0m     +  0.0000  18.2651
     47      0.9690        0.1407       0.8123      0.8909        0.2040        0.0000  18.2680
     48      0.9692        0.1405       0.8123      0.8909        0.2040        0.0000  18.2800
     49      0.9679        0.1407       0.8123      0.8909        0.2040        0.0000  18.2325
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 10 Test Accuracy: 0.8356
Iteration 10 Test F1 Score (micro): 0.9257
Iteration 10 Test F1 Score (macro): 0.9187
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_9.pt

Query 11: Using the exact images and labels from the CSV for this iteration.

Query 11: Using images from iteration=11 (random sampling).
Number of samples used for training in Query 11 is 7200
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9571[0m        [32m0.1528[0m       [35m0.8139[0m      [31m0.8938[0m        [94m0.2089[0m     +  0.0000  26.8485
      2      [36m0.9663[0m        [32m0.1376[0m       0.8094      0.8915        [94m0.2043[0m     +  0.0000  26.3164
      3      [36m0.9673[0m        [32m0.1342[0m       0.8101      0.8919        [94m0.2021[0m     +  0.0000  26.4928
      4      [36m0.9684[0m        [32m0.1301[0m       0.8132      0.8907        [94m0.2005[0m     +  0.0000  26.6479
      5      [36m0.9712[0m        [32m0.1268[0m       0.8054      0.8862        0.2102        0.0000  26.6326
      6      [36m0.9740[0m        [32m0.1229[0m       0.8135      0.8922        [94m0.1949[0m     +  0.0000  26.5857
      7      0.9737        [32m0.1214[0m       [35m0.8149[0m      0.8928        [94m0.1937[0m     +  0.0000  26.6471
      8      [36m0.9746[0m        [32m0.1194[0m       0.8127      0.8915        0.1939        0.0000  26.5837
      9      [36m0.9750[0m        [32m0.1193[0m       0.8149      0.8926        0.1943        0.0000  26.6609
     10      [36m0.9752[0m        [32m0.1178[0m       0.8142      0.8924        0.1939        0.0000  26.5353
     11      [36m0.9783[0m        [32m0.1158[0m       [35m0.8168[0m      0.8928        [94m0.1918[0m     +  0.0000  26.5519
     12      0.9771        [32m0.1158[0m       0.8120      0.8897        0.1928        0.0000  26.4756
     13      0.9775        [32m0.1148[0m       0.8132      0.8901        0.1920        0.0000  26.4798
     14      0.9779        0.1151       0.8160      0.8928        0.1922        0.0000  26.5437
     15      0.9780        [32m0.1141[0m       0.8148      0.8906        0.1919        0.0000  26.6001
     16      0.9766        [32m0.1139[0m       [35m0.8175[0m      0.8935        [94m0.1910[0m     +  0.0000  26.5842
     17      [36m0.9783[0m        [32m0.1133[0m       [35m0.8177[0m      0.8934        [94m0.1909[0m     +  0.0000  26.4427
     18      0.9777        0.1137       [35m0.8193[0m      [31m0.8944[0m        [94m0.1906[0m     +  0.0000  26.5547
     19      0.9780        [32m0.1132[0m       0.8191      0.8943        0.1906        0.0000  26.5061
     20      0.9783        [32m0.1129[0m       0.8189      0.8940        0.1906        0.0000  26.6153
     21      [36m0.9784[0m        0.1130       0.8187      0.8939        [94m0.1901[0m     +  0.0000  26.5681
     22      0.9780        0.1130       0.8187      0.8939        [94m0.1901[0m     +  0.0000  26.5055
     23      [36m0.9785[0m        [32m0.1119[0m       0.8184      0.8937        0.1902        0.0000  26.4766
     24      0.9782        0.1122       0.8189      0.8941        [94m0.1899[0m     +  0.0000  26.5503
     25      [36m0.9793[0m        0.1124       0.8184      0.8937        0.1900        0.0000  26.5197
     26      0.9784        0.1126       0.8184      0.8938        0.1899        0.0000  26.4858
     27      0.9781        0.1129       0.8189      0.8940        [94m0.1898[0m     +  0.0000  26.5782
     28      0.9775        0.1127       0.8191      0.8942        [94m0.1898[0m     +  0.0000  26.6787
     29      0.9790        0.1120       0.8189      0.8942        0.1899        0.0000  26.5666
     30      0.9791        0.1123       0.8184      0.8938        0.1899        0.0000  26.5393
     31      0.9786        [32m0.1112[0m       0.8184      0.8938        0.1899        0.0000  26.5882
     32      0.9780        0.1127       0.8187      0.8940        0.1899        0.0000  27.4589
     33      [36m0.9796[0m        0.1123       0.8189      0.8941        0.1899        0.0000  28.5198
     34      0.9792        0.1124       0.8191      0.8941        [94m0.1898[0m     +  0.0000  27.9091
     35      0.9779        0.1118       0.8187      0.8940        0.1898        0.0000  26.4273
     36      0.9789        0.1118       0.8187      0.8940        0.1898        0.0000  26.5192
     37      0.9779        0.1130       0.8189      0.8941        [94m0.1898[0m     +  0.0000  26.5354
     38      0.9779        0.1121       0.8189      0.8940        [94m0.1898[0m     +  0.0000  26.4883
     39      0.9792        0.1119       0.8191      0.8940        [94m0.1898[0m     +  0.0000  26.5497
     40      0.9790        0.1123       0.8191      0.8940        0.1898        0.0000  26.5950
     41      0.9775        0.1122       0.8191      0.8940        0.1898        0.0000  26.6244
     42      0.9788        0.1116       0.8191      0.8941        [94m0.1898[0m     +  0.0000  26.6116
     43      0.9787        0.1127       0.8191      0.8941        [94m0.1898[0m     +  0.0000  26.5349
     44      [36m0.9800[0m        0.1122       0.8191      0.8940        [94m0.1898[0m     +  0.0000  26.5353
     45      0.9776        0.1118       0.8191      0.8940        [94m0.1898[0m     +  0.0000  26.5526
     46      0.9790        0.1123       0.8191      0.8940        0.1898        0.0000  26.5092
     47      0.9789        0.1125       0.8191      0.8940        0.1898        0.0000  26.5512
     48      0.9777        0.1117       0.8191      0.8941        [94m0.1898[0m     +  0.0000  26.5357
     49      0.9780        0.1120       0.8191      0.8941        0.1898        0.0000  26.4773
     50      0.9790        0.1121       0.8191      0.8941        0.1898        0.0000  26.5541
     51      0.9785        0.1129       0.8191      0.8941        0.1898        0.0000  26.5508
     52      0.9779        0.1121       0.8191      0.8941        0.1898        0.0000  26.5810
     53      0.9783        0.1116       0.8191      0.8941        0.1898        0.0000  26.4739
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 11 Test Accuracy: 0.8436
Iteration 11 Test F1 Score (micro): 0.9283
Iteration 11 Test F1 Score (macro): 0.9219
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_10.pt

Query 12: Using the exact images and labels from the CSV for this iteration.

Query 12: Using images from iteration=12 (random sampling).
Number of samples used for training in Query 12 is 12824
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9669[0m        [32m0.1222[0m       [35m0.8023[0m      [31m0.8838[0m        [94m0.1972[0m     +  0.0000  41.2173
      2      [36m0.9746[0m        [32m0.1123[0m       [35m0.8087[0m      [31m0.8911[0m        [94m0.1965[0m     +  0.0000  41.4435
      3      [36m0.9750[0m        [32m0.1078[0m       [35m0.8109[0m      [31m0.8922[0m        [94m0.1942[0m     +  0.0000  41.4366
      4      [36m0.9771[0m        [32m0.1044[0m       [35m0.8155[0m      [31m0.8938[0m        0.1946        0.0000  41.4121
      5      [36m0.9775[0m        [32m0.1011[0m       [35m0.8170[0m      [31m0.8956[0m        [94m0.1918[0m     +  0.0000  41.3783
      6      [36m0.9797[0m        [32m0.0975[0m       [35m0.8293[0m      [31m0.8985[0m        [94m0.1846[0m     +  0.0000  41.3163
      7      [36m0.9808[0m        [32m0.0953[0m       [35m0.8323[0m      [31m0.9005[0m        [94m0.1826[0m     +  0.0000  41.3461
      8      0.9805        [32m0.0951[0m       [35m0.8345[0m      [31m0.9015[0m        [94m0.1819[0m     +  0.0000  41.3761
      9      [36m0.9811[0m        [32m0.0934[0m       [35m0.8378[0m      [31m0.9024[0m        [94m0.1806[0m     +  0.0000  41.2985
     10      [36m0.9817[0m        [32m0.0920[0m       0.8292      0.8991        0.1845        0.0000  41.3309
     11      0.9810        [32m0.0909[0m       0.8345      0.9001        [94m0.1804[0m     +  0.0000  41.2809
     12      [36m0.9820[0m        [32m0.0907[0m       0.8358      0.9008        [94m0.1799[0m     +  0.0000  41.3189
     13      0.9818        [32m0.0907[0m       0.8361      0.9007        0.1803        0.0000  41.3615
     14      [36m0.9827[0m        [32m0.0894[0m       0.8347      0.9001        0.1814        0.0000  41.3109
     15      0.9822        [32m0.0892[0m       0.8349      0.9003        0.1801        0.0000  41.3430
     16      0.9826        [32m0.0884[0m       0.8326      0.8989        [94m0.1796[0m     +  0.0000  41.2510
     17      0.9826        0.0887       0.8319      0.8985        [94m0.1794[0m     +  0.0000  41.3132
     18      [36m0.9829[0m        [32m0.0883[0m       0.8307      0.8979        0.1804        0.0000  41.5704
     19      0.9823        [32m0.0878[0m       0.8314      0.8981        0.1804        0.0000  41.8438
     20      0.9826        0.0885       0.8318      0.8983        0.1804        0.0000  41.8127
     21      [36m0.9832[0m        [32m0.0876[0m       0.8274      0.8964        0.1799        0.0000  41.6079
     22      0.9825        0.0878       0.8280      0.8962        0.1798        0.0000  42.2194
     23      [36m0.9832[0m        0.0879       0.8262      0.8953        0.1800        0.0000  41.2801
     24      0.9827        [32m0.0874[0m       0.8274      0.8963        0.1799        0.0000  41.3265
     25      0.9827        0.0875       0.8269      0.8957        0.1797        0.0000  41.5125
     26      0.9828        0.0879       0.8273      0.8956        0.1797        0.0000  41.4542
     27      0.9831        [32m0.0870[0m       0.8269      0.8955        0.1798        0.0000  41.4854
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 12 Test Accuracy: 0.8613
Iteration 12 Test F1 Score (micro): 0.9360
Iteration 12 Test F1 Score (macro): 0.9293
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_11.pt

Query 13: Using the exact images and labels from the CSV for this iteration.

Query 13: Using images from iteration=13 (random sampling).
Number of samples used for training in Query 13 is 22824
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9744[0m        [32m0.0940[0m       [35m0.8047[0m      [31m0.8905[0m        [94m0.1980[0m     +  0.0000  67.4885
      2      [36m0.9787[0m        [32m0.0862[0m       [35m0.8200[0m      [31m0.8953[0m        [94m0.1852[0m     +  0.0000  67.7838
      3      [36m0.9788[0m        [32m0.0829[0m       0.8165      [31m0.8957[0m        [94m0.1811[0m     +  0.0000  67.8145
      4      [36m0.9792[0m        [32m0.0799[0m       [35m0.8257[0m      [31m0.9003[0m        [94m0.1760[0m     +  0.0000  67.7452
      5      [36m0.9804[0m        [32m0.0764[0m       0.8208      0.8971        0.1772        0.0000  67.7215
      6      [36m0.9820[0m        [32m0.0729[0m       [35m0.8269[0m      0.8972        [94m0.1742[0m     +  0.0000  67.8401
      7      [36m0.9827[0m        [32m0.0716[0m       [35m0.8288[0m      0.8980        [94m0.1721[0m     +  0.0000  68.1551
      8      [36m0.9827[0m        [32m0.0704[0m       [35m0.8304[0m      0.8990        [94m0.1701[0m     +  0.0000  67.8471
      9      [36m0.9830[0m        [32m0.0691[0m       0.8304      0.8991        0.1704        0.0000  67.7683
     10      [36m0.9831[0m        [32m0.0676[0m       [35m0.8306[0m      0.8996        0.1703        0.0000  67.9520
     11      [36m0.9840[0m        [32m0.0659[0m       [35m0.8328[0m      0.8992        [94m0.1700[0m     +  0.0000  67.7506
     12      [36m0.9845[0m        [32m0.0659[0m       [35m0.8330[0m      0.8997        0.1704        0.0000  67.6873
     13      0.9842        [32m0.0654[0m       0.8323      0.8992        0.1706        0.0000  67.7380
     14      [36m0.9851[0m        [32m0.0645[0m       [35m0.8335[0m      [31m0.9004[0m        0.1706        0.0000  67.8251
     15      0.9846        0.0648       [35m0.8344[0m      [31m0.9005[0m        0.1709        0.0000  67.3308
     16      0.9846        [32m0.0640[0m       0.8330      0.8979        [94m0.1690[0m     +  0.0000  66.8901
     17      0.9849        [32m0.0632[0m       0.8337      0.8987        0.1695        0.0000  66.8821
     18      0.9849        0.0636       0.8335      0.8984        0.1695        0.0000  66.8014
     19      0.9851        0.0636       0.8328      0.8980        0.1701        0.0000  66.8399
     20      [36m0.9855[0m        0.0632       0.8335      0.8983        0.1692        0.0000  66.9233
     21      0.9855        [32m0.0629[0m       0.8342      0.8978        [94m0.1690[0m     +  0.0000  66.8421
     22      [36m0.9857[0m        [32m0.0621[0m       0.8340      0.8977        0.1692        0.0000  66.7602
     23      0.9853        0.0625       0.8332      0.8970        0.1695        0.0000  66.8290
     24      0.9854        0.0624       0.8330      0.8971        0.1696        0.0000  66.7808
     25      [36m0.9859[0m        0.0624       0.8325      0.8971        0.1698        0.0000  66.8906
     26      0.9853        0.0625       0.8330      0.8966        0.1696        0.0000  66.9073
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 13 Test Accuracy: 0.8627
Iteration 13 Test F1 Score (micro): 0.9360
Iteration 13 Test F1 Score (macro): 0.9285
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_12.pt

Query 14: Using the exact images and labels from the CSV for this iteration.

Query 14: Using images from iteration=14 (random sampling).
Number of samples used for training in Query 14 is 26880
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9796[0m        [32m0.0685[0m       [35m0.8365[0m      [31m0.8918[0m        [94m0.1695[0m     +  0.0000  77.2656
      2      [36m0.9823[0m        [32m0.0630[0m       [35m0.8384[0m      [31m0.8933[0m        [94m0.1641[0m     +  0.0000  77.4730
      3      [36m0.9827[0m        [32m0.0602[0m       0.8358      [31m0.8936[0m        0.1688        0.0000  77.4614
      4      [36m0.9835[0m        [32m0.0577[0m       [35m0.8401[0m      [31m0.8958[0m        0.1674        0.0000  77.4049
      5      [36m0.9840[0m        [32m0.0553[0m       [35m0.8406[0m      0.8954        0.1666        0.0000  77.3734
      6      [36m0.9850[0m        [32m0.0526[0m       0.8352      0.8945        0.1684        0.0000  77.3320
      7      [36m0.9855[0m        [32m0.0514[0m       0.8354      0.8953        0.1691        0.0000  77.3338
      8      [36m0.9860[0m        [32m0.0502[0m       0.8370      [31m0.8964[0m        0.1712        0.0000  77.2208
      9      [36m0.9866[0m        [32m0.0493[0m       0.8332      0.8949        0.1729        0.0000  77.2474
     10      [36m0.9871[0m        [32m0.0484[0m       0.8339      0.8955        0.1742        0.0000  77.2768
     11      [36m0.9876[0m        [32m0.0473[0m       0.8325      0.8949        0.1739        0.0000  77.2539
     12      0.9875        [32m0.0469[0m       0.8333      0.8961        0.1748        0.0000  77.2597
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 14 Test Accuracy: 0.8755
Iteration 14 Test F1 Score (micro): 0.9410
Iteration 14 Test F1 Score (macro): 0.9332
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\model_checkpoint_iteration_13.pt

Best F1 score across all iterations: 0.9332
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel_from_multiclass/DinoS/random_sampling_seed43_test\random_sampling_results_for_multilabel_classification_s43.pickle
