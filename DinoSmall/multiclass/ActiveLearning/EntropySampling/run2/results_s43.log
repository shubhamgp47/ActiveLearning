(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m1.0000[0m        [32m2.1595[0m       [35m0.1453[0m      [31m0.1453[0m        [94m1.9872[0m     +  0.0000  11.6562
      2      0.1250        [32m2.0908[0m       [35m0.1505[0m      [31m0.1505[0m        2.0840        0.0000  10.5621
      3      0.3750        [32m1.8666[0m       0.1398      0.1398        2.0760        0.0000  10.7116
      4      0.3750        [32m1.7781[0m       [35m0.1905[0m      [31m0.1905[0m        2.0335        0.0000  11.1935
      5      0.6250        [32m1.7384[0m       0.1215      0.1215        2.1399        0.0000  10.9825
      6      0.8750        [32m1.6053[0m       0.1316      0.1316        2.1244        0.0000  10.7806
      7      0.5000        1.6767       0.1554      0.1554        2.1176        0.0000  10.9942
      8      0.6250        [32m1.5302[0m       0.1653      0.1653        2.1099        0.0000  11.0824
      9      0.7500        [32m1.5159[0m       0.1760      0.1760        2.1129        0.0000  11.0726
     10      0.8750        [32m1.5005[0m       [35m0.1953[0m      [31m0.1953[0m        2.1037        0.0000  10.8532
     11      0.7500        1.5941       0.1932      0.1932        2.1058        0.0000  11.0037
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.2418
Pre F1 macro score = 0.1737

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7500[0m        [32m1.5469[0m       [35m0.2990[0m      [31m0.2990[0m        [94m1.8628[0m     +  0.0000  11.0282
      2      [36m0.7917[0m        [32m1.2255[0m       0.2878      0.2878        [94m1.8449[0m     +  0.0000  10.8565
      3      [36m0.9167[0m        [32m1.0276[0m       0.2670      0.2670        [94m1.8425[0m     +  0.0000  11.1247
      4      0.8333        [32m0.9575[0m       0.2524      0.2524        1.9045        0.0000  11.0904
      5      [36m0.9583[0m        [32m0.8052[0m       0.2378      0.2378        1.9381        0.0000  10.9688
      6      [36m1.0000[0m        [32m0.7634[0m       0.2378      0.2378        1.9354        0.0000  11.1718
      7      0.9583        0.8191       0.2378      0.2378        1.9316        0.0000  11.0156
      8      1.0000        [32m0.7299[0m       0.2387      0.2387        1.9374        0.0000  11.0358
      9      0.9583        [32m0.6952[0m       0.2352      0.2352        1.9471        0.0000  11.0246
     10      1.0000        [32m0.6944[0m       0.2326      0.2326        1.9472        0.0000  11.2085
     11      0.9167        0.7804       0.2328      0.2328        1.9473        0.0000  11.0928
     12      1.0000        [32m0.6583[0m       0.2328      0.2328        1.9477        0.0000  11.3766
     13      1.0000        0.7000       0.2330      0.2330        1.9480        0.0000  10.8526
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.25399305555555557
F1 Macro Score after query 1: 0.15848154363631337
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8214[0m        [32m1.1788[0m       [35m0.4668[0m      [31m0.4668[0m        [94m1.7050[0m     +  0.0000  11.1390
      2      [36m0.8571[0m        [32m0.9388[0m       [35m0.4717[0m      [31m0.4717[0m        [94m1.6786[0m     +  0.0000  11.4082
      3      0.8571        [32m0.7500[0m       0.4557      0.4557        [94m1.6671[0m     +  0.0000  11.0564
      4      [36m0.9107[0m        [32m0.7165[0m       0.4717      0.4717        [94m1.6589[0m     +  0.0000  11.3330
      5      0.8750        [32m0.7026[0m       0.4648      0.4648        [94m1.6444[0m     +  0.0000  11.1728
      6      [36m0.9286[0m        [32m0.6239[0m       0.4656      0.4656        [94m1.6437[0m     +  0.0000  11.0885
      7      0.9107        [32m0.5853[0m       0.4698      0.4698        [94m1.6413[0m     +  0.0000  11.1561
      8      0.9107        0.6721       0.4681      0.4681        1.6422        0.0000  11.1872
      9      0.9286        0.5929       0.4670      0.4670        [94m1.6394[0m     +  0.0000  11.0408
     10      0.8929        0.6425       0.4700      0.4700        [94m1.6390[0m     +  0.0000  11.1718
     11      0.8750        0.6093       0.4691      0.4691        1.6392        0.0000  11.1095
     12      0.9107        0.5913       0.4684      0.4684        1.6402        0.0000  11.1243
     13      0.9286        [32m0.5688[0m       0.4682      0.4682        1.6402        0.0000  11.1439
     14      0.9286        0.6080       0.4677      0.4677        1.6400        0.0000  11.4619
     15      0.9107        0.5795       0.4668      0.4668        1.6402        0.0000  11.2412
     16      0.8929        0.5807       0.4667      0.4667        1.6402        0.0000  11.3354
     17      0.9286        0.5856       0.4667      0.4667        1.6402        0.0000  11.5199
     18      0.9286        0.5853       0.4674      0.4674        1.6400        0.0000  11.3032
     19      0.9107        0.5852       0.4670      0.4670        1.6401        0.0000  11.3357
     20      0.9286        [32m0.5644[0m       0.4668      0.4668        1.6400        0.0000  11.3021
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.4479166666666667
F1 Macro Score after query 2: 0.11054457631239954
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6518[0m        [32m1.2715[0m       [35m0.4125[0m      [31m0.4125[0m        [94m1.5977[0m     +  0.0000  11.4747
      2      [36m0.7500[0m        [32m1.0450[0m       0.3920      0.3920        [94m1.5589[0m     +  0.0000  11.3689
      3      0.6875        [32m0.9780[0m       0.3929      0.3929        1.5643        0.0000  11.4593
      4      0.7054        [32m0.9593[0m       0.3922      0.3922        1.5696        0.0000  11.3645
      5      [36m0.7946[0m        [32m0.8441[0m       0.3965      0.3965        1.5740        0.0000  11.3184
      6      [36m0.8304[0m        [32m0.8073[0m       0.3863      0.3863        1.5952        0.0000  11.3960
      7      0.8214        [32m0.8041[0m       0.3885      0.3885        1.6020        0.0000  11.3953
      8      [36m0.8661[0m        [32m0.7605[0m       0.3899      0.3899        1.5983        0.0000  11.7107
      9      0.8482        [32m0.7460[0m       0.3913      0.3913        1.5967        0.0000  11.4604
     10      [36m0.8929[0m        [32m0.6970[0m       0.3929      0.3929        1.5992        0.0000  11.5221
     11      [36m0.9018[0m        [32m0.6954[0m       0.3936      0.3936        1.6006        0.0000  11.5189
     12      0.9018        [32m0.6937[0m       0.3936      0.3936        1.6012        0.0000  11.5386
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.46944444444444444
F1 Macro Score after query 3: 0.17378104727100024
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7692[0m        [32m0.9140[0m       [35m0.3814[0m      [31m0.3814[0m        [94m1.6021[0m     +  0.0000  12.0839
      2      [36m0.7981[0m        [32m0.8130[0m       0.3773      0.3773        [94m1.5933[0m     +  0.0000  11.9605
      3      [36m0.8317[0m        [32m0.7151[0m       [35m0.3819[0m      [31m0.3819[0m        1.6124        0.0000  11.9130
      4      [36m0.8798[0m        [32m0.6589[0m       [35m0.3858[0m      [31m0.3858[0m        [94m1.5878[0m     +  0.0000  12.1783
      5      0.8750        [32m0.6266[0m       [35m0.3976[0m      [31m0.3976[0m        1.5990        0.0000  11.9924
      6      [36m0.9183[0m        [32m0.5664[0m       [35m0.4002[0m      [31m0.4002[0m        1.6128        0.0000  11.9754
      7      [36m0.9327[0m        [32m0.5509[0m       0.3984      0.3984        1.6169        0.0000  12.2103
      8      0.9183        0.5620       0.3977      0.3977        1.6220        0.0000  11.6792
      9      0.9087        [32m0.5470[0m       0.4000      0.4000        1.6205        0.0000  12.0535
     10      [36m0.9471[0m        [32m0.5356[0m       [35m0.4005[0m      [31m0.4005[0m        1.6195        0.0000  12.0539
     11      0.9327        [32m0.5313[0m       0.4003      0.4003        1.6211        0.0000  11.9590
     12      0.9327        [32m0.5221[0m       0.4005      0.4005        1.6221        0.0000  12.0841
     13      0.9327        0.5375       [35m0.4007[0m      [31m0.4007[0m        1.6220        0.0000  12.1483
     14      0.9423        0.5224       0.3991      0.3991        1.6223        0.0000  11.9908
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.4609375
F1 Macro Score after query 4: 0.17387329174426552
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6771[0m        [32m1.0193[0m       [35m0.3781[0m      [31m0.3781[0m        [94m1.5933[0m     +  0.0000  12.5697
      2      [36m0.8021[0m        [32m0.8043[0m       [35m0.4014[0m      [31m0.4014[0m        1.5955        0.0000  13.2355
      3      [36m0.8776[0m        [32m0.6776[0m       [35m0.4198[0m      [31m0.4198[0m        [94m1.5873[0m     +  0.0000  12.8372
      4      [36m0.8906[0m        [32m0.6168[0m       [35m0.4288[0m      [31m0.4288[0m        [94m1.5541[0m     +  0.0000  12.8507
      5      [36m0.9219[0m        [32m0.5526[0m       [35m0.4316[0m      [31m0.4316[0m        1.5749        0.0000  12.7884
      6      [36m0.9323[0m        [32m0.5080[0m       [35m0.4401[0m      [31m0.4401[0m        1.5707        0.0000  12.8061
      7      [36m0.9349[0m        [32m0.4833[0m       [35m0.4436[0m      [31m0.4436[0m        1.5724        0.0000  12.9299
      8      [36m0.9375[0m        [32m0.4691[0m       [35m0.4472[0m      [31m0.4472[0m        1.5700        0.0000  13.0392
      9      [36m0.9479[0m        [32m0.4615[0m       [35m0.4531[0m      [31m0.4531[0m        1.5676        0.0000  12.7106
     10      0.9479        0.4670       0.4491      0.4491        1.5712        0.0000  12.9775
     11      [36m0.9505[0m        [32m0.4390[0m       0.4491      0.4491        1.5659        0.0000  12.8519
     12      0.9505        0.4422       0.4500      0.4500        1.5629        0.0000  12.9918
     13      [36m0.9531[0m        [32m0.4375[0m       0.4512      0.4512        1.5614        0.0000  12.8812
     14      [36m0.9609[0m        [32m0.4305[0m       0.4500      0.4500        1.5639        0.0000  12.7563
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.4852430555555556
F1 Macro Score after query 5: 0.20115306037520891
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8452[0m        [32m0.7043[0m       [35m0.4786[0m      [31m0.4786[0m        [94m1.3145[0m     +  0.0000  14.5858
      2      [36m0.9190[0m        [32m0.5237[0m       [35m0.5372[0m      [31m0.5372[0m        [94m1.1989[0m     +  0.0000  14.6020
      3      [36m0.9403[0m        [32m0.4671[0m       [35m0.5819[0m      [31m0.5819[0m        [94m1.1463[0m     +  0.0000  14.6192
      4      [36m0.9545[0m        [32m0.4172[0m       [35m0.5847[0m      [31m0.5847[0m        1.1502        0.0000  14.4792
      5      [36m0.9560[0m        [32m0.3711[0m       [35m0.6028[0m      [31m0.6028[0m        [94m1.1156[0m     +  0.0000  14.3369
      6      [36m0.9744[0m        [32m0.3397[0m       [35m0.6443[0m      [31m0.6443[0m        [94m1.0669[0m     +  0.0000  14.5860
      7      0.9730        0.3418       [35m0.6517[0m      [31m0.6517[0m        [94m1.0532[0m     +  0.0000  14.4781
      8      [36m0.9773[0m        [32m0.3388[0m       [35m0.6556[0m      [31m0.6556[0m        [94m1.0500[0m     +  0.0000  14.6489
      9      0.9773        [32m0.3148[0m       [35m0.6557[0m      [31m0.6557[0m        1.0506        0.0000  14.6181
     10      [36m0.9801[0m        [32m0.3064[0m       0.6557      0.6557        [94m1.0499[0m     +  0.0000  14.5237
     11      [36m0.9844[0m        [32m0.2984[0m       [35m0.6630[0m      [31m0.6630[0m        [94m1.0390[0m     +  0.0000  14.3695
     12      [36m0.9858[0m        0.3002       [35m0.6635[0m      [31m0.6635[0m        [94m1.0382[0m     +  0.0000  14.3359
     13      0.9844        0.3072       [35m0.6651[0m      [31m0.6651[0m        [94m1.0377[0m     +  0.0000  14.5704
     14      0.9830        0.3008       0.6644      0.6644        1.0385        0.0000  13.9952
     15      0.9815        [32m0.2907[0m       0.6649      0.6649        [94m1.0365[0m     +  0.0000  14.2245
     16      0.9844        [32m0.2880[0m       0.6651      0.6651        1.0371        0.0000  14.2905
     17      0.9830        0.2893       0.6648      0.6648        1.0376        0.0000  14.2887
     18      0.9858        0.2973       0.6644      0.6644        1.0378        0.0000  14.4277
     19      0.9844        0.2915       0.6644      0.6644        1.0376        0.0000  14.4073
     20      0.9844        0.2995       [35m0.6656[0m      [31m0.6656[0m        1.0372        0.0000  14.3057
     21      0.9844        0.2950       0.6649      0.6649        1.0375        0.0000  14.4454
     22      0.9858        0.2946       0.6653      0.6653        1.0375        0.0000  14.5077
     23      0.9844        0.3006       0.6653      0.6653        1.0377        0.0000  14.4460
     24      0.9858        0.2922       0.6646      0.6646        1.0379        0.0000  14.3351
     25      0.9830        0.2924       0.6649      0.6649        1.0380        0.0000  14.5041
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.7394097222222222
F1 Macro Score after query 6: 0.3184954252746477
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8829[0m        [32m0.6086[0m       [35m0.7314[0m      [31m0.7314[0m        [94m0.8587[0m     +  0.0000  17.3166
      2      [36m0.9517[0m        [32m0.4199[0m       [35m0.7436[0m      [31m0.7436[0m        [94m0.8343[0m     +  0.0000  17.2915
      3      [36m0.9660[0m        [32m0.3531[0m       0.7413      0.7413        [94m0.8262[0m     +  0.0000  17.2749
      4      [36m0.9699[0m        [32m0.3193[0m       0.7424      0.7424        [94m0.8044[0m     +  0.0000  16.9940
      5      [36m0.9763[0m        [32m0.2816[0m       0.7410      0.7410        0.8073        0.0000  17.0254
      6      [36m0.9818[0m        [32m0.2492[0m       0.7417      0.7417        0.8186        0.0000  17.0724
      7      [36m0.9858[0m        [32m0.2449[0m       0.7396      0.7396        0.8196        0.0000  17.1659
      8      [36m0.9881[0m        [32m0.2347[0m       [35m0.7439[0m      [31m0.7439[0m        0.8101        0.0000  17.2125
      9      0.9858        [32m0.2303[0m       0.7411      0.7411        0.8184        0.0000  17.1826
     10      0.9873        [32m0.2222[0m       0.7382      0.7382        0.8221        0.0000  17.1965
     11      [36m0.9889[0m        [32m0.2174[0m       0.7309      0.7309        0.8257        0.0000  17.2433
     12      [36m0.9897[0m        0.2198       0.7337      0.7337        0.8205        0.0000  17.2747
     13      [36m0.9905[0m        [32m0.2128[0m       0.7328      0.7328        0.8232        0.0000  17.1188
     14      0.9905        0.2140       0.7344      0.7344        0.8230        0.0000  17.2430
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.781423611111111
F1 Macro Score after query 7: 0.3299161852158271
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8803[0m        [32m0.5596[0m       [35m0.7569[0m      [31m0.7569[0m        [94m0.8067[0m     +  0.0000  22.3733
      2      [36m0.9293[0m        [32m0.4286[0m       0.7495      0.7495        0.8156        0.0000  22.0283
      3      [36m0.9413[0m        [32m0.3629[0m       0.7451      0.7451        [94m0.8057[0m     +  0.0000  22.1067
      4      [36m0.9461[0m        [32m0.3303[0m       [35m0.7627[0m      [31m0.7627[0m        [94m0.7741[0m     +  0.0000  22.3735
      5      [36m0.9510[0m        [32m0.3012[0m       0.7549      0.7549        0.7749        0.0000  22.2627
      6      [36m0.9669[0m        [32m0.2653[0m       [35m0.7675[0m      [31m0.7675[0m        [94m0.7483[0m     +  0.0000  22.1548
      7      0.9664        [32m0.2528[0m       0.7672      0.7672        [94m0.7469[0m     +  0.0000  22.2009
      8      [36m0.9686[0m        [32m0.2452[0m       0.7670      0.7670        0.7514        0.0000  22.3733
      9      [36m0.9731[0m        [32m0.2389[0m       0.7604      0.7604        0.7587        0.0000  22.2949
     10      [36m0.9757[0m        [32m0.2239[0m       0.7661      0.7661        0.7501        0.0000  22.0454
     11      [36m0.9775[0m        [32m0.2174[0m       [35m0.7745[0m      [31m0.7745[0m        [94m0.7287[0m     +  0.0000  22.1870
     12      [36m0.9806[0m        [32m0.2148[0m       0.7740      0.7740        0.7305        0.0000  22.2658
     13      0.9806        [32m0.2137[0m       0.7712      0.7712        0.7368        0.0000  22.1397
     14      0.9806        [32m0.2117[0m       0.7733      0.7733        0.7352        0.0000  22.1699
     15      0.9806        [32m0.2109[0m       0.7700      0.7700        0.7369        0.0000  22.1853
     16      [36m0.9845[0m        [32m0.2069[0m       0.7698      0.7698        0.7350        0.0000  21.9973
     17      0.9837        0.2074       0.7700      0.7700        0.7352        0.0000  22.3088
     18      0.9823        0.2072       0.7693      0.7693        0.7362        0.0000  22.1548
     19      0.9837        0.2077       0.7684      0.7684        0.7369        0.0000  21.9970
     20      0.9845        [32m0.2034[0m       0.7688      0.7688        0.7361        0.0000  22.4825
     21      0.9810        0.2057       0.7682      0.7682        0.7362        0.0000  22.2782
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7756944444444445
F1 Macro Score after query 8: 0.35319827414871297
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9017[0m        [32m0.4275[0m       [35m0.7750[0m      [31m0.7750[0m        [94m0.6683[0m     +  0.0000  30.9227
      2      [36m0.9347[0m        [32m0.3255[0m       0.7630      0.7630        0.6722        0.0000  31.0030
      3      [36m0.9500[0m        [32m0.2740[0m       0.7618      0.7618        0.6972        0.0000  31.2572
      4      [36m0.9609[0m        [32m0.2355[0m       0.7738      0.7738        0.6857        0.0000  30.8497
      5      [36m0.9621[0m        [32m0.2085[0m       0.7634      0.7634        0.7298        0.0000  31.0255
      6      [36m0.9757[0m        [32m0.1740[0m       0.7597      0.7597        0.7347        0.0000  31.0390
      7      [36m0.9822[0m        [32m0.1549[0m       0.7639      0.7639        0.7399        0.0000  31.1577
      8      [36m0.9844[0m        [32m0.1450[0m       0.7630      0.7630        0.7508        0.0000  31.3311
      9      [36m0.9871[0m        [32m0.1356[0m       0.7684      0.7684        0.7443        0.0000  31.1757
     10      [36m0.9896[0m        [32m0.1292[0m       0.7694      0.7694        0.7541        0.0000  31.4423
     11      [36m0.9906[0m        [32m0.1237[0m       0.7700      0.7700        0.7436        0.0000  31.0000
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8145833333333333
F1 Macro Score after query 9: 0.42556652886253965
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8961[0m        [32m0.4028[0m       [35m0.8243[0m      [31m0.8243[0m        [94m0.5404[0m     +  0.0000  46.6352
      2      [36m0.9253[0m        [32m0.3136[0m       0.8076      0.8076        0.5999        0.0000  46.7458
      3      [36m0.9363[0m        [32m0.2735[0m       0.8102      0.8102        0.5849        0.0000  47.0361
      4      [36m0.9456[0m        [32m0.2398[0m       0.8069      0.8069        0.6013        0.0000  46.9966
      5      [36m0.9506[0m        [32m0.2149[0m       0.7826      0.7826        0.7480        0.0000  47.3180
      6      [36m0.9658[0m        [32m0.1673[0m       0.7872      0.7872        0.7455        0.0000  47.0119
      7      [36m0.9721[0m        [32m0.1491[0m       0.7917      0.7917        0.7346        0.0000  47.3232
      8      [36m0.9778[0m        [32m0.1373[0m       0.7891      0.7891        0.7588        0.0000  47.1359
      9      [36m0.9811[0m        [32m0.1269[0m       0.7804      0.7804        0.8005        0.0000  46.8369
     10      [36m0.9840[0m        [32m0.1178[0m       0.7828      0.7828        0.8136        0.0000  47.0547
     11      [36m0.9861[0m        [32m0.1097[0m       0.7861      0.7861        0.7819        0.0000  47.0128
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8336805555555555
F1 Macro Score after query 10: 0.44076115385925696
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9191[0m        [32m0.3290[0m       [35m0.8038[0m      [31m0.8038[0m        [94m0.5915[0m     +  0.0000  75.2771
      2      [36m0.9351[0m        [32m0.2662[0m       [35m0.8128[0m      [31m0.8128[0m        [94m0.5665[0m     +  0.0000  75.4357
      3      [36m0.9437[0m        [32m0.2285[0m       0.8016      0.8016        0.6047        0.0000  75.3923
      4      [36m0.9503[0m        [32m0.2004[0m       0.7990      0.7990        0.6487        0.0000  75.9336
      5      [36m0.9551[0m        [32m0.1799[0m       0.8099      0.8099        0.5892        0.0000  75.2933
      6      [36m0.9685[0m        [32m0.1382[0m       0.8043      0.8043        0.6367        0.0000  75.8693
      7      [36m0.9724[0m        [32m0.1248[0m       0.8080      0.8080        0.6442        0.0000  75.8079
      8      [36m0.9768[0m        [32m0.1113[0m       0.7917      0.7917        0.7148        0.0000  75.3378
      9      [36m0.9796[0m        [32m0.1031[0m       0.7960      0.7960        0.7154        0.0000  75.6173
     10      [36m0.9829[0m        [32m0.0944[0m       0.7887      0.7887        0.7483        0.0000  74.9112
     11      [36m0.9869[0m        [32m0.0826[0m       0.7892      0.7892        0.7960        0.0000  74.9796
     12      [36m0.9878[0m        [32m0.0796[0m       0.7887      0.7887        0.8023        0.0000  75.6338
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8225694444444444
F1 Macro Score after query 11: 0.4589181882952944
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9595[0m        [32m0.1722[0m       [35m0.8094[0m      [31m0.8094[0m        [94m0.6224[0m     +  0.0000  126.6260
      2      [36m0.9627[0m        [32m0.1483[0m       0.8094      0.8094        0.6584        0.0000  126.7531
      3      [36m0.9674[0m        [32m0.1265[0m       0.8066      0.8066        0.6672        0.0000  126.4370
      4      [36m0.9712[0m        [32m0.1103[0m       [35m0.8116[0m      [31m0.8116[0m        0.6615        0.0000  126.5509
      5      [36m0.9728[0m        [32m0.1000[0m       0.8024      0.8024        0.7351        0.0000  126.6267
      6      [36m0.9805[0m        [32m0.0746[0m       [35m0.8219[0m      [31m0.8219[0m        0.6565        0.0000  126.0791
      7      [36m0.9848[0m        [32m0.0628[0m       0.8161      0.8161        0.6886        0.0000  126.7479
      8      [36m0.9876[0m        [32m0.0567[0m       0.8118      0.8118        0.6881        0.0000  125.4360
      9      [36m0.9891[0m        [32m0.0505[0m       0.8128      0.8128        0.7138        0.0000  126.3177
     10      [36m0.9911[0m        [32m0.0455[0m       0.8087      0.8087        0.7594        0.0000  126.7756
     11      [36m0.9930[0m        [32m0.0388[0m       0.8035      0.8035        0.8156        0.0000  126.4335
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8376736111111112
F1 Macro Score after query 12: 0.45234349010096814
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9696[0m        [32m0.1256[0m       [35m0.8172[0m      [31m0.8172[0m        [94m0.6402[0m     +  0.0000  146.5345
      2      [36m0.9712[0m        [32m0.1094[0m       [35m0.8234[0m      [31m0.8234[0m        [94m0.5706[0m     +  0.0000  147.6296
      3      [36m0.9729[0m        [32m0.0981[0m       0.8042      0.8042        0.6862        0.0000  147.2529
      4      [36m0.9763[0m        [32m0.0866[0m       0.7911      0.7911        0.7709        0.0000  147.3680
      5      [36m0.9782[0m        [32m0.0759[0m       0.8168      0.8168        0.6223        0.0000  147.6892
      6      [36m0.9852[0m        [32m0.0562[0m       0.7964      0.7964        0.7404        0.0000  147.3940
      7      [36m0.9887[0m        [32m0.0469[0m       0.7984      0.7984        0.7547        0.0000  147.0829
      8      [36m0.9903[0m        [32m0.0415[0m       0.7958      0.7958        0.7942        0.0000  146.6555
      9      [36m0.9924[0m        [32m0.0360[0m       0.7965      0.7965        0.7815        0.0000  147.7769
     10      [36m0.9940[0m        [32m0.0318[0m       0.7972      0.7972        0.8108        0.0000  147.1949
     11      [36m0.9953[0m        [32m0.0279[0m       0.7962      0.7962        0.8632        0.0000  147.4069
     12      [36m0.9959[0m        [32m0.0253[0m       0.7969      0.7969        0.8608        0.0000  147.3153
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8244791666666667
F1 Macro Score after query 13: 0.42851124990381256
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed43\AL_entropy_sampling_results_for_multiclass_classification_s43.pickle
