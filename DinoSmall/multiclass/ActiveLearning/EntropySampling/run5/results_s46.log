(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2500[0m        [32m2.0211[0m       [35m0.0312[0m      [31m0.0312[0m        [94m2.1711[0m     +  0.0000  11.4500
      2      0.2500        [32m1.9823[0m       [35m0.0905[0m      [31m0.0905[0m        [94m2.1182[0m     +  0.0000  10.7501
      3      [36m0.5000[0m        [32m1.8310[0m       0.0451      0.0451        2.1478        0.0000  10.5821
      4      [36m0.7500[0m        [32m1.6492[0m       [35m0.1793[0m      [31m0.1793[0m        [94m2.0752[0m     +  0.0000  10.8579
      5      0.5000        1.7120       0.1592      0.1592        2.1497        0.0000  10.7108
      6      0.6250        [32m1.5485[0m       [35m0.1861[0m      [31m0.1861[0m        2.1376        0.0000  10.7961
      7      0.6250        1.6592       [35m0.1941[0m      [31m0.1941[0m        2.1289        0.0000  10.9820
      8      0.5000        1.6032       0.1760      0.1760        2.1336        0.0000  10.7819
      9      0.7500        1.5510       0.1708      0.1708        2.1354        0.0000  10.8006
     10      0.6250        1.5952       0.1778      0.1778        2.1357        0.0000  10.8918
     11      [36m0.8750[0m        [32m1.4948[0m       0.1769      0.1769        2.1371        0.0000  10.6995
     12      0.6250        1.5925       0.1799      0.1799        2.1347        0.0000  10.7532
     13      0.5000        1.5659       0.1783      0.1783        2.1346        0.0000  10.9885
     14      0.6250        1.5298       0.1745      0.1745        2.1374        0.0000  10.8884
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.1036
Pre F1 macro score = 0.0714

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5833[0m        [32m1.7308[0m       [35m0.4470[0m      [31m0.4470[0m        [94m1.8530[0m     +  0.0000  10.8280
      2      [36m0.7917[0m        [32m1.3538[0m       [35m0.4561[0m      [31m0.4561[0m        [94m1.8088[0m     +  0.0000  11.0458
      3      [36m0.8750[0m        [32m1.0708[0m       0.4427      0.4427        [94m1.7947[0m     +  0.0000  10.9012
      4      0.8333        [32m0.8946[0m       0.4474      0.4474        [94m1.7756[0m     +  0.0000  10.8273
      5      0.8750        [32m0.8640[0m       0.3849      0.3849        1.8250        0.0000  10.9691
      6      [36m0.9583[0m        [32m0.7590[0m       0.3962      0.3962        1.8147        0.0000  10.7788
      7      0.9167        0.7791       0.3997      0.3997        1.8119        0.0000  10.9985
      8      0.9583        [32m0.7138[0m       0.3958      0.3958        1.8134        0.0000  10.8465
      9      0.9583        [32m0.6903[0m       0.4047      0.4047        1.8082        0.0000  10.9357
     10      0.9583        0.7131       0.4061      0.4061        1.8036        0.0000  10.9336
     11      0.8750        0.7213       0.4059      0.4059        1.8041        0.0000  10.8135
     12      [36m1.0000[0m        [32m0.6581[0m       0.4049      0.4049        1.8047        0.0000  11.0771
     13      0.9167        0.7304       0.4036      0.4036        1.8051        0.0000  11.0782
     14      0.9167        0.6837       0.4019      0.4019        1.8055        0.0000  10.8104
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.36944444444444446
F1 Macro Score after query 1: 0.10368146570592278
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7857[0m        [32m1.2224[0m       [35m0.2773[0m      [31m0.2773[0m        [94m1.9923[0m     +  0.0000  11.1366
      2      [36m0.8393[0m        [32m0.9213[0m       [35m0.2792[0m      [31m0.2792[0m        [94m1.9614[0m     +  0.0000  11.0155
      3      0.8393        [32m0.8487[0m       [35m0.2840[0m      [31m0.2840[0m        [94m1.9421[0m     +  0.0000  11.0923
      4      [36m0.8929[0m        [32m0.7759[0m       0.2753      0.2753        [94m1.9118[0m     +  0.0000  11.3463
      5      0.8929        [32m0.7353[0m       0.2733      0.2733        1.9205        0.0000  10.9816
      6      0.8929        [32m0.6622[0m       0.2741      0.2741        [94m1.9021[0m     +  0.0000  10.9540
      7      [36m0.9107[0m        0.6675       0.2762      0.2762        [94m1.8867[0m     +  0.0000  11.0479
      8      0.9107        0.6869       0.2771      0.2771        [94m1.8856[0m     +  0.0000  11.0594
      9      0.9107        [32m0.6523[0m       0.2780      0.2780        [94m1.8797[0m     +  0.0000  11.2638
     10      [36m0.9286[0m        [32m0.6101[0m       0.2792      0.2792        [94m1.8720[0m     +  0.0000  11.1627
     11      0.9107        0.6615       0.2790      0.2790        1.8725        0.0000  11.1317
     12      0.9286        0.6706       0.2802      0.2802        [94m1.8708[0m     +  0.0000  10.9341
     13      0.9107        0.6519       0.2802      0.2802        [94m1.8700[0m     +  0.0000  11.0465
     14      0.9286        0.6535       0.2812      0.2812        [94m1.8676[0m     +  0.0000  11.1092
     15      0.9107        0.6644       0.2816      0.2816        [94m1.8668[0m     +  0.0000  10.9518
     16      0.9107        0.6511       0.2812      0.2812        1.8673        0.0000  11.1240
     17      0.8929        0.6239       0.2816      0.2816        1.8672        0.0000  10.8691
     18      0.9107        0.6329       0.2814      0.2814        1.8675        0.0000  10.8961
     19      0.9107        0.6532       0.2816      0.2816        1.8668        0.0000  11.1236
     20      0.8929        0.6415       0.2818      0.2818        1.8672        0.0000  10.9842
     21      0.9286        0.6186       0.2818      0.2818        1.8671        0.0000  11.0289
     22      0.9107        [32m0.6036[0m       0.2818      0.2818        1.8671        0.0000  11.1430
     23      0.9286        0.6353       0.2818      0.2818        1.8670        0.0000  10.8762
     24      0.9107        0.6783       0.2818      0.2818        1.8671        0.0000  11.0486
     25      0.9107        0.6144       0.2818      0.2818        1.8671        0.0000  11.0296
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.2934027777777778
F1 Macro Score after query 2: 0.09524722990114841
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8929[0m        [32m0.8046[0m       [35m0.4479[0m      [31m0.4479[0m        [94m1.7006[0m     +  0.0000  11.2181
      2      [36m0.9018[0m        [32m0.6214[0m       [35m0.4800[0m      [31m0.4800[0m        [94m1.6382[0m     +  0.0000  11.3591
      3      [36m0.9107[0m        [32m0.5313[0m       0.4750      0.4750        [94m1.6261[0m     +  0.0000  11.1599
      4      [36m0.9286[0m        [32m0.5091[0m       0.4769      0.4769        [94m1.6151[0m     +  0.0000  11.2153
      5      [36m0.9464[0m        [32m0.4583[0m       0.4573      0.4573        1.6395        0.0000  11.2306
      6      [36m0.9554[0m        [32m0.4340[0m       0.4667      0.4667        1.6232        0.0000  11.3879
      7      0.9464        0.4532       0.4693      0.4693        1.6211        0.0000  11.3624
      8      [36m0.9643[0m        [32m0.4136[0m       0.4734      0.4734        1.6169        0.0000  11.3500
      9      0.9643        0.4195       0.4727      0.4727        1.6215        0.0000  11.3673
     10      0.9554        [32m0.4135[0m       0.4755      0.4755        1.6217        0.0000  11.3120
     11      [36m0.9732[0m        [32m0.3970[0m       0.4760      0.4760        1.6208        0.0000  11.2968
     12      0.9464        0.3981       0.4766      0.4766        1.6209        0.0000  11.2834
     13      0.9732        0.4105       0.4766      0.4766        1.6197        0.0000  11.3391
     14      0.9732        [32m0.3777[0m       0.4767      0.4767        1.6197        0.0000  11.3300
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.4953125
F1 Macro Score after query 3: 0.13321162470635692
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8798[0m        [32m0.7661[0m       [35m0.4740[0m      [31m0.4740[0m        [94m1.5442[0m     +  0.0000  11.6754
      2      [36m0.9327[0m        [32m0.5702[0m       [35m0.4757[0m      [31m0.4757[0m        [94m1.5435[0m     +  0.0000  11.6867
      3      [36m0.9663[0m        [32m0.4655[0m       0.4688      0.4688        1.5501        0.0000  11.7271
      4      0.9615        [32m0.4405[0m       0.4519      0.4519        1.5691        0.0000  11.8749
      5      0.9663        [32m0.3944[0m       0.4677      0.4677        1.5479        0.0000  11.6888
      6      [36m0.9808[0m        [32m0.3415[0m       0.4627      0.4627        1.5565        0.0000  11.7190
      7      0.9808        0.3615       0.4582      0.4582        1.5647        0.0000  11.7955
      8      0.9712        0.3448       0.4569      0.4569        1.5676        0.0000  11.8284
      9      0.9663        [32m0.3340[0m       0.4564      0.4564        1.5697        0.0000  11.7681
     10      0.9808        0.3502       0.4549      0.4549        1.5743        0.0000  11.8002
     11      [36m0.9856[0m        0.3378       0.4543      0.4543        1.5765        0.0000  11.7141
     12      0.9808        [32m0.3321[0m       0.4545      0.4545        1.5764        0.0000  11.7704
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.4595486111111111
F1 Macro Score after query 4: 0.15255440029686634
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8177[0m        [32m0.7822[0m       [35m0.4849[0m      [31m0.4849[0m        [94m1.4297[0m     +  0.0000  12.6773
      2      [36m0.9427[0m        [32m0.5549[0m       [35m0.5002[0m      [31m0.5002[0m        1.4586        0.0000  12.6390
      3      [36m0.9635[0m        [32m0.4826[0m       0.4984      0.4984        1.4714        0.0000  12.5929
      4      [36m0.9661[0m        [32m0.4411[0m       0.5000      0.5000        1.4780        0.0000  12.6718
      5      [36m0.9688[0m        [32m0.3827[0m       0.4983      0.4983        1.4822        0.0000  12.6675
      6      0.9688        [32m0.3714[0m       [35m0.5028[0m      [31m0.5028[0m        1.4852        0.0000  12.6432
      7      [36m0.9740[0m        [32m0.3621[0m       0.5021      0.5021        1.4864        0.0000  12.5334
      8      0.9740        [32m0.3596[0m       0.5026      0.5026        1.4868        0.0000  12.5311
      9      0.9740        [32m0.3522[0m       [35m0.5059[0m      [31m0.5059[0m        1.4891        0.0000  12.6213
     10      [36m0.9766[0m        [32m0.3293[0m       0.5052      0.5052        1.4911        0.0000  12.6888
     11      [36m0.9792[0m        0.3307       [35m0.5062[0m      [31m0.5062[0m        1.4909        0.0000  12.6510
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.5276041666666667
F1 Macro Score after query 5: 0.1730307328999588
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8082[0m        [32m0.8412[0m       [35m0.5630[0m      [31m0.5630[0m        [94m1.3760[0m     +  0.0000  14.2508
      2      [36m0.8750[0m        [32m0.6686[0m       [35m0.6264[0m      [31m0.6264[0m        [94m1.2838[0m     +  0.0000  14.0932
      3      [36m0.8935[0m        [32m0.6034[0m       [35m0.6330[0m      [31m0.6330[0m        [94m1.2726[0m     +  0.0000  14.4551
      4      [36m0.9062[0m        [32m0.5286[0m       [35m0.6399[0m      [31m0.6399[0m        [94m1.2566[0m     +  0.0000  14.3436
      5      [36m0.9190[0m        [32m0.5016[0m       [35m0.6455[0m      [31m0.6455[0m        [94m1.2385[0m     +  0.0000  14.0953
      6      [36m0.9375[0m        [32m0.4479[0m       [35m0.6472[0m      [31m0.6472[0m        [94m1.2163[0m     +  0.0000  14.0724
      7      [36m0.9418[0m        [32m0.4330[0m       [35m0.6474[0m      [31m0.6474[0m        [94m1.2041[0m     +  0.0000  14.1195
      8      [36m0.9432[0m        [32m0.4217[0m       [35m0.6517[0m      [31m0.6517[0m        [94m1.2026[0m     +  0.0000  13.9624
      9      [36m0.9545[0m        0.4244       0.6479      0.6479        [94m1.1968[0m     +  0.0000  13.8869
     10      [36m0.9560[0m        [32m0.4045[0m       0.6512      0.6512        [94m1.1921[0m     +  0.0000  14.3394
     11      [36m0.9574[0m        [32m0.3961[0m       0.6512      0.6512        [94m1.1896[0m     +  0.0000  14.2587
     12      [36m0.9616[0m        [32m0.3849[0m       0.6500      0.6500        1.1897        0.0000  13.9943
     13      0.9588        0.3853       0.6484      0.6484        [94m1.1845[0m     +  0.0000  14.0734
     14      0.9588        0.3919       0.6500      0.6500        1.1846        0.0000  14.1516
     15      0.9588        [32m0.3748[0m       0.6497      0.6497        1.1855        0.0000  13.9640
     16      0.9588        0.3895       0.6493      0.6493        [94m1.1839[0m     +  0.0000  14.3079
     17      0.9616        0.3749       0.6495      0.6495        [94m1.1828[0m     +  0.0000  13.9128
     18      0.9574        0.3762       0.6493      0.6493        [94m1.1826[0m     +  0.0000  14.1525
     19      0.9588        [32m0.3732[0m       0.6495      0.6495        [94m1.1825[0m     +  0.0000  14.1027
     20      0.9602        0.3863       0.6491      0.6491        1.1835        0.0000  14.0556
     21      0.9616        0.3783       0.6491      0.6491        1.1833        0.0000  14.1817
     22      0.9560        [32m0.3697[0m       0.6491      0.6491        1.1831        0.0000  14.4641
     23      0.9560        0.3719       0.6490      0.6490        1.1828        0.0000  14.2453
     24      [36m0.9631[0m        0.3705       0.6488      0.6488        [94m1.1824[0m     +  0.0000  14.3856
     25      0.9588        0.3774       0.6488      0.6488        1.1825        0.0000  14.0259
     26      0.9574        0.3803       0.6488      0.6488        [94m1.1824[0m     +  0.0000  14.0427
     27      0.9588        0.3727       0.6488      0.6488        [94m1.1823[0m     +  0.0000  14.2602
     28      0.9574        0.3755       0.6488      0.6488        [94m1.1823[0m     +  0.0000  14.0564
     29      0.9631        0.3722       0.6488      0.6488        [94m1.1823[0m     +  0.0000  14.1971
     30      [36m0.9673[0m        0.3733       0.6488      0.6488        [94m1.1822[0m     +  0.0000  14.0430
     31      0.9602        0.3726       0.6488      0.6488        [94m1.1822[0m     +  0.0000  14.2440
     32      0.9588        0.3730       0.6488      0.6488        [94m1.1822[0m     +  0.0000  14.1676
     33      0.9616        0.3716       0.6488      0.6488        [94m1.1822[0m     +  0.0000  14.0895
     34      0.9631        0.3818       0.6486      0.6486        [94m1.1822[0m     +  0.0000  14.3556
     35      0.9616        0.3719       0.6486      0.6486        [94m1.1822[0m     +  0.0000  14.1508
     36      0.9616        0.3708       0.6486      0.6486        [94m1.1822[0m     +  0.0000  14.1037
     37      0.9560        0.3798       0.6486      0.6486        [94m1.1822[0m     +  0.0000  14.1967
     38      0.9631        0.3754       0.6486      0.6486        [94m1.1822[0m     +  0.0000  14.1042
     39      0.9588        0.3735       0.6486      0.6486        [94m1.1822[0m     +  0.0000  14.2926
     40      0.9616        0.3741       0.6486      0.6486        [94m1.1822[0m     +  0.0000  13.9702
     41      0.9602        [32m0.3676[0m       0.6486      0.6486        [94m1.1822[0m     +  0.0000  14.3386
     42      0.9645        0.3712       0.6486      0.6486        [94m1.1822[0m     +  0.0000  14.1975
     43      0.9560        0.3767       0.6486      0.6486        [94m1.1822[0m     +  0.0000  14.0721
     44      0.9588        0.3719       0.6486      0.6486        [94m1.1822[0m     +  0.0000  14.2905
     45      0.9616        [32m0.3667[0m       0.6486      0.6486        [94m1.1822[0m     +  0.0000  14.0416
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6508680555555556
F1 Macro Score after query 6: 0.21995134574670155
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8845[0m        [32m0.6058[0m       [35m0.6101[0m      [31m0.6101[0m        [94m1.1843[0m     +  0.0000  17.1213
      2      [36m0.9407[0m        [32m0.4489[0m       [35m0.6655[0m      [31m0.6655[0m        [94m1.1317[0m     +  0.0000  16.8385
      3      [36m0.9549[0m        [32m0.3970[0m       [35m0.6780[0m      [31m0.6780[0m        [94m1.1027[0m     +  0.0000  16.8093
      4      0.9533        [32m0.3672[0m       [35m0.6814[0m      [31m0.6814[0m        [94m1.1021[0m     +  0.0000  16.8257
      5      [36m0.9612[0m        [32m0.3310[0m       [35m0.6946[0m      [31m0.6946[0m        [94m1.0725[0m     +  0.0000  17.0288
      6      [36m0.9707[0m        [32m0.2972[0m       [35m0.6979[0m      [31m0.6979[0m        1.0960        0.0000  16.9025
      7      [36m0.9731[0m        [32m0.2957[0m       [35m0.7000[0m      [31m0.7000[0m        1.0982        0.0000  16.7940
      8      [36m0.9755[0m        [32m0.2800[0m       [35m0.7010[0m      [31m0.7010[0m        1.1026        0.0000  16.9178
      9      [36m0.9786[0m        [32m0.2765[0m       0.6991      0.6991        1.1040        0.0000  17.0255
     10      0.9771        0.2767       0.6991      0.6991        1.1038        0.0000  17.0446
     11      0.9771        [32m0.2628[0m       0.6939      0.6939        1.1138        0.0000  16.9493
     12      [36m0.9794[0m        [32m0.2583[0m       0.6946      0.6946        1.1150        0.0000  17.0541
     13      0.9794        0.2600       0.6962      0.6962        1.1143        0.0000  16.6973
     14      [36m0.9818[0m        0.2604       0.6960      0.6960        1.1151        0.0000  16.9188
     15      0.9818        0.2592       0.6955      0.6955        1.1173        0.0000  17.0610
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.7262152777777777
F1 Macro Score after query 7: 0.38500662898483956
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8754[0m        [32m0.6039[0m       [35m0.6792[0m      [31m0.6792[0m        [94m1.0471[0m     +  0.0000  21.8890
      2      [36m0.9271[0m        [32m0.4549[0m       [35m0.6878[0m      [31m0.6878[0m        [94m1.0334[0m     +  0.0000  22.3132
      3      [36m0.9404[0m        [32m0.3916[0m       [35m0.7151[0m      [31m0.7151[0m        [94m1.0029[0m     +  0.0000  22.2699
      4      [36m0.9488[0m        [32m0.3540[0m       0.7069      0.7069        1.0345        0.0000  21.6462
      5      [36m0.9572[0m        [32m0.3194[0m       [35m0.7247[0m      [31m0.7247[0m        [94m0.9860[0m     +  0.0000  21.9512
      6      [36m0.9678[0m        [32m0.2754[0m       [35m0.7401[0m      [31m0.7401[0m        [94m0.9531[0m     +  0.0000  22.0460
      7      [36m0.9713[0m        [32m0.2584[0m       0.7394      0.7394        0.9581        0.0000  21.8590
      8      0.9713        [32m0.2557[0m       0.7389      0.7389        0.9562        0.0000  21.8587
      9      [36m0.9766[0m        [32m0.2406[0m       0.7399      0.7399        0.9532        0.0000  21.9547
     10      [36m0.9784[0m        [32m0.2352[0m       0.7391      0.7391        0.9574        0.0000  22.0775
     11      [36m0.9806[0m        0.2356       0.7384      0.7384        0.9544        0.0000  21.9512
     12      0.9792        [32m0.2276[0m       0.7384      0.7384        0.9557        0.0000  21.7658
     13      0.9806        0.2290       0.7378      0.7378        0.9571        0.0000  21.8261
     14      [36m0.9828[0m        [32m0.2245[0m       0.7392      0.7392        0.9551        0.0000  22.0141
     15      [36m0.9837[0m        [32m0.2211[0m       0.7385      0.7385        0.9579        0.0000  21.8753
     16      0.9837        [32m0.2205[0m       0.7382      0.7382        0.9597        0.0000  21.7969
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7803819444444444
F1 Macro Score after query 8: 0.4766642524423854
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8936[0m        [32m0.4786[0m       [35m0.8128[0m      [31m0.8128[0m        [94m0.6616[0m     +  0.0000  30.6291
      2      [36m0.9290[0m        [32m0.3753[0m       [35m0.8149[0m      [31m0.8149[0m        0.6795        0.0000  30.6454
      3      [36m0.9470[0m        [32m0.3157[0m       0.8127      0.8127        0.6820        0.0000  30.9126
      4      [36m0.9547[0m        [32m0.2768[0m       0.8028      0.8028        0.7611        0.0000  30.9296
      5      [36m0.9584[0m        [32m0.2515[0m       0.8118      0.8118        0.7600        0.0000  30.8027
      6      [36m0.9723[0m        [32m0.2134[0m       0.8035      0.8035        0.6999        0.0000  30.7699
      7      0.9720        [32m0.1980[0m       0.8054      0.8054        0.7102        0.0000  30.7558
      8      [36m0.9762[0m        [32m0.1880[0m       0.8089      0.8089        0.7152        0.0000  30.7093
      9      [36m0.9767[0m        [32m0.1806[0m       0.8059      0.8059        0.7286        0.0000  30.5989
     10      [36m0.9800[0m        [32m0.1716[0m       0.8064      0.8064        0.7290        0.0000  30.7553
     11      [36m0.9814[0m        [32m0.1651[0m       0.8075      0.8075        0.7620        0.0000  30.7244
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8385416666666666
F1 Macro Score after query 9: 0.5352308937285639
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8947[0m        [32m0.4476[0m       [35m0.7536[0m      [31m0.7536[0m        [94m0.7599[0m     +  0.0000  46.1856
      2      [36m0.9283[0m        [32m0.3485[0m       [35m0.7649[0m      [31m0.7649[0m        0.7623        0.0000  46.5669
      3      [36m0.9385[0m        [32m0.3015[0m       0.7498      0.7498        0.8052        0.0000  46.6595
      4      [36m0.9454[0m        [32m0.2655[0m       [35m0.7727[0m      [31m0.7727[0m        [94m0.7232[0m     +  0.0000  46.6255
      5      [36m0.9531[0m        [32m0.2367[0m       [35m0.7795[0m      [31m0.7795[0m        [94m0.7021[0m     +  0.0000  46.7023
      6      [36m0.9632[0m        [32m0.1952[0m       [35m0.7863[0m      [31m0.7863[0m        [94m0.6973[0m     +  0.0000  46.4419
      7      [36m0.9676[0m        [32m0.1804[0m       [35m0.7905[0m      [31m0.7905[0m        0.6975        0.0000  47.5069
      8      [36m0.9740[0m        [32m0.1652[0m       [35m0.7925[0m      [31m0.7925[0m        0.7187        0.0000  46.8985
      9      [36m0.9754[0m        [32m0.1562[0m       [35m0.7929[0m      [31m0.7929[0m        0.7106        0.0000  46.6223
     10      [36m0.9776[0m        [32m0.1491[0m       [35m0.7946[0m      [31m0.7946[0m        0.7312        0.0000  46.4408
     11      [36m0.9812[0m        [32m0.1334[0m       [35m0.8089[0m      [31m0.8089[0m        [94m0.6819[0m     +  0.0000  46.0284
     12      [36m0.9839[0m        [32m0.1319[0m       [35m0.8095[0m      [31m0.8095[0m        0.6845        0.0000  46.3826
     13      [36m0.9846[0m        [32m0.1280[0m       0.8056      0.8056        0.7002        0.0000  46.6538
     14      [36m0.9851[0m        [32m0.1260[0m       0.8047      0.8047        0.7072        0.0000  46.6956
     15      [36m0.9854[0m        [32m0.1230[0m       0.8076      0.8076        0.7134        0.0000  46.3169
     16      [36m0.9861[0m        [32m0.1199[0m       0.8080      0.8080        0.7176        0.0000  46.6090
     17      [36m0.9879[0m        [32m0.1180[0m       0.8068      0.8068        0.7203        0.0000  46.3464
     18      0.9868        0.1207       0.8082      0.8082        0.7206        0.0000  46.3904
     19      [36m0.9890[0m        [32m0.1167[0m       0.8061      0.8061        0.7256        0.0000  46.6121
     20      0.9878        [32m0.1158[0m       0.8083      0.8083        0.7233        0.0000  46.4639
     21      0.9885        0.1170       0.8090      0.8090        0.7241        0.0000  46.4546
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8414930555555555
F1 Macro Score after query 10: 0.5283721053328415
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9449[0m        [32m0.2419[0m       [35m0.8224[0m      [31m0.8224[0m        [94m0.5892[0m     +  0.0000  73.4144
      2      [36m0.9527[0m        [32m0.2045[0m       0.7937      0.7937        0.7104        0.0000  74.7641
      3      [36m0.9584[0m        [32m0.1781[0m       0.7953      0.7953        0.6950        0.0000  74.7079
      4      [36m0.9644[0m        [32m0.1553[0m       [35m0.8389[0m      [31m0.8389[0m        [94m0.5680[0m     +  0.0000  75.0767
      5      [36m0.9680[0m        [32m0.1374[0m       0.7906      0.7906        0.7989        0.0000  74.6705
      6      [36m0.9761[0m        [32m0.1068[0m       0.8295      0.8295        0.6399        0.0000  74.5599
      7      [36m0.9824[0m        [32m0.0888[0m       0.8267      0.8267        0.6623        0.0000  74.5780
      8      [36m0.9862[0m        [32m0.0781[0m       0.8266      0.8266        0.6679        0.0000  75.3317
      9      [36m0.9890[0m        [32m0.0681[0m       0.8269      0.8269        0.6878        0.0000  74.7281
     10      [36m0.9913[0m        [32m0.0631[0m       0.8241      0.8241        0.7366        0.0000  74.2046
     11      [36m0.9943[0m        [32m0.0548[0m       0.8182      0.8182        0.7556        0.0000  74.6535
     12      [36m0.9956[0m        [32m0.0499[0m       0.8168      0.8168        0.7728        0.0000  74.7167
     13      [36m0.9969[0m        [32m0.0474[0m       0.8207      0.8207        0.7615        0.0000  74.5184
     14      0.9962        [32m0.0456[0m       0.8175      0.8175        0.7842        0.0000  74.9554
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8380208333333333
F1 Macro Score after query 11: 0.5290357496347169
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9742[0m        [32m0.1170[0m       [35m0.7816[0m      [31m0.7816[0m        [94m0.8935[0m     +  0.0000  124.9006
      2      [36m0.9768[0m        [32m0.0985[0m       [35m0.8144[0m      [31m0.8144[0m        [94m0.7621[0m     +  0.0000  124.5315
      3      [36m0.9791[0m        [32m0.0859[0m       0.8123      0.8123        0.7795        0.0000  125.6019
      4      [36m0.9805[0m        [32m0.0771[0m       0.8036      0.8036        0.8022        0.0000  125.2413
      5      [36m0.9816[0m        [32m0.0728[0m       [35m0.8247[0m      [31m0.8247[0m        0.8191        0.0000  125.7710
      6      [36m0.9867[0m        [32m0.0538[0m       0.8236      0.8236        [94m0.7454[0m     +  0.0000  125.2348
      7      [36m0.9916[0m        [32m0.0407[0m       0.8200      0.8200        0.8042        0.0000  125.7221
      8      [36m0.9942[0m        [32m0.0324[0m       0.8135      0.8135        0.7977        0.0000  125.5777
      9      [36m0.9956[0m        [32m0.0274[0m       0.8089      0.8089        0.8397        0.0000  125.5713
     10      [36m0.9969[0m        [32m0.0224[0m       0.8144      0.8144        0.8730        0.0000  125.6226
     11      [36m0.9980[0m        [32m0.0205[0m       0.8156      0.8156        0.8672        0.0000  124.9097
     12      [36m0.9988[0m        [32m0.0179[0m       0.8128      0.8128        0.8895        0.0000  125.6203
     13      [36m0.9993[0m        [32m0.0167[0m       0.8139      0.8139        0.8892        0.0000  125.3123
     14      [36m0.9993[0m        [32m0.0159[0m       0.8127      0.8127        0.8953        0.0000  124.8300
     15      [36m0.9994[0m        [32m0.0146[0m       0.8158      0.8158        0.9031        0.0000  125.9391
     16      [36m0.9995[0m        [32m0.0144[0m       0.8128      0.8128        0.9247        0.0000  125.1646
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8449652777777777
F1 Macro Score after query 12: 0.5319896004980307
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9866[0m        [32m0.0533[0m       [35m0.7552[0m      [31m0.7552[0m        [94m1.0660[0m     +  0.0000  144.0331
      2      [36m0.9884[0m        [32m0.0462[0m       [35m0.7866[0m      [31m0.7866[0m        [94m0.9954[0m     +  0.0000  146.0915
      3      [36m0.9889[0m        [32m0.0454[0m       [35m0.8043[0m      [31m0.8043[0m        [94m0.9538[0m     +  0.0000  146.5402
      4      [36m0.9897[0m        [32m0.0390[0m       [35m0.8056[0m      [31m0.8056[0m        1.0183        0.0000  145.6866
      5      [36m0.9905[0m        [32m0.0362[0m       0.8035      0.8035        1.0365        0.0000  146.0614
      6      [36m0.9938[0m        [32m0.0257[0m       0.8056      0.8056        0.9724        0.0000  145.0670
      7      [36m0.9978[0m        [32m0.0146[0m       [35m0.8182[0m      [31m0.8182[0m        0.9821        0.0000  146.2767
      8      [36m0.9988[0m        [32m0.0108[0m       0.8158      0.8158        1.0268        0.0000  145.1721
      9      [36m0.9993[0m        [32m0.0090[0m       0.8073      0.8073        1.0481        0.0000  146.1476
     10      [36m0.9995[0m        [32m0.0076[0m       0.8128      0.8128        1.0767        0.0000  145.9835
     11      [36m0.9997[0m        [32m0.0068[0m       0.8082      0.8082        1.1097        0.0000  146.7197
     12      [36m0.9998[0m        [32m0.0060[0m       0.8115      0.8115        1.1026        0.0000  146.4759
     13      [36m0.9999[0m        [32m0.0058[0m       0.8095      0.8095        1.1184        0.0000  146.7445
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8390625000000002
F1 Macro Score after query 13: 0.5139557627355312
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed46\AL_entropy_sampling_results_for_multiclass_classification_s46.pickle
