(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.1250[0m        [32m2.1077[0m       [35m0.1382[0m      [31m0.1382[0m        [94m2.0710[0m     +  0.0000  11.9063
      2      [36m0.3750[0m        [32m1.9482[0m       [35m0.1682[0m      [31m0.1682[0m        2.0767        0.0000  10.5608
      3      0.3750        1.9746       0.0878      0.0878        2.0894        0.0000  10.2923
      4      0.2500        1.9569       0.0842      0.0842        2.0905        0.0000  10.7970
      5      [36m0.7500[0m        [32m1.7370[0m       0.1208      0.1208        2.1113        0.0000  10.6718
      6      0.7500        [32m1.6493[0m       0.1151      0.1151        2.1138        0.0000  10.4250
      7      0.7500        [32m1.5039[0m       0.1240      0.1240        2.1054        0.0000  10.7667
      8      0.7500        1.5832       0.1512      0.1512        2.0993        0.0000  10.9625
      9      [36m0.8750[0m        1.5343       0.1420      0.1420        2.1041        0.0000  10.8450
     10      [36m1.0000[0m        1.5615       0.1372      0.1372        2.1087        0.0000  11.0766
     11      0.6250        1.6494       0.1422      0.1422        2.1061        0.0000  10.8274
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.1997
Pre F1 macro score = 0.1318

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5417[0m        [32m1.7440[0m       [35m0.4431[0m      [31m0.4431[0m        [94m1.7639[0m     +  0.0000  10.7805
      2      [36m0.7083[0m        [32m1.2823[0m       [35m0.4747[0m      [31m0.4747[0m        1.7933        0.0000  10.7603
      3      [36m0.8750[0m        [32m1.0485[0m       0.4615      0.4615        1.7739        0.0000  10.8763
      4      [36m0.9583[0m        [32m0.9503[0m       0.4543      0.4543        1.7912        0.0000  10.5459
      5      0.8750        [32m0.8838[0m       0.4628      0.4628        1.7851        0.0000  10.7547
      6      0.9167        [32m0.7728[0m       0.4717      0.4717        1.7810        0.0000  10.9874
      7      0.9167        0.8011       0.4682      0.4682        1.7797        0.0000  10.5546
      8      0.9583        [32m0.7718[0m       0.4655      0.4655        1.7810        0.0000  10.6036
      9      0.9583        [32m0.7514[0m       0.4641      0.4641        1.7791        0.0000  10.7475
     10      0.9167        0.7572       0.4597      0.4597        1.7822        0.0000  10.9221
     11      0.9583        [32m0.7275[0m       0.4594      0.4594        1.7812        0.0000  10.9533
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.4861111111111111
F1 Macro Score after query 1: 0.14029493542212376
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.4464[0m        [32m1.6540[0m       [35m0.4670[0m      [31m0.4670[0m        [94m1.7323[0m     +  0.0000  10.6445
      2      [36m0.5714[0m        [32m1.4254[0m       0.4625      0.4625        [94m1.7137[0m     +  0.0000  10.8905
      3      [36m0.7143[0m        [32m1.2285[0m       0.4594      0.4594        [94m1.6805[0m     +  0.0000  10.6560
      4      [36m0.7679[0m        [32m1.0996[0m       0.4663      0.4663        [94m1.6414[0m     +  0.0000  11.0563
      5      [36m0.8214[0m        [32m0.9986[0m       0.4550      0.4550        1.6589        0.0000  11.0401
      6      0.8036        [32m0.9682[0m       [35m0.4708[0m      [31m0.4708[0m        1.6427        0.0000  11.0154
      7      0.8214        0.9906       [35m0.4715[0m      [31m0.4715[0m        [94m1.6375[0m     +  0.0000  11.0467
      8      0.8036        [32m0.9048[0m       [35m0.4722[0m      [31m0.4722[0m        [94m1.6364[0m     +  0.0000  10.8701
      9      0.8214        0.9410       [35m0.4731[0m      [31m0.4731[0m        1.6391        0.0000  10.9627
     10      0.8214        [32m0.8747[0m       [35m0.4733[0m      [31m0.4733[0m        1.6382        0.0000  10.8528
     11      0.8214        0.8797       0.4731      0.4731        1.6383        0.0000  10.7781
     12      [36m0.8750[0m        [32m0.8087[0m       0.4727      0.4727        1.6392        0.0000  10.7754
     13      0.8214        0.8882       0.4729      0.4729        1.6370        0.0000  10.8351
     14      0.8036        0.8867       0.4726      0.4726        1.6366        0.0000  10.8283
     15      0.8214        0.8829       0.4729      0.4729        1.6371        0.0000  10.9325
     16      0.8214        0.8371       0.4729      0.4729        1.6370        0.0000  10.7749
     17      0.8571        0.8700       0.4729      0.4729        1.6367        0.0000  10.6355
     18      0.8393        0.8426       0.4729      0.4729        1.6365        0.0000  10.9254
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.48506944444444444
F1 Macro Score after query 2: 0.13594100637277476
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5982[0m        [32m1.3932[0m       [35m0.4470[0m      [31m0.4470[0m        [94m1.4818[0m     +  0.0000  11.3585
      2      [36m0.6786[0m        [32m1.1348[0m       [35m0.5040[0m      [31m0.5040[0m        [94m1.4417[0m     +  0.0000  11.0593
      3      [36m0.8125[0m        [32m0.9939[0m       0.4835      0.4835        1.4718        0.0000  11.1626
      4      [36m0.8482[0m        [32m0.8915[0m       [35m0.5227[0m      [31m0.5227[0m        [94m1.4311[0m     +  0.0000  11.1888
      5      0.8482        [32m0.8778[0m       0.5144      0.5144        1.4325        0.0000  11.0880
      6      [36m0.8929[0m        [32m0.7828[0m       0.5085      0.5085        [94m1.4253[0m     +  0.0000  11.0543
      7      0.8661        [32m0.7592[0m       0.5113      0.5113        [94m1.4239[0m     +  0.0000  11.2977
      8      [36m0.9018[0m        [32m0.7296[0m       0.5111      0.5111        [94m1.4184[0m     +  0.0000  10.9860
      9      [36m0.9196[0m        0.7422       0.5099      0.5099        1.4185        0.0000  10.9369
     10      0.9196        [32m0.7041[0m       0.5073      0.5073        [94m1.4183[0m     +  0.0000  11.3868
     11      0.9018        0.7148       0.5061      0.5061        1.4208        0.0000  10.9215
     12      0.9196        0.7178       0.5045      0.5045        1.4204        0.0000  11.0403
     13      0.8929        0.7347       0.5045      0.5045        1.4208        0.0000  10.8049
     14      0.9196        0.7097       0.5047      0.5047        1.4199        0.0000  11.0686
     15      0.8929        [32m0.6871[0m       0.5038      0.5038        1.4205        0.0000  11.0405
     16      0.9196        0.6994       0.5036      0.5036        1.4205        0.0000  11.2262
     17      0.9196        0.6927       0.5033      0.5033        1.4200        0.0000  10.9404
     18      0.8929        0.7082       0.5035      0.5035        1.4198        0.0000  11.0257
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.49722222222222223
F1 Macro Score after query 3: 0.16510466170220273
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8462[0m        [32m0.8403[0m       [35m0.4743[0m      [31m0.4743[0m        [94m1.4763[0m     +  0.0000  11.3322
      2      [36m0.9087[0m        [32m0.6554[0m       [35m0.5049[0m      [31m0.5049[0m        [94m1.3590[0m     +  0.0000  11.6247
      3      [36m0.9423[0m        [32m0.5601[0m       [35m0.5090[0m      [31m0.5090[0m        [94m1.3451[0m     +  0.0000  11.5001
      4      0.9375        [32m0.5062[0m       [35m0.5325[0m      [31m0.5325[0m        [94m1.3100[0m     +  0.0000  11.3997
      5      0.9423        [32m0.4858[0m       [35m0.5483[0m      [31m0.5483[0m        [94m1.2982[0m     +  0.0000  11.6967
      6      [36m0.9615[0m        [32m0.4616[0m       0.5411      0.5411        [94m1.2980[0m     +  0.0000  11.6343
      7      [36m0.9663[0m        [32m0.4383[0m       0.5436      0.5436        [94m1.2959[0m     +  0.0000  11.6549
      8      [36m0.9760[0m        [32m0.4373[0m       0.5453      0.5453        1.2979        0.0000  11.4390
      9      0.9760        [32m0.4307[0m       0.5432      0.5432        1.2968        0.0000  11.6620
     10      0.9760        [32m0.4237[0m       0.5441      0.5441        [94m1.2943[0m     +  0.0000  11.8469
     11      0.9760        [32m0.4192[0m       0.5394      0.5394        1.2977        0.0000  11.5310
     12      0.9663        [32m0.4121[0m       0.5403      0.5403        1.2963        0.0000  11.4755
     13      [36m0.9808[0m        [32m0.4059[0m       0.5413      0.5413        1.2962        0.0000  11.4349
     14      0.9808        [32m0.3929[0m       0.5415      0.5415        1.2952        0.0000  11.4404
     15      0.9760        0.3994       0.5422      0.5422        1.2949        0.0000  11.7461
     16      0.9808        [32m0.3896[0m       0.5418      0.5418        1.2950        0.0000  11.5995
     17      0.9760        [32m0.3881[0m       0.5424      0.5424        1.2957        0.0000  11.5337
     18      0.9808        0.4032       0.5422      0.5422        1.2955        0.0000  11.8414
     19      0.9760        0.4059       0.5427      0.5427        1.2952        0.0000  11.4378
     20      0.9808        0.4212       0.5420      0.5420        1.2948        0.0000  11.4837
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.5487847222222222
F1 Macro Score after query 4: 0.19716497827441712
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8151[0m        [32m0.8714[0m       [35m0.6134[0m      [31m0.6134[0m        [94m1.2125[0m     +  0.0000  12.4220
      2      [36m0.8854[0m        [32m0.6674[0m       [35m0.6443[0m      [31m0.6443[0m        [94m1.1425[0m     +  0.0000  12.3705
      3      [36m0.9141[0m        [32m0.5693[0m       [35m0.6507[0m      [31m0.6507[0m        [94m1.1325[0m     +  0.0000  12.6894
      4      [36m0.9453[0m        [32m0.5180[0m       0.6467      0.6467        [94m1.1165[0m     +  0.0000  12.8903
      5      [36m0.9479[0m        [32m0.4805[0m       0.6493      0.6493        1.1310        0.0000  12.4845
      6      [36m0.9661[0m        [32m0.4547[0m       0.6424      0.6424        [94m1.1129[0m     +  0.0000  12.5756
      7      [36m0.9688[0m        [32m0.4387[0m       0.6389      0.6389        1.1138        0.0000  12.3787
      8      0.9661        [32m0.4245[0m       0.6385      0.6385        [94m1.1103[0m     +  0.0000  12.3612
      9      0.9661        [32m0.4138[0m       0.6326      0.6326        1.1181        0.0000  12.2199
     10      0.9661        [32m0.4101[0m       0.6406      0.6406        1.1147        0.0000  12.3990
     11      [36m0.9740[0m        [32m0.3912[0m       0.6354      0.6354        1.1160        0.0000  12.5309
     12      [36m0.9766[0m        0.4035       0.6340      0.6340        1.1153        0.0000  12.4374
     13      [36m0.9792[0m        0.4001       0.6328      0.6328        1.1163        0.0000  12.4583
     14      0.9740        [32m0.3839[0m       0.6335      0.6335        1.1128        0.0000  12.2341
     15      0.9714        0.3946       0.6335      0.6335        1.1154        0.0000  12.4775
     16      0.9740        0.3889       0.6325      0.6325        1.1170        0.0000  12.3916
     17      0.9792        0.3948       0.6321      0.6321        1.1175        0.0000  12.4404
     18      0.9740        0.3901       0.6323      0.6323        1.1174        0.0000  12.2633
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.6296875
F1 Macro Score after query 5: 0.2700817567649785
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8963[0m        [32m0.5838[0m       [35m0.7000[0m      [31m0.7000[0m        [94m1.0472[0m     +  0.0000  13.7974
      2      [36m0.9503[0m        [32m0.4516[0m       0.6821      0.6821        1.0650        0.0000  13.8141
      3      [36m0.9574[0m        [32m0.4074[0m       [35m0.7026[0m      [31m0.7026[0m        [94m1.0335[0m     +  0.0000  14.0403
      4      [36m0.9645[0m        [32m0.3811[0m       0.6580      0.6580        1.1032        0.0000  14.1005
      5      [36m0.9716[0m        [32m0.3468[0m       0.6491      0.6491        1.0686        0.0000  14.0403
      6      [36m0.9787[0m        [32m0.3218[0m       0.6821      0.6821        [94m1.0178[0m     +  0.0000  13.9996
      7      [36m0.9801[0m        [32m0.3212[0m       0.6687      0.6687        [94m1.0167[0m     +  0.0000  14.1320
      8      0.9801        [32m0.3064[0m       0.6802      0.6802        1.0246        0.0000  14.0567
      9      0.9801        [32m0.2938[0m       0.6715      0.6715        1.0172        0.0000  14.3567
     10      [36m0.9815[0m        0.2953       0.6795      0.6795        [94m1.0057[0m     +  0.0000  14.4057
     11      [36m0.9844[0m        [32m0.2884[0m       0.6781      0.6781        [94m0.9967[0m     +  0.0000  14.0113
     12      0.9844        0.2955       0.6717      0.6717        [94m0.9937[0m     +  0.0000  13.8716
     13      0.9830        0.2927       0.6726      0.6726        0.9945        0.0000  13.8721
     14      0.9830        [32m0.2830[0m       0.6734      0.6734        0.9953        0.0000  13.7766
     15      0.9844        [32m0.2810[0m       0.6781      0.6781        0.9978        0.0000  14.2469
     16      0.9830        0.2822       0.6722      0.6722        0.9943        0.0000  13.9479
     17      0.9830        0.2826       0.6694      0.6694        [94m0.9930[0m     +  0.0000  13.8079
     18      [36m0.9858[0m        0.2823       0.6675      0.6675        0.9932        0.0000  13.8695
     19      0.9844        0.2880       0.6674      0.6674        0.9933        0.0000  14.3710
     20      0.9830        0.2909       0.6674      0.6674        0.9930        0.0000  14.1516
     21      0.9844        0.2874       0.6672      0.6672        [94m0.9926[0m     +  0.0000  14.5110
     22      [36m0.9872[0m        [32m0.2808[0m       0.6670      0.6670        [94m0.9921[0m     +  0.0000  14.3239
     23      0.9844        0.2911       0.6667      0.6667        [94m0.9920[0m     +  0.0000  14.1668
     24      0.9844        0.2817       0.6665      0.6665        [94m0.9917[0m     +  0.0000  14.3094
     25      0.9830        0.2852       0.6665      0.6665        [94m0.9914[0m     +  0.0000  14.0574
     26      0.9872        [32m0.2729[0m       0.6663      0.6663        [94m0.9913[0m     +  0.0000  13.7621
     27      0.9858        0.2777       0.6658      0.6658        [94m0.9913[0m     +  0.0000  14.2159
     28      0.9815        0.2757       0.6655      0.6655        [94m0.9912[0m     +  0.0000  13.9932
     29      0.9872        0.2873       0.6655      0.6655        [94m0.9912[0m     +  0.0000  14.1851
     30      0.9858        0.2809       0.6658      0.6658        [94m0.9912[0m     +  0.0000  14.0105
     31      0.9858        0.2814       0.6658      0.6658        0.9912        0.0000  14.0117
     32      [36m0.9886[0m        0.2827       0.6658      0.6658        [94m0.9912[0m     +  0.0000  13.9974
     33      0.9844        0.2899       0.6658      0.6658        [94m0.9911[0m     +  0.0000  14.3561
     34      0.9858        0.2835       0.6656      0.6656        [94m0.9911[0m     +  0.0000  14.1377
     35      0.9844        0.2826       0.6656      0.6656        0.9911        0.0000  14.2459
     36      0.9858        0.2858       0.6656      0.6656        0.9911        0.0000  14.1833
     37      0.9815        0.2758       0.6656      0.6656        [94m0.9911[0m     +  0.0000  14.7609
     38      0.9844        0.2758       0.6656      0.6656        [94m0.9911[0m     +  0.0000  13.7582
     39      0.9858        0.2861       0.6656      0.6656        [94m0.9911[0m     +  0.0000  14.2002
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.6838541666666667
F1 Macro Score after query 6: 0.34196300590083334
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8378[0m        [32m0.6687[0m       [35m0.6161[0m      [31m0.6161[0m        [94m1.0107[0m     +  0.0000  16.5765
      2      [36m0.9019[0m        [32m0.5158[0m       [35m0.6651[0m      [31m0.6651[0m        [94m0.9267[0m     +  0.0000  16.7474
      3      [36m0.9201[0m        [32m0.4678[0m       [35m0.7033[0m      [31m0.7033[0m        [94m0.8850[0m     +  0.0000  16.7963
      4      [36m0.9312[0m        [32m0.4229[0m       0.6097      0.6097        1.0070        0.0000  16.8412
      5      [36m0.9422[0m        [32m0.3974[0m       0.6059      0.6059        1.0311        0.0000  16.6580
      6      [36m0.9486[0m        [32m0.3578[0m       0.6502      0.6502        0.9507        0.0000  16.5407
      7      [36m0.9565[0m        [32m0.3488[0m       0.6632      0.6632        0.9340        0.0000  16.5915
      8      [36m0.9573[0m        [32m0.3319[0m       0.6644      0.6644        0.9151        0.0000  17.2163
      9      [36m0.9589[0m        [32m0.3241[0m       0.6786      0.6786        0.9043        0.0000  16.9996
     10      0.9589        [32m0.3223[0m       0.6767      0.6767        0.9038        0.0000  16.8689
     11      [36m0.9668[0m        [32m0.3049[0m       [35m0.7106[0m      [31m0.7106[0m        [94m0.8438[0m     +  0.0000  16.8384
     12      0.9628        0.3084       [35m0.7130[0m      [31m0.7130[0m        [94m0.8360[0m     +  0.0000  16.7971
     13      0.9644        0.3052       [35m0.7134[0m      [31m0.7134[0m        0.8382        0.0000  16.8254
     14      0.9652        [32m0.2972[0m       [35m0.7163[0m      [31m0.7163[0m        [94m0.8337[0m     +  0.0000  16.8103
     15      0.9644        [32m0.2959[0m       [35m0.7182[0m      [31m0.7182[0m        0.8341        0.0000  16.5437
     16      0.9660        0.3016       0.7170      0.7170        [94m0.8326[0m     +  0.0000  16.5915
     17      0.9668        [32m0.2915[0m       0.7160      0.7160        0.8327        0.0000  16.7967
     18      0.9644        0.2953       0.7172      0.7172        [94m0.8316[0m     +  0.0000  16.9044
     19      [36m0.9691[0m        [32m0.2839[0m       0.7170      0.7170        [94m0.8309[0m     +  0.0000  16.9201
     20      0.9684        0.2895       0.7179      0.7179        0.8314        0.0000  16.8870
     21      0.9652        0.2951       [35m0.7188[0m      [31m0.7188[0m        [94m0.8307[0m     +  0.0000  16.6236
     22      0.9660        0.2940       0.7182      0.7182        0.8307        0.0000  16.4821
     23      0.9684        0.2902       [35m0.7189[0m      [31m0.7189[0m        [94m0.8306[0m     +  0.0000  16.6715
     24      0.9660        0.2924       0.7189      0.7189        0.8306        0.0000  16.8430
     25      0.9684        0.2880       [35m0.7198[0m      [31m0.7198[0m        [94m0.8304[0m     +  0.0000  16.6229
     26      0.9668        0.2939       [35m0.7200[0m      [31m0.7200[0m        [94m0.8303[0m     +  0.0000  16.4669
     27      0.9691        0.2860       0.7196      0.7196        [94m0.8302[0m     +  0.0000  17.0022
     28      0.9636        0.2921       0.7196      0.7196        [94m0.8301[0m     +  0.0000  16.4271
     29      0.9684        0.2905       0.7196      0.7196        [94m0.8301[0m     +  0.0000  16.7036
     30      [36m0.9699[0m        0.2945       0.7194      0.7194        [94m0.8300[0m     +  0.0000  16.6402
     31      0.9676        0.2928       0.7194      0.7194        0.8301        0.0000  17.0149
     32      0.9652        0.2997       0.7196      0.7196        0.8301        0.0000  16.6847
     33      0.9660        0.2948       0.7196      0.7196        0.8301        0.0000  16.6861
     34      0.9660        0.2903       0.7196      0.7196        0.8301        0.0000  16.4984
     35      0.9644        0.2951       0.7196      0.7196        0.8301        0.0000  16.8086
     36      0.9691        0.2872       0.7196      0.7196        0.8301        0.0000  16.8545
     37      0.9684        0.2914       0.7196      0.7196        0.8301        0.0000  16.8097
     38      0.9684        0.2923       0.7196      0.7196        0.8301        0.0000  16.9032
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.75
F1 Macro Score after query 7: 0.4767906455451786
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9015[0m        [32m0.4862[0m       [35m0.7887[0m      [31m0.7887[0m        [94m0.6735[0m     +  0.0000  21.9392
      2      [36m0.9329[0m        [32m0.3749[0m       [35m0.7936[0m      [31m0.7936[0m        [94m0.6374[0m     +  0.0000  22.0982
      3      [36m0.9408[0m        [32m0.3321[0m       0.7832      0.7832        0.6835        0.0000  22.2677
      4      [36m0.9505[0m        [32m0.2976[0m       [35m0.7981[0m      [31m0.7981[0m        0.6409        0.0000  22.0798
      5      [36m0.9594[0m        [32m0.2691[0m       0.7703      0.7703        0.7346        0.0000  21.9224
      6      [36m0.9664[0m        [32m0.2382[0m       0.7910      0.7910        0.6538        0.0000  22.6892
      7      [36m0.9744[0m        [32m0.2234[0m       0.7918      0.7918        0.6498        0.0000  22.5793
      8      0.9735        [32m0.2099[0m       0.7924      0.7924        0.6466        0.0000  22.3429
      9      [36m0.9761[0m        [32m0.2097[0m       0.7910      0.7910        0.6541        0.0000  21.9891
     10      [36m0.9788[0m        [32m0.2043[0m       0.7946      0.7946        0.6417        0.0000  22.2688
     11      [36m0.9819[0m        [32m0.1982[0m       [35m0.7986[0m      [31m0.7986[0m        [94m0.6316[0m     +  0.0000  21.7378
     12      [36m0.9832[0m        [32m0.1951[0m       0.7967      0.7967        0.6385        0.0000  22.0481
     13      [36m0.9837[0m        [32m0.1923[0m       0.7962      0.7962        0.6439        0.0000  21.9232
     14      [36m0.9841[0m        [32m0.1873[0m       0.7969      0.7969        0.6388        0.0000  21.5146
     15      [36m0.9854[0m        0.1909       0.7962      0.7962        0.6428        0.0000  21.6586
     16      0.9850        [32m0.1873[0m       0.7972      0.7972        0.6426        0.0000  22.1276
     17      [36m0.9867[0m        0.1885       0.7965      0.7965        0.6433        0.0000  21.6714
     18      [36m0.9872[0m        [32m0.1856[0m       0.7976      0.7976        0.6443        0.0000  21.4383
     19      0.9828        [32m0.1850[0m       0.7965      0.7965        0.6432        0.0000  21.9226
     20      0.9828        0.1881       0.7976      0.7976        0.6426        0.0000  21.9854
     21      [36m0.9876[0m        [32m0.1841[0m       0.7976      0.7976        0.6431        0.0000  21.4240
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7885416666666668
F1 Macro Score after query 8: 0.5090842230456236
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8916[0m        [32m0.4260[0m       [35m0.7731[0m      [31m0.7731[0m        [94m0.7787[0m     +  0.0000  30.2432
      2      [36m0.9245[0m        [32m0.3401[0m       [35m0.7939[0m      [31m0.7939[0m        [94m0.6472[0m     +  0.0000  30.4142
      3      [36m0.9465[0m        [32m0.2749[0m       0.7927      0.7927        0.6639        0.0000  30.4756
      4      [36m0.9527[0m        [32m0.2473[0m       0.7892      0.7892        0.6718        0.0000  30.4175
      5      [36m0.9589[0m        [32m0.2220[0m       0.7856      0.7856        0.6718        0.0000  30.6160
      6      [36m0.9713[0m        [32m0.1811[0m       [35m0.8023[0m      [31m0.8023[0m        [94m0.6146[0m     +  0.0000  30.2899
      7      [36m0.9809[0m        [32m0.1637[0m       0.8021      0.8021        0.6188        0.0000  30.6974
      8      [36m0.9812[0m        [32m0.1531[0m       0.7995      0.7995        0.6334        0.0000  30.3200
      9      [36m0.9837[0m        [32m0.1447[0m       0.7991      0.7991        0.6402        0.0000  30.7914
     10      [36m0.9854[0m        [32m0.1410[0m       0.8003      0.8003        0.6396        0.0000  30.8831
     11      [36m0.9903[0m        [32m0.1284[0m       0.7944      0.7944        0.6635        0.0000  30.3102
     12      [36m0.9923[0m        [32m0.1245[0m       0.7931      0.7931        0.6684        0.0000  30.9288
     13      0.9918        [32m0.1231[0m       0.7898      0.7898        0.6772        0.0000  30.6610
     14      [36m0.9936[0m        [32m0.1192[0m       0.7939      0.7939        0.6686        0.0000  30.4766
     15      0.9936        [32m0.1184[0m       0.7906      0.7906        0.6747        0.0000  30.9439
     16      0.9933        [32m0.1182[0m       0.7889      0.7889        0.6765        0.0000  30.8463
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8203125
F1 Macro Score after query 9: 0.531637215665459
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9028[0m        [32m0.3599[0m       [35m0.8038[0m      [31m0.8038[0m        [94m0.5798[0m     +  0.0000  46.2206
      2      [36m0.9278[0m        [32m0.2887[0m       [35m0.8128[0m      [31m0.8128[0m        [94m0.5629[0m     +  0.0000  46.7756
      3      [36m0.9418[0m        [32m0.2434[0m       [35m0.8238[0m      [31m0.8238[0m        [94m0.5368[0m     +  0.0000  46.4918
      4      [36m0.9493[0m        [32m0.2138[0m       0.8187      0.8187        0.5561        0.0000  46.3785
      5      [36m0.9582[0m        [32m0.1880[0m       0.7976      0.7976        0.6637        0.0000  45.7608
      6      [36m0.9736[0m        [32m0.1412[0m       0.8019      0.8019        0.6427        0.0000  46.6299
      7      [36m0.9801[0m        [32m0.1237[0m       0.7950      0.7950        0.6772        0.0000  46.5985
      8      [36m0.9853[0m        [32m0.1128[0m       0.8061      0.8061        0.6525        0.0000  46.7672
      9      [36m0.9874[0m        [32m0.1024[0m       0.8010      0.8010        0.6774        0.0000  46.8172
     10      [36m0.9890[0m        [32m0.0962[0m       0.8003      0.8003        0.6928        0.0000  46.6656
     11      [36m0.9917[0m        [32m0.0869[0m       0.8028      0.8028        0.6839        0.0000  47.3912
     12      [36m0.9933[0m        [32m0.0850[0m       0.8026      0.8026        0.6875        0.0000  46.9398
     13      [36m0.9939[0m        [32m0.0806[0m       0.8003      0.8003        0.6988        0.0000  46.4237
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8276041666666667
F1 Macro Score after query 10: 0.5315248276994862
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9443[0m        [32m0.2357[0m       [35m0.8372[0m      [31m0.8372[0m        [94m0.5231[0m     +  0.0000  74.4787
      2      [36m0.9521[0m        [32m0.1959[0m       0.8359      0.8359        0.5231        0.0000  75.1985
      3      [36m0.9595[0m        [32m0.1722[0m       0.8167      0.8167        0.6238        0.0000  74.9489
      4      [36m0.9648[0m        [32m0.1493[0m       0.8059      0.8059        0.6782        0.0000  75.3330
      5      [36m0.9664[0m        [32m0.1345[0m       0.7962      0.7962        0.7222        0.0000  74.7767
      6      [36m0.9782[0m        [32m0.1013[0m       0.7734      0.7734        0.7738        0.0000  74.6494
      7      [36m0.9848[0m        [32m0.0847[0m       0.7708      0.7708        0.8019        0.0000  75.9637
      8      [36m0.9882[0m        [32m0.0745[0m       0.7686      0.7686        0.8473        0.0000  74.7644
      9      [36m0.9901[0m        [32m0.0670[0m       0.7719      0.7719        0.8457        0.0000  75.0724
     10      [36m0.9927[0m        [32m0.0592[0m       0.7710      0.7710        0.8693        0.0000  74.8262
     11      [36m0.9941[0m        [32m0.0546[0m       0.7799      0.7799        0.8508        0.0000  74.9503
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8277777777777777
F1 Macro Score after query 11: 0.5340708893774135
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9683[0m        [32m0.1422[0m       [35m0.6509[0m      [31m0.6509[0m        [94m1.3168[0m     +  0.0000  125.1301
      2      [36m0.9715[0m        [32m0.1202[0m       [35m0.6941[0m      [31m0.6941[0m        [94m1.0167[0m     +  0.0000  126.5100
      3      [36m0.9759[0m        [32m0.1023[0m       [35m0.8410[0m      [31m0.8410[0m        [94m0.5212[0m     +  0.0000  125.6978
      4      [36m0.9780[0m        [32m0.0893[0m       0.8043      0.8043        0.6891        0.0000  125.7984
      5      [36m0.9796[0m        [32m0.0791[0m       0.7878      0.7878        0.7647        0.0000  126.0011
      6      [36m0.9853[0m        [32m0.0620[0m       0.7724      0.7724        0.8419        0.0000  125.4812
      7      [36m0.9895[0m        [32m0.0497[0m       0.7870      0.7870        0.7800        0.0000  126.0599
      8      [36m0.9924[0m        [32m0.0421[0m       0.7821      0.7821        0.8246        0.0000  125.8436
      9      [36m0.9941[0m        [32m0.0367[0m       0.7894      0.7894        0.8069        0.0000  125.9247
     10      [36m0.9955[0m        [32m0.0328[0m       0.7885      0.7885        0.8360        0.0000  125.9723
     11      [36m0.9964[0m        [32m0.0285[0m       0.7937      0.7937        0.8300        0.0000  125.1292
     12      [36m0.9973[0m        [32m0.0264[0m       0.7918      0.7918        0.8353        0.0000  126.6279
     13      [36m0.9978[0m        [32m0.0241[0m       0.7922      0.7922        0.8495        0.0000  125.8122
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8208333333333333
F1 Macro Score after query 12: 0.539412673082127
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9807[0m        [32m0.0782[0m       [35m0.7595[0m      [31m0.7595[0m        [94m0.9587[0m     +  0.0000  145.8465
      2      [36m0.9816[0m        [32m0.0709[0m       0.6851      0.6851        1.3590        0.0000  146.2469
      3      [36m0.9836[0m        [32m0.0628[0m       0.7255      0.7255        1.1412        0.0000  146.4123
      4      [36m0.9856[0m        [32m0.0559[0m       [35m0.7951[0m      [31m0.7951[0m        [94m0.7832[0m     +  0.0000  146.5790
      5      [36m0.9884[0m        [32m0.0483[0m       0.7493      0.7493        0.8945        0.0000  146.2797
      6      [36m0.9911[0m        [32m0.0360[0m       [35m0.8069[0m      [31m0.8069[0m        [94m0.7394[0m     +  0.0000  146.3138
      7      [36m0.9950[0m        [32m0.0271[0m       0.7937      0.7937        0.8200        0.0000  147.2670
      8      [36m0.9967[0m        [32m0.0223[0m       0.7965      0.7965        0.8399        0.0000  147.4306
      9      [36m0.9975[0m        [32m0.0195[0m       0.7859      0.7859        0.9172        0.0000  147.7693
     10      [36m0.9983[0m        [32m0.0165[0m       0.7727      0.7727        1.0163        0.0000  146.9380
     11      [36m0.9987[0m        [32m0.0139[0m       0.7858      0.7858        0.9601        0.0000  146.4564
     12      [36m0.9993[0m        [32m0.0129[0m       0.7856      0.7856        0.9823        0.0000  146.8176
     13      [36m0.9994[0m        [32m0.0119[0m       0.7852      0.7852        0.9846        0.0000  146.1644
     14      [36m0.9995[0m        [32m0.0115[0m       0.7866      0.7866        0.9955        0.0000  146.4221
     15      0.9994        [32m0.0111[0m       0.7868      0.7868        0.9968        0.0000  146.2197
     16      [36m0.9996[0m        [32m0.0108[0m       0.7920      0.7920        0.9954        0.0000  140.2939
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8197916666666667
F1 Macro Score after query 13: 0.5373582032966907
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed51\AL_entropy_sampling_results_for_multiclass_classification_s51.pickle
