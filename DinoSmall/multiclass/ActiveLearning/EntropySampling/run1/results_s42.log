(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2500[0m        [32m2.0239[0m       [35m0.3233[0m      [31m0.3233[0m        [94m1.9518[0m     +  0.0000  10.8438
      2      0.2500        2.0520       0.1965      0.1965        1.9794        0.0000  10.6596
      3      [36m0.3750[0m        [32m1.7789[0m       0.2443      0.2443        1.9609        0.0000  10.8791
      4      0.3750        [32m1.6955[0m       0.2712      0.2712        1.9824        0.0000  10.7370
      5      [36m0.5000[0m        [32m1.6955[0m       0.1828      0.1828        2.0405        0.0000  10.8641
      6      [36m0.6250[0m        [32m1.6262[0m       0.2477      0.2477        2.0203        0.0000  10.9361
      7      [36m0.7500[0m        [32m1.4494[0m       0.2788      0.2788        2.0094        0.0000  10.7049
      8      0.7500        1.4731       0.2892      0.2892        2.0019        0.0000  10.5496
      9      0.7500        [32m1.4338[0m       0.2870      0.2870        2.0048        0.0000  10.7248
     10      0.7500        1.4902       0.3016      0.3016        1.9939        0.0000  10.5982
     11      [36m1.0000[0m        [32m1.3427[0m       0.3005      0.3005        1.9949        0.0000  10.8612
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.3299
Pre F1 macro score = 0.1587

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8750[0m        [32m1.4369[0m       [35m0.4479[0m      [31m0.4479[0m        [94m1.7309[0m     +  0.0000  10.6442
      2      0.7500        [32m1.1672[0m       0.4479      0.4479        [94m1.7101[0m     +  0.0000  10.5835
      3      0.8333        [32m0.9595[0m       [35m0.4488[0m      [31m0.4488[0m        [94m1.6974[0m     +  0.0000  10.7711
      4      0.8750        [32m0.8220[0m       [35m0.4578[0m      [31m0.4578[0m        1.7041        0.0000  10.6890
      5      0.8750        [32m0.7147[0m       [35m0.4726[0m      [31m0.4726[0m        [94m1.6897[0m     +  0.0000  10.7959
      6      [36m0.9167[0m        0.7307       [35m0.4748[0m      [31m0.4748[0m        [94m1.6892[0m     +  0.0000  10.8774
      7      0.9167        0.7193       [35m0.4773[0m      [31m0.4773[0m        1.6905        0.0000  10.9159
      8      0.9167        [32m0.6540[0m       [35m0.4795[0m      [31m0.4795[0m        [94m1.6892[0m     +  0.0000  10.7922
      9      [36m0.9583[0m        [32m0.6346[0m       [35m0.4804[0m      [31m0.4804[0m        1.6894        0.0000  10.8220
     10      0.9583        [32m0.6014[0m       [35m0.4868[0m      [31m0.4868[0m        1.6903        0.0000  10.8290
     11      0.9167        0.6310       [35m0.4878[0m      [31m0.4878[0m        1.6906        0.0000  11.0002
     12      0.9583        0.6975       [35m0.4887[0m      [31m0.4887[0m        1.6903        0.0000  10.6692
     13      [36m1.0000[0m        [32m0.5529[0m       [35m0.4899[0m      [31m0.4899[0m        1.6904        0.0000  10.6570
     14      0.9583        0.6056       [35m0.4905[0m      [31m0.4905[0m        1.6910        0.0000  10.6691
     15      0.9583        0.6764       [35m0.4906[0m      [31m0.4906[0m        1.6914        0.0000  10.8690
     16      1.0000        0.6438       0.4906      0.4906        1.6914        0.0000  10.7671
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.5454861111111111
F1 Macro Score after query 1: 0.1792903874460744
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6964[0m        [32m1.2735[0m       [35m0.4203[0m      [31m0.4203[0m        [94m1.7032[0m     +  0.0000  11.0422
      2      [36m0.8393[0m        [32m1.0773[0m       [35m0.4955[0m      [31m0.4955[0m        [94m1.6429[0m     +  0.0000  10.9986
      3      [36m0.8571[0m        [32m0.7879[0m       [35m0.5446[0m      [31m0.5446[0m        [94m1.6029[0m     +  0.0000  10.9494
      4      [36m0.9286[0m        [32m0.7102[0m       0.5411      0.5411        [94m1.5962[0m     +  0.0000  10.8330
      5      [36m0.9821[0m        [32m0.5963[0m       0.5418      0.5418        [94m1.5867[0m     +  0.0000  10.9586
      6      0.9821        [32m0.5767[0m       0.5399      0.5399        1.5908        0.0000  10.8975
      7      [36m1.0000[0m        0.6005       0.5398      0.5398        1.5892        0.0000  10.9325
      8      1.0000        [32m0.5581[0m       0.5403      0.5403        1.5879        0.0000  10.7853
      9      0.9821        0.5833       0.5418      0.5418        [94m1.5845[0m     +  0.0000  11.0937
     10      0.9643        0.5785       0.5406      0.5406        1.5868        0.0000  10.9493
     11      0.9821        0.5606       0.5398      0.5398        1.5851        0.0000  11.0474
     12      0.9821        [32m0.5440[0m       0.5401      0.5401        1.5848        0.0000  10.9051
     13      1.0000        0.5556       0.5413      0.5413        [94m1.5837[0m     +  0.0000  10.8308
     14      0.9821        [32m0.5277[0m       0.5401      0.5401        1.5838        0.0000  10.7182
     15      0.9821        0.5556       0.5408      0.5408        1.5838        0.0000  10.9728
     16      0.9821        [32m0.5193[0m       0.5408      0.5408        1.5838        0.0000  10.9100
     17      0.9821        0.5563       0.5411      0.5411        1.5838        0.0000  11.1704
     18      1.0000        0.5435       0.5411      0.5411        1.5838        0.0000  10.9104
     19      1.0000        0.5622       0.5411      0.5411        [94m1.5837[0m     +  0.0000  10.8773
     20      1.0000        0.5584       0.5413      0.5413        [94m1.5836[0m     +  0.0000  10.8182
     21      1.0000        0.5430       0.5413      0.5413        [94m1.5835[0m     +  0.0000  10.8718
     22      0.9821        0.5513       0.5411      0.5411        1.5835        0.0000  10.8549
     23      0.9821        [32m0.4944[0m       0.5411      0.5411        [94m1.5835[0m     +  0.0000  10.9373
     24      0.9821        0.5144       0.5411      0.5411        1.5835        0.0000  10.8967
     25      1.0000        0.5144       0.5413      0.5413        [94m1.5834[0m     +  0.0000  10.9366
     26      1.0000        [32m0.4862[0m       0.5413      0.5413        1.5835        0.0000  10.9994
     27      0.9821        0.5541       0.5413      0.5413        1.5834        0.0000  10.8793
     28      0.9821        0.5456       0.5413      0.5413        1.5834        0.0000  10.8510
     29      0.9821        0.5669       0.5413      0.5413        1.5834        0.0000  10.8890
     30      1.0000        0.5452       0.5413      0.5413        1.5834        0.0000  11.0207
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.5732638888888889
F1 Macro Score after query 2: 0.2700035390304769
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8304[0m        [32m0.8902[0m       [35m0.5345[0m      [31m0.5345[0m        [94m1.4255[0m     +  0.0000  11.3131
      2      [36m0.9554[0m        [32m0.5478[0m       [35m0.5825[0m      [31m0.5825[0m        [94m1.3804[0m     +  0.0000  10.9987
      3      [36m0.9732[0m        [32m0.4699[0m       0.5813      0.5813        [94m1.3668[0m     +  0.0000  11.0940
      4      0.9643        [32m0.4419[0m       [35m0.5880[0m      [31m0.5880[0m        [94m1.3540[0m     +  0.0000  11.0961
      5      [36m0.9821[0m        [32m0.4178[0m       0.5830      0.5830        [94m1.3518[0m     +  0.0000  11.2604
      6      0.9821        [32m0.3984[0m       0.5870      0.5870        [94m1.3446[0m     +  0.0000  11.1849
      7      0.9821        0.4026       0.5835      0.5835        1.3463        0.0000  11.3787
      8      0.9821        [32m0.3847[0m       0.5844      0.5844        1.3449        0.0000  11.1861
      9      0.9821        0.3957       0.5840      0.5840        [94m1.3435[0m     +  0.0000  11.2552
     10      0.9821        [32m0.3820[0m       0.5790      0.5790        1.3450        0.0000  11.1459
     11      0.9821        0.3840       0.5792      0.5792        1.3439        0.0000  11.1571
     12      0.9821        0.3935       0.5790      0.5790        [94m1.3427[0m     +  0.0000  11.2952
     13      0.9821        0.3826       0.5785      0.5785        [94m1.3426[0m     +  0.0000  11.1434
     14      0.9821        [32m0.3642[0m       0.5807      0.5807        [94m1.3416[0m     +  0.0000  11.0837
     15      0.9821        0.3696       0.5809      0.5809        [94m1.3414[0m     +  0.0000  11.1249
     16      0.9821        [32m0.3522[0m       0.5806      0.5806        1.3415        0.0000  11.1482
     17      0.9821        0.3840       0.5804      0.5804        1.3416        0.0000  11.2042
     18      0.9821        0.3859       0.5799      0.5799        1.3415        0.0000  11.2778
     19      0.9821        0.3535       0.5800      0.5800        1.3416        0.0000  11.4069
     20      0.9821        0.3547       0.5799      0.5799        1.3415        0.0000  11.2158
     21      0.9821        0.3803       0.5799      0.5799        1.3415        0.0000  11.2490
     22      0.9821        0.4133       0.5799      0.5799        1.3414        0.0000  11.2786
     23      0.9821        0.3675       0.5800      0.5800        1.3414        0.0000  11.0143
     24      0.9821        [32m0.3434[0m       0.5802      0.5802        1.3414        0.0000  11.2310
     25      0.9821        0.3775       0.5802      0.5802        [94m1.3413[0m     +  0.0000  11.3859
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.6442708333333333
F1 Macro Score after query 3: 0.29842015307005765
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7981[0m        [32m0.8876[0m       [35m0.5302[0m      [31m0.5302[0m        [94m1.2922[0m     +  0.0000  11.7520
      2      [36m0.9038[0m        [32m0.6189[0m       [35m0.5497[0m      [31m0.5497[0m        [94m1.2599[0m     +  0.0000  11.5245
      3      [36m0.9279[0m        [32m0.5327[0m       0.5387      0.5387        [94m1.2424[0m     +  0.0000  11.7991
      4      [36m0.9519[0m        [32m0.4736[0m       [35m0.5578[0m      [31m0.5578[0m        [94m1.2228[0m     +  0.0000  11.8263
      5      0.9519        [32m0.4313[0m       [35m0.5894[0m      [31m0.5894[0m        [94m1.1556[0m     +  0.0000  11.7442
      6      [36m0.9712[0m        [32m0.3896[0m       [35m0.6413[0m      [31m0.6413[0m        [94m1.0975[0m     +  0.0000  11.5933
      7      0.9712        0.3916       0.6403      0.6403        1.0990        0.0000  11.9240
      8      0.9712        [32m0.3702[0m       0.6365      0.6365        1.0992        0.0000  11.7581
      9      0.9712        0.3833       0.6365      0.6365        1.1001        0.0000  11.8593
     10      [36m0.9808[0m        [32m0.3616[0m       0.6302      0.6302        1.1022        0.0000  11.6667
     11      0.9760        0.3865       0.6321      0.6321        1.1020        0.0000  11.5398
     12      0.9712        0.3653       0.6335      0.6335        1.1004        0.0000  11.6658
     13      0.9808        0.3656       0.6314      0.6314        1.1009        0.0000  11.8400
     14      0.9760        [32m0.3468[0m       0.6325      0.6325        1.1022        0.0000  11.5701
     15      0.9760        0.3596       0.6297      0.6297        1.1029        0.0000  11.6118
     16      0.9808        [32m0.3446[0m       0.6292      0.6292        1.1029        0.0000  11.6766
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.6565972222222223
F1 Macro Score after query 4: 0.23741703768280567
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8255[0m        [32m0.7343[0m       [35m0.6748[0m      [31m0.6748[0m        [94m1.0723[0m     +  0.0000  12.5846
      2      [36m0.9089[0m        [32m0.5400[0m       [35m0.6892[0m      [31m0.6892[0m        [94m1.0371[0m     +  0.0000  12.5407
      3      [36m0.9323[0m        [32m0.4743[0m       [35m0.6988[0m      [31m0.6988[0m        [94m0.9981[0m     +  0.0000  12.6252
      4      [36m0.9427[0m        [32m0.4229[0m       0.6964      0.6964        [94m0.9903[0m     +  0.0000  12.5155
      5      [36m0.9661[0m        [32m0.3720[0m       0.6983      0.6983        [94m0.9607[0m     +  0.0000  12.4261
      6      [36m0.9766[0m        [32m0.3357[0m       0.6905      0.6905        0.9821        0.0000  12.6174
      7      0.9661        [32m0.3339[0m       0.6934      0.6934        0.9787        0.0000  12.5311
      8      0.9766        [32m0.3141[0m       [35m0.7012[0m      [31m0.7012[0m        0.9676        0.0000  12.4121
      9      [36m0.9792[0m        [32m0.3048[0m       0.6995      0.6995        0.9663        0.0000  12.5243
     10      0.9792        0.3138       0.6927      0.6927        0.9788        0.0000  12.5519
     11      0.9792        [32m0.3004[0m       [35m0.7016[0m      [31m0.7016[0m        0.9660        0.0000  12.3721
     12      [36m0.9870[0m        [32m0.2973[0m       0.6997      0.6997        0.9668        0.0000  12.6703
     13      0.9870        [32m0.2944[0m       0.7009      0.7009        0.9653        0.0000  12.5241
     14      0.9818        0.3001       0.7010      0.7010        0.9651        0.0000  12.5397
     15      0.9818        [32m0.2944[0m       0.6991      0.6991        0.9672        0.0000  12.4688
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.6828125
F1 Macro Score after query 5: 0.28493258502166846
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8821[0m        [32m0.6024[0m       [35m0.7552[0m      [31m0.7552[0m        [94m0.8754[0m     +  0.0000  14.1595
      2      [36m0.9418[0m        [32m0.4310[0m       [35m0.7620[0m      [31m0.7620[0m        [94m0.8476[0m     +  0.0000  14.1996
      3      [36m0.9673[0m        [32m0.3548[0m       0.7573      0.7573        0.8630        0.0000  14.2259
      4      0.9673        [32m0.3348[0m       0.7571      0.7571        [94m0.8452[0m     +  0.0000  14.1416
      5      [36m0.9716[0m        [32m0.3042[0m       0.7585      0.7585        0.8578        0.0000  14.0963
      6      [36m0.9773[0m        [32m0.2797[0m       [35m0.7668[0m      [31m0.7668[0m        [94m0.8028[0m     +  0.0000  14.2006
      7      [36m0.9830[0m        [32m0.2664[0m       0.7660      0.7660        [94m0.8013[0m     +  0.0000  14.0033
      8      [36m0.9872[0m        0.2666       0.7632      0.7632        0.8025        0.0000  14.0002
      9      [36m0.9886[0m        [32m0.2463[0m       0.7646      0.7646        0.8046        0.0000  14.1414
     10      0.9872        0.2467       0.7627      0.7627        [94m0.8004[0m     +  0.0000  14.1566
     11      0.9886        [32m0.2430[0m       0.7592      0.7592        0.8138        0.0000  14.4239
     12      0.9872        [32m0.2349[0m       0.7589      0.7589        0.8122        0.0000  14.2499
     13      0.9858        [32m0.2333[0m       0.7568      0.7568        0.8149        0.0000  14.1260
     14      [36m0.9915[0m        [32m0.2320[0m       0.7594      0.7594        0.8112        0.0000  14.0465
     15      0.9886        0.2378       0.7590      0.7590        0.8114        0.0000  14.0433
     16      [36m0.9929[0m        [32m0.2272[0m       0.7562      0.7562        0.8147        0.0000  14.0076
     17      0.9886        [32m0.2231[0m       0.7562      0.7562        0.8163        0.0000  13.8731
     18      0.9929        0.2347       0.7543      0.7543        0.8178        0.0000  13.9842
     19      0.9901        0.2248       0.7535      0.7535        0.8186        0.0000  14.0824
     20      0.9915        0.2244       0.7535      0.7535        0.8193        0.0000  13.9383
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.7442708333333334
F1 Macro Score after query 6: 0.2979314255237592
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8600[0m        [32m0.5851[0m       [35m0.7122[0m      [31m0.7122[0m        [94m0.8976[0m     +  0.0000  16.8578
      2      [36m0.9304[0m        [32m0.4250[0m       0.7019      0.7019        0.9222        0.0000  16.9040
      3      [36m0.9549[0m        [32m0.3501[0m       [35m0.7401[0m      [31m0.7401[0m        [94m0.8952[0m     +  0.0000  16.8934
      4      [36m0.9691[0m        [32m0.3178[0m       0.7224      0.7224        [94m0.8848[0m     +  0.0000  16.9216
      5      0.9668        [32m0.2792[0m       0.7316      0.7316        [94m0.8729[0m     +  0.0000  16.8892
      6      [36m0.9763[0m        [32m0.2594[0m       [35m0.7424[0m      [31m0.7424[0m        [94m0.8378[0m     +  0.0000  16.8440
      7      [36m0.9802[0m        [32m0.2344[0m       [35m0.7595[0m      [31m0.7595[0m        [94m0.8113[0m     +  0.0000  16.7392
      8      0.9778        [32m0.2284[0m       [35m0.7597[0m      [31m0.7597[0m        [94m0.8078[0m     +  0.0000  16.8636
      9      [36m0.9842[0m        [32m0.2202[0m       [35m0.7655[0m      [31m0.7655[0m        [94m0.7874[0m     +  0.0000  16.9345
     10      0.9826        [32m0.2173[0m       0.7592      0.7592        0.8093        0.0000  16.8013
     11      [36m0.9850[0m        [32m0.2131[0m       [35m0.7684[0m      [31m0.7684[0m        [94m0.7870[0m     +  0.0000  16.7533
     12      0.9850        [32m0.2018[0m       [35m0.7731[0m      [31m0.7731[0m        [94m0.7818[0m     +  0.0000  16.7932
     13      [36m0.9858[0m        0.2073       [35m0.7760[0m      [31m0.7760[0m        [94m0.7783[0m     +  0.0000  16.7307
     14      [36m0.9866[0m        [32m0.1982[0m       [35m0.7776[0m      [31m0.7776[0m        [94m0.7754[0m     +  0.0000  17.1388
     15      0.9858        [32m0.1978[0m       [35m0.7788[0m      [31m0.7788[0m        [94m0.7716[0m     +  0.0000  16.6248
     16      [36m0.9873[0m        0.1998       [35m0.7818[0m      [31m0.7818[0m        [94m0.7700[0m     +  0.0000  16.9216
     17      0.9866        0.2026       [35m0.7828[0m      [31m0.7828[0m        [94m0.7692[0m     +  0.0000  16.9702
     18      [36m0.9881[0m        0.1994       0.7825      0.7825        [94m0.7684[0m     +  0.0000  16.6830
     19      0.9858        0.2015       0.7821      0.7821        0.7684        0.0000  17.1387
     20      0.9873        0.1991       0.7823      0.7823        0.7691        0.0000  16.9025
     21      0.9873        0.2044       0.7828      0.7828        0.7688        0.0000  16.9560
     22      0.9873        0.2013       [35m0.7832[0m      [31m0.7832[0m        0.7685        0.0000  16.7043
     23      0.9881        0.1985       0.7832      0.7832        [94m0.7682[0m     +  0.0000  16.8307
     24      [36m0.9889[0m        0.2016       0.7828      0.7828        [94m0.7681[0m     +  0.0000  16.8049
     25      0.9881        [32m0.1951[0m       0.7830      0.7830        [94m0.7679[0m     +  0.0000  16.7129
     26      0.9873        0.1994       0.7832      0.7832        [94m0.7679[0m     +  0.0000  16.8904
     27      0.9866        0.1967       0.7832      0.7832        0.7679        0.0000  16.7681
     28      0.9881        0.1994       0.7830      0.7830        0.7679        0.0000  16.8643
     29      0.9866        0.2014       0.7830      0.7830        0.7679        0.0000  16.9051
     30      0.9866        0.1976       0.7830      0.7830        0.7680        0.0000  16.7381
     31      0.9889        [32m0.1946[0m       0.7830      0.7830        0.7680        0.0000  16.7944
     32      0.9881        0.2011       0.7830      0.7830        0.7680        0.0000  16.6965
     33      0.9866        0.2015       0.7832      0.7832        0.7680        0.0000  16.9843
     34      0.9866        0.1974       0.7832      0.7832        0.7680        0.0000  16.7198
     35      [36m0.9905[0m        0.1973       0.7832      0.7832        0.7680        0.0000  16.5758
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.7482638888888888
F1 Macro Score after query 7: 0.3647383720222398
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8825[0m        [32m0.4992[0m       [35m0.8045[0m      [31m0.8045[0m        [94m0.6914[0m     +  0.0000  21.8743
      2      [36m0.9373[0m        [32m0.3524[0m       [35m0.8125[0m      [31m0.8125[0m        [94m0.6740[0m     +  0.0000  21.6510
      3      [36m0.9527[0m        [32m0.3000[0m       0.7917      0.7917        0.7747        0.0000  21.8749
      4      [36m0.9589[0m        [32m0.2634[0m       0.7905      0.7905        0.7560        0.0000  21.8936
      5      [36m0.9682[0m        [32m0.2352[0m       0.7988      0.7988        0.7360        0.0000  21.8766
      6      [36m0.9739[0m        [32m0.2056[0m       0.8066      0.8066        0.6752        0.0000  21.6357
      7      [36m0.9819[0m        [32m0.1826[0m       0.8083      0.8083        0.6816        0.0000  21.6369
      8      [36m0.9828[0m        [32m0.1704[0m       0.8120      0.8120        0.6794        0.0000  21.7354
      9      [36m0.9845[0m        [32m0.1667[0m       0.8108      0.8108        0.6864        0.0000  21.7003
     10      [36m0.9854[0m        [32m0.1641[0m       [35m0.8141[0m      [31m0.8141[0m        0.6794        0.0000  21.6484
     11      [36m0.9907[0m        [32m0.1517[0m       0.8113      0.8113        [94m0.6694[0m     +  0.0000  21.8080
     12      0.9876        0.1558       0.8128      0.8128        [94m0.6670[0m     +  0.0000  21.7149
     13      0.9898        [32m0.1500[0m       0.8125      0.8125        0.6672        0.0000  21.7162
     14      0.9903        [32m0.1495[0m       0.8116      0.8116        0.6681        0.0000  21.6984
     15      [36m0.9916[0m        [32m0.1441[0m       0.8118      0.8118        0.6676        0.0000  21.6846
     16      0.9907        [32m0.1431[0m       0.8116      0.8116        [94m0.6670[0m     +  0.0000  21.5113
     17      [36m0.9929[0m        [32m0.1409[0m       0.8111      0.8111        0.6673        0.0000  21.8093
     18      0.9920        0.1430       0.8109      0.8109        0.6677        0.0000  21.7172
     19      0.9907        0.1427       0.8109      0.8109        0.6676        0.0000  21.6529
     20      0.9920        0.1424       0.8113      0.8113        0.6682        0.0000  21.5914
     21      0.9920        0.1419       0.8115      0.8115        0.6683        0.0000  21.7605
     22      0.9916        0.1449       0.8115      0.8115        0.6684        0.0000  21.6504
     23      0.9920        0.1422       0.8120      0.8120        0.6685        0.0000  21.8393
     24      0.9912        0.1420       0.8118      0.8118        0.6686        0.0000  21.6672
     25      [36m0.9938[0m        0.1413       0.8118      0.8118        0.6685        0.0000  21.8274
     26      0.9929        0.1427       0.8118      0.8118        0.6685        0.0000  21.6515
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7793402777777778
F1 Macro Score after query 8: 0.4896434346949352
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8901[0m        [32m0.4174[0m       [35m0.7833[0m      [31m0.7833[0m        [94m0.6784[0m     +  0.0000  30.6101
      2      [36m0.9332[0m        [32m0.2990[0m       [35m0.8148[0m      [31m0.8148[0m        [94m0.5887[0m     +  0.0000  30.7528
      3      [36m0.9493[0m        [32m0.2401[0m       [35m0.8196[0m      [31m0.8196[0m        [94m0.5848[0m     +  0.0000  30.7992
      4      [36m0.9589[0m        [32m0.2119[0m       0.8179      0.8179        [94m0.5789[0m     +  0.0000  31.1119
      5      [36m0.9676[0m        [32m0.1845[0m       [35m0.8205[0m      [31m0.8205[0m        0.5877        0.0000  30.8620
      6      [36m0.9797[0m        [32m0.1459[0m       [35m0.8286[0m      [31m0.8286[0m        [94m0.5778[0m     +  0.0000  30.8279
      7      [36m0.9849[0m        [32m0.1273[0m       0.8271      0.8271        0.5964        0.0000  30.7995
      8      [36m0.9876[0m        [32m0.1168[0m       0.8271      0.8271        0.6186        0.0000  30.6748
      9      [36m0.9901[0m        [32m0.1097[0m       0.8276      0.8276        0.6293        0.0000  30.8297
     10      [36m0.9928[0m        [32m0.1029[0m       0.8281      0.8281        0.6267        0.0000  31.0472
     11      [36m0.9953[0m        [32m0.0968[0m       0.8274      0.8274        0.6383        0.0000  31.0781
     12      [36m0.9958[0m        [32m0.0968[0m       0.8266      0.8266        0.6381        0.0000  30.9067
     13      0.9958        [32m0.0924[0m       0.8271      0.8271        0.6413        0.0000  30.8416
     14      [36m0.9963[0m        [32m0.0923[0m       0.8266      0.8266        0.6381        0.0000  30.8769
     15      0.9958        [32m0.0889[0m       0.8273      0.8273        0.6436        0.0000  30.9054
     16      [36m0.9973[0m        [32m0.0859[0m       0.8271      0.8271        0.6365        0.0000  30.6258
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8102430555555555
F1 Macro Score after query 9: 0.5270625118127564
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9115[0m        [32m0.3371[0m       [35m0.8349[0m      [31m0.8349[0m        [94m0.5177[0m     +  0.0000  46.4083
      2      [36m0.9319[0m        [32m0.2715[0m       0.8163      0.8163        0.5707        0.0000  46.7777
      3      [36m0.9426[0m        [32m0.2349[0m       0.8271      0.8271        0.5302        0.0000  46.6988
      4      [36m0.9529[0m        [32m0.2021[0m       0.8222      0.8222        0.5854        0.0000  46.7273
      5      [36m0.9556[0m        [32m0.1857[0m       0.8306      0.8306        0.5508        0.0000  46.6358
      6      [36m0.9729[0m        [32m0.1448[0m       [35m0.8366[0m      [31m0.8366[0m        0.5380        0.0000  46.8363
      7      [36m0.9796[0m        [32m0.1221[0m       0.8359      0.8359        0.5525        0.0000  46.6357
      8      [36m0.9829[0m        [32m0.1112[0m       0.8351      0.8351        0.5703        0.0000  46.3330
      9      [36m0.9857[0m        [32m0.0987[0m       0.8342      0.8342        0.5889        0.0000  46.5408
     10      [36m0.9875[0m        [32m0.0935[0m       0.8361      0.8361        0.5782        0.0000  46.6824
     11      [36m0.9915[0m        [32m0.0816[0m       0.8349      0.8349        0.5873        0.0000  46.2853
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8361111111111111
F1 Macro Score after query 10: 0.5711154256313402
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9365[0m        [32m0.2608[0m       [35m0.7972[0m      [31m0.7972[0m        [94m0.6234[0m     +  0.0000  74.6013
      2      [36m0.9451[0m        [32m0.2232[0m       [35m0.8222[0m      [31m0.8222[0m        [94m0.5529[0m     +  0.0000  75.0111
      3      [36m0.9549[0m        [32m0.1865[0m       0.8075      0.8075        0.6374        0.0000  75.0571
      4      [36m0.9587[0m        [32m0.1633[0m       0.8009      0.8009        0.6483        0.0000  74.9660
      5      [36m0.9645[0m        [32m0.1451[0m       0.8076      0.8076        0.6373        0.0000  75.0595
      6      [36m0.9774[0m        [32m0.1038[0m       0.8196      0.8196        0.5995        0.0000  75.1064
      7      [36m0.9811[0m        [32m0.0891[0m       0.8172      0.8172        0.6167        0.0000  74.9934
      8      [36m0.9851[0m        [32m0.0780[0m       0.8222      0.8222        0.6178        0.0000  74.9178
      9      [36m0.9888[0m        [32m0.0689[0m       [35m0.8229[0m      [31m0.8229[0m        0.6325        0.0000  75.2104
     10      [36m0.9908[0m        [32m0.0600[0m       [35m0.8248[0m      [31m0.8248[0m        0.6396        0.0000  75.1818
     11      [36m0.9927[0m        [32m0.0536[0m       [35m0.8255[0m      [31m0.8255[0m        0.6593        0.0000  74.6143
     12      [36m0.9940[0m        [32m0.0505[0m       0.8233      0.8233        0.6645        0.0000  75.4012
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8350694444444444
F1 Macro Score after query 11: 0.5413769927418218
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9692[0m        [32m0.1362[0m       [35m0.7740[0m      [31m0.7740[0m        [94m0.7109[0m     +  0.0000  125.3968
      2      [36m0.9714[0m        [32m0.1182[0m       [35m0.7884[0m      [31m0.7884[0m        [94m0.7071[0m     +  0.0000  126.0917
      3      [36m0.9749[0m        [32m0.1020[0m       [35m0.7920[0m      [31m0.7920[0m        0.7507        0.0000  126.1715
      4      [36m0.9783[0m        [32m0.0876[0m       0.7830      0.7830        0.7965        0.0000  126.4122
      5      [36m0.9814[0m        [32m0.0758[0m       0.7816      0.7816        0.7980        0.0000  126.0704
      6      [36m0.9855[0m        [32m0.0591[0m       [35m0.8066[0m      [31m0.8066[0m        0.7091        0.0000  126.2263
      7      [36m0.9904[0m        [32m0.0457[0m       [35m0.8179[0m      [31m0.8179[0m        [94m0.6500[0m     +  0.0000  126.0059
      8      [36m0.9929[0m        [32m0.0390[0m       [35m0.8205[0m      [31m0.8205[0m        0.6742        0.0000  126.1946
      9      [36m0.9941[0m        [32m0.0338[0m       [35m0.8224[0m      [31m0.8224[0m        0.6858        0.0000  126.9585
     10      [36m0.9950[0m        [32m0.0295[0m       [35m0.8257[0m      [31m0.8257[0m        0.7009        0.0000  126.1732
     11      [36m0.9962[0m        [32m0.0258[0m       0.8252      0.8252        0.7193        0.0000  126.4807
     12      [36m0.9970[0m        [32m0.0233[0m       0.8257      0.8257        0.7310        0.0000  125.9130
     13      [36m0.9975[0m        [32m0.0222[0m       [35m0.8280[0m      [31m0.8280[0m        0.7361        0.0000  126.1055
     14      [36m0.9975[0m        [32m0.0214[0m       [35m0.8281[0m      [31m0.8281[0m        0.7369        0.0000  126.6144
     15      [36m0.9978[0m        [32m0.0204[0m       0.8278      0.8278        0.7471        0.0000  126.1785
     16      [36m0.9978[0m        [32m0.0199[0m       0.8255      0.8255        0.7738        0.0000  125.5992
     17      [36m0.9980[0m        [32m0.0191[0m       0.8255      0.8255        0.7751        0.0000  126.2444
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8532986111111112
F1 Macro Score after query 12: 0.572460188739222
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9865[0m        [32m0.0556[0m       [35m0.7109[0m      [31m0.7109[0m        [94m1.3941[0m     +  0.0000  146.0884
      2      0.9863        [32m0.0524[0m       0.6849      0.6849        1.5234        0.0000  147.1801
      3      [36m0.9884[0m        [32m0.0457[0m       [35m0.7252[0m      [31m0.7252[0m        [94m1.2517[0m     +  0.0000  146.7800
      4      0.9881        [32m0.0442[0m       [35m0.7757[0m      [31m0.7757[0m        [94m0.9520[0m     +  0.0000  146.9439
      5      [36m0.9896[0m        [32m0.0405[0m       [35m0.8163[0m      [31m0.8163[0m        [94m0.7870[0m     +  0.0000  147.0062
      6      [36m0.9937[0m        [32m0.0267[0m       [35m0.8227[0m      [31m0.8227[0m        [94m0.7655[0m     +  0.0000  146.5828
      7      [36m0.9970[0m        [32m0.0169[0m       [35m0.8259[0m      [31m0.8259[0m        0.7702        0.0000  146.9260
      8      [36m0.9978[0m        [32m0.0137[0m       0.8238      0.8238        0.7699        0.0000  146.7386
      9      [36m0.9985[0m        [32m0.0113[0m       0.8231      0.8231        0.8114        0.0000  147.7924
     10      [36m0.9989[0m        [32m0.0097[0m       0.8253      0.8253        0.8249        0.0000  147.6067
     11      0.9989        [32m0.0088[0m       [35m0.8293[0m      [31m0.8293[0m        0.8449        0.0000  145.5976
     12      [36m0.9994[0m        [32m0.0074[0m       0.8281      0.8281        0.8479        0.0000  139.1727
     13      [36m0.9995[0m        [32m0.0072[0m       0.8288      0.8288        0.8589        0.0000  139.2187
     14      0.9995        [32m0.0068[0m       0.8273      0.8273        0.8741        0.0000  139.6141
     15      [36m0.9996[0m        [32m0.0064[0m       0.8290      0.8290        0.8788        0.0000  146.7168
     16      [36m0.9996[0m        [32m0.0061[0m       0.8271      0.8271        0.9143        0.0000  144.2963
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8536458333333333
F1 Macro Score after query 13: 0.5838041419721318
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed42\AL_entropy_sampling_results_for_multiclass_classification_s42.pickle
