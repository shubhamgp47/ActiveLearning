(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2500[0m        [32m2.1566[0m       [35m0.0521[0m      [31m0.0521[0m        [94m2.0907[0m     +  0.0000  11.1661
      2      0.1250        [32m2.0046[0m       [35m0.2227[0m      [31m0.2227[0m        [94m2.0855[0m     +  0.0000  10.7192
      3      0.1250        [32m1.9192[0m       [35m0.3043[0m      [31m0.3043[0m        [94m2.0437[0m     +  0.0000  10.6046
      4      [36m0.5000[0m        [32m1.8037[0m       0.0095      0.0095        2.1493        0.0000  10.8434
      5      0.5000        [32m1.7943[0m       0.2667      0.2667        2.0469        0.0000  10.6043
      6      [36m0.6250[0m        [32m1.7228[0m       0.2422      0.2422        2.0583        0.0000  10.7324
      7      0.5000        [32m1.7174[0m       0.2024      0.2024        2.0671        0.0000  10.7498
      8      0.5000        [32m1.5976[0m       0.1783      0.1783        2.0723        0.0000  10.8042
      9      0.6250        1.6290       0.1965      0.1965        2.0685        0.0000  10.8876
     10      0.5000        1.6462       0.2286      0.2286        2.0617        0.0000  10.7834
     11      [36m0.8750[0m        [32m1.5189[0m       0.2274      0.2274        2.0622        0.0000  10.8336
     12      0.7500        1.6087       0.2236      0.2236        2.0637        0.0000  10.4167
     13      0.5000        1.7346       0.2219      0.2219        2.0638        0.0000  10.7141
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.2830
Pre F1 macro score = 0.1258

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5833[0m        [32m1.6864[0m       [35m0.4479[0m      [31m0.4479[0m        [94m1.8169[0m     +  0.0000  10.8612
      2      [36m0.7917[0m        [32m1.4010[0m       0.4462      0.4462        [94m1.8127[0m     +  0.0000  11.0663
      3      0.7917        [32m1.3326[0m       [35m0.4483[0m      [31m0.4483[0m        [94m1.8046[0m     +  0.0000  11.0156
      4      0.7917        [32m1.2205[0m       0.4443      0.4443        1.8062        0.0000  11.0052
      5      0.7917        [32m1.1750[0m       0.4479      0.4479        [94m1.7882[0m     +  0.0000  10.8802
      6      0.7917        [32m0.9978[0m       0.4476      0.4476        1.7893        0.0000  10.7781
      7      0.7917        1.0409       0.4477      0.4477        1.7893        0.0000  11.1241
      8      [36m0.8750[0m        1.0169       0.4479      0.4479        [94m1.7840[0m     +  0.0000  11.0466
      9      0.8750        [32m0.9507[0m       0.4477      0.4477        [94m1.7797[0m     +  0.0000  11.1293
     10      0.7917        0.9955       0.4474      0.4474        [94m1.7765[0m     +  0.0000  10.6693
     11      0.8750        [32m0.9413[0m       0.4477      0.4477        [94m1.7764[0m     +  0.0000  10.7367
     12      0.8333        0.9652       0.4477      0.4477        [94m1.7758[0m     +  0.0000  10.8796
     13      0.8333        [32m0.9240[0m       0.4477      0.4477        [94m1.7755[0m     +  0.0000  10.7835
     14      0.8333        0.9767       0.4479      0.4479        [94m1.7744[0m     +  0.0000  10.8620
     15      0.7917        1.0784       0.4481      0.4481        [94m1.7738[0m     +  0.0000  10.7357
     16      0.8333        0.9418       0.4479      0.4479        [94m1.7738[0m     +  0.0000  10.9663
     17      0.7917        1.0013       0.4481      0.4481        [94m1.7736[0m     +  0.0000  10.7360
     18      0.8750        0.9706       0.4481      0.4481        [94m1.7735[0m     +  0.0000  10.7358
     19      0.8333        1.0069       0.4481      0.4481        1.7735        0.0000  10.5936
     20      0.8333        0.9625       0.4481      0.4481        [94m1.7735[0m     +  0.0000  11.0128
     21      0.8333        0.9701       0.4481      0.4481        [94m1.7734[0m     +  0.0000  10.9102
     22      0.8333        0.9521       0.4481      0.4481        [94m1.7734[0m     +  0.0000  10.7176
     23      0.8750        0.9423       0.4481      0.4481        [94m1.7734[0m     +  0.0000  10.8621
     24      0.8333        0.9977       0.4481      0.4481        [94m1.7734[0m     +  0.0000  10.8698
     25      0.8333        0.9888       0.4481      0.4481        1.7734        0.0000  10.7832
     26      0.8333        0.9598       0.4481      0.4481        1.7734        0.0000  10.7824
     27      0.7917        1.0336       0.4481      0.4481        1.7734        0.0000  11.0064
     28      0.8750        0.9887       0.4481      0.4481        1.7734        0.0000  10.7828
     29      0.8750        0.9959       0.4481      0.4481        1.7734        0.0000  11.0145
     30      0.8750        0.9854       0.4481      0.4481        1.7734        0.0000  10.8723
     31      0.8750        0.9817       0.4481      0.4481        1.7734        0.0000  10.9032
     32      0.7917        0.9699       0.4481      0.4481        1.7734        0.0000  10.5462
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.4835069444444444
F1 Macro Score after query 1: 0.09002154152455244
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5536[0m        [32m1.5637[0m       [35m0.3542[0m      [31m0.3542[0m        [94m1.8625[0m     +  0.0000  10.6719
      2      [36m0.6964[0m        [32m1.2996[0m       [35m0.4062[0m      [31m0.4062[0m        [94m1.7603[0m     +  0.0000  10.9686
      3      0.6964        [32m1.2058[0m       [35m0.4382[0m      [31m0.4382[0m        [94m1.7191[0m     +  0.0000  10.9555
      4      0.6964        [32m1.1617[0m       0.4363      0.4363        [94m1.7159[0m     +  0.0000  11.1042
      5      [36m0.7143[0m        [32m1.0942[0m       [35m0.4460[0m      [31m0.4460[0m        [94m1.6983[0m     +  0.0000  10.9825
      6      [36m0.7679[0m        1.0958       0.4418      0.4418        [94m1.6895[0m     +  0.0000  11.0415
      7      0.7500        [32m0.9999[0m       0.4424      0.4424        [94m1.6885[0m     +  0.0000  11.1404
      8      0.7321        1.0535       0.4458      0.4458        [94m1.6855[0m     +  0.0000  11.0212
      9      0.7321        [32m0.9488[0m       0.4460      0.4460        [94m1.6835[0m     +  0.0000  11.2466
     10      0.7500        0.9887       0.4450      0.4450        [94m1.6834[0m     +  0.0000  10.9987
     11      [36m0.7857[0m        [32m0.9458[0m       0.4457      0.4457        1.6841        0.0000  10.9190
     12      0.7679        0.9536       [35m0.4472[0m      [31m0.4472[0m        1.6842        0.0000  10.9332
     13      [36m0.8036[0m        [32m0.9101[0m       0.4458      0.4458        1.6848        0.0000  11.1405
     14      0.7679        0.9307       0.4457      0.4457        1.6850        0.0000  11.2646
     15      0.7143        0.9477       0.4450      0.4450        1.6859        0.0000  11.0954
     16      0.7500        0.9348       0.4453      0.4453        1.6857        0.0000  11.1092
     17      0.7321        0.9599       0.4453      0.4453        1.6859        0.0000  10.9983
     18      [36m0.8214[0m        0.9198       0.4453      0.4453        1.6859        0.0000  11.0888
     19      0.7679        0.9137       0.4453      0.4453        1.6858        0.0000  10.8343
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.47760416666666666
F1 Macro Score after query 2: 0.1343248983314671
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5268[0m        [32m1.4212[0m       [35m0.5151[0m      [31m0.5151[0m        [94m1.6245[0m     +  0.0000  11.4477
      2      [36m0.6607[0m        [32m1.1971[0m       [35m0.5306[0m      [31m0.5306[0m        [94m1.5565[0m     +  0.0000  11.4734
      3      [36m0.8036[0m        [32m1.0365[0m       0.5193      0.5193        [94m1.5332[0m     +  0.0000  11.3646
      4      [36m0.8393[0m        [32m0.9327[0m       0.4832      0.4832        [94m1.5220[0m     +  0.0000  11.2537
      5      [36m0.8750[0m        [32m0.8745[0m       0.5146      0.5146        [94m1.5056[0m     +  0.0000  11.4587
      6      [36m0.9107[0m        [32m0.7410[0m       0.5231      0.5231        [94m1.4927[0m     +  0.0000  11.1843
      7      0.8929        0.7830       0.5122      0.5122        1.4929        0.0000  11.2360
      8      [36m0.9286[0m        [32m0.7328[0m       0.5087      0.5087        [94m1.4926[0m     +  0.0000  11.0898
      9      0.9286        [32m0.7096[0m       0.5061      0.5061        1.4933        0.0000  11.4556
     10      0.8929        0.7104       0.5033      0.5033        [94m1.4909[0m     +  0.0000  11.3280
     11      0.9107        0.7128       0.4976      0.4976        1.4929        0.0000  11.1252
     12      0.9196        0.7356       0.5010      0.5010        1.4919        0.0000  11.2160
     13      0.9107        0.7102       0.4998      0.4998        1.4918        0.0000  11.4218
     14      0.9107        [32m0.6740[0m       0.4979      0.4979        1.4929        0.0000  11.4236
     15      0.9107        0.7192       0.4964      0.4964        1.4940        0.0000  11.2989
     16      0.9196        0.7442       0.4962      0.4962        1.4942        0.0000  11.4738
     17      [36m0.9375[0m        0.6828       0.4965      0.4965        1.4942        0.0000  11.6674
     18      0.9286        0.6974       0.4965      0.4965        1.4940        0.0000  11.1402
     19      0.9196        0.7062       0.4965      0.4965        1.4939        0.0000  11.3557
     20      0.9107        0.7117       0.4965      0.4965        1.4939        0.0000  11.4256
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.5286458333333334
F1 Macro Score after query 3: 0.165914858655407
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6683[0m        [32m1.1555[0m       [35m0.5215[0m      [31m0.5215[0m        [94m1.5177[0m     +  0.0000  11.8230
      2      [36m0.8510[0m        [32m0.8943[0m       0.5097      0.5097        [94m1.4691[0m     +  0.0000  11.7970
      3      [36m0.8702[0m        [32m0.8257[0m       [35m0.5545[0m      [31m0.5545[0m        [94m1.4384[0m     +  0.0000  11.8402
      4      [36m0.8846[0m        [32m0.7478[0m       [35m0.5691[0m      [31m0.5691[0m        [94m1.4129[0m     +  0.0000  11.8749
      5      0.8846        [32m0.7166[0m       [35m0.5795[0m      [31m0.5795[0m        [94m1.3807[0m     +  0.0000  11.5487
      6      [36m0.9183[0m        [32m0.6724[0m       0.5646      0.5646        [94m1.3790[0m     +  0.0000  11.9182
      7      [36m0.9231[0m        [32m0.6347[0m       0.5674      0.5674        1.3818        0.0000  11.5421
      8      0.9183        0.6489       0.5720      0.5720        1.3805        0.0000  11.8125
      9      0.9231        [32m0.6336[0m       0.5608      0.5608        1.3821        0.0000  11.6564
     10      [36m0.9375[0m        [32m0.6118[0m       0.5641      0.5641        1.3804        0.0000  11.5464
     11      [36m0.9423[0m        [32m0.5971[0m       0.5622      0.5622        1.3803        0.0000  11.5986
     12      0.9375        [32m0.5919[0m       0.5628      0.5628        1.3802        0.0000  11.7600
     13      [36m0.9519[0m        [32m0.5890[0m       0.5623      0.5623        1.3805        0.0000  11.7370
     14      [36m0.9567[0m        [32m0.5684[0m       0.5608      0.5608        1.3806        0.0000  11.7144
     15      0.9519        0.5868       0.5599      0.5599        1.3808        0.0000  11.7828
     16      0.9567        0.5807       0.5599      0.5599        1.3805        0.0000  11.8787
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.6083333333333333
F1 Macro Score after query 4: 0.2494979990997602
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7995[0m        [32m0.9549[0m       [35m0.6483[0m      [31m0.6483[0m        [94m1.2483[0m     +  0.0000  12.6398
      2      [36m0.9141[0m        [32m0.7129[0m       0.6431      0.6431        [94m1.2322[0m     +  0.0000  12.4665
      3      [36m0.9167[0m        [32m0.6325[0m       [35m0.6488[0m      [31m0.6488[0m        [94m1.2217[0m     +  0.0000  12.8002
      4      [36m0.9219[0m        [32m0.5796[0m       0.6488      0.6488        [94m1.2164[0m     +  0.0000  12.3069
      5      [36m0.9349[0m        [32m0.5757[0m       [35m0.6585[0m      [31m0.6585[0m        [94m1.1999[0m     +  0.0000  12.7261
      6      [36m0.9401[0m        [32m0.5146[0m       0.6453      0.6453        1.2053        0.0000  12.8758
      7      [36m0.9479[0m        [32m0.5019[0m       0.6417      0.6417        1.2114        0.0000  12.6394
      8      [36m0.9505[0m        [32m0.4805[0m       0.6340      0.6340        1.2152        0.0000  12.4266
      9      0.9479        [32m0.4707[0m       0.6413      0.6413        1.2125        0.0000  12.5933
     10      [36m0.9635[0m        [32m0.4573[0m       0.6373      0.6373        1.2160        0.0000  12.5455
     11      0.9583        0.4740       0.6342      0.6342        1.2160        0.0000  12.6346
     12      0.9583        0.4754       0.6337      0.6337        1.2166        0.0000  12.6615
     13      0.9557        0.4646       0.6316      0.6316        1.2187        0.0000  12.4153
     14      0.9583        0.4612       0.6285      0.6285        1.2218        0.0000  12.6286
     15      0.9635        [32m0.4539[0m       0.6304      0.6304        1.2215        0.0000  12.6239
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.6684027777777778
F1 Macro Score after query 5: 0.2897211672055119
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8097[0m        [32m0.8308[0m       [35m0.7010[0m      [31m0.7010[0m        [94m1.0511[0m     +  0.0000  14.0049
      2      [36m0.8949[0m        [32m0.6401[0m       [35m0.7073[0m      [31m0.7073[0m        [94m1.0227[0m     +  0.0000  14.2968
      3      [36m0.9205[0m        [32m0.5723[0m       [35m0.7104[0m      [31m0.7104[0m        1.0275        0.0000  14.0782
      4      [36m0.9276[0m        [32m0.5168[0m       [35m0.7135[0m      [31m0.7135[0m        [94m1.0099[0m     +  0.0000  14.0643
      5      [36m0.9332[0m        [32m0.4833[0m       [35m0.7163[0m      [31m0.7163[0m        1.0192        0.0000  14.3329
      6      [36m0.9489[0m        [32m0.4336[0m       0.7099      0.7099        1.0356        0.0000  14.0468
      7      0.9489        [32m0.4269[0m       0.7120      0.7120        1.0365        0.0000  14.3744
      8      [36m0.9503[0m        [32m0.4190[0m       0.7111      0.7111        1.0356        0.0000  14.4589
      9      [36m0.9531[0m        [32m0.4170[0m       0.7108      0.7108        1.0408        0.0000  14.0346
     10      0.9489        [32m0.4083[0m       0.7099      0.7099        1.0395        0.0000  14.0580
     11      [36m0.9560[0m        [32m0.3990[0m       0.7087      0.7087        1.0429        0.0000  14.0682
     12      [36m0.9602[0m        0.4028       0.7068      0.7068        1.0462        0.0000  14.0778
     13      0.9545        0.4074       0.7080      0.7080        1.0447        0.0000  13.9169
     14      [36m0.9631[0m        [32m0.3956[0m       0.7068      0.7068        1.0458        0.0000  13.8751
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.7121527777777776
F1 Macro Score after query 6: 0.27133702897799217
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8204[0m        [32m0.8129[0m       [35m0.6946[0m      [31m0.6946[0m        [94m1.0280[0m     +  0.0000  16.7792
      2      [36m0.8900[0m        [32m0.6164[0m       [35m0.7538[0m      [31m0.7538[0m        [94m0.9285[0m     +  0.0000  17.1521
      3      [36m0.9114[0m        [32m0.5506[0m       [35m0.7576[0m      [31m0.7576[0m        [94m0.8912[0m     +  0.0000  16.6508
      4      [36m0.9264[0m        [32m0.5040[0m       0.7507      0.7507        0.8944        0.0000  16.8494
      5      [36m0.9272[0m        [32m0.4686[0m       0.7403      0.7403        0.9004        0.0000  17.1851
      6      [36m0.9391[0m        [32m0.4284[0m       [35m0.7595[0m      [31m0.7595[0m        [94m0.8672[0m     +  0.0000  17.0733
      7      [36m0.9446[0m        [32m0.4109[0m       0.7578      0.7578        [94m0.8653[0m     +  0.0000  17.0084
      8      [36m0.9486[0m        [32m0.4001[0m       0.7590      0.7590        [94m0.8615[0m     +  0.0000  16.9061
      9      [36m0.9549[0m        [32m0.3801[0m       [35m0.7597[0m      [31m0.7597[0m        0.8632        0.0000  16.7814
     10      [36m0.9557[0m        [32m0.3770[0m       [35m0.7604[0m      [31m0.7604[0m        0.8631        0.0000  16.9062
     11      0.9549        [32m0.3617[0m       [35m0.7615[0m      [31m0.7615[0m        0.8685        0.0000  17.0107
     12      0.9557        [32m0.3615[0m       [35m0.7628[0m      [31m0.7628[0m        0.8674        0.0000  16.8291
     13      [36m0.9612[0m        [32m0.3525[0m       0.7616      0.7616        0.8699        0.0000  17.0444
     14      0.9604        0.3536       [35m0.7641[0m      [31m0.7641[0m        0.8659        0.0000  16.6732
     15      0.9589        [32m0.3525[0m       0.7627      0.7627        0.8669        0.0000  16.9370
     16      0.9612        [32m0.3509[0m       [35m0.7646[0m      [31m0.7646[0m        0.8669        0.0000  16.9214
     17      [36m0.9636[0m        0.3529       0.7646      0.7646        0.8669        0.0000  16.8377
     18      [36m0.9684[0m        [32m0.3430[0m       0.7644      0.7644        0.8670        0.0000  16.7971
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.7626736111111111
F1 Macro Score after query 7: 0.3289322847876953
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8746[0m        [32m0.6035[0m       [35m0.7618[0m      [31m0.7618[0m        [94m0.8222[0m     +  0.0000  21.6979
      2      [36m0.9156[0m        [32m0.4726[0m       [35m0.7634[0m      [31m0.7634[0m        [94m0.7889[0m     +  0.0000  21.8256
      3      [36m0.9324[0m        [32m0.4057[0m       [35m0.7635[0m      [31m0.7635[0m        [94m0.7788[0m     +  0.0000  21.7031
      4      [36m0.9421[0m        [32m0.3718[0m       0.7571      0.7571        [94m0.7677[0m     +  0.0000  21.7289
      5      [36m0.9474[0m        [32m0.3378[0m       [35m0.7740[0m      [31m0.7740[0m        [94m0.7649[0m     +  0.0000  21.7153
      6      [36m0.9616[0m        [32m0.2912[0m       [35m0.7757[0m      [31m0.7757[0m        [94m0.7450[0m     +  0.0000  22.2219
      7      [36m0.9651[0m        [32m0.2811[0m       0.7743      0.7743        0.7542        0.0000  21.6520
      8      [36m0.9726[0m        [32m0.2695[0m       0.7750      0.7750        0.7586        0.0000  21.4058
      9      [36m0.9735[0m        [32m0.2608[0m       0.7752      0.7752        0.7599        0.0000  21.4356
     10      [36m0.9770[0m        [32m0.2482[0m       [35m0.7764[0m      [31m0.7764[0m        0.7629        0.0000  21.5051
     11      0.9770        [32m0.2391[0m       [35m0.7818[0m      [31m0.7818[0m        0.7518        0.0000  21.6071
     12      [36m0.9784[0m        [32m0.2380[0m       0.7809      0.7809        0.7508        0.0000  21.5627
     13      [36m0.9806[0m        [32m0.2356[0m       0.7806      0.7806        0.7535        0.0000  21.4207
     14      [36m0.9828[0m        [32m0.2305[0m       0.7797      0.7797        0.7574        0.0000  21.4541
     15      [36m0.9832[0m        0.2322       0.7806      0.7806        0.7546        0.0000  21.6703
     16      0.9814        [32m0.2258[0m       0.7797      0.7797        0.7566        0.0000  21.7518
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8234375
F1 Macro Score after query 8: 0.47757264360826396
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8755[0m        [32m0.5291[0m       [35m0.8200[0m      [31m0.8200[0m        [94m0.6147[0m     +  0.0000  30.5494
      2      [36m0.9111[0m        [32m0.4191[0m       0.8158      0.8158        [94m0.6095[0m     +  0.0000  30.7784
      3      [36m0.9290[0m        [32m0.3605[0m       [35m0.8229[0m      [31m0.8229[0m        [94m0.5968[0m     +  0.0000  30.7653
      4      [36m0.9399[0m        [32m0.3229[0m       0.8165      0.8165        0.6274        0.0000  30.7658
      5      [36m0.9483[0m        [32m0.2856[0m       [35m0.8233[0m      [31m0.8233[0m        0.6061        0.0000  30.7156
      6      [36m0.9616[0m        [32m0.2430[0m       0.8160      0.8160        0.6403        0.0000  30.3920
      7      [36m0.9676[0m        [32m0.2194[0m       0.8127      0.8127        0.6490        0.0000  30.4687
      8      [36m0.9730[0m        [32m0.2131[0m       0.8069      0.8069        0.6683        0.0000  30.4365
      9      [36m0.9740[0m        [32m0.1986[0m       0.8111      0.8111        0.6598        0.0000  31.2920
     10      [36m0.9772[0m        [32m0.1890[0m       0.8097      0.8097        0.6705        0.0000  30.9667
     11      [36m0.9807[0m        [32m0.1790[0m       0.8078      0.8078        0.6717        0.0000  30.9394
     12      [36m0.9834[0m        [32m0.1739[0m       0.8071      0.8071        0.6717        0.0000  30.6560
     13      [36m0.9837[0m        [32m0.1702[0m       0.8057      0.8057        0.6813        0.0000  30.6561
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.840625
F1 Macro Score after query 9: 0.5705585854736129
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8989[0m        [32m0.4252[0m       [35m0.8080[0m      [31m0.8080[0m        [94m0.6017[0m     +  0.0000  45.9568
      2      [36m0.9237[0m        [32m0.3456[0m       [35m0.8186[0m      [31m0.8186[0m        [94m0.5844[0m     +  0.0000  46.2358
      3      [36m0.9319[0m        [32m0.3002[0m       0.7884      0.7884        0.6769        0.0000  46.3749
      4      [36m0.9453[0m        [32m0.2654[0m       0.8151      0.8151        [94m0.5724[0m     +  0.0000  46.7480
      5      [36m0.9499[0m        [32m0.2328[0m       0.7962      0.7962        0.6466        0.0000  46.2532
      6      [36m0.9624[0m        [32m0.1915[0m       0.8135      0.8135        0.6297        0.0000  46.1406
      7      [36m0.9706[0m        [32m0.1696[0m       0.8142      0.8142        0.6352        0.0000  46.5865
      8      [36m0.9747[0m        [32m0.1566[0m       0.8104      0.8104        0.6604        0.0000  46.6406
      9      [36m0.9810[0m        [32m0.1440[0m       0.8146      0.8146        0.6549        0.0000  46.6129
     10      [36m0.9814[0m        [32m0.1344[0m       0.8184      0.8184        0.6523        0.0000  46.5425
     11      [36m0.9836[0m        [32m0.1287[0m       0.8108      0.8108        0.6897        0.0000  46.3969
     12      [36m0.9858[0m        [32m0.1211[0m       0.8083      0.8083        0.7021        0.0000  46.4506
     13      [36m0.9875[0m        [32m0.1193[0m       0.8094      0.8094        0.6973        0.0000  46.6069
     14      [36m0.9882[0m        [32m0.1154[0m       0.8111      0.8111        0.6981        0.0000  46.0742
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8522569444444444
F1 Macro Score after query 10: 0.5923637131388697
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9499[0m        [32m0.2468[0m       [35m0.8033[0m      [31m0.8033[0m        [94m0.6172[0m     +  0.0000  73.0775
      2      [36m0.9539[0m        [32m0.2100[0m       0.8023      0.8023        [94m0.6126[0m     +  0.0000  74.3148
      3      [36m0.9570[0m        [32m0.1862[0m       0.8003      0.8003        [94m0.6113[0m     +  0.0000  74.0564
      4      [36m0.9630[0m        [32m0.1615[0m       0.7910      0.7910        0.7396        0.0000  74.2904
      5      [36m0.9682[0m        [32m0.1384[0m       0.7637      0.7637        0.9250        0.0000  73.9659
      6      [36m0.9764[0m        [32m0.1105[0m       [35m0.8056[0m      [31m0.8056[0m        0.7324        0.0000  74.0003
      7      [36m0.9840[0m        [32m0.0877[0m       [35m0.8083[0m      [31m0.8083[0m        0.7508        0.0000  74.4377
      8      [36m0.9874[0m        [32m0.0773[0m       [35m0.8095[0m      [31m0.8095[0m        0.7513        0.0000  74.0144
      9      [36m0.9907[0m        [32m0.0684[0m       0.8082      0.8082        0.7719        0.0000  74.1673
     10      [36m0.9930[0m        [32m0.0611[0m       0.8043      0.8043        0.7924        0.0000  74.1865
     11      [36m0.9946[0m        [32m0.0551[0m       [35m0.8142[0m      [31m0.8142[0m        0.7399        0.0000  75.0710
     12      [36m0.9954[0m        [32m0.0516[0m       0.8127      0.8127        0.7499        0.0000  74.4220
     13      [36m0.9963[0m        [32m0.0483[0m       0.8127      0.8127        0.7581        0.0000  75.1163
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8536458333333333
F1 Macro Score after query 11: 0.5891508591434735
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9746[0m        [32m0.1245[0m       [35m0.8003[0m      [31m0.8003[0m        [94m0.6565[0m     +  0.0000  124.4632
      2      [36m0.9770[0m        [32m0.1065[0m       0.7806      0.7806        0.8165        0.0000  124.5461
      3      [36m0.9784[0m        [32m0.0925[0m       [35m0.8241[0m      [31m0.8241[0m        0.6787        0.0000  124.5314
      4      [36m0.9820[0m        [32m0.0780[0m       0.8083      0.8083        0.7392        0.0000  124.3100
      5      [36m0.9830[0m        [32m0.0689[0m       0.7896      0.7896        0.8371        0.0000  124.5600
      6      [36m0.9887[0m        [32m0.0517[0m       [35m0.8248[0m      [31m0.8248[0m        0.7042        0.0000  124.4998
      7      [36m0.9922[0m        [32m0.0393[0m       [35m0.8267[0m      [31m0.8267[0m        0.7094        0.0000  124.4676
      8      [36m0.9944[0m        [32m0.0327[0m       0.8141      0.8141        0.7962        0.0000  125.2542
      9      [36m0.9967[0m        [32m0.0265[0m       0.8139      0.8139        0.8156        0.0000  124.1702
     10      [36m0.9972[0m        [32m0.0239[0m       0.8210      0.8210        0.8111        0.0000  124.2317
     11      [36m0.9978[0m        [32m0.0208[0m       0.8082      0.8082        0.8925        0.0000  124.7528
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8524305555555556
F1 Macro Score after query 12: 0.5748834273654706
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9794[0m        [32m0.0964[0m       [35m0.7851[0m      [31m0.7851[0m        [94m0.8199[0m     +  0.0000  147.8301
      2      [36m0.9807[0m        [32m0.0810[0m       0.7724      0.7724        0.9576        0.0000  149.3167
      3      [36m0.9828[0m        [32m0.0714[0m       0.7849      0.7849        0.9040        0.0000  148.8459
      4      [36m0.9847[0m        [32m0.0625[0m       [35m0.7882[0m      [31m0.7882[0m        0.8657        0.0000  149.2809
      5      [36m0.9863[0m        [32m0.0564[0m       [35m0.7915[0m      [31m0.7915[0m        0.9535        0.0000  144.5637
      6      [36m0.9899[0m        [32m0.0441[0m       [35m0.8222[0m      [31m0.8222[0m        [94m0.7279[0m     +  0.0000  145.7190
      7      [36m0.9941[0m        [32m0.0305[0m       0.8101      0.8101        0.7814        0.0000  144.2520
      8      [36m0.9961[0m        [32m0.0248[0m       0.8167      0.8167        0.7925        0.0000  144.5170
      9      [36m0.9974[0m        [32m0.0212[0m       0.8156      0.8156        0.8371        0.0000  144.8061
     10      [36m0.9982[0m        [32m0.0175[0m       [35m0.8224[0m      [31m0.8224[0m        0.8289        0.0000  144.6244
     11      0.9982        [32m0.0161[0m       [35m0.8250[0m      [31m0.8250[0m        0.8682        0.0000  145.1977
     12      [36m0.9989[0m        [32m0.0135[0m       0.8233      0.8233        0.8774        0.0000  144.2192
     13      [36m0.9991[0m        [32m0.0127[0m       0.8214      0.8214        0.9066        0.0000  143.9692
     14      [36m0.9992[0m        [32m0.0123[0m       0.8224      0.8224        0.9186        0.0000  144.0474
     15      [36m0.9994[0m        [32m0.0118[0m       0.8205      0.8205        0.9280        0.0000  144.8091
     16      [36m0.9994[0m        [32m0.0111[0m       0.8226      0.8226        0.9197        0.0000  145.4781
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8434027777777778
F1 Macro Score after query 13: 0.6053170534134809
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed50\AL_entropy_sampling_results_for_multiclass_classification_s50.pickle
