(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2500[0m        [32m2.0327[0m       [35m0.2233[0m      [31m0.2233[0m        [94m1.9289[0m     +  0.0000  11.4858
      2      0.2500        [32m1.9712[0m       0.1854      0.1854        1.9898        0.0000  10.7213
      3      [36m0.5000[0m        [32m1.7284[0m       [35m0.3267[0m      [31m0.3267[0m        [94m1.8632[0m     +  0.0000  10.9489
      4      [36m0.6250[0m        [32m1.6674[0m       0.2106      0.2106        1.9695        0.0000  10.5865
      5      0.6250        [32m1.5344[0m       [35m0.3321[0m      [31m0.3321[0m        1.8673        0.0000  10.7655
      6      [36m0.8750[0m        [32m1.3737[0m       [35m0.3359[0m      [31m0.3359[0m        1.8914        0.0000  11.1582
      7      0.7500        1.4372       0.3214      0.3214        1.9118        0.0000  11.1311
      8      0.8750        [32m1.3501[0m       0.3087      0.3087        1.9198        0.0000  11.0158
      9      [36m1.0000[0m        1.3720       0.3149      0.3149        1.9225        0.0000  11.0944
     10      0.8750        [32m1.3006[0m       0.3182      0.3182        1.9235        0.0000  10.7891
     11      0.8750        1.3092       0.3167      0.3167        1.9235        0.0000  10.8582
     12      1.0000        1.3720       0.3158      0.3158        1.9257        0.0000  11.0212
     13      0.7500        1.4509       0.3153      0.3153        1.9249        0.0000  10.7188
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.2668
Pre F1 macro score = 0.1538

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5417[0m        [32m1.6863[0m       [35m0.1257[0m      [31m0.1257[0m        [94m1.9824[0m     +  0.0000  11.0538
      2      [36m0.6250[0m        [32m1.4849[0m       [35m0.1986[0m      [31m0.1986[0m        [94m1.9111[0m     +  0.0000  10.8540
      3      [36m0.7500[0m        [32m1.3396[0m       [35m0.2592[0m      [31m0.2592[0m        [94m1.8961[0m     +  0.0000  10.9005
      4      [36m0.8333[0m        [32m1.2023[0m       [35m0.3090[0m      [31m0.3090[0m        [94m1.8096[0m     +  0.0000  10.9065
      5      [36m0.9167[0m        [32m1.0352[0m       [35m0.3318[0m      [31m0.3318[0m        [94m1.7523[0m     +  0.0000  10.8390
      6      0.9167        [32m1.0064[0m       0.3309      0.3309        1.7563        0.0000  10.8590
      7      0.9167        [32m0.9053[0m       [35m0.3330[0m      [31m0.3330[0m        1.7585        0.0000  11.0943
      8      [36m0.9583[0m        0.9671       [35m0.3413[0m      [31m0.3413[0m        1.7566        0.0000  10.9146
      9      0.9583        0.9457       [35m0.3542[0m      [31m0.3542[0m        1.7525        0.0000  10.7460
     10      0.9583        [32m0.8726[0m       0.3497      0.3497        1.7567        0.0000  11.0912
     11      0.9167        0.8807       0.3493      0.3493        1.7579        0.0000  11.0352
     12      0.9583        0.9133       0.3500      0.3500        1.7584        0.0000  11.1740
     13      0.9583        [32m0.8432[0m       0.3502      0.3502        1.7579        0.0000  11.0255
     14      0.9583        0.9185       0.3514      0.3514        1.7573        0.0000  10.7856
     15      0.9167        0.9152       0.3510      0.3510        1.7570        0.0000  11.0282
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.35173611111111114
F1 Macro Score after query 1: 0.18105666566205098
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7857[0m        [32m1.2897[0m       [35m0.3783[0m      [31m0.3783[0m        [94m1.6573[0m     +  0.0000  11.2172
      2      [36m0.8929[0m        [32m0.8601[0m       [35m0.4679[0m      [31m0.4679[0m        [94m1.6444[0m     +  0.0000  10.9895
      3      [36m0.9464[0m        [32m0.7701[0m       0.4644      0.4644        [94m1.6443[0m     +  0.0000  10.9668
      4      0.9464        [32m0.6792[0m       0.4595      0.4595        [94m1.6440[0m     +  0.0000  10.8930
      5      [36m0.9643[0m        [32m0.6705[0m       [35m0.4828[0m      [31m0.4828[0m        [94m1.6068[0m     +  0.0000  10.9988
      6      0.9286        [32m0.6367[0m       0.4753      0.4753        1.6120        0.0000  11.0402
      7      0.9286        [32m0.6102[0m       0.4681      0.4681        1.6156        0.0000  11.1411
      8      0.9464        [32m0.5902[0m       0.4703      0.4703        1.6128        0.0000  11.1084
      9      0.9464        0.6079       0.4641      0.4641        1.6144        0.0000  11.0994
     10      0.9464        [32m0.5608[0m       0.4639      0.4639        1.6156        0.0000  11.0672
     11      0.9464        0.5812       0.4630      0.4630        1.6154        0.0000  11.2983
     12      0.9643        0.6088       0.4632      0.4632        1.6145        0.0000  11.3280
     13      0.9286        0.5637       0.4606      0.4606        1.6149        0.0000  11.0303
     14      0.9286        0.5994       0.4589      0.4589        1.6149        0.0000  11.0452
     15      0.9464        0.5843       0.4585      0.4585        1.6149        0.0000  11.1967
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.4217013888888889
F1 Macro Score after query 2: 0.15152885417850737
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9286[0m        [32m0.7292[0m       [35m0.4479[0m      [31m0.4479[0m        [94m1.5776[0m     +  0.0000  11.4330
      2      0.9107        [32m0.6112[0m       [35m0.4523[0m      [31m0.4523[0m        [94m1.5426[0m     +  0.0000  11.4087
      3      [36m0.9375[0m        [32m0.4468[0m       [35m0.4542[0m      [31m0.4542[0m        [94m1.5215[0m     +  0.0000  11.3612
      4      0.9375        [32m0.4387[0m       [35m0.4543[0m      [31m0.4543[0m        [94m1.5050[0m     +  0.0000  11.1984
      5      [36m0.9554[0m        [32m0.4111[0m       [35m0.4550[0m      [31m0.4550[0m        [94m1.4877[0m     +  0.0000  11.3895
      6      [36m0.9643[0m        [32m0.3833[0m       [35m0.4590[0m      [31m0.4590[0m        [94m1.4793[0m     +  0.0000  11.6869
      7      0.9464        [32m0.3829[0m       [35m0.4622[0m      [31m0.4622[0m        [94m1.4685[0m     +  0.0000  11.4800
      8      0.9554        0.3861       [35m0.4655[0m      [31m0.4655[0m        [94m1.4645[0m     +  0.0000  11.3816
      9      0.9643        [32m0.3771[0m       [35m0.4656[0m      [31m0.4656[0m        [94m1.4629[0m     +  0.0000  11.3709
     10      0.9643        0.3803       [35m0.4660[0m      [31m0.4660[0m        [94m1.4607[0m     +  0.0000  11.5099
     11      [36m0.9732[0m        [32m0.3741[0m       [35m0.4668[0m      [31m0.4668[0m        [94m1.4584[0m     +  0.0000  11.3897
     12      0.9732        0.3872       [35m0.4674[0m      [31m0.4674[0m        [94m1.4561[0m     +  0.0000  11.6216
     13      0.9732        [32m0.3361[0m       [35m0.4682[0m      [31m0.4682[0m        [94m1.4550[0m     +  0.0000  11.1050
     14      0.9732        0.3759       [35m0.4689[0m      [31m0.4689[0m        [94m1.4528[0m     +  0.0000  11.2784
     15      0.9732        [32m0.3310[0m       [35m0.4693[0m      [31m0.4693[0m        [94m1.4514[0m     +  0.0000  11.3629
     16      0.9732        0.3754       0.4693      0.4693        [94m1.4512[0m     +  0.0000  11.4063
     17      [36m0.9821[0m        0.3535       0.4693      0.4693        [94m1.4510[0m     +  0.0000  11.5829
     18      0.9821        0.3424       0.4689      0.4689        1.4511        0.0000  11.5227
     19      0.9643        0.3576       0.4691      0.4691        [94m1.4508[0m     +  0.0000  11.5336
     20      0.9821        0.3609       0.4691      0.4691        [94m1.4507[0m     +  0.0000  11.4050
     21      0.9732        0.3807       0.4691      0.4691        1.4507        0.0000  11.2166
     22      0.9643        0.3523       0.4691      0.4691        1.4507        0.0000  11.4607
     23      0.9732        [32m0.3290[0m       0.4691      0.4691        [94m1.4507[0m     +  0.0000  11.0803
     24      0.9643        0.3708       0.4691      0.4691        [94m1.4507[0m     +  0.0000  11.6252
     25      0.9732        0.3687       0.4691      0.4691        [94m1.4506[0m     +  0.0000  11.6097
     26      0.9643        0.3684       0.4691      0.4691        [94m1.4506[0m     +  0.0000  11.2546
     27      0.9732        0.3578       0.4691      0.4691        [94m1.4506[0m     +  0.0000  11.5620
     28      0.9821        0.3352       0.4691      0.4691        [94m1.4506[0m     +  0.0000  11.2174
     29      0.9554        0.3548       0.4691      0.4691        [94m1.4505[0m     +  0.0000  11.2648
     30      0.9732        0.3667       0.4691      0.4691        [94m1.4505[0m     +  0.0000  11.2822
     31      0.9732        0.3621       0.4691      0.4691        [94m1.4505[0m     +  0.0000  11.1937
     32      0.9643        0.3349       0.4691      0.4691        [94m1.4505[0m     +  0.0000  11.4185
     33      0.9732        0.3599       0.4691      0.4691        [94m1.4505[0m     +  0.0000  11.5889
     34      0.9732        0.3750       0.4691      0.4691        [94m1.4505[0m     +  0.0000  11.4568
     35      0.9643        0.3821       0.4691      0.4691        [94m1.4505[0m     +  0.0000  11.2157
     36      0.9643        0.3635       0.4691      0.4691        [94m1.4505[0m     +  0.0000  11.4320
     37      0.9732        0.3424       0.4691      0.4691        [94m1.4505[0m     +  0.0000  11.3146
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.4947916666666667
F1 Macro Score after query 3: 0.11206771157177749
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8606[0m        [32m0.7966[0m       [35m0.4979[0m      [31m0.4979[0m        [94m1.4480[0m     +  0.0000  11.9570
      2      [36m0.8990[0m        [32m0.6301[0m       [35m0.5260[0m      [31m0.5260[0m        [94m1.3302[0m     +  0.0000  11.7043
      3      [36m0.9087[0m        [32m0.5569[0m       0.5222      0.5222        [94m1.3093[0m     +  0.0000  11.8866
      4      [36m0.9183[0m        [32m0.5343[0m       0.5153      0.5153        1.3133        0.0000  11.6486
      5      [36m0.9279[0m        [32m0.5030[0m       [35m0.5328[0m      [31m0.5328[0m        1.3143        0.0000  12.1808
      6      [36m0.9327[0m        [32m0.4422[0m       [35m0.5398[0m      [31m0.5398[0m        [94m1.3077[0m     +  0.0000  11.9046
      7      0.9231        0.4589       0.5375      0.5375        [94m1.3002[0m     +  0.0000  11.8078
      8      [36m0.9423[0m        [32m0.4421[0m       [35m0.5427[0m      [31m0.5427[0m        1.3002        0.0000  12.1054
      9      0.9327        0.4532       [35m0.5450[0m      [31m0.5450[0m        [94m1.2967[0m     +  0.0000  12.0257
     10      0.9327        [32m0.4354[0m       0.5439      0.5439        [94m1.2951[0m     +  0.0000  11.7256
     11      0.9375        0.4367       0.5446      0.5446        [94m1.2950[0m     +  0.0000  12.2791
     12      0.9375        [32m0.4299[0m       [35m0.5457[0m      [31m0.5457[0m        [94m1.2948[0m     +  0.0000  11.8056
     13      0.9423        [32m0.4164[0m       [35m0.5462[0m      [31m0.5462[0m        [94m1.2942[0m     +  0.0000  12.4484
     14      0.9375        0.4389       [35m0.5469[0m      [31m0.5469[0m        [94m1.2932[0m     +  0.0000  11.8054
     15      0.9375        0.4255       [35m0.5477[0m      [31m0.5477[0m        [94m1.2920[0m     +  0.0000  12.0075
     16      0.9423        0.4179       [35m0.5479[0m      [31m0.5479[0m        [94m1.2916[0m     +  0.0000  11.8536
     17      [36m0.9471[0m        0.4367       0.5479      0.5479        1.2918        0.0000  11.9471
     18      0.9375        0.4301       0.5479      0.5479        1.2920        0.0000  11.9013
     19      0.9423        0.4237       [35m0.5483[0m      [31m0.5483[0m        1.2921        0.0000  11.9005
     20      0.9471        0.4471       0.5483      0.5483        1.2923        0.0000  12.1211
     21      0.9279        0.4294       [35m0.5484[0m      [31m0.5484[0m        1.2922        0.0000  11.8213
     22      0.9375        0.4325       0.5484      0.5484        1.2922        0.0000  11.8704
     23      0.9423        [32m0.4110[0m       0.5484      0.5484        1.2922        0.0000  12.0420
     24      0.9423        [32m0.4069[0m       0.5484      0.5484        1.2922        0.0000  11.8678
     25      0.9471        0.4179       0.5484      0.5484        1.2922        0.0000  11.5572
     26      0.9471        0.4230       0.5484      0.5484        1.2921        0.0000  11.7761
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.5522569444444444
F1 Macro Score after query 4: 0.18204048237394602
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9115[0m        [32m0.6420[0m       [35m0.5627[0m      [31m0.5627[0m        [94m1.3297[0m     +  0.0000  12.4334
      2      [36m0.9453[0m        [32m0.4975[0m       [35m0.5703[0m      [31m0.5703[0m        [94m1.2465[0m     +  0.0000  12.1967
      3      [36m0.9479[0m        [32m0.4331[0m       [35m0.5858[0m      [31m0.5858[0m        [94m1.2251[0m     +  0.0000  12.8526
      4      [36m0.9505[0m        [32m0.3926[0m       [35m0.6182[0m      [31m0.6182[0m        [94m1.1861[0m     +  0.0000  12.1352
      5      [36m0.9557[0m        [32m0.3533[0m       [35m0.6297[0m      [31m0.6297[0m        [94m1.1631[0m     +  0.0000  12.7139
      6      [36m0.9583[0m        [32m0.3514[0m       0.6220      0.6220        [94m1.1548[0m     +  0.0000  12.5564
      7      0.9505        [32m0.3342[0m       0.6227      0.6227        [94m1.1500[0m     +  0.0000  12.4478
      8      0.9557        [32m0.3119[0m       0.6210      0.6210        1.1541        0.0000  12.5261
      9      [36m0.9661[0m        [32m0.3102[0m       0.6219      0.6219        1.1531        0.0000  12.7447
     10      0.9661        0.3146       0.6207      0.6207        1.1550        0.0000  12.7924
     11      0.9635        0.3130       0.6207      0.6207        1.1579        0.0000  12.8224
     12      [36m0.9714[0m        0.3125       0.6212      0.6212        1.1579        0.0000  13.2101
     13      0.9661        [32m0.3046[0m       0.6212      0.6212        1.1570        0.0000  12.5865
     14      0.9635        [32m0.3035[0m       0.6208      0.6208        1.1580        0.0000  12.3818
     15      0.9714        [32m0.2991[0m       0.6214      0.6214        1.1588        0.0000  12.7450
     16      [36m0.9740[0m        [32m0.2941[0m       0.6210      0.6210        1.1587        0.0000  12.8997
     17      0.9635        [32m0.2899[0m       0.6210      0.6210        1.1583        0.0000  12.8995
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.6340277777777777
F1 Macro Score after query 5: 0.2366920248613235
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8395[0m        [32m0.7223[0m       [35m0.6868[0m      [31m0.6868[0m        [94m1.0724[0m     +  0.0000  14.0438
      2      [36m0.9119[0m        [32m0.5209[0m       [35m0.7080[0m      [31m0.7080[0m        [94m0.9645[0m     +  0.0000  14.1361
      3      [36m0.9489[0m        [32m0.4263[0m       [35m0.7399[0m      [31m0.7399[0m        [94m0.9035[0m     +  0.0000  14.2145
      4      [36m0.9588[0m        [32m0.3854[0m       [35m0.7429[0m      [31m0.7429[0m        [94m0.8852[0m     +  0.0000  14.1520
      5      [36m0.9659[0m        [32m0.3488[0m       [35m0.7444[0m      [31m0.7444[0m        [94m0.8692[0m     +  0.0000  14.2038
      6      [36m0.9759[0m        [32m0.3229[0m       0.7415      0.7415        [94m0.8585[0m     +  0.0000  14.1048
      7      0.9716        [32m0.3165[0m       0.7434      0.7434        [94m0.8545[0m     +  0.0000  13.8710
      8      0.9744        [32m0.3039[0m       0.7417      0.7417        0.8558        0.0000  14.5593
      9      0.9759        [32m0.2974[0m       [35m0.7491[0m      [31m0.7491[0m        [94m0.8481[0m     +  0.0000  13.6827
     10      0.9730        [32m0.2921[0m       0.7467      0.7467        0.8498        0.0000  14.2743
     11      [36m0.9815[0m        [32m0.2892[0m       0.7441      0.7441        0.8608        0.0000  14.0899
     12      0.9773        [32m0.2823[0m       0.7436      0.7436        0.8616        0.0000  14.4667
     13      0.9815        [32m0.2785[0m       0.7413      0.7413        0.8655        0.0000  14.7150
     14      0.9801        [32m0.2726[0m       0.7424      0.7424        0.8607        0.0000  14.1047
     15      [36m0.9844[0m        0.2770       0.7413      0.7413        0.8594        0.0000  14.3075
     16      0.9815        0.2732       0.7410      0.7410        0.8622        0.0000  14.3242
     17      0.9815        0.2783       0.7417      0.7417        0.8626        0.0000  14.0924
     18      [36m0.9858[0m        0.2781       0.7415      0.7415        0.8638        0.0000  14.0091
     19      0.9801        [32m0.2654[0m       0.7406      0.7406        0.8652        0.0000  14.2304
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.7637152777777778
F1 Macro Score after query 6: 0.3372794794825081
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8592[0m        [32m0.6306[0m       [35m0.7271[0m      [31m0.7271[0m        [94m0.8929[0m     +  0.0000  17.1834
      2      [36m0.9114[0m        [32m0.4766[0m       [35m0.7521[0m      [31m0.7521[0m        [94m0.8418[0m     +  0.0000  17.0149
      3      [36m0.9146[0m        [32m0.4361[0m       [35m0.7656[0m      [31m0.7656[0m        [94m0.8080[0m     +  0.0000  16.9209
      4      [36m0.9312[0m        [32m0.3869[0m       0.7655      0.7655        0.8165        0.0000  16.9057
      5      [36m0.9407[0m        [32m0.3619[0m       [35m0.7677[0m      [31m0.7677[0m        0.8090        0.0000  16.8075
      6      [36m0.9446[0m        [32m0.3342[0m       0.7634      0.7634        [94m0.7857[0m     +  0.0000  16.9192
      7      [36m0.9581[0m        [32m0.3169[0m       0.7660      0.7660        [94m0.7769[0m     +  0.0000  17.0277
      8      [36m0.9612[0m        [32m0.3086[0m       [35m0.7693[0m      [31m0.7693[0m        0.7824        0.0000  16.9822
      9      [36m0.9620[0m        [32m0.3005[0m       0.7675      0.7675        0.7783        0.0000  16.9022
     10      [36m0.9652[0m        [32m0.2967[0m       [35m0.7719[0m      [31m0.7719[0m        [94m0.7735[0m     +  0.0000  16.8731
     11      0.9604        [32m0.2930[0m       0.7642      0.7642        [94m0.7480[0m     +  0.0000  17.0598
     12      0.9644        [32m0.2836[0m       0.7672      0.7672        0.7521        0.0000  16.7157
     13      [36m0.9668[0m        [32m0.2829[0m       0.7675      0.7675        0.7516        0.0000  17.0468
     14      0.9636        [32m0.2788[0m       0.7701      0.7701        0.7558        0.0000  16.7333
     15      0.9636        0.2816       0.7696      0.7696        0.7545        0.0000  16.9008
     16      0.9644        0.2804       0.7701      0.7701        0.7552        0.0000  17.1453
     17      [36m0.9699[0m        [32m0.2752[0m       0.7698      0.7698        0.7548        0.0000  16.9506
     18      0.9652        0.2878       0.7701      0.7701        0.7565        0.0000  17.0746
     19      0.9636        0.2825       0.7703      0.7703        0.7570        0.0000  17.1699
     20      0.9668        [32m0.2715[0m       0.7701      0.7701        0.7562        0.0000  16.9201
     21      0.9652        [32m0.2693[0m       0.7700      0.7700        0.7565        0.0000  17.2144
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.7711805555555555
F1 Macro Score after query 7: 0.39061690085280065
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8883[0m        [32m0.5126[0m       [35m0.7788[0m      [31m0.7788[0m        [94m0.6679[0m     +  0.0000  21.6234
      2      [36m0.9262[0m        [32m0.3815[0m       [35m0.7892[0m      [31m0.7892[0m        0.6848        0.0000  22.1889
      3      [36m0.9448[0m        [32m0.3286[0m       0.7651      0.7651        0.6971        0.0000  22.4086
      4      [36m0.9541[0m        [32m0.2913[0m       0.7653      0.7653        0.7113        0.0000  21.9379
      5      [36m0.9589[0m        [32m0.2626[0m       0.7712      0.7712        0.7200        0.0000  22.0171
      6      [36m0.9700[0m        [32m0.2358[0m       0.7769      0.7769        0.7246        0.0000  22.2382
      7      [36m0.9735[0m        [32m0.2210[0m       0.7778      0.7778        0.7277        0.0000  22.0602
      8      [36m0.9748[0m        [32m0.2184[0m       0.7788      0.7788        0.7212        0.0000  21.5476
      9      [36m0.9775[0m        [32m0.2033[0m       0.7792      0.7792        0.7285        0.0000  22.1286
     10      [36m0.9788[0m        [32m0.2013[0m       0.7743      0.7743        0.7311        0.0000  21.9706
     11      [36m0.9823[0m        [32m0.1921[0m       0.7764      0.7764        0.7423        0.0000  21.8614
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8329861111111111
F1 Macro Score after query 8: 0.4352592303401476
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8738[0m        [32m0.5154[0m       [35m0.7993[0m      [31m0.7993[0m        [94m0.6240[0m     +  0.0000  30.4953
      2      [36m0.9111[0m        [32m0.3976[0m       [35m0.8102[0m      [31m0.8102[0m        [94m0.6091[0m     +  0.0000  30.5998
      3      [36m0.9322[0m        [32m0.3423[0m       0.8035      0.8035        [94m0.5971[0m     +  0.0000  31.0538
      4      [36m0.9403[0m        [32m0.3072[0m       0.7885      0.7885        0.6380        0.0000  30.7687
      5      [36m0.9507[0m        [32m0.2742[0m       0.7974      0.7974        0.6925        0.0000  30.8637
      6      [36m0.9577[0m        [32m0.2376[0m       0.7983      0.7983        0.6457        0.0000  30.3946
      7      [36m0.9644[0m        [32m0.2202[0m       0.7988      0.7988        0.6533        0.0000  30.5862
      8      [36m0.9705[0m        [32m0.2111[0m       0.7976      0.7976        0.6566        0.0000  30.7584
      9      [36m0.9728[0m        [32m0.1986[0m       0.8019      0.8019        0.6567        0.0000  30.3681
     10      [36m0.9745[0m        [32m0.1932[0m       0.8028      0.8028        0.6567        0.0000  31.0817
     11      [36m0.9780[0m        [32m0.1787[0m       0.7972      0.7972        0.6673        0.0000  30.4599
     12      [36m0.9812[0m        [32m0.1753[0m       0.7967      0.7967        0.6676        0.0000  30.8930
     13      0.9800        0.1754       0.7969      0.7969        0.6699        0.0000  31.1448
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8296875
F1 Macro Score after query 9: 0.4238698122537079
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9000[0m        [32m0.4019[0m       [35m0.8203[0m      [31m0.8203[0m        [94m0.5381[0m     +  0.0000  45.6879
      2      [36m0.9267[0m        [32m0.3244[0m       [35m0.8226[0m      [31m0.8226[0m        0.5446        0.0000  47.2248
      3      [36m0.9376[0m        [32m0.2818[0m       0.8092      0.8092        0.5842        0.0000  46.5628
      4      [36m0.9458[0m        [32m0.2492[0m       0.7950      0.7950        0.6332        0.0000  46.8590
      5      [36m0.9542[0m        [32m0.2152[0m       0.8094      0.8094        0.6308        0.0000  46.4387
      6      [36m0.9663[0m        [32m0.1792[0m       0.8089      0.8089        0.6414        0.0000  46.6583
      7      [36m0.9712[0m        [32m0.1630[0m       0.8094      0.8094        0.6479        0.0000  46.2756
      8      [36m0.9739[0m        [32m0.1510[0m       0.8123      0.8123        0.6570        0.0000  46.8899
      9      [36m0.9779[0m        [32m0.1431[0m       0.8141      0.8141        0.6679        0.0000  46.5175
     10      [36m0.9796[0m        [32m0.1355[0m       0.8118      0.8118        0.6857        0.0000  46.4659
     11      [36m0.9840[0m        [32m0.1266[0m       0.8120      0.8120        0.6727        0.0000  45.9743
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8298611111111112
F1 Macro Score after query 10: 0.49084162006383414
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9234[0m        [32m0.3123[0m       [35m0.8410[0m      [31m0.8410[0m        [94m0.4945[0m     +  0.0000  74.3683
      2      [36m0.9403[0m        [32m0.2562[0m       0.7896      0.7896        0.6661        0.0000  75.8473
      3      [36m0.9467[0m        [32m0.2214[0m       0.8123      0.8123        0.5367        0.0000  74.9581
      4      [36m0.9526[0m        [32m0.1946[0m       0.8089      0.8089        0.5594        0.0000  75.0232
      5      [36m0.9564[0m        [32m0.1720[0m       0.7962      0.7962        0.6142        0.0000  74.7749
      6      [36m0.9667[0m        [32m0.1394[0m       0.8160      0.8160        0.6157        0.0000  74.9886
      7      [36m0.9740[0m        [32m0.1208[0m       0.8095      0.8095        0.6350        0.0000  74.6929
      8      [36m0.9775[0m        [32m0.1109[0m       0.8075      0.8075        0.6559        0.0000  74.8505
      9      [36m0.9806[0m        [32m0.1021[0m       0.8059      0.8059        0.6684        0.0000  75.8209
     10      [36m0.9835[0m        [32m0.0942[0m       0.8069      0.8069        0.6792        0.0000  75.2388
     11      [36m0.9861[0m        [32m0.0851[0m       0.8076      0.8076        0.7095        0.0000  75.1298
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8267361111111111
F1 Macro Score after query 11: 0.49239875228373764
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9610[0m        [32m0.1818[0m       [35m0.8141[0m      [31m0.8141[0m        [94m0.6148[0m     +  0.0000  125.6849
      2      [36m0.9634[0m        [32m0.1506[0m       [35m0.8238[0m      [31m0.8238[0m        [94m0.5448[0m     +  0.0000  126.7766
      3      [36m0.9680[0m        [32m0.1281[0m       0.8194      0.8194        0.5918        0.0000  125.7852
      4      [36m0.9692[0m        [32m0.1142[0m       0.8148      0.8148        0.6168        0.0000  125.8603
      5      [36m0.9724[0m        [32m0.1004[0m       0.8080      0.8080        0.7364        0.0000  124.6951
      6      [36m0.9805[0m        [32m0.0787[0m       0.7899      0.7899        0.7422        0.0000  126.5094
      7      [36m0.9846[0m        [32m0.0680[0m       0.8021      0.8021        0.7117        0.0000  125.6058
      8      [36m0.9872[0m        [32m0.0608[0m       0.8043      0.8043        0.7245        0.0000  125.9225
      9      [36m0.9884[0m        [32m0.0549[0m       0.8050      0.8050        0.7323        0.0000  125.8388
     10      [36m0.9902[0m        [32m0.0504[0m       0.8073      0.8073        0.7421        0.0000  126.1925
     11      [36m0.9923[0m        [32m0.0445[0m       0.8128      0.8128        0.7332        0.0000  125.8048
     12      [36m0.9928[0m        [32m0.0424[0m       0.8128      0.8128        0.7351        0.0000  125.7918
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8243055555555555
F1 Macro Score after query 12: 0.4835968834461011
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9715[0m        [32m0.1158[0m       [35m0.7937[0m      [31m0.7937[0m        [94m0.7779[0m     +  0.0000  145.7546
      2      [36m0.9741[0m        [32m0.1008[0m       0.7833      0.7833        0.8165        0.0000  146.2104
      3      [36m0.9768[0m        [32m0.0897[0m       0.7910      0.7910        0.8207        0.0000  147.4515
      4      [36m0.9788[0m        [32m0.0775[0m       0.7807      0.7807        0.9839        0.0000  146.4013
      5      [36m0.9812[0m        [32m0.0688[0m       [35m0.7962[0m      [31m0.7962[0m        0.9573        0.0000  146.6061
      6      [36m0.9855[0m        [32m0.0556[0m       0.7950      0.7950        [94m0.7545[0m     +  0.0000  146.6253
      7      [36m0.9895[0m        [32m0.0454[0m       [35m0.8026[0m      [31m0.8026[0m        [94m0.7448[0m     +  0.0000  146.7943
      8      [36m0.9904[0m        [32m0.0404[0m       0.7997      0.7997        0.7807        0.0000  146.7341
      9      [36m0.9924[0m        [32m0.0359[0m       0.8026      0.8026        0.7961        0.0000  146.7030
     10      [36m0.9941[0m        [32m0.0316[0m       [35m0.8043[0m      [31m0.8043[0m        0.7680        0.0000  146.6067
     11      [36m0.9955[0m        [32m0.0272[0m       0.8038      0.8038        0.8297        0.0000  146.2332
     12      [36m0.9959[0m        [32m0.0250[0m       [35m0.8080[0m      [31m0.8080[0m        0.8199        0.0000  146.6452
     13      [36m0.9968[0m        [32m0.0240[0m       0.8061      0.8061        0.8283        0.0000  146.8522
     14      [36m0.9968[0m        [32m0.0230[0m       [35m0.8104[0m      [31m0.8104[0m        0.7999        0.0000  146.3755
     15      [36m0.9974[0m        [32m0.0216[0m       0.8099      0.8099        0.8119        0.0000  146.8979
     16      0.9974        [32m0.0208[0m       0.8092      0.8092        0.8277        0.0000  147.0192
     17      [36m0.9979[0m        0.0211       0.8099      0.8099        0.8181        0.0000  146.5553
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8355902777777777
F1 Macro Score after query 13: 0.47278530977998473
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed48\AL_entropy_sampling_results_for_multiclass_classification_s48.pickle
