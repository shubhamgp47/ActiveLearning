(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.1250[0m        [32m2.0162[0m       [35m0.1920[0m      [31m0.1920[0m        [94m2.0201[0m     +  0.0000  11.5184
      2      [36m0.3750[0m        [32m1.9376[0m       [35m0.1969[0m      [31m0.1969[0m        2.1121        0.0000  10.7983
      3      0.3750        [32m1.8182[0m       0.1042      0.1042        2.1218        0.0000  10.8903
      4      0.3750        [32m1.7852[0m       0.1526      0.1526        2.1028        0.0000  10.6560
      5      [36m0.6250[0m        [32m1.6003[0m       0.1151      0.1151        2.1397        0.0000  10.4616
      6      [36m0.8750[0m        [32m1.4333[0m       0.1177      0.1177        2.1392        0.0000  10.9043
      7      0.7500        1.5687       0.1085      0.1085        2.1484        0.0000  10.3755
      8      [36m1.0000[0m        [32m1.3191[0m       0.1076      0.1076        2.1507        0.0000  10.9511
      9      0.8750        [32m1.2833[0m       0.1066      0.1066        2.1540        0.0000  10.7763
     10      0.6250        1.4975       0.1187      0.1188        2.1512        0.0000  10.6561
     11      0.7500        1.3694       0.1165      0.1165        2.1527        0.0000  10.8768
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.2059
Pre F1 macro score = 0.1244

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5417[0m        [32m1.7321[0m       [35m0.3998[0m      [31m0.3998[0m        [94m1.8057[0m     +  0.0000  11.1139
      2      [36m0.7500[0m        [32m1.3718[0m       0.3793      0.3793        [94m1.7642[0m     +  0.0000  10.9856
      3      [36m0.8333[0m        [32m1.1098[0m       0.3710      0.3710        1.7689        0.0000  10.7292
      4      0.8333        [32m0.9922[0m       0.3641      0.3641        1.7834        0.0000  10.6115
      5      [36m0.9583[0m        [32m0.9411[0m       0.3757      0.3757        1.7742        0.0000  10.8609
      6      0.9583        [32m0.8503[0m       0.3750      0.3750        1.7731        0.0000  10.8473
      7      0.9583        0.8704       0.3767      0.3767        1.7766        0.0000  10.8759
      8      0.9583        [32m0.7972[0m       0.3786      0.3786        1.7767        0.0000  10.6282
      9      0.9583        [32m0.7768[0m       0.3795      0.3795        1.7746        0.0000  10.9335
     10      0.9583        0.8831       0.3830      0.3830        1.7741        0.0000  11.0120
     11      [36m1.0000[0m        0.7807       0.3832      0.3832        1.7743        0.0000  10.9258
     12      0.9583        [32m0.7653[0m       0.3833      0.3833        1.7743        0.0000  10.9062
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.4340277777777778
F1 Macro Score after query 1: 0.16146334835780335
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7857[0m        [32m1.2633[0m       [35m0.4479[0m      [31m0.4479[0m        [94m1.6380[0m     +  0.0000  10.8782
      2      [36m0.8571[0m        [32m0.8778[0m       0.4479      0.4479        [94m1.5888[0m     +  0.0000  10.8170
      3      0.8571        [32m0.7395[0m       0.4479      0.4479        [94m1.5627[0m     +  0.0000  10.6621
      4      0.8571        [32m0.7005[0m       [35m0.4481[0m      [31m0.4481[0m        [94m1.5378[0m     +  0.0000  10.9064
      5      [36m0.9107[0m        [32m0.6682[0m       [35m0.4550[0m      [31m0.4550[0m        [94m1.5212[0m     +  0.0000  10.7930
      6      [36m0.9464[0m        [32m0.5843[0m       0.4543      0.4543        [94m1.5192[0m     +  0.0000  11.0027
      7      0.8929        0.6062       [35m0.4554[0m      [31m0.4554[0m        [94m1.5168[0m     +  0.0000  11.1266
      8      [36m0.9643[0m        [32m0.5636[0m       [35m0.4557[0m      [31m0.4557[0m        [94m1.5153[0m     +  0.0000  11.0949
      9      0.9464        0.5812       0.4556      0.4556        [94m1.5106[0m     +  0.0000  10.8443
     10      [36m0.9821[0m        [32m0.5556[0m       0.4554      0.4554        [94m1.5091[0m     +  0.0000  11.1741
     11      0.9821        0.5934       0.4554      0.4554        [94m1.5086[0m     +  0.0000  11.0002
     12      [36m1.0000[0m        [32m0.5479[0m       0.4552      0.4552        [94m1.5086[0m     +  0.0000  10.7979
     13      0.9286        0.5835       0.4552      0.4552        [94m1.5079[0m     +  0.0000  11.0462
     14      0.9821        0.5872       0.4552      0.4552        [94m1.5078[0m     +  0.0000  10.9852
     15      0.9821        0.5547       0.4554      0.4554        [94m1.5071[0m     +  0.0000  11.0402
     16      0.9821        [32m0.5253[0m       0.4556      0.4556        [94m1.5071[0m     +  0.0000  10.9571
     17      0.9821        0.5667       [35m0.4564[0m      [31m0.4564[0m        [94m1.5069[0m     +  0.0000  10.9642
     18      0.9643        0.5778       [35m0.4566[0m      [31m0.4566[0m        [94m1.5068[0m     +  0.0000  10.8606
     19      0.9821        0.5340       0.4566      0.4566        [94m1.5067[0m     +  0.0000  10.9895
     20      0.9286        0.6397       0.4566      0.4566        [94m1.5065[0m     +  0.0000  10.9832
     21      0.9643        0.5480       0.4566      0.4566        1.5065        0.0000  10.8273
     22      0.9643        0.5350       0.4566      0.4566        1.5066        0.0000  10.8725
     23      0.9643        0.5643       0.4566      0.4566        [94m1.5065[0m     +  0.0000  11.0326
     24      0.9643        0.5278       0.4566      0.4566        [94m1.5065[0m     +  0.0000  11.1589
     25      0.9821        0.5966       0.4566      0.4566        [94m1.5064[0m     +  0.0000  11.2989
     26      0.9643        0.5438       0.4566      0.4566        [94m1.5064[0m     +  0.0000  10.9372
     27      0.9643        0.5778       0.4566      0.4566        [94m1.5064[0m     +  0.0000  10.7634
     28      0.9643        0.5604       0.4566      0.4566        [94m1.5064[0m     +  0.0000  10.9852
     29      0.9821        0.5783       0.4566      0.4566        [94m1.5064[0m     +  0.0000  11.0469
     30      0.9821        0.5463       0.4566      0.4566        [94m1.5064[0m     +  0.0000  10.9552
     31      0.9821        0.5302       0.4566      0.4566        [94m1.5064[0m     +  0.0000  10.8420
     32      0.9286        0.6088       0.4566      0.4566        [94m1.5064[0m     +  0.0000  10.9824
     33      0.9643        0.5862       0.4566      0.4566        [94m1.5064[0m     +  0.0000  10.8461
     34      0.9286        0.5716       0.4566      0.4566        [94m1.5064[0m     +  0.0000  11.0657
     35      0.9286        0.5879       0.4566      0.4566        [94m1.5064[0m     +  0.0000  11.2049
     36      0.9643        0.5488       0.4566      0.4566        [94m1.5064[0m     +  0.0000  11.0158
     37      0.9643        0.5703       0.4566      0.4566        [94m1.5064[0m     +  0.0000  11.1531
     38      0.9643        0.5511       0.4566      0.4566        [94m1.5064[0m     +  0.0000  11.2043
     39      0.9643        0.5391       0.4566      0.4566        [94m1.5064[0m     +  0.0000  11.0553
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.4942708333333333
F1 Macro Score after query 2: 0.1090454565449989
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7143[0m        [32m1.0071[0m       [35m0.5191[0m      [31m0.5191[0m        [94m1.4826[0m     +  0.0000  11.3448
      2      [36m0.8125[0m        [32m0.8712[0m       [35m0.5469[0m      [31m0.5469[0m        [94m1.3926[0m     +  0.0000  11.5424
      3      0.7589        [32m0.8058[0m       [35m0.5623[0m      [31m0.5623[0m        [94m1.3626[0m     +  0.0000  11.5609
      4      [36m0.8571[0m        [32m0.7575[0m       0.5469      0.5469        [94m1.3351[0m     +  0.0000  11.2488
      5      0.8214        [32m0.7108[0m       0.5611      0.5611        [94m1.3211[0m     +  0.0000  11.6144
      6      0.8393        [32m0.6793[0m       [35m0.5708[0m      [31m0.5708[0m        [94m1.3159[0m     +  0.0000  11.2376
      7      0.8304        0.6855       [35m0.5783[0m      [31m0.5783[0m        [94m1.3120[0m     +  0.0000  11.0142
      8      0.8304        0.7306       [35m0.5861[0m      [31m0.5861[0m        1.3129        0.0000  10.6914
      9      0.8571        0.6999       [35m0.5927[0m      [31m0.5927[0m        [94m1.3042[0m     +  0.0000  11.4673
     10      [36m0.8750[0m        [32m0.6463[0m       0.5889      0.5889        1.3091        0.0000  11.1236
     11      0.8482        [32m0.6396[0m       0.5899      0.5899        1.3076        0.0000  11.3593
     12      0.8393        0.6769       0.5913      0.5913        1.3068        0.0000  11.2527
     13      0.8393        0.6597       [35m0.5934[0m      [31m0.5934[0m        1.3050        0.0000  11.3439
     14      0.8304        0.6574       [35m0.5938[0m      [31m0.5938[0m        [94m1.3042[0m     +  0.0000  11.2656
     15      0.8571        [32m0.6362[0m       [35m0.5941[0m      [31m0.5941[0m        1.3044        0.0000  11.3316
     16      0.8482        0.6623       0.5939      0.5939        1.3043        0.0000  11.1514
     17      0.8750        0.6409       0.5939      0.5939        [94m1.3041[0m     +  0.0000  11.1127
     18      0.8482        0.6632       0.5938      0.5938        1.3042        0.0000  11.5971
     19      0.8571        [32m0.6337[0m       0.5939      0.5939        1.3041        0.0000  11.4325
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.6076388888888888
F1 Macro Score after query 3: 0.1921067779677465
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7115[0m        [32m1.0106[0m       [35m0.3280[0m      [31m0.3280[0m        [94m1.5879[0m     +  0.0000  11.8415
      2      [36m0.8077[0m        [32m0.8220[0m       [35m0.5391[0m      [31m0.5391[0m        [94m1.4020[0m     +  0.0000  11.7689
      3      0.8077        [32m0.7625[0m       [35m0.5809[0m      [31m0.5809[0m        [94m1.3704[0m     +  0.0000  11.7540
      4      [36m0.8606[0m        [32m0.7005[0m       [35m0.6024[0m      [31m0.6024[0m        [94m1.3354[0m     +  0.0000  11.7043
      5      0.8462        [32m0.6758[0m       [35m0.6464[0m      [31m0.6464[0m        [94m1.2397[0m     +  0.0000  11.6721
      6      [36m0.8942[0m        [32m0.6243[0m       [35m0.6655[0m      [31m0.6655[0m        [94m1.1931[0m     +  0.0000  11.4148
      7      0.8894        0.6336       0.6653      0.6653        1.1949        0.0000  12.0262
      8      [36m0.8990[0m        [32m0.6111[0m       0.6653      0.6653        1.1947        0.0000  11.9607
      9      0.8846        [32m0.5891[0m       [35m0.6656[0m      [31m0.6656[0m        [94m1.1917[0m     +  0.0000  11.7046
     10      0.8990        [32m0.5660[0m       0.6637      0.6637        1.1957        0.0000  11.7864
     11      [36m0.9183[0m        0.5880       0.6651      0.6651        1.1933        0.0000  11.6398
     12      [36m0.9231[0m        0.5763       0.6655      0.6655        1.1926        0.0000  11.8910
     13      0.9231        0.5753       0.6648      0.6648        1.1930        0.0000  11.6563
     14      0.9087        0.5672       0.6644      0.6644        1.1921        0.0000  11.5627
     15      0.9135        [32m0.5578[0m       0.6648      0.6648        [94m1.1917[0m     +  0.0000  11.3938
     16      0.8990        [32m0.5569[0m       0.6644      0.6644        [94m1.1914[0m     +  0.0000  11.7029
     17      [36m0.9423[0m        [32m0.5544[0m       0.6648      0.6648        [94m1.1910[0m     +  0.0000  11.9052
     18      0.9183        0.5777       0.6648      0.6648        1.1911        0.0000  11.8913
     19      0.9038        0.5647       0.6651      0.6651        1.1913        0.0000  11.8840
     20      0.9183        [32m0.5447[0m       0.6648      0.6648        1.1910        0.0000  11.6898
     21      0.9135        0.5547       0.6648      0.6648        [94m1.1909[0m     +  0.0000  11.7444
     22      0.8990        0.5688       0.6646      0.6646        [94m1.1908[0m     +  0.0000  11.7075
     23      0.9183        0.5498       0.6646      0.6646        [94m1.1907[0m     +  0.0000  11.8129
     24      0.9183        0.5613       0.6646      0.6646        [94m1.1907[0m     +  0.0000  11.7669
     25      0.9279        0.5506       0.6644      0.6644        [94m1.1906[0m     +  0.0000  11.7853
     26      0.9183        0.5762       0.6644      0.6644        [94m1.1905[0m     +  0.0000  11.9267
     27      0.9279        0.5579       0.6644      0.6644        1.1906        0.0000  11.8116
     28      0.9279        0.5500       0.6644      0.6644        1.1906        0.0000  11.7522
     29      0.9231        0.5581       0.6644      0.6644        1.1906        0.0000  11.7927
     30      0.9135        0.5660       0.6644      0.6644        1.1906        0.0000  11.7808
     31      0.9279        0.5823       0.6644      0.6644        1.1906        0.0000  11.8160
     32      0.9327        0.5463       0.6644      0.6644        1.1906        0.0000  11.7962
     33      0.9279        0.5624       0.6644      0.6644        1.1906        0.0000  11.6843
     34      0.8990        0.5681       0.6644      0.6644        1.1906        0.0000  11.9232
     35      0.9135        0.5768       0.6644      0.6644        1.1906        0.0000  11.6530
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.6725694444444444
F1 Macro Score after query 4: 0.22347518413179268
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8151[0m        [32m0.8819[0m       [35m0.7158[0m      [31m0.7158[0m        [94m1.1227[0m     +  0.0000  12.5784
      2      [36m0.8906[0m        [32m0.6908[0m       0.7054      0.7054        [94m1.0448[0m     +  0.0000  12.6099
      3      [36m0.9271[0m        [32m0.5800[0m       0.6882      0.6882        [94m1.0426[0m     +  0.0000  12.5489
      4      [36m0.9375[0m        [32m0.5227[0m       0.6903      0.6903        [94m1.0274[0m     +  0.0000  12.7255
      5      [36m0.9479[0m        [32m0.4933[0m       0.6934      0.6934        1.0278        0.0000  12.9995
      6      0.9453        [32m0.4779[0m       0.6936      0.6936        [94m1.0168[0m     +  0.0000  12.8879
      7      [36m0.9635[0m        [32m0.4531[0m       0.6941      0.6941        [94m1.0145[0m     +  0.0000  12.3831
      8      0.9583        [32m0.4478[0m       0.6937      0.6937        [94m1.0135[0m     +  0.0000  12.5455
      9      0.9635        [32m0.4227[0m       0.6941      0.6941        1.0157        0.0000  12.7944
     10      0.9557        0.4254       0.6936      0.6936        1.0141        0.0000  12.5744
     11      [36m0.9714[0m        [32m0.4137[0m       0.6937      0.6937        1.0155        0.0000  12.8102
     12      0.9557        0.4200       0.6936      0.6936        1.0157        0.0000  12.7936
     13      0.9661        0.4199       0.6934      0.6934        1.0167        0.0000  12.5526
     14      0.9688        [32m0.4100[0m       0.6941      0.6941        1.0145        0.0000  13.0402
     15      0.9661        [32m0.4042[0m       0.6932      0.6932        1.0152        0.0000  12.7504
     16      0.9688        0.4181       0.6934      0.6934        1.0154        0.0000  12.6836
     17      0.9688        0.4130       0.6937      0.6937        1.0156        0.0000  12.8383
     18      [36m0.9740[0m        0.4150       0.6937      0.6937        1.0149        0.0000  12.7058
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.7404513888888888
F1 Macro Score after query 5: 0.33438511470780763
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8139[0m        [32m0.8073[0m       [35m0.7188[0m      [31m0.7188[0m        [94m0.9268[0m     +  0.0000  14.3393
      2      [36m0.8991[0m        [32m0.6101[0m       [35m0.7250[0m      [31m0.7250[0m        [94m0.8929[0m     +  0.0000  14.1413
      3      [36m0.9318[0m        [32m0.5092[0m       0.7248      0.7248        0.8949        0.0000  14.2327
      4      [36m0.9403[0m        [32m0.4717[0m       [35m0.7266[0m      [31m0.7266[0m        [94m0.8723[0m     +  0.0000  14.2762
      5      [36m0.9474[0m        [32m0.4331[0m       0.7212      0.7212        [94m0.8695[0m     +  0.0000  14.4250
      6      [36m0.9631[0m        [32m0.3892[0m       0.7168      0.7168        [94m0.8620[0m     +  0.0000  14.2476
      7      0.9602        [32m0.3863[0m       0.7193      0.7193        [94m0.8555[0m     +  0.0000  14.1903
      8      [36m0.9645[0m        [32m0.3742[0m       0.7134      0.7134        0.8618        0.0000  14.2855
      9      [36m0.9659[0m        [32m0.3653[0m       0.7135      0.7135        0.8625        0.0000  14.2152
     10      [36m0.9688[0m        [32m0.3522[0m       0.7151      0.7151        0.8613        0.0000  14.2963
     11      [36m0.9730[0m        [32m0.3483[0m       0.7186      0.7186        0.8612        0.0000  14.4382
     12      0.9716        [32m0.3454[0m       0.7224      0.7224        0.8566        0.0000  14.0863
     13      0.9702        0.3494       0.7186      0.7186        0.8621        0.0000  13.9099
     14      0.9716        0.3503       0.7188      0.7188        0.8619        0.0000  14.3774
     15      0.9716        [32m0.3445[0m       0.7198      0.7198        0.8621        0.0000  14.2776
     16      0.9716        0.3498       0.7182      0.7182        0.8646        0.0000  14.3951
     17      0.9730        [32m0.3393[0m       0.7182      0.7182        0.8645        0.0000  14.3777
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8060763888888889
F1 Macro Score after query 6: 0.44704982106928814
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8663[0m        [32m0.6130[0m       [35m0.7387[0m      [31m0.7387[0m        [94m0.8057[0m     +  0.0000  17.0934
      2      [36m0.9161[0m        [32m0.4755[0m       [35m0.7418[0m      [31m0.7418[0m        [94m0.7908[0m     +  0.0000  17.1840
      3      [36m0.9351[0m        [32m0.4161[0m       0.7398      0.7398        [94m0.7746[0m     +  0.0000  17.1853
      4      [36m0.9470[0m        [32m0.3899[0m       [35m0.7497[0m      [31m0.7497[0m        [94m0.7613[0m     +  0.0000  17.0943
      5      [36m0.9517[0m        [32m0.3482[0m       0.7349      0.7349        0.8073        0.0000  17.2847
      6      [36m0.9612[0m        [32m0.3212[0m       0.7491      0.7491        [94m0.7380[0m     +  0.0000  17.1053
      7      [36m0.9668[0m        [32m0.3042[0m       0.7477      0.7477        0.7384        0.0000  17.1642
      8      [36m0.9699[0m        [32m0.2910[0m       [35m0.7507[0m      [31m0.7507[0m        0.7384        0.0000  17.1447
      9      [36m0.9731[0m        [32m0.2859[0m       0.7479      0.7479        [94m0.7363[0m     +  0.0000  17.2911
     10      0.9731        [32m0.2849[0m       0.7481      0.7481        0.7417        0.0000  17.1086
     11      [36m0.9786[0m        [32m0.2679[0m       0.7477      0.7477        0.7425        0.0000  17.0708
     12      [36m0.9794[0m        0.2758       0.7458      0.7458        0.7444        0.0000  17.2250
     13      0.9794        0.2706       0.7477      0.7477        0.7399        0.0000  17.0179
     14      [36m0.9802[0m        [32m0.2637[0m       0.7474      0.7474        0.7422        0.0000  17.3594
     15      [36m0.9810[0m        [32m0.2542[0m       0.7476      0.7476        0.7416        0.0000  17.2029
     16      0.9810        0.2580       0.7483      0.7483        0.7430        0.0000  17.1409
     17      0.9786        0.2598       0.7477      0.7477        0.7437        0.0000  17.3262
     18      [36m0.9834[0m        [32m0.2527[0m       0.7476      0.7476        0.7441        0.0000  16.9377
     19      0.9794        0.2632       0.7477      0.7477        0.7450        0.0000  17.0467
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.8133680555555556
F1 Macro Score after query 7: 0.4806177515229287
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8768[0m        [32m0.5101[0m       [35m0.7681[0m      [31m0.7681[0m        [94m0.7041[0m     +  0.0000  22.1771
      2      [36m0.9258[0m        [32m0.3989[0m       0.7571      0.7571        0.7330        0.0000  21.7812
      3      [36m0.9430[0m        [32m0.3431[0m       [35m0.7691[0m      [31m0.7691[0m        0.7292        0.0000  22.3042
      4      [36m0.9501[0m        [32m0.3065[0m       0.7681      0.7681        0.7272        0.0000  22.0845
      5      [36m0.9585[0m        [32m0.2769[0m       [35m0.7700[0m      [31m0.7700[0m        0.7182        0.0000  22.2503
      6      [36m0.9638[0m        [32m0.2472[0m       0.7366      0.7366        0.7517        0.0000  22.0089
      7      [36m0.9708[0m        [32m0.2345[0m       0.7375      0.7375        0.7574        0.0000  22.2027
      8      [36m0.9757[0m        [32m0.2202[0m       0.7418      0.7418        0.7436        0.0000  22.2338
      9      0.9735        [32m0.2153[0m       0.7439      0.7439        0.7341        0.0000  22.3550
     10      [36m0.9784[0m        [32m0.2080[0m       0.7443      0.7443        0.7478        0.0000  22.1882
     11      0.9770        [32m0.2040[0m       0.7451      0.7451        0.7311        0.0000  21.8932
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8059027777777777
F1 Macro Score after query 8: 0.5248450406602126
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8740[0m        [32m0.4994[0m       [35m0.7873[0m      [31m0.7873[0m        [94m0.6028[0m     +  0.0000  30.7324
      2      [36m0.9181[0m        [32m0.3890[0m       [35m0.8023[0m      [31m0.8023[0m        [94m0.5588[0m     +  0.0000  30.9693
      3      [36m0.9347[0m        [32m0.3349[0m       [35m0.8033[0m      [31m0.8033[0m        [94m0.5566[0m     +  0.0000  31.1473
      4      [36m0.9411[0m        [32m0.2957[0m       0.7976      0.7976        0.5784        0.0000  31.1724
      5      [36m0.9522[0m        [32m0.2640[0m       0.7970      0.7970        0.5973        0.0000  31.3322
      6      [36m0.9658[0m        [32m0.2245[0m       0.7977      0.7977        0.6068        0.0000  31.1845
      7      [36m0.9718[0m        [32m0.2055[0m       0.8017      0.8017        0.6134        0.0000  31.2306
      8      [36m0.9743[0m        [32m0.1925[0m       0.8026      0.8026        0.6114        0.0000  31.3438
      9      [36m0.9760[0m        [32m0.1827[0m       0.8021      0.8021        0.6174        0.0000  31.4052
     10      [36m0.9775[0m        [32m0.1741[0m       0.8021      0.8021        0.6156        0.0000  31.1718
     11      [36m0.9812[0m        [32m0.1666[0m       0.7979      0.7979        0.6412        0.0000  31.2942
     12      [36m0.9856[0m        [32m0.1587[0m       0.7962      0.7962        0.6416        0.0000  31.2191
     13      0.9854        0.1616       0.7964      0.7964        0.6418        0.0000  31.1138
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8366319444444444
F1 Macro Score after query 9: 0.5259103768857081
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8935[0m        [32m0.4114[0m       [35m0.7969[0m      [31m0.7969[0m        [94m0.5856[0m     +  0.0000  46.5319
      2      [36m0.9187[0m        [32m0.3322[0m       [35m0.7981[0m      [31m0.7981[0m        0.6009        0.0000  47.0359
      3      [36m0.9328[0m        [32m0.2859[0m       [35m0.8146[0m      [31m0.8146[0m        [94m0.5801[0m     +  0.0000  47.2794
      4      [36m0.9410[0m        [32m0.2511[0m       0.8007      0.8007        0.6612        0.0000  47.1560
      5      [36m0.9469[0m        [32m0.2265[0m       0.7925      0.7925        0.7248        0.0000  47.2139
      6      [36m0.9607[0m        [32m0.1824[0m       0.8109      0.8109        0.6097        0.0000  47.1719
      7      [36m0.9697[0m        [32m0.1606[0m       0.8095      0.8095        0.6291        0.0000  47.0231
      8      [36m0.9726[0m        [32m0.1506[0m       0.8130      0.8130        0.6316        0.0000  46.9930
      9      [36m0.9779[0m        [32m0.1403[0m       0.8104      0.8104        0.6405        0.0000  47.0557
     10      [36m0.9804[0m        [32m0.1304[0m       0.8116      0.8116        0.6502        0.0000  46.9845
     11      [36m0.9836[0m        [32m0.1189[0m       0.8113      0.8113        0.6391        0.0000  47.3285
     12      [36m0.9846[0m        [32m0.1156[0m       0.8134      0.8134        0.6373        0.0000  47.2342
     13      [36m0.9862[0m        [32m0.1121[0m       0.8104      0.8104        0.6489        0.0000  47.1561
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8494791666666667
F1 Macro Score after query 10: 0.5470686468630932
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9486[0m        [32m0.2316[0m       [35m0.8030[0m      [31m0.8030[0m        [94m0.6061[0m     +  0.0000  75.0113
      2      [36m0.9556[0m        [32m0.1944[0m       0.7957      0.7957        0.6502        0.0000  75.5846
      3      [36m0.9626[0m        [32m0.1658[0m       0.7861      0.7861        0.7645        0.0000  75.7344
      4      [36m0.9665[0m        [32m0.1464[0m       0.7866      0.7866        0.7682        0.0000  75.7345
      5      [36m0.9687[0m        [32m0.1317[0m       0.7885      0.7885        0.7597        0.0000  75.5877
      6      [36m0.9779[0m        [32m0.1038[0m       0.7984      0.7984        0.6769        0.0000  75.7259
      7      [36m0.9831[0m        [32m0.0903[0m       [35m0.8043[0m      [31m0.8043[0m        0.6764        0.0000  75.6161
      8      [36m0.9852[0m        [32m0.0822[0m       [35m0.8078[0m      [31m0.8078[0m        0.6738        0.0000  75.5580
      9      [36m0.9878[0m        [32m0.0742[0m       [35m0.8113[0m      [31m0.8113[0m        0.6683        0.0000  75.5470
     10      [36m0.9892[0m        [32m0.0676[0m       [35m0.8139[0m      [31m0.8139[0m        0.6674        0.0000  75.6904
     11      [36m0.9917[0m        [32m0.0613[0m       0.8073      0.8073        0.6941        0.0000  74.7906
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8296875
F1 Macro Score after query 11: 0.55225549744163
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9681[0m        [32m0.1562[0m       [35m0.7979[0m      [31m0.7979[0m        [94m0.6681[0m     +  0.0000  127.0076
      2      [36m0.9711[0m        [32m0.1303[0m       [35m0.8101[0m      [31m0.8101[0m        [94m0.6357[0m     +  0.0000  127.0466
      3      [36m0.9720[0m        [32m0.1156[0m       0.7769      0.7769        0.7482        0.0000  126.7658
      4      [36m0.9759[0m        [32m0.0993[0m       0.7816      0.7816        0.6651        0.0000  126.4376
      5      [36m0.9777[0m        [32m0.0894[0m       0.7727      0.7727        0.8037        0.0000  126.4065
      6      [36m0.9812[0m        [32m0.0720[0m       [35m0.8215[0m      [31m0.8215[0m        0.6681        0.0000  126.7656
      7      [36m0.9862[0m        [32m0.0593[0m       [35m0.8252[0m      [31m0.8252[0m        0.6656        0.0000  126.2189
      8      [36m0.9889[0m        [32m0.0529[0m       0.8250      0.8250        0.6700        0.0000  126.6915
      9      [36m0.9907[0m        [32m0.0475[0m       0.8198      0.8198        0.6734        0.0000  126.0087
     10      [36m0.9918[0m        [32m0.0421[0m       0.8165      0.8165        0.6907        0.0000  126.2035
     11      [36m0.9935[0m        [32m0.0368[0m       0.8151      0.8151        0.7159        0.0000  126.4463
     12      [36m0.9942[0m        [32m0.0358[0m       0.8115      0.8115        0.7271        0.0000  126.8614
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.84375
F1 Macro Score after query 12: 0.5182677939926313
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9759[0m        [32m0.1002[0m       [35m0.7658[0m      [31m0.7658[0m        [94m1.0371[0m     +  0.0000  145.9375
      2      [36m0.9799[0m        [32m0.0853[0m       0.7634      0.7634        1.0805        0.0000  147.4687
      3      [36m0.9802[0m        [32m0.0781[0m       [35m0.7965[0m      [31m0.7965[0m        [94m0.8749[0m     +  0.0000  147.1092
      4      [36m0.9818[0m        [32m0.0711[0m       [35m0.8063[0m      [31m0.8062[0m        [94m0.8441[0m     +  0.0000  147.2499
      5      [36m0.9837[0m        [32m0.0632[0m       0.7927      0.7927        0.9154        0.0000  148.0155
      6      [36m0.9874[0m        [32m0.0508[0m       [35m0.8158[0m      [31m0.8158[0m        [94m0.7352[0m     +  0.0000  147.2984
      7      [36m0.9908[0m        [32m0.0400[0m       0.8123      0.8123        0.7424        0.0000  147.3480
      8      [36m0.9926[0m        [32m0.0343[0m       0.8075      0.8075        0.7786        0.0000  147.4745
      9      [36m0.9939[0m        [32m0.0298[0m       0.8104      0.8104        0.7811        0.0000  147.3444
     10      [36m0.9948[0m        [32m0.0263[0m       0.8064      0.8064        0.8186        0.0000  147.0157
     11      [36m0.9961[0m        [32m0.0234[0m       0.8153      0.8153        0.8290        0.0000  147.3863
     12      [36m0.9970[0m        [32m0.0204[0m       0.8144      0.8144        0.8248        0.0000  147.6091
     13      [36m0.9974[0m        [32m0.0193[0m       0.8153      0.8153        0.8242        0.0000  148.1111
     14      [36m0.9978[0m        [32m0.0189[0m       0.8151      0.8151        0.8334        0.0000  148.3520
     15      0.9978        [32m0.0181[0m       0.8139      0.8139        0.8474        0.0000  147.7540
     16      0.9978        [32m0.0170[0m       [35m0.8179[0m      [31m0.8179[0m        0.8411        0.0000  148.2227
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.831423611111111
F1 Macro Score after query 13: 0.5132789389068722
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed45\AL_entropy_sampling_results_for_multiclass_classification_s45.pickle
