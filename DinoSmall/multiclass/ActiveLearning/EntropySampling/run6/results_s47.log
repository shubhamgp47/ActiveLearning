(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.1250[0m        [32m2.3066[0m       [35m0.1903[0m      [31m0.1903[0m        [94m2.0700[0m     +  0.0000  11.0651
      2      0.1250        [32m2.0493[0m       [35m0.2160[0m      [31m0.2160[0m        2.0935        0.0000  10.2250
      3      0.1250        [32m1.9417[0m       [35m0.2642[0m      [31m0.2642[0m        [94m2.0373[0m     +  0.0000  10.4078
      4      [36m0.3750[0m        [32m1.8097[0m       0.2458      0.2458        2.0832        0.0000  10.5486
      5      0.3750        1.8271       [35m0.3099[0m      [31m0.3099[0m        [94m2.0203[0m     +  0.0000  10.5124
      6      [36m0.6250[0m        [32m1.5837[0m       0.2814      0.2814        2.0302        0.0000  10.4427
      7      [36m0.7500[0m        1.6243       0.2812      0.2812        2.0275        0.0000  10.6241
      8      0.6250        1.6901       0.2780      0.2780        2.0236        0.0000  10.6983
      9      0.6250        [32m1.5773[0m       0.2776      0.2776        2.0253        0.0000  11.1220
     10      0.5000        1.7114       0.2802      0.2802        2.0278        0.0000  10.9910
     11      0.7500        1.6301       0.2809      0.2809        2.0269        0.0000  10.8152
     12      0.6250        1.6136       0.2851      0.2851        2.0255        0.0000  10.8485
     13      0.7500        1.6053       0.2861      0.2861        2.0244        0.0000  11.0300
     14      0.6250        1.6241       0.2875      0.2875        2.0237        0.0000  11.0001
     15      0.6250        1.6527       0.2894      0.2894        2.0225        0.0000  10.8674
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.3057
Pre F1 macro score = 0.1273

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5833[0m        [32m1.6798[0m       [35m0.4486[0m      [31m0.4486[0m        [94m1.8299[0m     +  0.0000  11.0929
      2      [36m0.7500[0m        [32m1.2552[0m       [35m0.4583[0m      [31m0.4583[0m        [94m1.7808[0m     +  0.0000  11.0897
      3      [36m0.7917[0m        [32m1.1746[0m       0.4549      0.4549        1.8055        0.0000  10.9826
      4      [36m0.8333[0m        [32m1.0346[0m       0.4576      0.4576        [94m1.7489[0m     +  0.0000  10.9815
      5      0.8333        [32m0.9860[0m       0.4569      0.4569        1.7609        0.0000  10.9224
      6      [36m0.9167[0m        [32m0.8933[0m       0.4580      0.4580        1.7509        0.0000  11.1153
      7      0.9167        [32m0.8320[0m       [35m0.4594[0m      [31m0.4594[0m        [94m1.7483[0m     +  0.0000  11.0042
      8      0.8750        [32m0.7977[0m       [35m0.4595[0m      [31m0.4595[0m        [94m1.7416[0m     +  0.0000  11.0858
      9      0.8750        0.8766       [35m0.4604[0m      [31m0.4604[0m        [94m1.7409[0m     +  0.0000  11.3063
     10      0.8750        0.8946       [35m0.4606[0m      [31m0.4606[0m        1.7411        0.0000  10.9581
     11      [36m0.9583[0m        0.8112       0.4604      0.4604        [94m1.7401[0m     +  0.0000  11.0341
     12      0.9583        [32m0.7656[0m       0.4601      0.4601        [94m1.7396[0m     +  0.0000  11.0230
     13      0.9167        0.8113       0.4602      0.4602        [94m1.7395[0m     +  0.0000  11.1607
     14      0.9583        0.8046       0.4602      0.4602        [94m1.7392[0m     +  0.0000  10.9904
     15      0.9167        0.8013       0.4606      0.4606        [94m1.7387[0m     +  0.0000  11.0409
     16      0.8750        0.8511       0.4606      0.4606        1.7387        0.0000  11.0532
     17      0.8750        0.8337       0.4606      0.4606        1.7388        0.0000  11.0195
     18      0.9167        0.8280       0.4606      0.4606        1.7388        0.0000  10.9641
     19      0.8750        0.8284       0.4606      0.4606        1.7389        0.0000  10.8597
     20      0.9583        0.8628       0.4606      0.4606        1.7388        0.0000  11.0344
     21      0.9167        [32m0.7651[0m       0.4606      0.4606        1.7388        0.0000  10.8520
     22      0.8333        0.8875       0.4606      0.4606        1.7388        0.0000  10.9475
     23      0.9167        0.8075       0.4606      0.4606        1.7388        0.0000  10.7845
     24      0.9167        0.8043       0.4606      0.4606        1.7388        0.0000  11.0832
     25      0.9167        0.8618       0.4606      0.4606        1.7388        0.0000  10.9948
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.4909722222222222
F1 Macro Score after query 1: 0.1331670424060888
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6071[0m        [32m1.4112[0m       [35m0.4259[0m      [31m0.4259[0m        [94m1.6624[0m     +  0.0000  11.1733
      2      [36m0.7143[0m        [32m1.2381[0m       [35m0.4278[0m      [31m0.4278[0m        [94m1.6540[0m     +  0.0000  11.0362
      3      [36m0.7500[0m        [32m1.0261[0m       [35m0.4344[0m      [31m0.4344[0m        1.6626        0.0000  11.1049
      4      [36m0.8393[0m        [32m0.9195[0m       0.4344      0.4344        [94m1.6511[0m     +  0.0000  11.1239
      5      [36m0.8571[0m        [32m0.8936[0m       0.4307      0.4307        [94m1.6365[0m     +  0.0000  11.2251
      6      0.8571        [32m0.8123[0m       0.4321      0.4321        [94m1.6329[0m     +  0.0000  11.0952
      7      [36m0.8750[0m        [32m0.7692[0m       0.4335      0.4335        [94m1.6321[0m     +  0.0000  11.2559
      8      0.8750        [32m0.7684[0m       [35m0.4365[0m      [31m0.4365[0m        [94m1.6290[0m     +  0.0000  11.0421
      9      [36m0.8929[0m        [32m0.7678[0m       [35m0.4382[0m      [31m0.4382[0m        [94m1.6287[0m     +  0.0000  11.1794
     10      0.8929        0.7690       [35m0.4427[0m      [31m0.4427[0m        [94m1.6246[0m     +  0.0000  11.1867
     11      0.8929        [32m0.7421[0m       0.4418      0.4418        1.6251        0.0000  11.0733
     12      [36m0.9107[0m        [32m0.7009[0m       0.4418      0.4418        1.6251        0.0000  11.1614
     13      0.8929        0.7116       0.4422      0.4422        1.6249        0.0000  11.1828
     14      [36m0.9286[0m        0.7306       0.4427      0.4427        [94m1.6243[0m     +  0.0000  11.0000
     15      0.9107        0.7327       [35m0.4437[0m      [31m0.4437[0m        1.6244        0.0000  11.1723
     16      0.8929        [32m0.6914[0m       0.4437      0.4437        1.6245        0.0000  11.0469
     17      0.9107        0.7371       [35m0.4439[0m      [31m0.4439[0m        1.6245        0.0000  11.0627
     18      0.9107        0.7900       0.4439      0.4439        1.6243        0.0000  11.2381
     19      0.9286        0.7395       [35m0.4443[0m      [31m0.4443[0m        1.6244        0.0000  11.1666
     20      0.8929        0.7322       [35m0.4444[0m      [31m0.4444[0m        1.6245        0.0000  11.1090
     21      0.9107        0.7347       0.4444      0.4444        1.6244        0.0000  11.1520
     22      0.9286        0.7045       [35m0.4446[0m      [31m0.4446[0m        1.6244        0.0000  11.1562
     23      0.9107        0.7059       0.4446      0.4446        1.6244        0.0000  11.1521
     24      0.9107        0.7108       0.4446      0.4446        1.6243        0.0000  11.0978
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.5295138888888888
F1 Macro Score after query 2: 0.18339004738436535
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8571[0m        [32m0.8469[0m       [35m0.4479[0m      [31m0.4479[0m        [94m1.6820[0m     +  0.0000  11.3654
      2      [36m0.8750[0m        [32m0.6900[0m       [35m0.4495[0m      [31m0.4495[0m        [94m1.6063[0m     +  0.0000  11.2290
      3      [36m0.9375[0m        [32m0.5496[0m       [35m0.4531[0m      [31m0.4531[0m        [94m1.5910[0m     +  0.0000  11.3176
      4      [36m0.9554[0m        [32m0.5313[0m       [35m0.4641[0m      [31m0.4641[0m        [94m1.5715[0m     +  0.0000  11.4850
      5      0.9464        [32m0.4700[0m       0.4597      0.4597        [94m1.5635[0m     +  0.0000  11.3822
      6      0.9554        [32m0.4465[0m       0.4571      0.4571        [94m1.5623[0m     +  0.0000  11.3734
      7      [36m0.9643[0m        [32m0.4231[0m       0.4602      0.4602        [94m1.5593[0m     +  0.0000  11.3082
      8      [36m0.9911[0m        [32m0.4221[0m       0.4609      0.4609        1.5594        0.0000  11.4219
      9      0.9821        [32m0.4083[0m       [35m0.4675[0m      [31m0.4675[0m        [94m1.5563[0m     +  0.0000  11.4217
     10      0.9821        0.4216       0.4630      0.4630        1.5603        0.0000  11.4220
     11      0.9732        0.4238       0.4622      0.4622        1.5595        0.0000  11.3129
     12      0.9643        0.4084       0.4634      0.4634        1.5583        0.0000  11.4500
     13      0.9732        [32m0.4079[0m       0.4635      0.4635        1.5589        0.0000  11.4694
     14      0.9643        0.4134       0.4635      0.4635        1.5587        0.0000  11.3921
     15      0.9732        0.4132       0.4637      0.4637        1.5584        0.0000  11.2815
     16      0.9732        [32m0.3964[0m       0.4637      0.4637        1.5585        0.0000  11.3927
     17      0.9643        0.4145       0.4635      0.4635        1.5584        0.0000  11.5796
     18      0.9643        0.4036       0.4635      0.4635        1.5581        0.0000  11.4158
     19      0.9643        [32m0.3870[0m       0.4637      0.4637        1.5579        0.0000  11.4943
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.5182291666666666
F1 Macro Score after query 3: 0.1459440339735775
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8894[0m        [32m0.6424[0m       [35m0.4880[0m      [31m0.4880[0m        [94m1.5155[0m     +  0.0000  11.9641
      2      [36m0.9038[0m        [32m0.5317[0m       [35m0.4925[0m      [31m0.4925[0m        [94m1.4914[0m     +  0.0000  11.8557
      3      [36m0.9327[0m        [32m0.4449[0m       0.4830      0.4830        [94m1.4835[0m     +  0.0000  11.7920
      4      [36m0.9567[0m        [32m0.3979[0m       0.4917      0.4917        [94m1.4519[0m     +  0.0000  11.8543
      5      0.9471        0.4064       [35m0.4974[0m      [31m0.4974[0m        [94m1.4455[0m     +  0.0000  11.7304
      6      [36m0.9712[0m        [32m0.3621[0m       0.4887      0.4887        1.4520        0.0000  12.1214
      7      0.9712        0.3652       0.4825      0.4825        1.4523        0.0000  11.9194
      8      0.9712        [32m0.3510[0m       0.4804      0.4804        1.4529        0.0000  11.9188
      9      0.9712        [32m0.3288[0m       0.4806      0.4806        1.4502        0.0000  11.7611
     10      0.9712        0.3346       0.4814      0.4814        1.4457        0.0000  11.9806
     11      0.9712        [32m0.3206[0m       0.4800      0.4800        1.4477        0.0000  12.0890
     12      [36m0.9856[0m        0.3217       0.4799      0.4799        1.4487        0.0000  11.9028
     13      0.9808        0.3370       0.4804      0.4804        1.4469        0.0000  12.0121
     14      0.9712        [32m0.3090[0m       0.4799      0.4799        1.4462        0.0000  12.0557
     15      0.9760        0.3222       0.4800      0.4800        [94m1.4440[0m     +  0.0000  11.8042
     16      0.9808        0.3194       0.4799      0.4799        1.4443        0.0000  11.6872
     17      0.9663        0.3309       0.4802      0.4802        [94m1.4439[0m     +  0.0000  11.9503
     18      0.9712        0.3179       0.4806      0.4806        [94m1.4435[0m     +  0.0000  11.8880
     19      0.9712        0.3248       0.4802      0.4802        1.4437        0.0000  11.9012
     20      0.9712        0.3334       0.4802      0.4802        [94m1.4432[0m     +  0.0000  11.9036
     21      0.9760        0.3211       0.4799      0.4799        1.4435        0.0000  11.9799
     22      0.9808        0.3221       0.4800      0.4800        1.4437        0.0000  11.9040
     23      0.9712        0.3188       0.4800      0.4800        1.4438        0.0000  11.8711
     24      0.9712        0.3103       0.4799      0.4799        1.4439        0.0000  11.9978
     25      0.9856        0.3283       0.4800      0.4800        1.4438        0.0000  11.9168
     26      0.9808        0.3246       0.4800      0.4800        1.4438        0.0000  11.8854
     27      0.9663        0.3122       0.4799      0.4799        1.4438        0.0000  11.8848
     28      0.9808        [32m0.3024[0m       0.4800      0.4800        1.4438        0.0000  11.9497
     29      0.9856        0.3153       0.4799      0.4799        1.4438        0.0000  11.9304
     30      0.9856        0.3232       0.4799      0.4799        1.4438        0.0000  11.8856
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.5685763888888888
F1 Macro Score after query 4: 0.18327300016899178
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8958[0m        [32m0.6225[0m       [35m0.5182[0m      [31m0.5182[0m        [94m1.4148[0m     +  0.0000  12.7170
      2      [36m0.9688[0m        [32m0.4401[0m       [35m0.6293[0m      [31m0.6293[0m        [94m1.2467[0m     +  0.0000  12.7471
      3      [36m0.9792[0m        [32m0.3792[0m       0.6264      0.6264        [94m1.2159[0m     +  0.0000  12.6999
      4      [36m0.9818[0m        [32m0.3387[0m       [35m0.6530[0m      [31m0.6530[0m        [94m1.1837[0m     +  0.0000  12.7627
      5      0.9818        [32m0.3278[0m       0.6281      0.6281        [94m1.1731[0m     +  0.0000  12.4846
      6      0.9818        [32m0.3075[0m       0.6526      0.6526        [94m1.1703[0m     +  0.0000  12.7795
      7      [36m0.9870[0m        [32m0.2923[0m       0.6441      0.6441        1.1734        0.0000  12.7792
      8      0.9870        [32m0.2920[0m       0.6241      0.6241        1.1810        0.0000  12.8248
      9      0.9870        [32m0.2905[0m       0.6236      0.6236        1.1781        0.0000  12.7640
     10      0.9870        [32m0.2898[0m       0.6134      0.6134        1.1748        0.0000  12.7625
     11      [36m0.9896[0m        [32m0.2804[0m       0.6163      0.6163        1.1769        0.0000  12.7011
     12      0.9870        [32m0.2747[0m       0.6155      0.6155        1.1794        0.0000  12.9502
     13      [36m0.9922[0m        [32m0.2728[0m       0.6156      0.6156        1.1768        0.0000  12.7915
     14      0.9896        0.2732       0.6146      0.6146        1.1757        0.0000  12.7636
     15      0.9896        [32m0.2693[0m       0.6099      0.6099        1.1803        0.0000  12.6840
     16      0.9922        0.2705       0.6115      0.6115        1.1792        0.0000  12.7954
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.7069444444444445
F1 Macro Score after query 5: 0.2929973332180785
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8764[0m        [32m0.6200[0m       [35m0.7045[0m      [31m0.7045[0m        [94m1.0786[0m     +  0.0000  14.2653
      2      [36m0.9134[0m        [32m0.4797[0m       [35m0.7201[0m      [31m0.7201[0m        [94m0.9770[0m     +  0.0000  14.6710
      3      [36m0.9446[0m        [32m0.4268[0m       0.7161      0.7161        [94m0.9583[0m     +  0.0000  14.3429
      4      0.9418        [32m0.4091[0m       0.7193      0.7193        [94m0.9411[0m     +  0.0000  14.3269
      5      [36m0.9489[0m        [32m0.3669[0m       [35m0.7259[0m      [31m0.7259[0m        [94m0.9339[0m     +  0.0000  14.3757
      6      [36m0.9673[0m        [32m0.3352[0m       0.7016      0.7016        [94m0.9153[0m     +  0.0000  14.4688
      7      [36m0.9702[0m        [32m0.3128[0m       0.7095      0.7095        [94m0.9148[0m     +  0.0000  14.4269
      8      [36m0.9730[0m        [32m0.3026[0m       0.7113      0.7113        [94m0.9132[0m     +  0.0000  14.3921
      9      [36m0.9759[0m        0.3089       0.7128      0.7128        [94m0.9072[0m     +  0.0000  14.4847
     10      [36m0.9773[0m        [32m0.2919[0m       0.7127      0.7127        0.9113        0.0000  14.4528
     11      0.9759        0.2954       0.7066      0.7066        [94m0.9018[0m     +  0.0000  14.4696
     12      0.9773        0.2964       0.7101      0.7101        [94m0.8995[0m     +  0.0000  14.3910
     13      0.9759        0.2920       0.7101      0.7101        [94m0.8982[0m     +  0.0000  14.2344
     14      [36m0.9801[0m        [32m0.2909[0m       0.7102      0.7102        [94m0.8971[0m     +  0.0000  14.4383
     15      0.9801        [32m0.2890[0m       0.7116      0.7116        [94m0.8971[0m     +  0.0000  14.3249
     16      0.9801        [32m0.2846[0m       0.7113      0.7113        [94m0.8967[0m     +  0.0000  14.4052
     17      [36m0.9830[0m        0.2861       0.7104      0.7104        0.8971        0.0000  14.2644
     18      0.9801        [32m0.2796[0m       0.7102      0.7102        0.8970        0.0000  14.3446
     19      0.9815        0.2921       0.7106      0.7106        [94m0.8956[0m     +  0.0000  14.3434
     20      0.9830        0.2852       0.7108      0.7108        0.8958        0.0000  14.3274
     21      0.9830        [32m0.2764[0m       0.7113      0.7113        0.8957        0.0000  14.2797
     22      0.9815        [32m0.2745[0m       0.7106      0.7106        0.8958        0.0000  14.5319
     23      0.9801        0.2881       0.7106      0.7106        0.8957        0.0000  14.3055
     24      0.9815        0.2808       0.7106      0.7106        0.8957        0.0000  14.3749
     25      [36m0.9844[0m        0.2776       0.7108      0.7108        0.8957        0.0000  14.6399
     26      [36m0.9872[0m        0.2834       0.7108      0.7108        0.8957        0.0000  14.4222
     27      0.9801        0.2798       0.7108      0.7108        0.8957        0.0000  14.3111
     28      0.9801        0.2895       0.7108      0.7108        0.8957        0.0000  14.2924
     29      0.9872        0.2837       0.7108      0.7108        0.8957        0.0000  14.3263
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.7192708333333334
F1 Macro Score after query 6: 0.28005503121885766
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8307[0m        [32m0.6652[0m       [35m0.6467[0m      [31m0.6467[0m        [94m1.0415[0m     +  0.0000  17.0960
      2      [36m0.8916[0m        [32m0.5147[0m       [35m0.6681[0m      [31m0.6681[0m        [94m1.0116[0m     +  0.0000  17.1568
      3      [36m0.9114[0m        [32m0.4638[0m       [35m0.6845[0m      [31m0.6845[0m        [94m1.0030[0m     +  0.0000  17.1763
      4      [36m0.9248[0m        [32m0.4185[0m       [35m0.7318[0m      [31m0.7318[0m        [94m0.8924[0m     +  0.0000  17.1099
      5      [36m0.9375[0m        [32m0.3837[0m       0.6679      0.6679        0.9717        0.0000  17.2218
      6      [36m0.9541[0m        [32m0.3484[0m       [35m0.7373[0m      [31m0.7373[0m        [94m0.8653[0m     +  0.0000  17.1717
      7      [36m0.9604[0m        [32m0.3262[0m       0.7366      0.7366        [94m0.8505[0m     +  0.0000  17.0945
      8      0.9604        [32m0.3262[0m       0.7332      0.7332        0.8574        0.0000  17.2990
      9      [36m0.9636[0m        [32m0.3160[0m       [35m0.7403[0m      [31m0.7403[0m        [94m0.8409[0m     +  0.0000  17.1420
     10      [36m0.9668[0m        [32m0.3100[0m       [35m0.7413[0m      [31m0.7413[0m        0.8421        0.0000  17.7418
     11      [36m0.9755[0m        [32m0.2930[0m       [35m0.7483[0m      [31m0.7483[0m        [94m0.8265[0m     +  0.0000  17.2636
     12      0.9715        0.2968       [35m0.7490[0m      [31m0.7490[0m        [94m0.8230[0m     +  0.0000  17.1912
     13      0.9723        0.2974       0.7462      0.7462        0.8266        0.0000  17.2341
     14      0.9699        0.2939       0.7483      0.7483        [94m0.8218[0m     +  0.0000  17.1588
     15      0.9723        [32m0.2857[0m       0.7462      0.7462        0.8266        0.0000  17.0496
     16      0.9747        0.2859       [35m0.7491[0m      [31m0.7491[0m        0.8218        0.0000  17.2355
     17      0.9747        0.2964       [35m0.7493[0m      [31m0.7493[0m        [94m0.8208[0m     +  0.0000  17.2352
     18      0.9755        0.2858       [35m0.7497[0m      [31m0.7497[0m        0.8216        0.0000  17.1432
     19      0.9739        [32m0.2766[0m       0.7490      0.7490        0.8211        0.0000  17.3597
     20      0.9755        0.2862       0.7484      0.7484        0.8213        0.0000  17.2657
     21      0.9739        0.2842       0.7490      0.7490        0.8211        0.0000  17.4030
     22      0.9755        0.2798       0.7488      0.7488        0.8212        0.0000  17.2810
     23      0.9715        0.2859       0.7491      0.7491        0.8209        0.0000  17.2336
     24      0.9755        0.2788       0.7490      0.7490        0.8209        0.0000  17.2213
     25      0.9747        0.2804       0.7491      0.7491        [94m0.8208[0m     +  0.0000  17.3614
     26      0.9755        0.2880       0.7491      0.7491        [94m0.8207[0m     +  0.0000  17.2968
     27      0.9747        0.2776       0.7491      0.7491        [94m0.8207[0m     +  0.0000  17.0975
     28      0.9739        0.2847       0.7491      0.7491        [94m0.8207[0m     +  0.0000  17.1288
     29      0.9731        0.2913       0.7491      0.7491        0.8207        0.0000  17.1740
     30      [36m0.9771[0m        0.2836       0.7491      0.7491        0.8207        0.0000  17.1543
     31      0.9763        0.2858       0.7491      0.7491        0.8207        0.0000  17.2375
     32      0.9747        0.2874       0.7491      0.7491        0.8207        0.0000  17.0972
     33      [36m0.9786[0m        0.2848       0.7491      0.7491        0.8207        0.0000  17.4077
     34      [36m0.9794[0m        0.2777       0.7491      0.7491        0.8207        0.0000  17.1119
     35      0.9786        0.2786       0.7491      0.7491        [94m0.8207[0m     +  0.0000  16.9848
     36      0.9763        0.2809       0.7491      0.7491        0.8207        0.0000  17.0665
     37      0.9755        0.2802       0.7491      0.7491        [94m0.8207[0m     +  0.0000  17.2353
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.7423611111111111
F1 Macro Score after query 7: 0.31240122940384424
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8644[0m        [32m0.5973[0m       [35m0.7800[0m      [31m0.7800[0m        [94m0.7022[0m     +  0.0000  22.1478
      2      [36m0.9254[0m        [32m0.4446[0m       0.7764      0.7764        0.7265        0.0000  22.3053
      3      [36m0.9364[0m        [32m0.3949[0m       0.7727      0.7727        0.7353        0.0000  22.3164
      4      [36m0.9448[0m        [32m0.3538[0m       [35m0.7811[0m      [31m0.7811[0m        [94m0.7011[0m     +  0.0000  22.1162
      5      [36m0.9541[0m        [32m0.3145[0m       0.7764      0.7764        0.7501        0.0000  22.1166
      6      [36m0.9695[0m        [32m0.2676[0m       [35m0.7837[0m      [31m0.7837[0m        0.7120        0.0000  22.1465
      7      [36m0.9753[0m        [32m0.2531[0m       0.7835      0.7835        0.7127        0.0000  22.1295
      8      [36m0.9766[0m        [32m0.2409[0m       0.7807      0.7807        0.7199        0.0000  22.1141
      9      [36m0.9797[0m        [32m0.2306[0m       [35m0.7880[0m      [31m0.7880[0m        0.7059        0.0000  22.1146
     10      [36m0.9810[0m        [32m0.2256[0m       0.7845      0.7845        0.7107        0.0000  22.0231
     11      [36m0.9837[0m        [32m0.2151[0m       0.7819      0.7819        0.7131        0.0000  22.3167
     12      [36m0.9859[0m        [32m0.2112[0m       0.7812      0.7812        0.7159        0.0000  22.0858
     13      0.9854        0.2124       0.7826      0.7826        0.7130        0.0000  22.1322
     14      [36m0.9863[0m        [32m0.2075[0m       0.7793      0.7793        0.7195        0.0000  22.1004
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7840277777777778
F1 Macro Score after query 8: 0.4759301876982183
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8983[0m        [32m0.4697[0m       [35m0.8333[0m      [31m0.8333[0m        [94m0.5784[0m     +  0.0000  30.9983
      2      [36m0.9312[0m        [32m0.3698[0m       [35m0.8368[0m      [31m0.8368[0m        [94m0.5744[0m     +  0.0000  31.0692
      3      [36m0.9418[0m        [32m0.3177[0m       0.8330      0.8330        0.5854        0.0000  31.1002
      4      [36m0.9515[0m        [32m0.2908[0m       0.8299      0.8299        0.5998        0.0000  31.1133
      5      [36m0.9614[0m        [32m0.2503[0m       0.8302      0.8302        0.5897        0.0000  31.0480
      6      [36m0.9696[0m        [32m0.2143[0m       0.8365      0.8365        0.5861        0.0000  31.2638
      7      [36m0.9777[0m        [32m0.1910[0m       [35m0.8373[0m      [31m0.8373[0m        0.5962        0.0000  31.0301
      8      [36m0.9787[0m        [32m0.1815[0m       0.8373      0.8373        0.6072        0.0000  30.9672
      9      [36m0.9842[0m        [32m0.1703[0m       0.8313      0.8313        0.6129        0.0000  31.4136
     10      [36m0.9847[0m        [32m0.1665[0m       0.8300      0.8300        0.6221        0.0000  31.0626
     11      [36m0.9884[0m        [32m0.1566[0m       0.8271      0.8271        0.6308        0.0000  31.0767
     12      [36m0.9896[0m        [32m0.1500[0m       0.8280      0.8280        0.6300        0.0000  30.9417
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.7993055555555556
F1 Macro Score after query 9: 0.5062535238266122
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8949[0m        [32m0.4233[0m       [35m0.8470[0m      [31m0.8470[0m        [94m0.5125[0m     +  0.0000  46.5334
      2      [36m0.9247[0m        [32m0.3374[0m       0.8368      0.8368        0.5229        0.0000  46.8922
      3      [36m0.9386[0m        [32m0.2852[0m       0.8457      0.8457        0.5169        0.0000  47.1107
      4      [36m0.9439[0m        [32m0.2571[0m       0.8385      0.8385        0.5399        0.0000  47.1240
      5      [36m0.9497[0m        [32m0.2294[0m       0.8446      0.8446        0.5325        0.0000  46.9864
      6      [36m0.9678[0m        [32m0.1811[0m       0.8434      0.8434        0.5360        0.0000  47.1264
      7      [36m0.9736[0m        [32m0.1647[0m       0.8382      0.8382        0.5698        0.0000  47.0617
      8      [36m0.9774[0m        [32m0.1523[0m       0.8403      0.8403        0.5557        0.0000  47.0310
      9      [36m0.9814[0m        [32m0.1423[0m       0.8389      0.8389        0.5678        0.0000  46.9857
     10      [36m0.9838[0m        [32m0.1304[0m       0.8377      0.8377        0.5706        0.0000  47.0276
     11      [36m0.9879[0m        [32m0.1210[0m       0.8408      0.8408        0.5737        0.0000  46.9361
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8220486111111112
F1 Macro Score after query 10: 0.4984674248407208
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9279[0m        [32m0.3199[0m       [35m0.8281[0m      [31m0.8281[0m        [94m0.5918[0m     +  0.0000  74.7892
      2      [36m0.9417[0m        [32m0.2598[0m       [35m0.8300[0m      [31m0.8300[0m        [94m0.5513[0m     +  0.0000  75.1127
      3      [36m0.9485[0m        [32m0.2238[0m       0.8189      0.8189        0.5967        0.0000  75.2625
      4      [36m0.9549[0m        [32m0.1953[0m       0.8148      0.8148        0.6007        0.0000  75.3641
      5      [36m0.9600[0m        [32m0.1705[0m       0.8262      0.8262        0.6464        0.0000  75.4448
      6      [36m0.9719[0m        [32m0.1339[0m       [35m0.8351[0m      [31m0.8351[0m        0.6009        0.0000  75.2305
      7      [36m0.9791[0m        [32m0.1165[0m       [35m0.8396[0m      [31m0.8396[0m        0.5947        0.0000  75.4638
      8      [36m0.9821[0m        [32m0.1063[0m       0.8337      0.8337        0.6376        0.0000  75.2589
      9      [36m0.9844[0m        [32m0.0948[0m       [35m0.8422[0m      [31m0.8422[0m        0.6267        0.0000  75.4151
     10      [36m0.9869[0m        [32m0.0851[0m       0.8380      0.8380        0.6355        0.0000  75.4453
     11      [36m0.9903[0m        [32m0.0769[0m       0.8384      0.8384        0.6344        0.0000  75.4007
     12      [36m0.9920[0m        [32m0.0728[0m       0.8399      0.8399        0.6357        0.0000  75.3383
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8239583333333333
F1 Macro Score after query 11: 0.516625218042335
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9645[0m        [32m0.1668[0m       [35m0.7615[0m      [31m0.7615[0m        [94m0.8041[0m     +  0.0000  125.4999
      2      [36m0.9674[0m        [32m0.1394[0m       0.6944      0.6944        1.3271        0.0000  126.3721
      3      [36m0.9716[0m        [32m0.1199[0m       0.7247      0.7247        1.0776        0.0000  126.2750
      4      [36m0.9731[0m        [32m0.1081[0m       0.7319      0.7319        1.0591        0.0000  126.0809
      5      [36m0.9763[0m        [32m0.0940[0m       0.7057      0.7057        1.4063        0.0000  126.0875
      6      [36m0.9840[0m        [32m0.0720[0m       [35m0.8344[0m      [31m0.8344[0m        [94m0.6621[0m     +  0.0000  126.2330
      7      [36m0.9886[0m        [32m0.0578[0m       [35m0.8372[0m      [31m0.8372[0m        0.6701        0.0000  126.1557
      8      [36m0.9905[0m        [32m0.0497[0m       0.8300      0.8300        0.7069        0.0000  126.3243
      9      [36m0.9925[0m        [32m0.0439[0m       0.8113      0.8113        0.7898        0.0000  127.5446
     10      [36m0.9940[0m        [32m0.0379[0m       0.8280      0.8280        0.7489        0.0000  126.2562
     11      [36m0.9949[0m        [32m0.0340[0m       0.8264      0.8264        0.7551        0.0000  126.1260
     12      [36m0.9965[0m        [32m0.0305[0m       0.8288      0.8288        0.7580        0.0000  126.4549
     13      [36m0.9971[0m        [32m0.0285[0m       0.8276      0.8276        0.7627        0.0000  126.0584
     14      0.9971        [32m0.0273[0m       0.8276      0.8276        0.7773        0.0000  126.1257
     15      [36m0.9973[0m        [32m0.0263[0m       0.8269      0.8269        0.7885        0.0000  126.4401
     16      [36m0.9974[0m        [32m0.0251[0m       0.8316      0.8316        0.7675        0.0000  126.1875
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8189236111111111
F1 Macro Score after query 12: 0.5301817291969166
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9836[0m        [32m0.0680[0m       [35m0.7715[0m      [31m0.7715[0m        [94m0.9921[0m     +  0.0000  145.4826
      2      [36m0.9842[0m        [32m0.0619[0m       0.7682      0.7682        1.0651        0.0000  146.6720
      3      [36m0.9858[0m        [32m0.0555[0m       [35m0.7976[0m      [31m0.7976[0m        [94m0.9778[0m     +  0.0000  146.4665
      4      [36m0.9865[0m        [32m0.0507[0m       0.7524      0.7524        1.1625        0.0000  147.0312
      5      [36m0.9884[0m        [32m0.0461[0m       0.7255      0.7255        1.6488        0.0000  146.5398
      6      [36m0.9917[0m        [32m0.0346[0m       [35m0.8273[0m      [31m0.8273[0m        [94m0.8248[0m     +  0.0000  146.8727
      7      [36m0.9955[0m        [32m0.0241[0m       [35m0.8302[0m      [31m0.8302[0m        0.8388        0.0000  147.1769
      8      [36m0.9971[0m        [32m0.0188[0m       0.8189      0.8189        0.9440        0.0000  146.9681
      9      [36m0.9980[0m        [32m0.0157[0m       0.8132      0.8132        0.9936        0.0000  146.7345
     10      [36m0.9986[0m        [32m0.0132[0m       0.8168      0.8168        0.9967        0.0000  147.0871
     11      [36m0.9989[0m        [32m0.0116[0m       0.8234      0.8234        0.9694        0.0000  146.6619
     12      [36m0.9992[0m        [32m0.0108[0m       0.8224      0.8224        0.9882        0.0000  146.8768
     13      [36m0.9994[0m        [32m0.0100[0m       0.8248      0.8248        0.9798        0.0000  146.4528
     14      [36m0.9995[0m        [32m0.0095[0m       0.8236      0.8236        0.9998        0.0000  146.8089
     15      0.9994        [32m0.0092[0m       0.8241      0.8241        0.9956        0.0000  146.9530
     16      [36m0.9996[0m        [32m0.0090[0m       0.8297      0.8297        0.9787        0.0000  146.5178
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8069444444444445
F1 Macro Score after query 13: 0.5100652071195635
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/entropy_sampling_seed47\AL_entropy_sampling_results_for_multiclass_classification_s47.pickle
