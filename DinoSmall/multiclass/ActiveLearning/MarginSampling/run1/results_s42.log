(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2500[0m        [32m2.0239[0m       [35m0.3233[0m      [31m0.3233[0m        [94m1.9518[0m     +  0.0000  11.4595
      2      0.2500        2.0520       0.1965      0.1965        1.9794        0.0000  10.8414
      3      [36m0.3750[0m        [32m1.7789[0m       0.2443      0.2443        1.9609        0.0000  10.6795
      4      0.3750        [32m1.6955[0m       0.2712      0.2712        1.9824        0.0000  10.8299
      5      [36m0.5000[0m        [32m1.6955[0m       0.1828      0.1828        2.0405        0.0000  10.8715
      6      [36m0.6250[0m        [32m1.6262[0m       0.2477      0.2477        2.0203        0.0000  10.7028
      7      [36m0.7500[0m        [32m1.4494[0m       0.2788      0.2788        2.0094        0.0000  10.6884
      8      0.7500        1.4731       0.2892      0.2892        2.0019        0.0000  10.8898
      9      0.7500        [32m1.4338[0m       0.2870      0.2870        2.0048        0.0000  10.8019
     10      0.7500        1.4902       0.3016      0.3016        1.9939        0.0000  10.9703
     11      [36m1.0000[0m        [32m1.3427[0m       0.3005      0.3005        1.9949        0.0000  10.8907
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.3299
Pre F1 macro score = 0.1587

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5833[0m        [32m1.6727[0m       [35m0.4479[0m      [31m0.4479[0m        [94m1.7298[0m     +  0.0000  10.8445
      2      0.5000        [32m1.6467[0m       0.4479      0.4479        [94m1.6680[0m     +  0.0000  10.8640
      3      0.5833        [32m1.4183[0m       [35m0.4595[0m      [31m0.4595[0m        [94m1.6540[0m     +  0.0000  10.8579
      4      [36m0.6250[0m        [32m1.2761[0m       [35m0.4785[0m      [31m0.4785[0m        [94m1.6342[0m     +  0.0000  10.9059
      5      [36m0.7917[0m        [32m1.1675[0m       0.4778      0.4778        1.6377        0.0000  10.9679
      6      0.7917        [32m1.1179[0m       [35m0.4984[0m      [31m0.4984[0m        [94m1.6155[0m     +  0.0000  10.9222
      7      0.7083        1.1428       [35m0.5045[0m      [31m0.5045[0m        [94m1.6089[0m     +  0.0000  10.8162
      8      [36m0.8750[0m        [32m1.0068[0m       0.5038      0.5038        [94m1.6049[0m     +  0.0000  10.9375
      9      0.7917        [32m0.9846[0m       0.5042      0.5042        1.6055        0.0000  10.8695
     10      0.8750        [32m0.9609[0m       [35m0.5071[0m      [31m0.5071[0m        [94m1.5997[0m     +  0.0000  11.0208
     11      0.8333        1.0280       0.5064      0.5064        [94m1.5985[0m     +  0.0000  10.9241
     12      0.7917        1.0564       0.5056      0.5056        [94m1.5973[0m     +  0.0000  10.7540
     13      0.8750        [32m0.9280[0m       0.5057      0.5057        [94m1.5970[0m     +  0.0000  10.8871
     14      0.8750        0.9719       0.5054      0.5054        [94m1.5967[0m     +  0.0000  11.0300
     15      [36m0.9167[0m        1.0437       0.5057      0.5057        [94m1.5964[0m     +  0.0000  10.7953
     16      0.8750        0.9954       0.5061      0.5061        [94m1.5964[0m     +  0.0000  10.9381
     17      0.9167        0.9845       0.5059      0.5059        [94m1.5963[0m     +  0.0000  10.8797
     18      0.8750        0.9674       0.5059      0.5059        1.5964        0.0000  10.6954
     19      0.9167        0.9585       0.5059      0.5059        1.5963        0.0000  10.9847
     20      0.7917        1.0573       0.5059      0.5059        [94m1.5962[0m     +  0.0000  10.8254
     21      [36m1.0000[0m        1.0483       0.5059      0.5059        [94m1.5961[0m     +  0.0000  10.8982
     22      0.8333        1.0249       0.5059      0.5059        [94m1.5961[0m     +  0.0000  10.9239
     23      0.9167        [32m0.8878[0m       0.5059      0.5059        [94m1.5961[0m     +  0.0000  10.9557
     24      0.9167        1.0432       0.5059      0.5059        [94m1.5961[0m     +  0.0000  10.9070
     25      0.9167        1.0216       0.5059      0.5059        1.5961        0.0000  10.9462
     26      0.8750        0.9675       0.5059      0.5059        [94m1.5961[0m     +  0.0000  10.7534
     27      0.9167        0.9635       0.5059      0.5059        [94m1.5961[0m     +  0.0000  10.9053
     28      0.7917        0.9713       0.5059      0.5059        [94m1.5961[0m     +  0.0000  10.8311
     29      0.7917        0.9953       0.5059      0.5059        1.5961        0.0000  10.8447
     30      0.7500        1.0517       0.5059      0.5059        [94m1.5961[0m     +  0.0000  10.7918
     31      0.9167        0.9699       0.5059      0.5059        1.5961        0.0000  10.8415
     32      0.8333        0.9948       0.5059      0.5059        1.5961        0.0000  10.8020
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.5661458333333333
F1 Macro Score after query 1: 0.20706907569185407
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5714[0m        [32m1.4873[0m       [35m0.4332[0m      [31m0.4332[0m        [94m1.6264[0m     +  0.0000  11.0124
      2      [36m0.6786[0m        [32m1.3793[0m       [35m0.4722[0m      [31m0.4722[0m        [94m1.4927[0m     +  0.0000  11.0002
      3      [36m0.7143[0m        [32m1.2152[0m       0.4668      0.4668        1.5636        0.0000  10.9233
      4      [36m0.7857[0m        [32m1.1191[0m       0.4622      0.4622        1.5269        0.0000  11.0156
      5      [36m0.8929[0m        [32m0.9602[0m       [35m0.4773[0m      [31m0.4773[0m        [94m1.4715[0m     +  0.0000  11.0017
      6      0.8750        0.9666       [35m0.4830[0m      [31m0.4830[0m        [94m1.4554[0m     +  0.0000  10.9459
      7      [36m0.9107[0m        [32m0.8714[0m       [35m0.4885[0m      [31m0.4885[0m        [94m1.4549[0m     +  0.0000  11.0631
      8      [36m0.9286[0m        [32m0.8154[0m       [35m0.4934[0m      [31m0.4934[0m        [94m1.4532[0m     +  0.0000  11.0777
      9      0.9286        0.8814       [35m0.4946[0m      [31m0.4946[0m        [94m1.4494[0m     +  0.0000  11.1455
     10      0.9286        0.8349       0.4908      0.4908        1.4552        0.0000  11.0636
     11      0.9107        0.8346       0.4898      0.4898        1.4565        0.0000  11.0276
     12      0.9107        0.8265       0.4887      0.4887        1.4560        0.0000  11.0983
     13      0.9286        0.8340       0.4889      0.4889        1.4565        0.0000  11.1251
     14      0.9107        0.8412       0.4873      0.4873        1.4573        0.0000  11.0306
     15      0.9107        [32m0.8130[0m       0.4875      0.4875        1.4571        0.0000  10.9684
     16      [36m0.9464[0m        [32m0.7860[0m       0.4873      0.4873        1.4572        0.0000  10.8390
     17      0.9286        [32m0.7547[0m       0.4872      0.4872        1.4571        0.0000  11.1256
     18      [36m0.9643[0m        0.7837       0.4873      0.4873        1.4569        0.0000  11.1478
     19      0.9464        0.7561       0.4873      0.4873        1.4569        0.0000  11.1137
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.5961805555555556
F1 Macro Score after query 2: 0.2872624576776501
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6161[0m        [32m1.2958[0m       [35m0.6332[0m      [31m0.6332[0m        [94m1.2961[0m     +  0.0000  11.4866
      2      [36m0.6964[0m        [32m1.1261[0m       [35m0.6486[0m      [31m0.6486[0m        [94m1.1960[0m     +  0.0000  11.3523
      3      [36m0.8661[0m        [32m0.9069[0m       0.6406      0.6406        [94m1.1535[0m     +  0.0000  11.3455
      4      0.8571        [32m0.8843[0m       0.6333      0.6333        [94m1.1453[0m     +  0.0000  11.3248
      5      0.8393        [32m0.8119[0m       0.6460      0.6460        [94m1.1206[0m     +  0.0000  11.2973
      6      [36m0.9018[0m        [32m0.7496[0m       0.6377      0.6377        [94m1.1131[0m     +  0.0000  11.3250
      7      0.9018        [32m0.7231[0m       0.6394      0.6394        [94m1.1075[0m     +  0.0000  11.3905
      8      [36m0.9107[0m        [32m0.6910[0m       0.6434      0.6434        [94m1.1038[0m     +  0.0000  11.1846
      9      0.9018        0.6998       0.6358      0.6358        1.1115        0.0000  11.3905
     10      0.9107        0.7150       0.6356      0.6356        1.1099        0.0000  11.3315
     11      [36m0.9375[0m        [32m0.6379[0m       0.6411      0.6411        1.1049        0.0000  11.4065
     12      0.9286        0.6813       0.6424      0.6424        [94m1.1022[0m     +  0.0000  11.4624
     13      0.9375        0.7010       0.6436      0.6436        [94m1.1017[0m     +  0.0000  11.4073
     14      0.9375        0.6834       0.6434      0.6434        [94m1.1011[0m     +  0.0000  11.3084
     15      0.9375        0.6536       0.6432      0.6432        [94m1.1004[0m     +  0.0000  11.3904
     16      [36m0.9464[0m        0.6484       0.6432      0.6432        [94m1.1004[0m     +  0.0000  11.2624
     17      [36m0.9554[0m        0.6623       0.6438      0.6438        [94m1.1002[0m     +  0.0000  11.3453
     18      0.9196        0.6426       0.6443      0.6443        [94m1.0998[0m     +  0.0000  11.3499
     19      0.9375        0.6616       0.6438      0.6438        1.1002        0.0000  11.2110
     20      0.9107        0.6692       0.6443      0.6443        1.1001        0.0000  11.4376
     21      0.9375        [32m0.6190[0m       0.6441      0.6441        1.1002        0.0000  11.1093
     22      0.9554        0.6668       0.6441      0.6441        1.1003        0.0000  11.3268
     23      0.9375        0.6601       0.6443      0.6443        1.1002        0.0000  11.3568
     24      0.9464        0.6859       0.6443      0.6443        1.1002        0.0000  11.3888
     25      0.9286        0.6597       0.6441      0.6441        1.1001        0.0000  11.2641
     26      0.9464        0.6691       0.6443      0.6443        1.1001        0.0000  11.3696
     27      0.9286        0.6391       0.6441      0.6441        1.1001        0.0000  11.3598
     28      0.9107        0.6726       0.6441      0.6441        1.1001        0.0000  11.2720
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.7135416666666666
F1 Macro Score after query 3: 0.2928877986827434
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6010[0m        [32m1.2003[0m       [35m0.7401[0m      [31m0.7401[0m        [94m1.0602[0m     +  0.0000  11.8277
      2      [36m0.7596[0m        [32m0.9503[0m       0.7361      0.7361        [94m1.0090[0m     +  0.0000  11.8542
      3      [36m0.8413[0m        [32m0.8285[0m       0.7252      0.7252        [94m1.0040[0m     +  0.0000  11.8091
      4      [36m0.8942[0m        [32m0.7560[0m       0.7231      0.7231        1.0155        0.0000  11.7679
      5      [36m0.9423[0m        [32m0.7100[0m       0.7214      0.7214        1.0134        0.0000  11.6983
      6      0.9423        [32m0.6451[0m       0.7003      0.7003        [94m1.0031[0m     +  0.0000  11.8331
      7      [36m0.9663[0m        [32m0.6190[0m       0.6937      0.6937        1.0047        0.0000  11.7591
      8      0.9663        [32m0.6170[0m       0.6922      0.6922        1.0054        0.0000  11.7659
      9      0.9663        [32m0.5947[0m       0.6887      0.6887        1.0107        0.0000  11.7030
     10      0.9663        [32m0.5587[0m       0.6920      0.6920        [94m1.0025[0m     +  0.0000  11.7344
     11      0.9663        0.5738       0.6885      0.6885        1.0030        0.0000  11.8273
     12      0.9663        [32m0.5496[0m       0.6894      0.6894        [94m1.0021[0m     +  0.0000  11.8121
     13      [36m0.9760[0m        0.5658       0.6892      0.6892        1.0025        0.0000  11.7542
     14      0.9615        0.5637       0.6905      0.6905        [94m1.0021[0m     +  0.0000  11.9318
     15      0.9663        0.5734       0.6898      0.6898        1.0022        0.0000  11.7557
     16      0.9712        0.5728       0.6892      0.6892        1.0023        0.0000  11.8282
     17      0.9663        0.5847       0.6891      0.6891        1.0023        0.0000  11.8326
     18      0.9712        0.5639       0.6892      0.6892        1.0022        0.0000  11.8387
     19      0.9760        0.5839       0.6887      0.6887        1.0023        0.0000  11.7922
     20      0.9760        [32m0.5493[0m       0.6891      0.6891        1.0021        0.0000  11.9271
     21      0.9712        0.5733       0.6889      0.6889        [94m1.0020[0m     +  0.0000  11.8108
     22      0.9712        0.5670       0.6887      0.6887        1.0021        0.0000  11.7467
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.746875
F1 Macro Score after query 4: 0.4035702218093371
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7344[0m        [32m0.9832[0m       [35m0.7014[0m      [31m0.7014[0m        [94m0.9385[0m     +  0.0000  12.6673
      2      [36m0.8776[0m        [32m0.7730[0m       [35m0.7245[0m      [31m0.7245[0m        [94m0.9028[0m     +  0.0000  12.7191
      3      [36m0.9141[0m        [32m0.6634[0m       [35m0.7307[0m      [31m0.7307[0m        [94m0.8781[0m     +  0.0000  12.4823
      4      [36m0.9323[0m        [32m0.5947[0m       0.7115      0.7115        0.8877        0.0000  12.6564
      5      [36m0.9427[0m        [32m0.5457[0m       0.7177      0.7177        0.8805        0.0000  12.7395
      6      [36m0.9661[0m        [32m0.5002[0m       [35m0.7344[0m      [31m0.7344[0m        [94m0.8534[0m     +  0.0000  12.4948
      7      0.9635        [32m0.4736[0m       0.7299      0.7299        0.8561        0.0000  12.8075
      8      0.9635        [32m0.4644[0m       0.7280      0.7280        0.8586        0.0000  12.6933
      9      [36m0.9714[0m        0.4746       [35m0.7351[0m      [31m0.7351[0m        [94m0.8506[0m     +  0.0000  12.6540
     10      [36m0.9766[0m        [32m0.4568[0m       0.7328      0.7328        0.8511        0.0000  12.7519
     11      0.9740        [32m0.4423[0m       [35m0.7352[0m      [31m0.7352[0m        0.8513        0.0000  12.5936
     12      0.9766        [32m0.4390[0m       0.7344      0.7344        0.8539        0.0000  12.5473
     13      0.9688        [32m0.4265[0m       [35m0.7365[0m      [31m0.7365[0m        [94m0.8503[0m     +  0.0000  12.7318
     14      0.9766        0.4449       0.7361      0.7361        0.8530        0.0000  12.6769
     15      0.9766        [32m0.4234[0m       [35m0.7377[0m      [31m0.7377[0m        0.8518        0.0000  12.5053
     16      0.9740        0.4286       0.7365      0.7365        0.8525        0.0000  12.4697
     17      0.9740        [32m0.4232[0m       0.7359      0.7359        0.8535        0.0000  12.6692
     18      0.9766        [32m0.4109[0m       0.7347      0.7347        0.8541        0.0000  12.7349
     19      0.9766        0.4336       0.7344      0.7344        0.8548        0.0000  12.6728
     20      [36m0.9792[0m        0.4418       0.7339      0.7339        0.8557        0.0000  12.7626
     21      0.9792        0.4150       0.7337      0.7337        0.8558        0.0000  12.8093
     22      0.9792        0.4195       0.7339      0.7339        0.8560        0.0000  12.7344
     23      0.9766        0.4246       0.7340      0.7340        0.8558        0.0000  12.7209
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.7644097222222223
F1 Macro Score after query 5: 0.45264198583600557
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8395[0m        [32m0.7607[0m       [35m0.6922[0m      [31m0.6922[0m        [94m0.8906[0m     +  0.0000  14.1973
      2      [36m0.9020[0m        [32m0.5926[0m       [35m0.7359[0m      [31m0.7359[0m        [94m0.8665[0m     +  0.0000  14.0491
      3      [36m0.9389[0m        [32m0.4968[0m       [35m0.7372[0m      [31m0.7372[0m        0.8722        0.0000  14.2373
      4      [36m0.9531[0m        [32m0.4408[0m       0.7243      0.7243        [94m0.8514[0m     +  0.0000  14.2500
      5      0.9517        [32m0.4088[0m       [35m0.7509[0m      [31m0.7509[0m        0.8572        0.0000  14.1129
      6      [36m0.9645[0m        [32m0.3645[0m       0.7406      0.7406        [94m0.8178[0m     +  0.0000  14.2451
      7      [36m0.9716[0m        [32m0.3443[0m       0.7398      0.7398        0.8187        0.0000  14.2440
      8      0.9702        [32m0.3283[0m       0.7377      0.7377        0.8260        0.0000  14.1682
      9      [36m0.9801[0m        [32m0.3164[0m       0.7372      0.7372        0.8297        0.0000  14.1268
     10      0.9773        [32m0.3129[0m       0.7375      0.7375        0.8235        0.0000  14.2967
     11      [36m0.9830[0m        0.3138       0.7439      0.7439        [94m0.7999[0m     +  0.0000  14.2461
     12      0.9815        [32m0.3005[0m       0.7446      0.7446        [94m0.7976[0m     +  0.0000  14.1708
     13      0.9830        [32m0.2981[0m       0.7455      0.7455        [94m0.7920[0m     +  0.0000  14.1425
     14      [36m0.9844[0m        0.3002       0.7446      0.7446        0.7953        0.0000  14.1565
     15      0.9844        [32m0.2949[0m       0.7458      0.7458        0.7959        0.0000  14.1580
     16      0.9830        [32m0.2944[0m       0.7481      0.7481        [94m0.7873[0m     +  0.0000  14.1884
     17      [36m0.9872[0m        [32m0.2912[0m       0.7488      0.7488        [94m0.7829[0m     +  0.0000  14.0515
     18      0.9858        0.3025       0.7500      0.7500        [94m0.7818[0m     +  0.0000  14.1904
     19      0.9830        0.3014       [35m0.7510[0m      [31m0.7510[0m        [94m0.7780[0m     +  0.0000  14.0199
     20      0.9830        [32m0.2850[0m       0.7507      0.7507        0.7795        0.0000  14.1071
     21      0.9815        0.2939       0.7507      0.7507        0.7789        0.0000  13.8612
     22      0.9872        0.2886       0.7503      0.7503        0.7789        0.0000  14.3315
     23      0.9801        [32m0.2831[0m       0.7505      0.7505        0.7788        0.0000  13.9543
     24      0.9858        0.2855       [35m0.7512[0m      [31m0.7512[0m        0.7784        0.0000  14.1912
     25      0.9815        0.2857       0.7512      0.7512        0.7784        0.0000  14.1196
     26      0.9830        0.2868       [35m0.7514[0m      [31m0.7514[0m        0.7783        0.0000  14.1718
     27      0.9858        0.2901       0.7512      0.7512        0.7782        0.0000  13.8327
     28      0.9815        0.2899       0.7512      0.7512        0.7781        0.0000  14.4706
     29      0.9858        0.2919       0.7514      0.7514        [94m0.7780[0m     +  0.0000  14.2984
     30      0.9858        [32m0.2826[0m       [35m0.7517[0m      [31m0.7517[0m        [94m0.7779[0m     +  0.0000  14.2075
     31      0.9872        0.2884       0.7517      0.7517        0.7779        0.0000  14.2028
     32      0.9830        0.2907       0.7516      0.7516        0.7779        0.0000  14.0986
     33      0.9872        0.2893       0.7516      0.7516        0.7779        0.0000  14.1863
     34      0.9815        0.2859       0.7516      0.7516        0.7779        0.0000  14.2365
     35      0.9858        0.2846       0.7516      0.7516        0.7779        0.0000  14.2083
     36      0.9830        0.2925       0.7516      0.7516        0.7779        0.0000  14.2973
     37      0.9844        0.2870       0.7516      0.7516        0.7779        0.0000  14.0941
     38      0.9858        0.2850       0.7516      0.7516        0.7779        0.0000  14.1225
     39      0.9815        0.2888       0.7516      0.7516        0.7779        0.0000  14.2030
     40      0.9844        [32m0.2734[0m       0.7516      0.7516        0.7779        0.0000  14.2598
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.7930555555555556
F1 Macro Score after query 6: 0.47794854144785587
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8149[0m        [32m0.6817[0m       [35m0.7969[0m      [31m0.7969[0m        [94m0.6747[0m     +  0.0000  16.8425
      2      [36m0.8797[0m        [32m0.5288[0m       [35m0.7972[0m      [31m0.7972[0m        [94m0.6464[0m     +  0.0000  17.0887
      3      [36m0.9201[0m        [32m0.4476[0m       [35m0.8056[0m      [31m0.8056[0m        [94m0.6379[0m     +  0.0000  16.7303
      4      [36m0.9415[0m        [32m0.3825[0m       [35m0.8085[0m      [31m0.8085[0m        0.6446        0.0000  16.8308
      5      [36m0.9565[0m        [32m0.3325[0m       0.7927      0.7927        0.6783        0.0000  17.0431
      6      [36m0.9731[0m        [32m0.2931[0m       0.7901      0.7901        0.7076        0.0000  16.9305
      7      0.9731        [32m0.2813[0m       0.7903      0.7903        0.7061        0.0000  17.0299
      8      [36m0.9763[0m        [32m0.2651[0m       0.7901      0.7901        0.7043        0.0000  16.8612
      9      [36m0.9826[0m        [32m0.2482[0m       0.7898      0.7898        0.6981        0.0000  16.8022
     10      0.9818        [32m0.2449[0m       0.7873      0.7873        0.6995        0.0000  16.8915
     11      [36m0.9858[0m        [32m0.2332[0m       0.7875      0.7875        0.6918        0.0000  16.9572
     12      0.9842        [32m0.2330[0m       0.7892      0.7892        0.6928        0.0000  17.0324
     13      0.9858        0.2375       0.7884      0.7884        0.6913        0.0000  16.8365
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.8036458333333333
F1 Macro Score after query 7: 0.4834577521688723
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8251[0m        [32m0.6431[0m       [35m0.7311[0m      [31m0.7311[0m        [94m0.7646[0m     +  0.0000  21.8239
      2      [36m0.8710[0m        [32m0.5207[0m       [35m0.7679[0m      [31m0.7679[0m        [94m0.6943[0m     +  0.0000  21.7774
      3      [36m0.9068[0m        [32m0.4444[0m       [35m0.7970[0m      [31m0.7970[0m        [94m0.6543[0m     +  0.0000  21.7936
      4      [36m0.9170[0m        [32m0.3963[0m       [35m0.8101[0m      [31m0.8101[0m        [94m0.6423[0m     +  0.0000  21.8090
      5      [36m0.9364[0m        [32m0.3419[0m       0.7925      0.7925        0.6749        0.0000  21.7623
      6      [36m0.9510[0m        [32m0.2959[0m       0.8087      0.8087        [94m0.6320[0m     +  0.0000  21.7139
      7      [36m0.9660[0m        [32m0.2666[0m       0.8057      0.8057        0.6392        0.0000  21.7937
      8      [36m0.9735[0m        [32m0.2472[0m       0.8069      0.8069        0.6446        0.0000  21.9363
      9      [36m0.9779[0m        [32m0.2311[0m       [35m0.8120[0m      [31m0.8120[0m        0.6426        0.0000  21.8551
     10      0.9770        [32m0.2227[0m       0.8083      0.8083        0.6624        0.0000  21.7943
     11      [36m0.9792[0m        [32m0.2185[0m       0.8095      0.8095        0.6555        0.0000  21.8282
     12      [36m0.9814[0m        [32m0.2087[0m       0.8078      0.8078        0.6578        0.0000  21.7292
     13      [36m0.9828[0m        [32m0.2078[0m       0.8085      0.8085        0.6637        0.0000  21.8542
     14      [36m0.9837[0m        [32m0.2032[0m       0.8080      0.8080        0.6648        0.0000  21.9322
     15      [36m0.9859[0m        [32m0.1968[0m       0.8082      0.8082        0.6590        0.0000  21.9648
     16      0.9845        [32m0.1941[0m       [35m0.8123[0m      [31m0.8123[0m        0.6543        0.0000  21.9167
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8265625
F1 Macro Score after query 8: 0.5078290960020369
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8743[0m        [32m0.4760[0m       [35m0.8363[0m      [31m0.8363[0m        [94m0.5296[0m     +  0.0000  30.7052
      2      [36m0.9104[0m        [32m0.3860[0m       0.8299      0.8299        0.5424        0.0000  30.9246
      3      [36m0.9230[0m        [32m0.3435[0m       0.8142      0.8142        0.5651        0.0000  30.9396
      4      [36m0.9359[0m        [32m0.3033[0m       0.8156      0.8156        0.5664        0.0000  31.0806
      5      [36m0.9463[0m        [32m0.2686[0m       0.8042      0.8042        0.6046        0.0000  30.9235
      6      [36m0.9626[0m        [32m0.2174[0m       0.8234      0.8234        0.5762        0.0000  30.9236
      7      [36m0.9696[0m        [32m0.1951[0m       0.8134      0.8134        0.6106        0.0000  30.8941
      8      [36m0.9775[0m        [32m0.1810[0m       0.8144      0.8144        0.6161        0.0000  30.6436
      9      [36m0.9795[0m        [32m0.1669[0m       0.8130      0.8130        0.6199        0.0000  30.9225
     10      [36m0.9842[0m        [32m0.1543[0m       0.8106      0.8106        0.6285        0.0000  30.9695
     11      [36m0.9859[0m        [32m0.1464[0m       0.8163      0.8163        0.6174        0.0000  31.0017
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8388888888888889
F1 Macro Score after query 9: 0.5494248366359684
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8922[0m        [32m0.4280[0m       [35m0.8378[0m      [31m0.8378[0m        [94m0.5233[0m     +  0.0000  46.2414
      2      [36m0.9137[0m        [32m0.3495[0m       0.8352      0.8352        [94m0.5034[0m     +  0.0000  46.6374
      3      [36m0.9274[0m        [32m0.3046[0m       0.8347      0.8347        0.5182        0.0000  46.2229
      4      [36m0.9372[0m        [32m0.2677[0m       0.7000      0.7000        0.9274        0.0000  46.4268
      5      [36m0.9458[0m        [32m0.2396[0m       0.8215      0.8215        0.5587        0.0000  46.4447
      6      [36m0.9639[0m        [32m0.1862[0m       0.8335      0.8335        0.5473        0.0000  46.4023
      7      [36m0.9721[0m        [32m0.1625[0m       0.8349      0.8349        0.5541        0.0000  46.5257
      8      [36m0.9778[0m        [32m0.1477[0m       0.8297      0.8297        0.5714        0.0000  46.4160
      9      [36m0.9804[0m        [32m0.1352[0m       0.8325      0.8325        0.5883        0.0000  46.2735
     10      [36m0.9836[0m        [32m0.1251[0m       0.8257      0.8257        0.6126        0.0000  46.4631
     11      [36m0.9865[0m        [32m0.1128[0m       0.8300      0.8300        0.6173        0.0000  46.5543
     12      [36m0.9889[0m        [32m0.1075[0m       0.8295      0.8295        0.6237        0.0000  46.2109
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8402777777777778
F1 Macro Score after query 10: 0.5777511736421341
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9475[0m        [32m0.2525[0m       [35m0.8309[0m      [31m0.8309[0m        [94m0.5678[0m     +  0.0000  74.4779
      2      [36m0.9520[0m        [32m0.2216[0m       0.8250      0.8250        0.6232        0.0000  74.3647
      3      [36m0.9569[0m        [32m0.1944[0m       0.8207      0.8207        0.6088        0.0000  74.5064
      4      [36m0.9615[0m        [32m0.1641[0m       0.8205      0.8205        0.6236        0.0000  74.6382
      5      [36m0.9662[0m        [32m0.1451[0m       0.8205      0.8205        0.5883        0.0000  74.4956
      6      [36m0.9726[0m        [32m0.1193[0m       0.8240      0.8240        0.6223        0.0000  74.6497
      7      [36m0.9810[0m        [32m0.0951[0m       0.8276      0.8276        0.6084        0.0000  74.9804
      8      [36m0.9867[0m        [32m0.0827[0m       0.8264      0.8264        0.6271        0.0000  74.6370
      9      [36m0.9894[0m        [32m0.0717[0m       0.8271      0.8271        0.6350        0.0000  74.6822
     10      [36m0.9908[0m        [32m0.0655[0m       0.8222      0.8222        0.6890        0.0000  74.8202
     11      [36m0.9932[0m        [32m0.0590[0m       0.8307      0.8307        0.6613        0.0000  74.4461
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8380208333333333
F1 Macro Score after query 11: 0.607062358859795
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9680[0m        [32m0.1579[0m       [35m0.7561[0m      [31m0.7561[0m        [94m0.7662[0m     +  0.0000  125.4292
      2      [36m0.9710[0m        [32m0.1351[0m       0.7422      0.7422        0.8498        0.0000  124.4075
      3      [36m0.9730[0m        [32m0.1159[0m       [35m0.7979[0m      [31m0.7979[0m        [94m0.6451[0m     +  0.0000  125.1377
      4      [36m0.9747[0m        [32m0.1032[0m       0.7908      0.7908        0.7446        0.0000  125.1964
      5      [36m0.9780[0m        [32m0.0902[0m       0.7964      0.7964        0.7796        0.0000  125.5869
      6      [36m0.9830[0m        [32m0.0707[0m       [35m0.8368[0m      [31m0.8368[0m        [94m0.5917[0m     +  0.0000  125.4901
      7      [36m0.9881[0m        [32m0.0566[0m       0.8299      0.8299        0.6358        0.0000  125.3356
      8      [36m0.9906[0m        [32m0.0483[0m       [35m0.8401[0m      [31m0.8401[0m        0.6226        0.0000  125.6158
      9      [36m0.9928[0m        [32m0.0422[0m       0.8363      0.8363        0.6602        0.0000  125.5840
     10      [36m0.9945[0m        [32m0.0359[0m       0.8365      0.8365        0.6919        0.0000  125.5652
     11      [36m0.9959[0m        [32m0.0310[0m       0.8339      0.8339        0.7176        0.0000  125.7874
     12      [36m0.9971[0m        [32m0.0284[0m       0.8351      0.8351        0.7216        0.0000  125.3635
     13      [36m0.9976[0m        [32m0.0266[0m       0.8347      0.8347        0.7224        0.0000  125.5727
     14      [36m0.9979[0m        [32m0.0256[0m       0.8319      0.8319        0.7356        0.0000  125.5554
     15      [36m0.9980[0m        [32m0.0249[0m       0.8328      0.8328        0.7349        0.0000  125.3700
     16      [36m0.9981[0m        [32m0.0242[0m       0.8328      0.8328        0.7445        0.0000  125.5019
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8520833333333333
F1 Macro Score after query 12: 0.5753016789316266
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9822[0m        [32m0.0686[0m       [35m0.8170[0m      [31m0.8170[0m        [94m0.7385[0m     +  0.0000  144.8625
      2      [36m0.9836[0m        [32m0.0629[0m       [35m0.8175[0m      [31m0.8175[0m        [94m0.7211[0m     +  0.0000  146.4726
      3      [36m0.9866[0m        [32m0.0549[0m       [35m0.8271[0m      [31m0.8271[0m        0.7502        0.0000  145.5138
      4      0.9856        [32m0.0523[0m       0.8156      0.8156        0.8318        0.0000  146.0263
      5      [36m0.9877[0m        [32m0.0470[0m       0.7993      0.7993        0.8825        0.0000  146.1064
      6      [36m0.9914[0m        [32m0.0358[0m       [35m0.8286[0m      [31m0.8286[0m        0.7323        0.0000  146.0992
      7      [36m0.9954[0m        [32m0.0242[0m       [35m0.8358[0m      [31m0.8358[0m        0.7411        0.0000  146.3323
      8      [36m0.9967[0m        [32m0.0199[0m       [35m0.8375[0m      [31m0.8375[0m        0.7540        0.0000  145.8489
      9      [36m0.9975[0m        [32m0.0167[0m       [35m0.8417[0m      [31m0.8417[0m        0.7558        0.0000  146.2398
     10      [36m0.9981[0m        [32m0.0146[0m       0.8316      0.8316        0.8065        0.0000  145.8785
     11      [36m0.9984[0m        [32m0.0130[0m       0.8314      0.8314        0.8148        0.0000  146.9243
     12      [36m0.9989[0m        [32m0.0123[0m       0.8354      0.8354        0.8079        0.0000  147.5815
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8598958333333333
F1 Macro Score after query 13: 0.6130520255658167
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed42\AL_margin_sampling_results_for_multiclass_classification_s42.pickle
