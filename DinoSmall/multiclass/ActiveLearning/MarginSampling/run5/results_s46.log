(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2500[0m        [32m2.0211[0m       [35m0.0312[0m      [31m0.0312[0m        [94m2.1711[0m     +  0.0000  11.1114
      2      0.2500        [32m1.9823[0m       [35m0.0905[0m      [31m0.0905[0m        [94m2.1182[0m     +  0.0000  10.1907
      3      [36m0.5000[0m        [32m1.8310[0m       0.0451      0.0451        2.1478        0.0000  10.2167
      4      [36m0.7500[0m        [32m1.6492[0m       [35m0.1793[0m      [31m0.1793[0m        [94m2.0752[0m     +  0.0000  10.5609
      5      0.5000        1.7120       0.1592      0.1592        2.1497        0.0000  10.9192
      6      0.6250        [32m1.5485[0m       [35m0.1861[0m      [31m0.1861[0m        2.1376        0.0000  10.7617
      7      0.6250        1.6592       [35m0.1941[0m      [31m0.1941[0m        2.1289        0.0000  10.7922
      8      0.5000        1.6032       0.1760      0.1760        2.1336        0.0000  10.8907
      9      0.7500        1.5510       0.1708      0.1708        2.1354        0.0000  10.9221
     10      0.6250        1.5952       0.1778      0.1778        2.1357        0.0000  11.0782
     11      [36m0.8750[0m        [32m1.4948[0m       0.1769      0.1769        2.1371        0.0000  10.8956
     12      0.6250        1.5925       0.1799      0.1799        2.1347        0.0000  10.8172
     13      0.5000        1.5659       0.1783      0.1783        2.1346        0.0000  10.9232
     14      0.6250        1.5298       0.1745      0.1745        2.1374        0.0000  10.8618
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.1036
Pre F1 macro score = 0.0714

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.4167[0m        [32m1.7786[0m       [35m0.4472[0m      [31m0.4472[0m        [94m1.8385[0m     +  0.0000  10.9213
      2      0.4167        [32m1.7279[0m       [35m0.4564[0m      [31m0.4564[0m        [94m1.8215[0m     +  0.0000  10.8504
      3      [36m0.5417[0m        [32m1.6124[0m       0.4375      0.4375        [94m1.8038[0m     +  0.0000  10.9740
      4      [36m0.6667[0m        [32m1.3895[0m       0.3828      0.3828        [94m1.7878[0m     +  0.0000  10.8628
      5      0.6250        [32m1.3658[0m       0.4047      0.4047        [94m1.7740[0m     +  0.0000  11.0300
      6      [36m0.7500[0m        [32m1.2646[0m       0.3962      0.3962        [94m1.7733[0m     +  0.0000  10.9496
      7      0.7500        1.2651       0.3832      0.3832        [94m1.7692[0m     +  0.0000  10.9973
      8      [36m0.7917[0m        [32m1.2365[0m       0.3932      0.3932        [94m1.7623[0m     +  0.0000  10.9518
      9      0.6667        [32m1.1846[0m       0.3964      0.3964        [94m1.7570[0m     +  0.0000  10.9238
     10      0.7917        [32m1.1726[0m       0.3832      0.3832        [94m1.7568[0m     +  0.0000  10.9189
     11      0.7500        [32m1.1717[0m       0.3825      0.3825        1.7568        0.0000  10.9372
     12      0.7917        [32m1.1348[0m       0.3845      0.3845        [94m1.7552[0m     +  0.0000  11.0936
     13      [36m0.8333[0m        [32m1.1323[0m       0.3814      0.3814        1.7566        0.0000  10.9843
     14      0.7917        1.1440       0.3816      0.3816        1.7564        0.0000  10.9411
     15      0.7917        [32m1.0952[0m       0.3780      0.3780        1.7582        0.0000  10.9212
     16      0.7083        1.1798       0.3776      0.3776        1.7580        0.0000  11.0451
     17      0.7083        1.1995       0.3781      0.3781        1.7577        0.0000  10.9984
     18      0.7083        1.1046       0.3781      0.3781        1.7573        0.0000  10.8905
     19      0.7500        1.1529       0.3781      0.3781        1.7571        0.0000  11.0670
     20      0.7917        1.1650       0.3786      0.3786        1.7568        0.0000  11.1512
     21      0.8333        1.1516       0.3795      0.3795        1.7566        0.0000  10.8415
     22      0.7917        1.1504       0.3795      0.3795        1.7566        0.0000  11.0457
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.3828125
F1 Macro Score after query 1: 0.1113503103616956
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5357[0m        [32m1.5375[0m       [35m0.5776[0m      [31m0.5776[0m        [94m1.5543[0m     +  0.0000  11.1579
      2      [36m0.5893[0m        [32m1.4786[0m       0.5403      0.5403        [94m1.4946[0m     +  0.0000  11.1119
      3      [36m0.7143[0m        [32m1.2859[0m       0.5681      0.5681        [94m1.4850[0m     +  0.0000  11.2674
      4      [36m0.7679[0m        [32m1.1807[0m       0.5602      0.5602        [94m1.4220[0m     +  0.0000  11.2954
      5      [36m0.7857[0m        [32m1.1179[0m       [35m0.5823[0m      [31m0.5823[0m        [94m1.4006[0m     +  0.0000  11.1883
      6      0.7857        [32m1.0317[0m       0.5712      0.5712        1.4017        0.0000  11.0743
      7      [36m0.8750[0m        [32m0.9723[0m       0.5597      0.5597        1.4046        0.0000  11.2716
      8      [36m0.8929[0m        0.9800       0.5615      0.5615        1.4031        0.0000  11.1530
      9      0.8214        [32m0.9634[0m       0.5609      0.5609        [94m1.4003[0m     +  0.0000  11.1568
     10      0.8571        0.9813       0.5556      0.5556        1.4045        0.0000  11.1093
     11      0.8929        [32m0.9198[0m       0.5582      0.5582        1.4044        0.0000  11.1388
     12      0.8571        0.9547       0.5590      0.5590        1.4045        0.0000  11.1702
     13      0.8571        0.9329       0.5590      0.5590        1.4044        0.0000  11.0706
     14      [36m0.9643[0m        [32m0.9040[0m       0.5589      0.5589        1.4037        0.0000  11.0923
     15      0.9643        [32m0.8856[0m       0.5568      0.5568        1.4048        0.0000  11.1200
     16      0.8929        0.9458       0.5566      0.5566        1.4046        0.0000  11.0940
     17      0.9286        [32m0.8726[0m       0.5568      0.5568        1.4046        0.0000  11.0499
     18      0.8929        0.9087       0.5568      0.5568        1.4044        0.0000  11.0916
     19      0.8750        0.8915       0.5568      0.5568        1.4041        0.0000  11.1495
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.5930555555555556
F1 Macro Score after query 2: 0.2165292401732271
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6161[0m        [32m1.3891[0m       [35m0.6552[0m      [31m0.6552[0m        [94m1.3412[0m     +  0.0000  11.3880
      2      [36m0.7679[0m        [32m1.1330[0m       [35m0.6946[0m      [31m0.6946[0m        [94m1.2541[0m     +  0.0000  11.3495
      3      0.7679        [32m1.0374[0m       0.6861      0.6861        [94m1.2110[0m     +  0.0000  11.4980
      4      [36m0.8304[0m        [32m0.9133[0m       0.6852      0.6852        [94m1.2064[0m     +  0.0000  11.4531
      5      [36m0.8571[0m        [32m0.8239[0m       [35m0.7108[0m      [31m0.7108[0m        [94m1.1679[0m     +  0.0000  11.3867
      6      [36m0.9554[0m        [32m0.7679[0m       0.7061      0.7061        [94m1.1534[0m     +  0.0000  11.3866
      7      0.9286        [32m0.7403[0m       0.7057      0.7057        [94m1.1499[0m     +  0.0000  11.3564
      8      0.9375        [32m0.7391[0m       0.7083      0.7083        [94m1.1387[0m     +  0.0000  11.4381
      9      0.9375        [32m0.7101[0m       0.7076      0.7076        [94m1.1383[0m     +  0.0000  11.3939
     10      [36m0.9643[0m        0.7137       0.7082      0.7082        [94m1.1367[0m     +  0.0000  11.4673
     11      0.9554        [32m0.6946[0m       0.7075      0.7075        [94m1.1362[0m     +  0.0000  11.4315
     12      0.9554        [32m0.6828[0m       0.7071      0.7071        [94m1.1358[0m     +  0.0000  11.4092
     13      0.9643        0.6957       0.7066      0.7066        [94m1.1340[0m     +  0.0000  11.3897
     14      0.9554        0.6856       0.7066      0.7066        [94m1.1335[0m     +  0.0000  11.4639
     15      [36m0.9732[0m        0.7121       0.7064      0.7064        [94m1.1326[0m     +  0.0000  11.4238
     16      0.9732        [32m0.6779[0m       0.7059      0.7059        1.1327        0.0000  11.3940
     17      0.9464        [32m0.6621[0m       0.7052      0.7052        [94m1.1326[0m     +  0.0000  11.3975
     18      0.9732        0.7099       0.7056      0.7056        [94m1.1324[0m     +  0.0000  11.2967
     19      0.9643        0.7014       0.7059      0.7059        [94m1.1322[0m     +  0.0000  11.4092
     20      0.9375        0.7005       0.7056      0.7056        [94m1.1322[0m     +  0.0000  11.3664
     21      0.9643        0.6912       0.7056      0.7056        [94m1.1321[0m     +  0.0000  11.4347
     22      0.9643        0.6954       0.7056      0.7056        [94m1.1321[0m     +  0.0000  11.2991
     23      0.9554        0.6726       0.7057      0.7057        [94m1.1320[0m     +  0.0000  11.4823
     24      0.9643        0.7012       0.7057      0.7057        [94m1.1319[0m     +  0.0000  11.4050
     25      0.9554        0.6832       0.7057      0.7057        [94m1.1318[0m     +  0.0000  11.4865
     26      0.9732        0.6999       0.7057      0.7057        1.1318        0.0000  11.4630
     27      0.9643        0.7041       0.7059      0.7059        [94m1.1318[0m     +  0.0000  11.3750
     28      0.9554        0.6804       0.7059      0.7059        [94m1.1318[0m     +  0.0000  11.4059
     29      0.9554        0.6805       0.7059      0.7059        [94m1.1318[0m     +  0.0000  11.4444
     30      0.9732        0.6678       0.7059      0.7059        [94m1.1318[0m     +  0.0000  11.4060
     31      0.9732        0.6930       0.7059      0.7059        1.1318        0.0000  11.3835
     32      0.9643        0.6918       0.7059      0.7059        1.1318        0.0000  11.4431
     33      0.9464        0.6744       0.7059      0.7059        1.1318        0.0000  11.4222
     34      0.9554        0.7000       0.7059      0.7059        1.1318        0.0000  11.4182
     35      0.9554        0.6988       0.7059      0.7059        1.1318        0.0000  11.4699
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.7277777777777776
F1 Macro Score after query 3: 0.2672518239208984
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6635[0m        [32m1.2110[0m       [35m0.7377[0m      [31m0.7377[0m        [94m1.0933[0m     +  0.0000  11.8089
      2      [36m0.8510[0m        [32m0.9606[0m       [35m0.7448[0m      [31m0.7448[0m        [94m1.0256[0m     +  0.0000  11.8888
      3      [36m0.8894[0m        [32m0.8621[0m       0.7271      0.7271        1.0297        0.0000  11.7926
      4      [36m0.9231[0m        [32m0.7670[0m       [35m0.7477[0m      [31m0.7477[0m        [94m0.9989[0m     +  0.0000  11.7639
      5      [36m0.9471[0m        [32m0.7131[0m       0.7410      0.7410        1.0556        0.0000  11.8418
      6      [36m0.9567[0m        [32m0.6550[0m       [35m0.7550[0m      [31m0.7550[0m        [94m0.9811[0m     +  0.0000  11.7321
      7      [36m0.9663[0m        [32m0.6310[0m       0.7536      0.7536        [94m0.9797[0m     +  0.0000  11.8150
      8      [36m0.9760[0m        [32m0.6139[0m       0.7490      0.7490        0.9800        0.0000  11.8767
      9      0.9712        [32m0.6127[0m       0.7488      0.7488        0.9800        0.0000  11.8876
     10      0.9712        [32m0.5894[0m       0.7497      0.7497        [94m0.9796[0m     +  0.0000  11.8604
     11      [36m0.9808[0m        0.5966       0.7498      0.7498        0.9803        0.0000  11.8325
     12      0.9760        [32m0.5884[0m       0.7491      0.7491        [94m0.9787[0m     +  0.0000  12.0105
     13      0.9760        [32m0.5799[0m       0.7476      0.7476        0.9797        0.0000  11.8440
     14      0.9712        [32m0.5798[0m       0.7464      0.7464        [94m0.9784[0m     +  0.0000  11.6782
     15      0.9808        [32m0.5703[0m       0.7446      0.7446        0.9785        0.0000  11.9574
     16      0.9760        0.5935       0.7455      0.7455        0.9786        0.0000  11.9582
     17      [36m0.9856[0m        [32m0.5648[0m       0.7451      0.7451        0.9784        0.0000  11.8949
     18      0.9615        [32m0.5592[0m       0.7450      0.7450        0.9785        0.0000  11.9753
     19      0.9808        0.5743       0.7453      0.7453        [94m0.9783[0m     +  0.0000  11.8577
     20      0.9808        [32m0.5387[0m       0.7453      0.7453        [94m0.9781[0m     +  0.0000  11.8154
     21      0.9760        0.5693       0.7451      0.7451        [94m0.9781[0m     +  0.0000  11.8677
     22      0.9760        0.5660       0.7450      0.7450        0.9781        0.0000  12.0029
     23      0.9808        0.5672       0.7451      0.7451        [94m0.9780[0m     +  0.0000  12.1062
     24      0.9760        0.5666       0.7451      0.7451        [94m0.9780[0m     +  0.0000  11.8119
     25      0.9856        0.5448       0.7453      0.7453        [94m0.9780[0m     +  0.0000  11.8215
     26      0.9712        0.5662       0.7451      0.7451        [94m0.9780[0m     +  0.0000  12.0710
     27      0.9808        0.5593       0.7453      0.7453        [94m0.9780[0m     +  0.0000  11.7895
     28      0.9808        0.5538       0.7455      0.7455        [94m0.9780[0m     +  0.0000  11.6915
     29      0.9808        0.5624       0.7453      0.7453        [94m0.9780[0m     +  0.0000  11.8082
     30      0.9760        0.5598       0.7453      0.7453        [94m0.9779[0m     +  0.0000  11.9626
     31      0.9856        0.5478       0.7453      0.7453        [94m0.9779[0m     +  0.0000  11.8824
     32      0.9760        0.5699       0.7453      0.7453        0.9779        0.0000  11.7418
     33      0.9856        0.5579       0.7453      0.7453        0.9779        0.0000  11.9632
     34      0.9712        0.5730       0.7453      0.7453        0.9779        0.0000  11.8066
     35      0.9760        0.5724       0.7453      0.7453        [94m0.9779[0m     +  0.0000  11.8225
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.7706597222222221
F1 Macro Score after query 4: 0.3593433484425491
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7682[0m        [32m0.9940[0m       [35m0.7479[0m      [31m0.7479[0m        [94m0.9569[0m     +  0.0000  12.7271
      2      [36m0.8490[0m        [32m0.8169[0m       [35m0.7561[0m      [31m0.7561[0m        [94m0.9122[0m     +  0.0000  12.7596
      3      [36m0.9010[0m        [32m0.6910[0m       [35m0.7715[0m      [31m0.7715[0m        [94m0.8665[0m     +  0.0000  12.7912
      4      [36m0.9479[0m        [32m0.5932[0m       [35m0.7795[0m      [31m0.7795[0m        [94m0.8527[0m     +  0.0000  12.9622
      5      [36m0.9505[0m        [32m0.5483[0m       [35m0.7819[0m      [31m0.7819[0m        [94m0.8456[0m     +  0.0000  12.6495
      6      [36m0.9609[0m        [32m0.5225[0m       [35m0.7865[0m      [31m0.7865[0m        [94m0.8454[0m     +  0.0000  12.7150
      7      [36m0.9688[0m        [32m0.4839[0m       0.7861      0.7861        0.8455        0.0000  12.9318
      8      [36m0.9714[0m        [32m0.4751[0m       0.7854      0.7854        [94m0.8444[0m     +  0.0000  12.7586
      9      0.9714        [32m0.4720[0m       0.7833      0.7833        [94m0.8420[0m     +  0.0000  12.7560
     10      0.9714        [32m0.4531[0m       0.7861      0.7861        0.8446        0.0000  12.6968
     11      0.9714        [32m0.4501[0m       0.7859      0.7859        0.8449        0.0000  12.6663
     12      [36m0.9818[0m        [32m0.4418[0m       [35m0.7872[0m      [31m0.7872[0m        0.8443        0.0000  12.7111
     13      0.9740        0.4425       0.7870      0.7870        0.8440        0.0000  12.7140
     14      0.9661        0.4501       0.7865      0.7865        0.8433        0.0000  12.6975
     15      0.9740        [32m0.4389[0m       [35m0.7885[0m      [31m0.7885[0m        0.8435        0.0000  12.6659
     16      0.9818        [32m0.4382[0m       0.7885      0.7885        0.8435        0.0000  12.6670
     17      0.9766        0.4507       0.7882      0.7882        0.8434        0.0000  12.6181
     18      0.9714        [32m0.4367[0m       [35m0.7889[0m      [31m0.7889[0m        0.8432        0.0000  12.7600
     19      0.9714        0.4441       0.7889      0.7889        0.8436        0.0000  12.6325
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.8052083333333333
F1 Macro Score after query 5: 0.4088259367573246
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7926[0m        [32m0.8448[0m       [35m0.7955[0m      [31m0.7955[0m        [94m0.7997[0m     +  0.0000  14.4624
      2      [36m0.9091[0m        [32m0.6023[0m       0.7932      0.7932        0.8255        0.0000  14.3546
      3      [36m0.9531[0m        [32m0.4944[0m       [35m0.8049[0m      [31m0.8049[0m        0.8095        0.0000  14.3528
      4      [36m0.9588[0m        [32m0.4466[0m       [35m0.8071[0m      [31m0.8071[0m        [94m0.7950[0m     +  0.0000  14.3251
      5      [36m0.9673[0m        [32m0.4119[0m       0.7931      0.7931        0.8131        0.0000  14.2114
      6      [36m0.9716[0m        [32m0.3893[0m       [35m0.8128[0m      [31m0.8128[0m        [94m0.7768[0m     +  0.0000  14.4633
      7      [36m0.9730[0m        [32m0.3633[0m       0.8122      0.8122        [94m0.7763[0m     +  0.0000  14.3089
      8      [36m0.9759[0m        [32m0.3547[0m       0.8095      0.8095        0.7866        0.0000  14.3568
      9      [36m0.9787[0m        [32m0.3455[0m       [35m0.8132[0m      [31m0.8132[0m        0.7787        0.0000  14.4471
     10      0.9773        [32m0.3404[0m       [35m0.8137[0m      [31m0.8137[0m        0.7805        0.0000  14.2271
     11      [36m0.9815[0m        [32m0.3284[0m       [35m0.8200[0m      [31m0.8200[0m        [94m0.7669[0m     +  0.0000  14.3224
     12      [36m0.9844[0m        0.3310       0.8194      0.8194        [94m0.7668[0m     +  0.0000  14.1512
     13      0.9830        [32m0.3225[0m       [35m0.8201[0m      [31m0.8201[0m        [94m0.7652[0m     +  0.0000  14.2760
     14      0.9787        0.3372       0.8198      0.8198        [94m0.7648[0m     +  0.0000  14.4184
     15      [36m0.9858[0m        [32m0.3099[0m       [35m0.8210[0m      [31m0.8210[0m        0.7660        0.0000  14.3389
     16      0.9844        0.3244       [35m0.8212[0m      [31m0.8212[0m        0.7653        0.0000  14.2760
     17      0.9844        0.3178       0.8210      0.8210        0.7649        0.0000  14.2605
     18      0.9844        0.3218       [35m0.8215[0m      [31m0.8215[0m        [94m0.7644[0m     +  0.0000  14.3196
     19      0.9830        0.3212       0.8214      0.8214        [94m0.7641[0m     +  0.0000  14.2282
     20      0.9830        0.3278       0.8214      0.8214        0.7647        0.0000  14.3079
     21      0.9830        0.3127       0.8214      0.8214        0.7644        0.0000  14.3851
     22      0.9815        0.3266       0.8212      0.8212        0.7642        0.0000  14.3810
     23      0.9830        0.3233       0.8214      0.8214        [94m0.7641[0m     +  0.0000  14.2105
     24      0.9830        0.3218       0.8214      0.8214        [94m0.7641[0m     +  0.0000  14.2143
     25      0.9844        0.3185       0.8214      0.8214        [94m0.7639[0m     +  0.0000  14.3388
     26      0.9844        0.3200       0.8214      0.8214        0.7640        0.0000  14.3229
     27      0.9844        0.3153       0.8214      0.8214        0.7640        0.0000  14.4034
     28      0.9815        0.3180       0.8214      0.8214        0.7640        0.0000  14.4807
     29      0.9844        0.3240       0.8214      0.8214        0.7640        0.0000  14.1957
     30      0.9858        0.3143       0.8215      0.8215        0.7641        0.0000  14.2298
     31      0.9858        0.3179       0.8215      0.8215        0.7641        0.0000  14.3531
     32      0.9844        0.3248       0.8215      0.8215        0.7641        0.0000  14.5393
     33      [36m0.9886[0m        0.3122       0.8215      0.8215        0.7641        0.0000  14.4613
     34      0.9844        0.3175       0.8215      0.8215        0.7641        0.0000  14.2739
     35      0.9844        0.3134       0.8215      0.8215        0.7641        0.0000  14.3397
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8083333333333333
F1 Macro Score after query 6: 0.43958619947576316
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8220[0m        [32m0.7174[0m       [35m0.8175[0m      [31m0.8175[0m        [94m0.7016[0m     +  0.0000  17.1204
      2      [36m0.8829[0m        [32m0.5695[0m       [35m0.8252[0m      [31m0.8252[0m        [94m0.6953[0m     +  0.0000  16.9025
      3      [36m0.9106[0m        [32m0.4862[0m       [35m0.8335[0m      [31m0.8335[0m        [94m0.6832[0m     +  0.0000  16.9034
      4      [36m0.9335[0m        [32m0.4390[0m       0.8295      0.8295        [94m0.6633[0m     +  0.0000  17.3196
      5      [36m0.9351[0m        [32m0.4101[0m       0.8297      0.8297        [94m0.6400[0m     +  0.0000  17.1992
      6      [36m0.9478[0m        [32m0.3572[0m       [35m0.8368[0m      [31m0.8368[0m        0.6565        0.0000  17.1044
      7      [36m0.9565[0m        [32m0.3547[0m       0.8333      0.8333        0.6575        0.0000  16.9482
      8      [36m0.9604[0m        [32m0.3363[0m       0.8337      0.8337        0.6748        0.0000  17.0590
      9      0.9533        0.3406       0.8328      0.8328        0.6775        0.0000  17.1498
     10      [36m0.9652[0m        [32m0.3162[0m       0.8351      0.8351        0.6707        0.0000  17.1670
     11      [36m0.9668[0m        [32m0.3081[0m       0.8250      0.8250        0.6756        0.0000  17.0441
     12      [36m0.9676[0m        [32m0.3037[0m       0.8269      0.8269        0.6774        0.0000  16.9953
     13      [36m0.9699[0m        [32m0.3021[0m       0.8280      0.8280        0.6787        0.0000  17.0758
     14      [36m0.9723[0m        [32m0.2987[0m       0.8266      0.8266        0.6770        0.0000  17.2294
     15      [36m0.9731[0m        0.3017       0.8253      0.8253        0.6807        0.0000  16.9963
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.8203125
F1 Macro Score after query 7: 0.434388317625251
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8525[0m        [32m0.6301[0m       [35m0.7976[0m      [31m0.7976[0m        [94m0.6820[0m     +  0.0000  22.3110
      2      [36m0.8891[0m        [32m0.5266[0m       [35m0.8151[0m      [31m0.8151[0m        [94m0.6386[0m     +  0.0000  21.9671
      3      [36m0.9156[0m        [32m0.4493[0m       0.8047      0.8047        0.6578        0.0000  21.8934
      4      [36m0.9289[0m        [32m0.4094[0m       [35m0.8186[0m      [31m0.8186[0m        0.6542        0.0000  22.4220
      5      [36m0.9351[0m        [32m0.3792[0m       [35m0.8201[0m      [31m0.8201[0m        0.6435        0.0000  22.1100
      6      [36m0.9510[0m        [32m0.3248[0m       0.8177      0.8177        0.6593        0.0000  21.9193
      7      [36m0.9607[0m        [32m0.3015[0m       [35m0.8217[0m      [31m0.8217[0m        0.6510        0.0000  22.0465
      8      [36m0.9633[0m        [32m0.2843[0m       0.8149      0.8149        0.6623        0.0000  22.0781
      9      [36m0.9678[0m        [32m0.2702[0m       0.8182      0.8182        0.6612        0.0000  22.0624
     10      [36m0.9739[0m        [32m0.2607[0m       0.8170      0.8170        0.6683        0.0000  21.9525
     11      [36m0.9775[0m        [32m0.2460[0m       [35m0.8224[0m      [31m0.8224[0m        0.6581        0.0000  22.0947
     12      0.9766        [32m0.2406[0m       0.8210      0.8210        0.6608        0.0000  22.0924
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8236111111111111
F1 Macro Score after query 8: 0.4323400511087992
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8646[0m        [32m0.5659[0m       [35m0.7976[0m      [31m0.7976[0m        [94m0.6287[0m     +  0.0000  30.7729
      2      [36m0.8960[0m        [32m0.4690[0m       [35m0.8066[0m      [31m0.8066[0m        [94m0.6286[0m     +  0.0000  31.1769
      3      [36m0.9114[0m        [32m0.4150[0m       [35m0.8130[0m      [31m0.8130[0m        [94m0.6085[0m     +  0.0000  30.9414
      4      [36m0.9245[0m        [32m0.3733[0m       0.8090      0.8090        0.6087        0.0000  31.0073
      5      [36m0.9354[0m        [32m0.3415[0m       [35m0.8156[0m      [31m0.8156[0m        [94m0.6035[0m     +  0.0000  30.8524
      6      [36m0.9522[0m        [32m0.2788[0m       [35m0.8160[0m      [31m0.8160[0m        0.6496        0.0000  30.8984
      7      [36m0.9614[0m        [32m0.2563[0m       0.8144      0.8144        0.6686        0.0000  31.0047
      8      [36m0.9700[0m        [32m0.2360[0m       [35m0.8170[0m      [31m0.8170[0m        0.6779        0.0000  30.7242
      9      [36m0.9723[0m        [32m0.2232[0m       [35m0.8174[0m      [31m0.8174[0m        0.6797        0.0000  31.0338
     10      [36m0.9772[0m        [32m0.2081[0m       0.8165      0.8165        0.6940        0.0000  30.9081
     11      [36m0.9800[0m        [32m0.1963[0m       0.8167      0.8167        0.7011        0.0000  30.7286
     12      [36m0.9814[0m        [32m0.1915[0m       0.8172      0.8172        0.7089        0.0000  31.7975
     13      [36m0.9837[0m        [32m0.1881[0m       0.8165      0.8165        0.7145        0.0000  30.9999
     14      0.9834        [32m0.1858[0m       0.8155      0.8155        0.7172        0.0000  30.6883
     15      [36m0.9847[0m        [32m0.1836[0m       0.8158      0.8158        0.7205        0.0000  31.0642
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8123263888888889
F1 Macro Score after query 9: 0.4287610176680646
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9108[0m        [32m0.3894[0m       [35m0.8349[0m      [31m0.8349[0m        [94m0.5331[0m     +  0.0000  46.3748
      2      [36m0.9304[0m        [32m0.3336[0m       0.8182      0.8182        0.5790        0.0000  46.9068
      3      [36m0.9387[0m        [32m0.2927[0m       0.8130      0.8130        0.6056        0.0000  46.7931
      4      [36m0.9476[0m        [32m0.2601[0m       0.8097      0.8097        0.6133        0.0000  46.7454
      5      [36m0.9500[0m        [32m0.2334[0m       0.8033      0.8033        0.6600        0.0000  46.9528
      6      [36m0.9667[0m        [32m0.1861[0m       0.8111      0.8111        0.6396        0.0000  46.4376
      7      [36m0.9729[0m        [32m0.1627[0m       0.8134      0.8134        0.6492        0.0000  46.5833
      8      [36m0.9769[0m        [32m0.1495[0m       0.8115      0.8115        0.6669        0.0000  46.7987
      9      [36m0.9815[0m        [32m0.1379[0m       0.8142      0.8142        0.6889        0.0000  46.7196
     10      [36m0.9846[0m        [32m0.1265[0m       0.8064      0.8064        0.7291        0.0000  46.7154
     11      [36m0.9881[0m        [32m0.1151[0m       0.8130      0.8130        0.7071        0.0000  46.8164
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8177083333333333
F1 Macro Score after query 10: 0.5139446732454652
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9449[0m        [32m0.2740[0m       [35m0.8219[0m      [31m0.8219[0m        [94m0.6694[0m     +  0.0000  74.7042
      2      [36m0.9510[0m        [32m0.2333[0m       [35m0.8229[0m      [31m0.8229[0m        0.6880        0.0000  74.6796
      3      [36m0.9598[0m        [32m0.2006[0m       [35m0.8276[0m      [31m0.8276[0m        0.6864        0.0000  74.7933
      4      [36m0.9613[0m        [32m0.1744[0m       0.8253      0.8253        0.7168        0.0000  74.7258
      5      [36m0.9655[0m        [32m0.1531[0m       [35m0.8281[0m      [31m0.8281[0m        0.6920        0.0000  74.7381
      6      [36m0.9745[0m        [32m0.1214[0m       0.8227      0.8227        [94m0.6523[0m     +  0.0000  74.5749
      7      [36m0.9804[0m        [32m0.1031[0m       0.8200      0.8200        0.6758        0.0000  74.8124
      8      [36m0.9840[0m        [32m0.0906[0m       0.8220      0.8220        0.7497        0.0000  74.6128
      9      [36m0.9868[0m        [32m0.0817[0m       0.8187      0.8187        0.7227        0.0000  74.3468
     10      [36m0.9896[0m        [32m0.0740[0m       0.8092      0.8092        0.7501        0.0000  74.6326
     11      [36m0.9912[0m        [32m0.0651[0m       0.8012      0.8012        0.8147        0.0000  74.7661
     12      [36m0.9931[0m        [32m0.0601[0m       0.8016      0.8016        0.8227        0.0000  74.8435
     13      [36m0.9937[0m        [32m0.0578[0m       0.7969      0.7969        0.8490        0.0000  75.1093
     14      [36m0.9948[0m        [32m0.0546[0m       0.7988      0.7988        0.8563        0.0000  74.7436
     15      [36m0.9949[0m        [32m0.0520[0m       0.7964      0.7964        0.8684        0.0000  74.4235
     16      [36m0.9955[0m        [32m0.0513[0m       0.8007      0.8007        0.8595        0.0000  75.3439
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8222222222222222
F1 Macro Score after query 11: 0.4794366573703761
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9788[0m        [32m0.1019[0m       [35m0.7408[0m      [31m0.7408[0m        [94m0.9235[0m     +  0.0000  124.6781
      2      [36m0.9801[0m        [32m0.0869[0m       [35m0.7429[0m      [31m0.7429[0m        [94m0.8987[0m     +  0.0000  125.3626
      3      [36m0.9818[0m        [32m0.0785[0m       0.7132      0.7132        1.0640        0.0000  125.3680
      4      [36m0.9836[0m        [32m0.0711[0m       [35m0.7731[0m      [31m0.7731[0m        [94m0.8744[0m     +  0.0000  125.1450
      5      [36m0.9854[0m        [32m0.0618[0m       [35m0.7993[0m      [31m0.7993[0m        [94m0.7929[0m     +  0.0000  125.6142
      6      [36m0.9904[0m        [32m0.0448[0m       [35m0.8109[0m      [31m0.8109[0m        0.8260        0.0000  125.3231
      7      [36m0.9945[0m        [32m0.0323[0m       [35m0.8144[0m      [31m0.8144[0m        0.8359        0.0000  126.0237
      8      [36m0.9960[0m        [32m0.0271[0m       0.8130      0.8130        0.8826        0.0000  125.4524
      9      [36m0.9967[0m        [32m0.0241[0m       0.8123      0.8123        0.8982        0.0000  125.0425
     10      [36m0.9976[0m        [32m0.0205[0m       0.8069      0.8069        0.9652        0.0000  125.5621
     11      [36m0.9984[0m        [32m0.0170[0m       0.8019      0.8019        0.9888        0.0000  125.2948
     12      [36m0.9989[0m        [32m0.0158[0m       0.7969      0.7969        1.0167        0.0000  125.0346
     13      0.9989        [32m0.0152[0m       0.7960      0.7960        1.0263        0.0000  125.6676
     14      [36m0.9989[0m        [32m0.0146[0m       0.7995      0.7995        1.0167        0.0000  124.9695
     15      [36m0.9992[0m        [32m0.0134[0m       0.7988      0.7988        1.0303        0.0000  125.4367
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8220486111111112
F1 Macro Score after query 12: 0.4904954497448137
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9872[0m        [32m0.0552[0m       [35m0.7616[0m      [31m0.7616[0m        [94m1.1740[0m     +  0.0000  144.7685
      2      [36m0.9889[0m        [32m0.0488[0m       0.7332      0.7332        1.5127        0.0000  146.4500
      3      [36m0.9890[0m        [32m0.0449[0m       [35m0.7865[0m      [31m0.7865[0m        [94m1.1667[0m     +  0.0000  145.5329
      4      [36m0.9898[0m        [32m0.0417[0m       0.7618      0.7618        1.3533        0.0000  145.8585
      5      [36m0.9902[0m        [32m0.0381[0m       0.7434      0.7434        1.4350        0.0000  145.0493
      6      [36m0.9945[0m        [32m0.0260[0m       [35m0.8238[0m      [31m0.8238[0m        [94m0.8920[0m     +  0.0000  146.1252
      7      [36m0.9974[0m        [32m0.0156[0m       [35m0.8273[0m      [31m0.8273[0m        [94m0.8766[0m     +  0.0000  145.7383
      8      [36m0.9986[0m        [32m0.0125[0m       0.8094      0.8094        0.9820        0.0000  146.2185
      9      [36m0.9988[0m        [32m0.0110[0m       0.8193      0.8193        1.0101        0.0000  145.7748
     10      [36m0.9988[0m        [32m0.0097[0m       0.8090      0.8090        1.1290        0.0000  146.2655
     11      [36m0.9993[0m        [32m0.0084[0m       0.8080      0.8080        1.1165        0.0000  145.8613
     12      [36m0.9995[0m        [32m0.0074[0m       0.8083      0.8083        1.1331        0.0000  146.3462
     13      [36m0.9996[0m        [32m0.0068[0m       0.8094      0.8094        1.1391        0.0000  145.3402
     14      [36m0.9996[0m        [32m0.0065[0m       0.8064      0.8064        1.1706        0.0000  143.6652
     15      [36m0.9997[0m        0.0065       0.8056      0.8056        1.1992        0.0000  140.2514
     16      [36m0.9997[0m        [32m0.0060[0m       0.8075      0.8075        1.1849        0.0000  140.0479
     17      0.9997        0.0062       0.8083      0.8083        1.1820        0.0000  139.6981
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8243055555555555
F1 Macro Score after query 13: 0.5165038170460604
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed46\AL_margin_sampling_results_for_multiclass_classification_s46.pickle
