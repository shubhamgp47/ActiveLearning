(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.1250[0m        [32m2.0162[0m       [35m0.1920[0m      [31m0.1920[0m        [94m2.0201[0m     +  0.0000  10.7310
      2      [36m0.3750[0m        [32m1.9376[0m       [35m0.1969[0m      [31m0.1969[0m        2.1121        0.0000  10.1097
      3      0.3750        [32m1.8182[0m       0.1042      0.1042        2.1218        0.0000  10.5238
      4      0.3750        [32m1.7852[0m       0.1526      0.1526        2.1028        0.0000  10.8389
      5      [36m0.6250[0m        [32m1.6003[0m       0.1151      0.1151        2.1397        0.0000  10.4675
      6      [36m0.8750[0m        [32m1.4333[0m       0.1177      0.1177        2.1392        0.0000  10.5143
      7      0.7500        1.5687       0.1085      0.1085        2.1484        0.0000  10.6235
      8      [36m1.0000[0m        [32m1.3191[0m       0.1076      0.1076        2.1507        0.0000  10.5300
      9      0.8750        [32m1.2833[0m       0.1066      0.1066        2.1540        0.0000  10.5642
     10      0.6250        1.4975       0.1187      0.1188        2.1512        0.0000  10.7139
     11      0.7500        1.3694       0.1165      0.1165        2.1527        0.0000  10.6690
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.2059
Pre F1 macro score = 0.1244

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.4167[0m        [32m1.8674[0m       [35m0.2646[0m      [31m0.2646[0m        [94m1.8577[0m     +  0.0000  10.7005
      2      [36m0.4583[0m        [32m1.5963[0m       [35m0.2792[0m      [31m0.2792[0m        [94m1.7861[0m     +  0.0000  10.7516
      3      [36m0.5417[0m        [32m1.5600[0m       [35m0.3464[0m      [31m0.3464[0m        [94m1.7016[0m     +  0.0000  10.7092
      4      [36m0.6667[0m        [32m1.4721[0m       [35m0.4859[0m      [31m0.4859[0m        [94m1.6645[0m     +  0.0000  10.7932
      5      [36m0.7917[0m        [32m1.2898[0m       0.4799      0.4799        [94m1.6581[0m     +  0.0000  10.5814
      6      0.7500        [32m1.2272[0m       0.4519      0.4519        [94m1.6325[0m     +  0.0000  10.6753
      7      0.6667        1.2293       0.4639      0.4639        [94m1.6228[0m     +  0.0000  10.6269
      8      0.7917        [32m1.1544[0m       0.4679      0.4679        [94m1.6166[0m     +  0.0000  10.7194
      9      [36m0.8750[0m        [32m1.0908[0m       0.4762      0.4762        [94m1.6110[0m     +  0.0000  10.5653
     10      0.7917        1.2197       0.4747      0.4747        [94m1.6041[0m     +  0.0000  10.5658
     11      0.7917        1.1141       0.4755      0.4755        [94m1.6031[0m     +  0.0000  10.6500
     12      0.7917        1.1327       0.4747      0.4747        1.6032        0.0000  10.6255
     13      0.7917        1.1185       0.4743      0.4743        [94m1.6031[0m     +  0.0000  10.7826
     14      0.8333        1.0936       0.4750      0.4750        [94m1.6028[0m     +  0.0000  10.7031
     15      0.7917        1.1258       0.4752      0.4752        [94m1.6018[0m     +  0.0000  10.8011
     16      0.7917        1.1166       0.4757      0.4757        [94m1.6018[0m     +  0.0000  10.4217
     17      0.7917        1.1498       0.4755      0.4755        [94m1.6016[0m     +  0.0000  10.6756
     18      0.7917        1.1495       0.4760      0.4760        [94m1.6014[0m     +  0.0000  10.8445
     19      0.8333        1.1317       0.4762      0.4762        [94m1.6013[0m     +  0.0000  10.7598
     20      0.7500        1.1500       0.4764      0.4764        [94m1.6011[0m     +  0.0000  10.8466
     21      0.8750        [32m1.0789[0m       0.4764      0.4764        [94m1.6011[0m     +  0.0000  10.7223
     22      0.8750        1.0853       0.4766      0.4766        1.6011        0.0000  10.4688
     23      0.8333        [32m1.0604[0m       0.4766      0.4766        [94m1.6011[0m     +  0.0000  10.4899
     24      0.8333        1.0918       0.4767      0.4767        [94m1.6010[0m     +  0.0000  10.5259
     25      0.8750        1.1180       0.4769      0.4769        [94m1.6010[0m     +  0.0000  10.5958
     26      0.8750        1.1081       0.4769      0.4769        [94m1.6010[0m     +  0.0000  10.5739
     27      0.7500        1.1306       0.4769      0.4769        [94m1.6010[0m     +  0.0000  10.7679
     28      0.7917        1.1073       0.4769      0.4769        [94m1.6010[0m     +  0.0000  10.6094
     29      0.8333        1.0962       0.4771      0.4771        [94m1.6010[0m     +  0.0000  10.8285
     30      0.8333        1.1527       0.4771      0.4771        1.6010        0.0000  10.7973
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.4890625
F1 Macro Score after query 1: 0.1456761441511913
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5357[0m        [32m1.4766[0m       [35m0.5328[0m      [31m0.5328[0m        [94m1.4604[0m     +  0.0000  10.7526
      2      [36m0.7321[0m        [32m1.2077[0m       [35m0.5363[0m      [31m0.5363[0m        [94m1.4137[0m     +  0.0000  10.7232
      3      [36m0.8214[0m        [32m1.0367[0m       [35m0.5649[0m      [31m0.5649[0m        [94m1.3702[0m     +  0.0000  10.8898
      4      [36m0.8393[0m        [32m0.9601[0m       [35m0.5733[0m      [31m0.5733[0m        [94m1.3493[0m     +  0.0000  10.6913
      5      0.8393        [32m0.9191[0m       [35m0.5878[0m      [31m0.5878[0m        [94m1.3273[0m     +  0.0000  10.7646
      6      0.8393        [32m0.8844[0m       0.5861      0.5861        [94m1.3163[0m     +  0.0000  10.8114
      7      [36m0.8750[0m        [32m0.8320[0m       0.5833      0.5833        [94m1.3094[0m     +  0.0000  10.9831
      8      0.8750        0.8380       0.5840      0.5840        [94m1.3059[0m     +  0.0000  11.1427
      9      [36m0.8929[0m        [32m0.8056[0m       0.5816      0.5816        1.3062        0.0000  10.9616
     10      0.8750        [32m0.7907[0m       0.5835      0.5835        [94m1.3020[0m     +  0.0000  10.7996
     11      0.8929        0.8087       0.5844      0.5844        [94m1.3012[0m     +  0.0000  10.7657
     12      0.8750        0.8318       0.5840      0.5840        [94m1.3009[0m     +  0.0000  10.7040
     13      [36m0.9286[0m        [32m0.7740[0m       0.5852      0.5852        [94m1.3006[0m     +  0.0000  11.0618
     14      [36m0.9464[0m        0.7783       0.5849      0.5849        [94m1.3001[0m     +  0.0000  10.8888
     15      0.9464        [32m0.7597[0m       0.5845      0.5845        [94m1.2993[0m     +  0.0000  10.8300
     16      0.9286        0.7970       0.5845      0.5845        [94m1.2991[0m     +  0.0000  10.8257
     17      0.9286        0.7901       0.5849      0.5849        [94m1.2991[0m     +  0.0000  10.8613
     18      0.9286        [32m0.7365[0m       0.5845      0.5845        1.2991        0.0000  10.7952
     19      0.9107        0.7854       0.5842      0.5842        1.2991        0.0000  10.7500
     20      0.8750        0.7572       0.5845      0.5845        [94m1.2989[0m     +  0.0000  10.7754
     21      0.9464        0.7668       0.5845      0.5845        [94m1.2988[0m     +  0.0000  11.0640
     22      0.8929        0.7691       0.5845      0.5845        [94m1.2988[0m     +  0.0000  11.0231
     23      0.9286        [32m0.7276[0m       0.5845      0.5845        [94m1.2988[0m     +  0.0000  10.8447
     24      0.9464        0.7291       0.5845      0.5845        [94m1.2988[0m     +  0.0000  10.8530
     25      0.9286        0.7545       0.5845      0.5845        [94m1.2987[0m     +  0.0000  10.9533
     26      0.9107        0.7840       0.5844      0.5844        [94m1.2987[0m     +  0.0000  10.8325
     27      0.9464        [32m0.7072[0m       0.5844      0.5844        1.2987        0.0000  10.8163
     28      0.9107        0.7808       0.5845      0.5845        [94m1.2987[0m     +  0.0000  10.6419
     29      0.9107        0.7526       0.5845      0.5845        [94m1.2987[0m     +  0.0000  10.8282
     30      0.9286        0.7686       0.5845      0.5845        [94m1.2987[0m     +  0.0000  10.7531
     31      0.9464        [32m0.7045[0m       0.5845      0.5845        [94m1.2987[0m     +  0.0000  11.0191
     32      0.8929        0.7379       0.5845      0.5845        [94m1.2987[0m     +  0.0000  11.0456
     33      0.8929        0.7622       0.5845      0.5845        [94m1.2987[0m     +  0.0000  10.9734
     34      0.9286        0.7829       0.5845      0.5845        1.2987        0.0000  11.1541
     35      0.9286        0.7196       0.5845      0.5845        [94m1.2987[0m     +  0.0000  10.8661
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.5979166666666667
F1 Macro Score after query 2: 0.19804061778012613
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6964[0m        [32m1.2205[0m       [35m0.6505[0m      [31m0.6505[0m        [94m1.2048[0m     +  0.0000  11.1930
      2      [36m0.7679[0m        [32m1.0421[0m       [35m0.6793[0m      [31m0.6793[0m        [94m1.1472[0m     +  0.0000  11.1886
      3      [36m0.8482[0m        [32m0.9259[0m       [35m0.6837[0m      [31m0.6837[0m        [94m1.1174[0m     +  0.0000  11.1558
      4      [36m0.8750[0m        [32m0.8395[0m       [35m0.6901[0m      [31m0.6901[0m        [94m1.1037[0m     +  0.0000  11.2935
      5      [36m0.9018[0m        [32m0.7935[0m       [35m0.6932[0m      [31m0.6932[0m        [94m1.0957[0m     +  0.0000  11.0146
      6      [36m0.9107[0m        [32m0.7603[0m       [35m0.7071[0m      [31m0.7071[0m        [94m1.0766[0m     +  0.0000  10.9563
      7      [36m0.9286[0m        [32m0.7228[0m       [35m0.7089[0m      [31m0.7089[0m        [94m1.0677[0m     +  0.0000  11.3112
      8      [36m0.9464[0m        [32m0.7037[0m       [35m0.7097[0m      [31m0.7097[0m        [94m1.0654[0m     +  0.0000  11.3314
      9      0.9286        [32m0.6892[0m       [35m0.7130[0m      [31m0.7130[0m        [94m1.0623[0m     +  0.0000  11.2989
     10      0.9375        0.6962       0.7116      0.7116        [94m1.0593[0m     +  0.0000  11.1258
     11      [36m0.9732[0m        [32m0.6648[0m       0.7115      0.7115        1.0594        0.0000  11.0801
     12      0.9464        [32m0.6618[0m       0.7118      0.7118        [94m1.0589[0m     +  0.0000  11.1268
     13      0.9554        0.6652       0.7123      0.7123        [94m1.0587[0m     +  0.0000  11.1405
     14      0.9464        [32m0.6501[0m       [35m0.7134[0m      [31m0.7134[0m        [94m1.0581[0m     +  0.0000  11.0492
     15      0.9375        0.6658       0.7125      0.7125        [94m1.0572[0m     +  0.0000  11.0911
     16      0.9643        0.6530       0.7130      0.7130        [94m1.0571[0m     +  0.0000  11.2946
     17      0.9464        0.6555       0.7127      0.7127        [94m1.0570[0m     +  0.0000  11.1561
     18      0.9375        0.6632       0.7123      0.7123        [94m1.0569[0m     +  0.0000  11.1441
     19      0.9464        [32m0.6480[0m       0.7118      0.7118        [94m1.0568[0m     +  0.0000  11.0451
     20      0.9464        0.6506       0.7120      0.7120        [94m1.0567[0m     +  0.0000  11.2211
     21      0.9375        [32m0.6376[0m       0.7120      0.7120        [94m1.0567[0m     +  0.0000  11.1561
     22      0.9554        0.6416       0.7122      0.7122        [94m1.0567[0m     +  0.0000  11.1447
     23      0.9643        0.6683       0.7125      0.7125        [94m1.0566[0m     +  0.0000  11.3288
     24      0.9554        0.6756       0.7125      0.7125        1.0566        0.0000  11.1684
     25      0.9464        0.6490       0.7125      0.7125        [94m1.0566[0m     +  0.0000  11.6408
     26      0.9464        0.7081       0.7125      0.7125        1.0566        0.0000  10.9999
     27      0.9375        0.6783       0.7125      0.7125        [94m1.0566[0m     +  0.0000  11.1100
     28      0.9375        0.6726       0.7125      0.7125        [94m1.0566[0m     +  0.0000  11.3405
     29      0.9554        0.6499       0.7125      0.7125        [94m1.0566[0m     +  0.0000  11.2281
     30      0.9464        0.6919       0.7125      0.7125        1.0566        0.0000  11.0902
     31      0.9554        0.6639       0.7125      0.7125        1.0566        0.0000  11.0486
     32      0.9554        0.6586       0.7125      0.7125        1.0566        0.0000  11.2399
     33      0.9464        0.6465       0.7125      0.7125        1.0566        0.0000  11.1747
     34      0.9286        0.6767       0.7125      0.7125        1.0566        0.0000  11.0539
     35      0.9286        0.6787       0.7125      0.7125        [94m1.0566[0m     +  0.0000  11.2616
     36      0.9554        0.6483       0.7125      0.7125        [94m1.0566[0m     +  0.0000  11.2332
     37      0.9643        [32m0.6336[0m       0.7125      0.7125        [94m1.0566[0m     +  0.0000  11.3022
     38      0.9464        0.6450       0.7125      0.7125        [94m1.0566[0m     +  0.0000  11.2225
     39      0.9643        0.6633       0.7125      0.7125        [94m1.0566[0m     +  0.0000  11.1286
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.7394097222222222
F1 Macro Score after query 3: 0.3024178955433601
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7212[0m        [32m1.0546[0m       [35m0.6757[0m      [31m0.6757[0m        [94m1.1576[0m     +  0.0000  11.9073
      2      [36m0.8269[0m        [32m0.8880[0m       [35m0.7434[0m      [31m0.7434[0m        [94m1.0997[0m     +  0.0000  11.8476
      3      [36m0.8798[0m        [32m0.7575[0m       [35m0.7634[0m      [31m0.7634[0m        [94m1.0600[0m     +  0.0000  11.6401
      4      [36m0.9423[0m        [32m0.6839[0m       0.7540      0.7540        [94m1.0114[0m     +  0.0000  11.8296
      5      [36m0.9471[0m        [32m0.6325[0m       0.7512      0.7512        [94m1.0093[0m     +  0.0000  11.8283
      6      0.9471        [32m0.5978[0m       0.7378      0.7378        [94m0.9635[0m     +  0.0000  11.6748
      7      [36m0.9615[0m        [32m0.5723[0m       0.7415      0.7415        [94m0.9559[0m     +  0.0000  11.9529
      8      [36m0.9663[0m        [32m0.5524[0m       0.7391      0.7391        [94m0.9549[0m     +  0.0000  11.8261
      9      0.9567        [32m0.5382[0m       0.7403      0.7403        [94m0.9509[0m     +  0.0000  11.4790
     10      0.9615        0.5498       0.7429      0.7429        [94m0.9494[0m     +  0.0000  11.6573
     11      [36m0.9712[0m        [32m0.5263[0m       0.7458      0.7458        [94m0.9458[0m     +  0.0000  11.7046
     12      0.9615        0.5330       0.7446      0.7446        [94m0.9450[0m     +  0.0000  11.6739
     13      0.9663        [32m0.5217[0m       0.7451      0.7451        [94m0.9432[0m     +  0.0000  11.6370
     14      0.9615        0.5469       0.7443      0.7443        [94m0.9431[0m     +  0.0000  11.7180
     15      0.9712        [32m0.5010[0m       0.7444      0.7444        [94m0.9414[0m     +  0.0000  11.6734
     16      0.9712        0.5177       0.7446      0.7446        [94m0.9411[0m     +  0.0000  11.8875
     17      0.9712        0.5147       0.7446      0.7446        [94m0.9410[0m     +  0.0000  11.7112
     18      0.9615        0.5297       0.7439      0.7439        [94m0.9409[0m     +  0.0000  11.8851
     19      [36m0.9760[0m        0.5143       0.7439      0.7439        [94m0.9408[0m     +  0.0000  11.7326
     20      0.9712        0.5189       0.7441      0.7441        [94m0.9406[0m     +  0.0000  12.2909
     21      0.9712        0.5078       0.7438      0.7438        [94m0.9406[0m     +  0.0000  11.6377
     22      0.9663        0.5246       0.7438      0.7438        [94m0.9405[0m     +  0.0000  11.8237
     23      0.9663        0.5189       0.7438      0.7438        [94m0.9405[0m     +  0.0000  11.7144
     24      0.9760        0.5168       0.7438      0.7438        [94m0.9404[0m     +  0.0000  11.8403
     25      0.9663        0.5244       0.7438      0.7438        [94m0.9404[0m     +  0.0000  11.8867
     26      0.9567        0.5184       0.7438      0.7438        [94m0.9404[0m     +  0.0000  11.7742
     27      0.9760        0.5185       0.7438      0.7438        [94m0.9404[0m     +  0.0000  11.6367
     28      0.9615        0.5378       0.7438      0.7438        [94m0.9403[0m     +  0.0000  11.8583
     29      0.9712        0.5428       0.7438      0.7438        [94m0.9403[0m     +  0.0000  11.6984
     30      0.9760        0.5071       0.7438      0.7438        [94m0.9403[0m     +  0.0000  12.0913
     31      0.9760        0.5123       0.7438      0.7438        [94m0.9403[0m     +  0.0000  11.8993
     32      0.9760        0.5260       0.7438      0.7438        [94m0.9403[0m     +  0.0000  11.6707
     33      0.9712        0.5058       0.7438      0.7438        [94m0.9403[0m     +  0.0000  11.7008
     34      0.9760        0.5073       0.7438      0.7438        0.9403        0.0000  11.8195
     35      0.9615        0.5343       0.7438      0.7438        [94m0.9403[0m     +  0.0000  11.7345
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.7932291666666667
F1 Macro Score after query 4: 0.37622168159260705
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7240[0m        [32m0.9061[0m       [35m0.7722[0m      [31m0.7722[0m        [94m0.9465[0m     +  0.0000  12.8259
      2      [36m0.8932[0m        [32m0.6674[0m       [35m0.7825[0m      [31m0.7825[0m        [94m0.8621[0m     +  0.0000  12.9064
      3      [36m0.9479[0m        [32m0.5637[0m       0.7649      0.7649        0.8718        0.0000  12.7403
      4      [36m0.9557[0m        [32m0.5106[0m       0.7781      0.7781        [94m0.8362[0m     +  0.0000  12.6569
      5      [36m0.9609[0m        [32m0.4663[0m       [35m0.7837[0m      [31m0.7837[0m        [94m0.8160[0m     +  0.0000  12.7534
      6      [36m0.9766[0m        [32m0.4222[0m       [35m0.7875[0m      [31m0.7875[0m        [94m0.8069[0m     +  0.0000  12.9324
      7      0.9740        0.4242       0.7849      0.7849        0.8083        0.0000  12.6855
      8      [36m0.9792[0m        [32m0.4087[0m       0.7875      0.7875        [94m0.8045[0m     +  0.0000  12.8435
      9      [36m0.9818[0m        [32m0.3910[0m       [35m0.7885[0m      [31m0.7885[0m        [94m0.8005[0m     +  0.0000  12.9222
     10      0.9792        [32m0.3811[0m       0.7866      0.7866        0.8005        0.0000  12.6246
     11      0.9818        0.3863       0.7875      0.7875        [94m0.7985[0m     +  0.0000  12.7249
     12      0.9818        0.3841       0.7873      0.7873        [94m0.7978[0m     +  0.0000  12.9959
     13      [36m0.9844[0m        [32m0.3801[0m       0.7880      0.7880        [94m0.7965[0m     +  0.0000  12.8312
     14      0.9844        [32m0.3657[0m       0.7882      0.7882        [94m0.7960[0m     +  0.0000  12.8671
     15      0.9818        0.3734       0.7873      0.7873        [94m0.7955[0m     +  0.0000  12.8521
     16      0.9844        0.3725       0.7877      0.7877        [94m0.7951[0m     +  0.0000  12.8315
     17      [36m0.9870[0m        0.3733       0.7877      0.7877        [94m0.7946[0m     +  0.0000  12.8856
     18      0.9844        0.3716       0.7877      0.7877        [94m0.7944[0m     +  0.0000  12.9150
     19      0.9844        0.3696       0.7884      0.7884        0.7945        0.0000  12.7048
     20      0.9818        0.3740       [35m0.7896[0m      [31m0.7896[0m        [94m0.7940[0m     +  0.0000  12.9530
     21      0.9844        0.3729       0.7894      0.7894        [94m0.7939[0m     +  0.0000  12.7707
     22      0.9844        0.3741       0.7894      0.7894        [94m0.7939[0m     +  0.0000  12.8965
     23      0.9844        0.3687       0.7892      0.7892        [94m0.7939[0m     +  0.0000  12.6570
     24      0.9844        [32m0.3639[0m       0.7892      0.7892        [94m0.7939[0m     +  0.0000  12.9255
     25      0.9818        [32m0.3568[0m       0.7891      0.7891        [94m0.7938[0m     +  0.0000  12.7959
     26      0.9844        0.3767       0.7891      0.7891        0.7938        0.0000  12.9459
     27      0.9844        0.3774       0.7891      0.7891        [94m0.7938[0m     +  0.0000  12.7558
     28      0.9844        0.3605       0.7891      0.7891        0.7938        0.0000  12.8364
     29      0.9844        0.3581       0.7892      0.7892        0.7938        0.0000  12.9436
     30      0.9792        0.3759       0.7892      0.7892        [94m0.7938[0m     +  0.0000  12.8231
     31      0.9844        0.3651       0.7892      0.7892        0.7938        0.0000  12.6826
     32      0.9844        0.3656       0.7892      0.7892        [94m0.7938[0m     +  0.0000  12.8796
     33      0.9844        0.3696       0.7892      0.7892        [94m0.7938[0m     +  0.0000  12.8111
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.8170138888888889
F1 Macro Score after query 5: 0.4287478720454252
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8466[0m        [32m0.6616[0m       [35m0.8139[0m      [31m0.8139[0m        [94m0.7186[0m     +  0.0000  14.9639
      2      [36m0.9162[0m        [32m0.5110[0m       [35m0.8144[0m      [31m0.8144[0m        [94m0.6806[0m     +  0.0000  14.7124
      3      [36m0.9403[0m        [32m0.4206[0m       [35m0.8311[0m      [31m0.8311[0m        [94m0.6523[0m     +  0.0000  14.9078
      4      [36m0.9560[0m        [32m0.3855[0m       0.8210      0.8210        0.6647        0.0000  14.8940
      5      [36m0.9588[0m        [32m0.3512[0m       0.8203      0.8203        0.6591        0.0000  14.8156
      6      [36m0.9645[0m        [32m0.3302[0m       0.8038      0.8038        0.6750        0.0000  14.6183
      7      [36m0.9744[0m        [32m0.3113[0m       0.8042      0.8042        0.6632        0.0000  14.6865
      8      0.9744        [32m0.2962[0m       0.8021      0.8021        0.6681        0.0000  15.0466
      9      [36m0.9787[0m        0.3018       0.8071      0.8071        0.6658        0.0000  14.6455
     10      [36m0.9801[0m        [32m0.2886[0m       0.8007      0.8007        0.6704        0.0000  14.6055
     11      [36m0.9830[0m        [32m0.2798[0m       0.8158      0.8158        0.6559        0.0000  14.7348
     12      [36m0.9844[0m        0.2880       0.8148      0.8148        0.6619        0.0000  14.9062
     13      0.9830        [32m0.2724[0m       0.8142      0.8142        0.6621        0.0000  14.7445
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8182291666666666
F1 Macro Score after query 6: 0.3897804921347105
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8157[0m        [32m0.6980[0m       [35m0.8385[0m      [31m0.8385[0m        [94m0.6325[0m     +  0.0000  18.2498
      2      [36m0.8908[0m        [32m0.5158[0m       0.8194      0.8194        [94m0.6302[0m     +  0.0000  18.0648
      3      [36m0.9106[0m        [32m0.4663[0m       0.8226      0.8226        [94m0.6239[0m     +  0.0000  17.9123
      4      [36m0.9272[0m        [32m0.4111[0m       0.8085      0.8085        0.6578        0.0000  18.1410
      5      [36m0.9446[0m        [32m0.3792[0m       0.8153      0.8153        0.6776        0.0000  18.2393
      6      [36m0.9509[0m        [32m0.3319[0m       0.8094      0.8094        0.6517        0.0000  18.3342
      7      [36m0.9589[0m        [32m0.3109[0m       0.8092      0.8092        0.6503        0.0000  18.2292
      8      [36m0.9620[0m        [32m0.3006[0m       0.8111      0.8111        0.6450        0.0000  18.0645
      9      [36m0.9644[0m        [32m0.2981[0m       0.8111      0.8111        0.6481        0.0000  17.8634
     10      [36m0.9668[0m        [32m0.2799[0m       0.8115      0.8115        0.6430        0.0000  18.1798
     11      [36m0.9676[0m        [32m0.2722[0m       0.8132      0.8132        0.6355        0.0000  18.0452
     12      0.9668        0.2780       0.8137      0.8137        0.6351        0.0000  17.8891
     13      [36m0.9684[0m        [32m0.2664[0m       0.8146      0.8146        0.6350        0.0000  18.1288
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.8423611111111111
F1 Macro Score after query 7: 0.4529809156966441
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8229[0m        [32m0.6353[0m       [35m0.8113[0m      [31m0.8113[0m        [94m0.6609[0m     +  0.0000  23.9289
      2      [36m0.8865[0m        [32m0.4958[0m       0.8026      0.8026        0.6654        0.0000  24.2428
      3      [36m0.9099[0m        [32m0.4330[0m       0.8094      0.8094        0.6626        0.0000  24.3450
      4      [36m0.9258[0m        [32m0.3805[0m       0.8108      0.8108        [94m0.6577[0m     +  0.0000  24.4249
      5      [36m0.9382[0m        [32m0.3485[0m       0.7880      0.7880        0.6887        0.0000  24.3483
      6      [36m0.9501[0m        [32m0.2984[0m       0.8050      0.8050        [94m0.6460[0m     +  0.0000  24.1407
      7      [36m0.9549[0m        [32m0.2822[0m       [35m0.8115[0m      [31m0.8115[0m        [94m0.6294[0m     +  0.0000  24.3106
      8      [36m0.9594[0m        [32m0.2673[0m       0.8083      0.8083        0.6425        0.0000  24.3902
      9      [36m0.9647[0m        [32m0.2569[0m       0.8085      0.8085        0.6469        0.0000  24.0613
     10      [36m0.9713[0m        [32m0.2446[0m       0.8097      0.8097        0.6452        0.0000  23.9080
     11      [36m0.9726[0m        [32m0.2354[0m       0.8113      0.8113        0.6443        0.0000  24.1402
     12      [36m0.9761[0m        [32m0.2280[0m       0.8102      0.8102        0.6477        0.0000  24.3179
     13      [36m0.9775[0m        [32m0.2256[0m       0.8097      0.8097        0.6499        0.0000  24.0451
     14      0.9757        0.2260       0.8102      0.8102        0.6503        0.0000  23.8229
     15      0.9770        [32m0.2233[0m       0.8106      0.8106        0.6515        0.0000  24.1896
     16      [36m0.9806[0m        [32m0.2145[0m       0.8104      0.8104        0.6473        0.0000  23.9687
     17      [36m0.9814[0m        0.2169       0.8102      0.8102        0.6476        0.0000  24.3136
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8487847222222222
F1 Macro Score after query 8: 0.49224003924302034
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8829[0m        [32m0.4668[0m       [35m0.8330[0m      [31m0.8330[0m        [94m0.5704[0m     +  0.0000  34.5387
      2      [36m0.9062[0m        [32m0.3901[0m       [35m0.8373[0m      [31m0.8373[0m        [94m0.5539[0m     +  0.0000  34.9741
      3      [36m0.9213[0m        [32m0.3467[0m       0.8307      0.8307        0.5614        0.0000  35.0470
      4      [36m0.9342[0m        [32m0.3143[0m       0.8219      0.8219        0.5787        0.0000  35.0509
      5      [36m0.9441[0m        [32m0.2744[0m       0.8271      0.8271        0.5649        0.0000  34.7967
      6      [36m0.9545[0m        [32m0.2400[0m       0.8333      0.8333        [94m0.5504[0m     +  0.0000  34.9425
      7      [36m0.9639[0m        [32m0.2154[0m       0.8325      0.8325        0.5672        0.0000  35.0209
      8      [36m0.9668[0m        [32m0.1987[0m       0.8314      0.8314        0.5756        0.0000  34.8750
      9      [36m0.9700[0m        [32m0.1912[0m       0.8288      0.8288        0.5890        0.0000  34.7416
     10      [36m0.9713[0m        [32m0.1846[0m       0.8280      0.8280        0.5967        0.0000  35.2565
     11      [36m0.9782[0m        [32m0.1722[0m       0.8255      0.8255        0.6071        0.0000  35.0001
     12      [36m0.9827[0m        [32m0.1677[0m       0.8266      0.8266        0.6076        0.0000  35.1407
     13      0.9804        [32m0.1650[0m       0.8262      0.8262        0.6121        0.0000  34.9222
     14      [36m0.9832[0m        [32m0.1637[0m       0.8267      0.8267        0.6146        0.0000  35.1874
     15      0.9827        [32m0.1597[0m       0.8260      0.8260        0.6156        0.0000  35.1721
     16      [36m0.9854[0m        [32m0.1561[0m       0.8266      0.8266        0.6149        0.0000  34.7812
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8390625000000002
F1 Macro Score after query 9: 0.5357815197931501
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9415[0m        [32m0.2758[0m       [35m0.7990[0m      [31m0.7990[0m        [94m0.6346[0m     +  0.0000  54.3127
      2      [36m0.9461[0m        [32m0.2401[0m       [35m0.8118[0m      [31m0.8118[0m        [94m0.5987[0m     +  0.0000  54.3437
      3      [36m0.9524[0m        [32m0.2124[0m       [35m0.8222[0m      [31m0.8222[0m        [94m0.5825[0m     +  0.0000  54.1047
      4      [36m0.9617[0m        [32m0.1856[0m       0.8137      0.8137        0.6155        0.0000  54.4152
      5      [36m0.9665[0m        [32m0.1630[0m       0.8043      0.8043        0.6431        0.0000  54.3822
      6      [36m0.9774[0m        [32m0.1289[0m       0.8194      0.8194        0.5975        0.0000  53.9219
      7      [36m0.9815[0m        [32m0.1157[0m       0.8186      0.8186        0.6142        0.0000  54.0562
      8      [36m0.9849[0m        [32m0.1078[0m       0.8153      0.8153        0.6441        0.0000  54.5310
      9      [36m0.9872[0m        [32m0.0985[0m       0.8182      0.8182        0.6509        0.0000  54.5940
     10      [36m0.9885[0m        [32m0.0930[0m       0.8215      0.8215        0.6619        0.0000  54.0502
     11      [36m0.9918[0m        [32m0.0846[0m       0.8132      0.8132        0.6837        0.0000  54.3589
     12      [36m0.9924[0m        [32m0.0807[0m       0.8146      0.8146        0.6844        0.0000  54.6130
     13      [36m0.9925[0m        [32m0.0787[0m       0.8141      0.8141        0.6906        0.0000  53.9794
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8371527777777777
F1 Macro Score after query 10: 0.5459637764246685
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9513[0m        [32m0.2133[0m       [35m0.7882[0m      [31m0.7882[0m        [94m0.7019[0m     +  0.0000  87.7185
      2      [36m0.9561[0m        [32m0.1881[0m       [35m0.8420[0m      [31m0.8420[0m        [94m0.5234[0m     +  0.0000  88.0783
      3      [36m0.9615[0m        [32m0.1632[0m       0.8087      0.8087        0.6153        0.0000  88.7589
      4      [36m0.9648[0m        [32m0.1429[0m       0.7944      0.7944        0.7099        0.0000  89.4238
      5      [36m0.9680[0m        [32m0.1289[0m       0.8335      0.8335        0.5817        0.0000  88.1977
      6      [36m0.9779[0m        [32m0.0997[0m       0.8104      0.8104        0.6558        0.0000  88.6314
      7      [36m0.9845[0m        [32m0.0848[0m       0.8153      0.8153        0.6631        0.0000  89.2869
      8      [36m0.9864[0m        [32m0.0779[0m       0.8122      0.8122        0.6895        0.0000  88.5759
      9      [36m0.9884[0m        [32m0.0698[0m       0.8144      0.8144        0.7182        0.0000  88.2978
     10      [36m0.9900[0m        [32m0.0638[0m       0.8174      0.8174        0.6971        0.0000  89.2186
     11      [36m0.9924[0m        [32m0.0556[0m       0.8247      0.8247        0.6998        0.0000  88.8907
     12      [36m0.9929[0m        [32m0.0527[0m       0.8247      0.8247        0.7061        0.0000  88.5622
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8411458333333333
F1 Macro Score after query 11: 0.5369114026009839
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9725[0m        [32m0.1247[0m       [35m0.8092[0m      [31m0.8092[0m        [94m0.7354[0m     +  0.0000  149.7937
      2      [36m0.9749[0m        [32m0.1053[0m       [35m0.8217[0m      [31m0.8217[0m        [94m0.6291[0m     +  0.0000  150.5467
      3      [36m0.9778[0m        [32m0.0922[0m       0.8165      0.8165        0.6642        0.0000  150.0936
      4      [36m0.9795[0m        [32m0.0818[0m       0.8200      0.8200        0.7338        0.0000  150.4866
      5      [36m0.9811[0m        [32m0.0737[0m       0.8196      0.8196        0.6662        0.0000  150.5716
      6      [36m0.9865[0m        [32m0.0565[0m       0.8155      0.8155        0.7177        0.0000  150.6716
      7      [36m0.9909[0m        [32m0.0447[0m       0.8125      0.8125        0.7388        0.0000  150.3315
      8      [36m0.9925[0m        [32m0.0391[0m       [35m0.8240[0m      [31m0.8240[0m        0.7442        0.0000  150.0400
      9      [36m0.9938[0m        [32m0.0347[0m       [35m0.8281[0m      [31m0.8281[0m        0.7466        0.0000  151.0944
     10      [36m0.9955[0m        [32m0.0295[0m       0.8257      0.8257        0.7634        0.0000  150.3725
     11      [36m0.9961[0m        [32m0.0266[0m       [35m0.8293[0m      [31m0.8293[0m        0.7545        0.0000  150.6746
     12      [36m0.9969[0m        [32m0.0239[0m       0.8288      0.8288        0.7593        0.0000  150.4185
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8574652777777778
F1 Macro Score after query 12: 0.546790631692627
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9808[0m        [32m0.0817[0m       [35m0.7965[0m      [31m0.7965[0m        [94m0.8779[0m     +  0.0000  174.5942
      2      [36m0.9816[0m        [32m0.0719[0m       [35m0.8212[0m      [31m0.8212[0m        [94m0.6368[0m     +  0.0000  175.2981
      3      [36m0.9836[0m        [32m0.0633[0m       [35m0.8219[0m      [31m0.8219[0m        0.6845        0.0000  175.0954
      4      [36m0.9842[0m        [32m0.0589[0m       0.8023      0.8023        0.8401        0.0000  174.4833
      5      [36m0.9867[0m        [32m0.0511[0m       0.8075      0.8075        0.9175        0.0000  175.6035
      6      [36m0.9907[0m        [32m0.0385[0m       0.8132      0.8132        0.8042        0.0000  175.4662
      7      [36m0.9942[0m        [32m0.0284[0m       0.8163      0.8163        0.8163        0.0000  157.7345
      8      [36m0.9955[0m        [32m0.0253[0m       0.8175      0.8175        0.8135        0.0000  139.2564
      9      [36m0.9961[0m        [32m0.0214[0m       0.8153      0.8153        0.8428        0.0000  140.2790
     10      [36m0.9971[0m        [32m0.0178[0m       0.8149      0.8149        0.8794        0.0000  141.3385
     11      [36m0.9977[0m        [32m0.0160[0m       0.8208      0.8208        0.8660        0.0000  155.3328
     12      [36m0.9983[0m        [32m0.0140[0m       0.8194      0.8194        0.8774        0.0000  168.7812
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8588541666666667
F1 Macro Score after query 13: 0.5769772940047713
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed45\AL_margin_sampling_results_for_multiclass_classification_s45.pickle
