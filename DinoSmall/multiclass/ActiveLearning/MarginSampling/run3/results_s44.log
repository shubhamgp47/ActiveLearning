(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2500[0m        [32m2.0680[0m       [35m0.0681[0m      [31m0.0681[0m        [94m2.0433[0m     +  0.0000  11.5722
      2      0.1250        [32m2.0342[0m       [35m0.0974[0m      [31m0.0974[0m        2.0815        0.0000  10.6417
      3      0.1250        [32m1.8353[0m       0.0868      0.0868        2.0730        0.0000  10.4167
      4      0.2500        1.8643       [35m0.2356[0m      [31m0.2356[0m        [94m2.0238[0m     +  0.0000  10.8063
      5      [36m0.3750[0m        [32m1.7453[0m       0.0925      0.0925        2.1370        0.0000  10.5358
      6      [36m0.7500[0m        [32m1.5699[0m       0.1229      0.1229        2.1193        0.0000  10.9840
      7      0.7500        [32m1.4449[0m       0.1455      0.1455        2.1077        0.0000  10.6569
      8      [36m0.8750[0m        [32m1.4169[0m       0.1530      0.1530        2.1011        0.0000  10.6767
      9      0.7500        1.4854       0.1488      0.1488        2.1046        0.0000  11.0098
     10      0.7500        1.4983       0.1623      0.1623        2.0929        0.0000  10.9590
     11      [36m1.0000[0m        [32m1.3437[0m       0.1622      0.1622        2.0925        0.0000  10.7121
     12      0.8750        [32m1.2569[0m       0.1611      0.1611        2.0942        0.0000  10.8228
     13      0.7500        1.4251       0.1618      0.1618        2.0936        0.0000  10.9122
     14      0.7500        1.3116       0.1623      0.1623        2.0940        0.0000  10.6621
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.1825
Pre F1 macro score = 0.1215

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5000[0m        [32m1.7560[0m       [35m0.4344[0m      [31m0.4344[0m        [94m1.7139[0m     +  0.0000  10.8867
      2      0.4583        [32m1.7049[0m       0.4240      0.4240        1.7533        0.0000  10.8147
      3      [36m0.5833[0m        [32m1.5327[0m       0.3918      0.3918        1.7431        0.0000  10.9271
      4      [36m0.7083[0m        [32m1.3066[0m       0.3484      0.3484        1.7701        0.0000  11.0052
      5      0.7083        [32m1.3027[0m       0.4208      0.4208        1.7328        0.0000  10.9221
      6      [36m0.8333[0m        [32m1.1783[0m       0.4097      0.4097        1.7281        0.0000  10.9685
      7      0.7083        1.2786       0.4141      0.4141        1.7287        0.0000  10.9322
      8      0.7917        1.1841       [35m0.4406[0m      [31m0.4406[0m        1.7263        0.0000  10.9423
      9      0.8333        [32m1.1350[0m       [35m0.4467[0m      [31m0.4467[0m        1.7252        0.0000  10.9640
     10      0.8333        [32m1.1310[0m       0.4439      0.4439        1.7262        0.0000  10.8590
     11      0.7917        1.1563       0.4460      0.4460        1.7253        0.0000  10.9690
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.4439236111111111
F1 Macro Score after query 1: 0.2332735786521486
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.3750[0m        [32m1.7210[0m       [35m0.4849[0m      [31m0.4849[0m        [94m1.6236[0m     +  0.0000  11.1212
      2      [36m0.4821[0m        [32m1.5966[0m       [35m0.5188[0m      [31m0.5188[0m        [94m1.5764[0m     +  0.0000  10.9947
      3      [36m0.6607[0m        [32m1.4218[0m       0.4722      0.4722        [94m1.5728[0m     +  0.0000  11.1910
      4      0.6429        [32m1.3172[0m       [35m0.5436[0m      [31m0.5436[0m        [94m1.5219[0m     +  0.0000  11.2460
      5      [36m0.6964[0m        [32m1.2477[0m       0.5363      0.5363        [94m1.5000[0m     +  0.0000  10.8858
      6      [36m0.8036[0m        [32m1.1490[0m       [35m0.5543[0m      [31m0.5543[0m        [94m1.4663[0m     +  0.0000  11.0591
      7      0.7500        1.1661       [35m0.5597[0m      [31m0.5597[0m        [94m1.4526[0m     +  0.0000  11.1371
      8      0.7321        [32m1.0996[0m       [35m0.5644[0m      [31m0.5644[0m        [94m1.4495[0m     +  0.0000  11.0757
      9      0.7500        1.1551       0.5639      0.5639        [94m1.4410[0m     +  0.0000  11.1658
     10      0.7500        1.1291       [35m0.5653[0m      [31m0.5653[0m        [94m1.4382[0m     +  0.0000  11.1823
     11      0.7679        [32m1.0550[0m       0.5646      0.5646        [94m1.4366[0m     +  0.0000  11.2113
     12      0.8036        [32m1.0477[0m       0.5632      0.5632        [94m1.4346[0m     +  0.0000  11.0889
     13      0.7857        1.0892       0.5630      0.5630        [94m1.4333[0m     +  0.0000  11.2613
     14      0.7679        1.1272       0.5623      0.5623        [94m1.4326[0m     +  0.0000  11.0887
     15      0.7857        [32m1.0189[0m       0.5622      0.5622        [94m1.4322[0m     +  0.0000  11.0735
     16      0.7679        1.1027       0.5622      0.5622        [94m1.4321[0m     +  0.0000  11.1999
     17      [36m0.8571[0m        [32m0.9858[0m       0.5623      0.5623        [94m1.4320[0m     +  0.0000  10.9885
     18      0.7500        1.0741       0.5625      0.5625        [94m1.4319[0m     +  0.0000  11.1681
     19      0.8036        1.0310       0.5622      0.5622        [94m1.4315[0m     +  0.0000  10.9170
     20      0.7500        1.0761       0.5623      0.5623        [94m1.4313[0m     +  0.0000  11.1204
     21      0.8036        1.0582       0.5623      0.5623        [94m1.4313[0m     +  0.0000  11.1520
     22      0.7321        1.0111       0.5622      0.5622        [94m1.4312[0m     +  0.0000  11.0274
     23      0.8393        1.0353       0.5620      0.5620        [94m1.4311[0m     +  0.0000  11.0562
     24      0.7679        1.0513       0.5618      0.5618        [94m1.4311[0m     +  0.0000  11.0402
     25      0.8036        1.0362       0.5618      0.5618        [94m1.4310[0m     +  0.0000  11.0436
     26      0.7857        1.0819       0.5618      0.5618        [94m1.4310[0m     +  0.0000  11.0736
     27      0.7679        1.1219       0.5618      0.5618        1.4310        0.0000  11.1984
     28      0.7857        1.0221       0.5618      0.5618        [94m1.4310[0m     +  0.0000  11.1215
     29      0.7857        1.0321       0.5618      0.5618        [94m1.4310[0m     +  0.0000  11.0889
     30      0.7679        1.0390       0.5618      0.5618        [94m1.4310[0m     +  0.0000  11.2467
     31      0.8214        1.0130       0.5618      0.5618        [94m1.4309[0m     +  0.0000  10.9161
     32      0.7321        1.0420       0.5618      0.5618        [94m1.4309[0m     +  0.0000  11.1347
     33      0.8036        1.0343       0.5618      0.5618        [94m1.4309[0m     +  0.0000  11.1662
     34      0.8036        1.0690       0.5618      0.5618        [94m1.4309[0m     +  0.0000  11.1396
     35      0.7857        1.0494       0.5618      0.5618        [94m1.4309[0m     +  0.0000  10.9409
     36      0.7857        1.0740       0.5618      0.5618        [94m1.4309[0m     +  0.0000  11.0729
     37      0.7679        1.0789       0.5618      0.5618        [94m1.4309[0m     +  0.0000  11.0114
     38      0.7857        1.0143       0.5618      0.5618        [94m1.4309[0m     +  0.0000  11.1044
     39      0.8214        1.0350       0.5618      0.5618        [94m1.4309[0m     +  0.0000  11.2154
     40      0.7679        1.0724       0.5618      0.5618        [94m1.4309[0m     +  0.0000  11.7145
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.6090277777777777
F1 Macro Score after query 2: 0.17191307742965328
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.4911[0m        [32m1.4842[0m       [35m0.5969[0m      [31m0.5969[0m        [94m1.3934[0m     +  0.0000  11.4296
      2      [36m0.6161[0m        [32m1.3501[0m       [35m0.6425[0m      [31m0.6425[0m        [94m1.3036[0m     +  0.0000  11.5273
      3      [36m0.6875[0m        [32m1.1868[0m       [35m0.6477[0m      [31m0.6477[0m        [94m1.2563[0m     +  0.0000  11.3862
      4      [36m0.7143[0m        [32m1.1040[0m       0.6439      0.6439        [94m1.2301[0m     +  0.0000  11.3719
      5      [36m0.8036[0m        [32m1.0057[0m       [35m0.6679[0m      [31m0.6679[0m        [94m1.2290[0m     +  0.0000  11.4480
      6      [36m0.8482[0m        [32m0.9373[0m       [35m0.6696[0m      [31m0.6696[0m        [94m1.2025[0m     +  0.0000  11.7297
      7      [36m0.8750[0m        [32m0.9253[0m       [35m0.6738[0m      [31m0.6738[0m        [94m1.1915[0m     +  0.0000  11.3554
      8      0.8661        [32m0.8866[0m       [35m0.6740[0m      [31m0.6740[0m        [94m1.1905[0m     +  0.0000  11.4788
      9      [36m0.8839[0m        0.9066       [35m0.6745[0m      [31m0.6745[0m        [94m1.1868[0m     +  0.0000  11.4806
     10      0.8661        [32m0.8583[0m       [35m0.6762[0m      [31m0.6762[0m        1.1873        0.0000  11.2453
     11      0.8482        [32m0.8554[0m       0.6760      0.6760        [94m1.1855[0m     +  0.0000  11.4179
     12      0.8750        [32m0.8512[0m       0.6762      0.6762        [94m1.1842[0m     +  0.0000  11.4167
     13      0.8214        0.9234       [35m0.6771[0m      [31m0.6771[0m        [94m1.1832[0m     +  0.0000  11.2292
     14      0.8839        [32m0.8087[0m       0.6764      0.6764        [94m1.1823[0m     +  0.0000  11.4906
     15      0.8393        0.8413       0.6769      0.6769        [94m1.1819[0m     +  0.0000  11.3553
     16      [36m0.8929[0m        0.8524       0.6769      0.6769        [94m1.1816[0m     +  0.0000  11.3709
     17      0.8661        0.8373       [35m0.6773[0m      [31m0.6773[0m        1.1816        0.0000  11.3234
     18      0.8661        0.8735       [35m0.6774[0m      [31m0.6774[0m        [94m1.1814[0m     +  0.0000  11.4192
     19      0.8571        0.8767       0.6774      0.6774        [94m1.1814[0m     +  0.0000  11.3083
     20      0.8839        0.8693       0.6774      0.6774        [94m1.1811[0m     +  0.0000  11.3857
     21      0.8929        0.8319       [35m0.6776[0m      [31m0.6776[0m        1.1812        0.0000  11.3841
     22      0.8750        0.8933       0.6776      0.6776        [94m1.1811[0m     +  0.0000  11.4644
     23      0.8571        0.8684       0.6776      0.6776        [94m1.1811[0m     +  0.0000  11.3437
     24      0.8839        0.8467       0.6776      0.6776        [94m1.1810[0m     +  0.0000  11.4322
     25      0.8393        0.8901       0.6776      0.6776        [94m1.1810[0m     +  0.0000  11.4479
     26      [36m0.9018[0m        0.8463       0.6776      0.6776        [94m1.1810[0m     +  0.0000  11.4006
     27      0.8661        0.8265       0.6776      0.6776        [94m1.1810[0m     +  0.0000  11.4321
     28      0.8839        0.8569       0.6776      0.6776        [94m1.1810[0m     +  0.0000  11.1837
     29      0.8661        0.8541       0.6776      0.6776        [94m1.1810[0m     +  0.0000  11.3552
     30      0.8571        0.8345       0.6776      0.6776        [94m1.1809[0m     +  0.0000  11.4336
     31      0.8839        0.8798       0.6776      0.6776        [94m1.1809[0m     +  0.0000  11.4499
     32      0.8571        0.8728       0.6776      0.6776        [94m1.1809[0m     +  0.0000  11.4032
     33      0.8929        0.8778       0.6776      0.6776        [94m1.1809[0m     +  0.0000  11.2229
     34      0.8839        0.8294       0.6776      0.6776        1.1809        0.0000  11.4169
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.7302083333333335
F1 Macro Score after query 3: 0.2841867189960498
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6875[0m        [32m1.1718[0m       [35m0.7314[0m      [31m0.7314[0m        [94m1.1263[0m     +  0.0000  12.3721
      2      [36m0.8029[0m        [32m0.9897[0m       [35m0.7498[0m      [31m0.7498[0m        [94m1.0783[0m     +  0.0000  12.3741
      3      [36m0.8750[0m        [32m0.8515[0m       0.7457      0.7457        [94m1.0483[0m     +  0.0000  11.8855
      4      [36m0.9087[0m        [32m0.7715[0m       0.7448      0.7448        [94m1.0429[0m     +  0.0000  11.9797
      5      [36m0.9327[0m        [32m0.7350[0m       0.7427      0.7427        [94m1.0304[0m     +  0.0000  12.1825
      6      [36m0.9519[0m        [32m0.6495[0m       0.7002      0.7002        [94m1.0222[0m     +  0.0000  11.7756
      7      [36m0.9615[0m        [32m0.6393[0m       0.7036      0.7036        [94m1.0149[0m     +  0.0000  11.7605
      8      0.9519        [32m0.6188[0m       0.7031      0.7031        1.0168        0.0000  11.9654
      9      0.9615        [32m0.6079[0m       0.7095      0.7095        [94m1.0090[0m     +  0.0000  12.0122
     10      [36m0.9663[0m        0.6162       0.7075      0.7075        [94m1.0052[0m     +  0.0000  11.9482
     11      [36m0.9712[0m        [32m0.5860[0m       0.7064      0.7064        1.0057        0.0000  12.0077
     12      0.9615        0.5956       0.7040      0.7040        1.0068        0.0000  11.8099
     13      0.9471        [32m0.5662[0m       0.7045      0.7045        1.0065        0.0000  12.0418
     14      0.9423        0.6024       0.7043      0.7043        1.0059        0.0000  11.9582
     15      0.9567        0.5977       0.7031      0.7031        1.0065        0.0000  12.3359
     16      0.9567        0.5756       0.7024      0.7024        1.0069        0.0000  12.0582
     17      0.9615        0.5879       0.7028      0.7028        1.0067        0.0000  12.0075
     18      0.9663        0.5671       0.7030      0.7030        1.0068        0.0000  11.8101
     19      0.9519        0.5835       0.7024      0.7024        1.0068        0.0000  12.1051
     20      0.9615        0.5675       0.7023      0.7023        1.0067        0.0000  11.8856
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.7347222222222223
F1 Macro Score after query 4: 0.2785886476802346
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6953[0m        [32m1.0131[0m       [35m0.7021[0m      [31m0.7021[0m        [94m1.0668[0m     +  0.0000  13.1070
      2      [36m0.8776[0m        [32m0.7660[0m       [35m0.7394[0m      [31m0.7394[0m        [94m0.9941[0m     +  0.0000  13.0453
      3      [36m0.9271[0m        [32m0.6533[0m       [35m0.7495[0m      [31m0.7495[0m        [94m0.9673[0m     +  0.0000  13.5750
      4      [36m0.9505[0m        [32m0.5729[0m       0.7316      0.7316        0.9703        0.0000  12.9832
      5      [36m0.9531[0m        [32m0.5170[0m       0.7387      0.7387        [94m0.9544[0m     +  0.0000  12.9325
      6      [36m0.9583[0m        [32m0.4882[0m       0.7474      0.7474        [94m0.9342[0m     +  0.0000  13.1663
      7      [36m0.9635[0m        [32m0.4776[0m       0.7465      0.7465        [94m0.9292[0m     +  0.0000  13.1400
      8      0.9583        [32m0.4543[0m       0.7425      0.7425        0.9350        0.0000  13.1211
      9      0.9557        [32m0.4514[0m       0.7458      0.7458        0.9322        0.0000  13.0596
     10      [36m0.9688[0m        [32m0.4364[0m       0.7429      0.7429        0.9322        0.0000  12.9134
     11      0.9661        [32m0.4138[0m       0.7405      0.7405        [94m0.9280[0m     +  0.0000  13.1894
     12      0.9661        0.4279       0.7385      0.7385        0.9285        0.0000  13.0567
     13      0.9661        0.4312       0.7406      0.7406        [94m0.9263[0m     +  0.0000  13.1072
     14      [36m0.9714[0m        0.4297       0.7382      0.7382        0.9285        0.0000  13.2646
     15      0.9688        0.4281       0.7406      0.7406        0.9266        0.0000  13.0282
     16      0.9661        0.4267       0.7401      0.7401        0.9263        0.0000  12.9795
     17      0.9661        0.4157       0.7384      0.7384        0.9268        0.0000  12.8270
     18      0.9661        0.4291       0.7392      0.7392        0.9263        0.0000  13.1234
     19      0.9661        0.4166       0.7387      0.7387        0.9266        0.0000  13.0903
     20      0.9688        0.4157       0.7382      0.7382        0.9267        0.0000  12.9796
     21      0.9661        0.4265       0.7384      0.7384        0.9265        0.0000  12.9906
     22      0.9714        0.4298       0.7380      0.7380        0.9266        0.0000  13.0292
     23      0.9714        0.4262       0.7382      0.7382        0.9264        0.0000  13.2938
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.76875
F1 Macro Score after query 5: 0.33816490294962964
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7912[0m        [32m0.7990[0m       [35m0.7781[0m      [31m0.7781[0m        [94m0.8448[0m     +  0.0000  15.0157
      2      [36m0.9048[0m        [32m0.6065[0m       [35m0.7783[0m      [31m0.7783[0m        0.8499        0.0000  14.9843
      3      [36m0.9332[0m        [32m0.4897[0m       0.7679      0.7679        0.8657        0.0000  15.0301
      4      [36m0.9503[0m        [32m0.4363[0m       0.7703      0.7703        0.8514        0.0000  15.2949
      5      0.9489        [32m0.4063[0m       [35m0.7786[0m      [31m0.7786[0m        [94m0.8441[0m     +  0.0000  15.0461
      6      [36m0.9645[0m        [32m0.3693[0m       0.7752      0.7752        [94m0.8229[0m     +  0.0000  14.7174
      7      [36m0.9673[0m        [32m0.3634[0m       [35m0.7828[0m      [31m0.7828[0m        [94m0.7953[0m     +  0.0000  14.8716
      8      0.9659        [32m0.3455[0m       0.7760      0.7760        0.8175        0.0000  14.8743
      9      [36m0.9716[0m        [32m0.3395[0m       0.7776      0.7776        0.8148        0.0000  15.1234
     10      [36m0.9801[0m        [32m0.3227[0m       0.7795      0.7795        0.8047        0.0000  14.8278
     11      0.9744        0.3276       0.7677      0.7677        0.8110        0.0000  15.0756
     12      0.9801        [32m0.3205[0m       0.7696      0.7696        0.8067        0.0000  15.1389
     13      [36m0.9815[0m        0.3247       0.7684      0.7684        0.8084        0.0000  14.9063
     14      [36m0.9844[0m        0.3285       0.7701      0.7701        0.8025        0.0000  14.8399
     15      0.9830        [32m0.3178[0m       0.7712      0.7712        0.7996        0.0000  15.0762
     16      [36m0.9872[0m        [32m0.2998[0m       0.7693      0.7693        0.8024        0.0000  14.8097
     17      0.9872        0.3059       0.7682      0.7682        0.8028        0.0000  15.1091
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8008680555555555
F1 Macro Score after query 6: 0.47170575825678723
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8331[0m        [32m0.7055[0m       [35m0.6821[0m      [31m0.6821[0m        [94m1.0151[0m     +  0.0000  18.2664
      2      [36m0.8877[0m        [32m0.5575[0m       [35m0.7344[0m      [31m0.7344[0m        [94m0.9070[0m     +  0.0000  18.2848
      3      [36m0.9138[0m        [32m0.4830[0m       [35m0.7373[0m      [31m0.7373[0m        0.9074        0.0000  18.3895
      4      [36m0.9264[0m        [32m0.4359[0m       [35m0.7432[0m      [31m0.7432[0m        [94m0.9049[0m     +  0.0000  18.2205
      5      [36m0.9517[0m        [32m0.3756[0m       [35m0.7677[0m      [31m0.7677[0m        [94m0.8237[0m     +  0.0000  18.1745
      6      [36m0.9597[0m        [32m0.3427[0m       [35m0.7925[0m      [31m0.7925[0m        [94m0.7354[0m     +  0.0000  18.3785
      7      [36m0.9668[0m        [32m0.3333[0m       [35m0.7941[0m      [31m0.7941[0m        [94m0.7332[0m     +  0.0000  18.2680
      8      [36m0.9699[0m        [32m0.3095[0m       [35m0.7943[0m      [31m0.7943[0m        0.7335        0.0000  18.2593
      9      [36m0.9739[0m        [32m0.3031[0m       0.7884      0.7884        0.7456        0.0000  18.3955
     10      0.9715        [32m0.3016[0m       0.7924      0.7924        [94m0.7326[0m     +  0.0000  18.4961
     11      [36m0.9747[0m        [32m0.2935[0m       [35m0.7988[0m      [31m0.7988[0m        [94m0.7137[0m     +  0.0000  18.1907
     12      [36m0.9778[0m        [32m0.2906[0m       [35m0.8019[0m      [31m0.8019[0m        [94m0.7091[0m     +  0.0000  18.2363
     13      0.9778        [32m0.2770[0m       0.7995      0.7995        0.7114        0.0000  18.4075
     14      0.9778        0.2814       0.7977      0.7977        0.7157        0.0000  18.2874
     15      0.9771        0.2790       0.8010      0.8010        [94m0.7090[0m     +  0.0000  18.4270
     16      [36m0.9802[0m        0.2803       0.8009      0.8009        0.7093        0.0000  18.4090
     17      [36m0.9842[0m        [32m0.2724[0m       0.7991      0.7991        0.7116        0.0000  18.3617
     18      0.9802        0.2765       0.7995      0.7995        0.7101        0.0000  18.2692
     19      0.9818        [32m0.2701[0m       0.8012      0.8012        [94m0.7077[0m     +  0.0000  18.2915
     20      0.9826        0.2715       0.8007      0.8007        0.7093        0.0000  18.2379
     21      0.9802        0.2730       0.8007      0.8007        0.7092        0.0000  18.3933
     22      0.9786        0.2713       0.8009      0.8009        0.7098        0.0000  18.3131
     23      0.9826        0.2715       0.8009      0.8009        0.7094        0.0000  18.3130
     24      [36m0.9850[0m        0.2701       0.8009      0.8009        0.7098        0.0000  18.3558
     25      0.9810        0.2722       0.8005      0.8005        0.7101        0.0000  18.2184
     26      0.9842        [32m0.2677[0m       0.8005      0.8005        0.7102        0.0000  18.3919
     27      0.9818        0.2681       0.8005      0.8005        0.7102        0.0000  18.4713
     28      0.9826        0.2692       0.8005      0.8005        0.7103        0.0000  18.2198
     29      0.9842        0.2680       0.8005      0.8005        0.7104        0.0000  18.3591
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.8258680555555556
F1 Macro Score after query 7: 0.5506974268955287
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8163[0m        [32m0.6649[0m       [35m0.7403[0m      [31m0.7403[0m        [94m0.8389[0m     +  0.0000  24.2373
      2      [36m0.8874[0m        [32m0.4936[0m       [35m0.7585[0m      [31m0.7585[0m        [94m0.8023[0m     +  0.0000  24.4780
      3      [36m0.9183[0m        [32m0.4176[0m       [35m0.7670[0m      [31m0.7670[0m        [94m0.7941[0m     +  0.0000  24.5879
      4      [36m0.9333[0m        [32m0.3782[0m       [35m0.7780[0m      [31m0.7780[0m        [94m0.7614[0m     +  0.0000  24.5938
      5      [36m0.9448[0m        [32m0.3351[0m       [35m0.7788[0m      [31m0.7788[0m        0.7834        0.0000  24.3680
      6      [36m0.9585[0m        [32m0.2835[0m       [35m0.8128[0m      [31m0.8128[0m        [94m0.6599[0m     +  0.0000  24.2900
      7      [36m0.9647[0m        [32m0.2627[0m       [35m0.8130[0m      [31m0.8130[0m        0.6651        0.0000  24.5093
      8      [36m0.9713[0m        [32m0.2547[0m       0.8125      0.8125        0.6731        0.0000  24.6027
      9      [36m0.9761[0m        [32m0.2420[0m       0.8116      0.8116        0.6708        0.0000  24.4474
     10      [36m0.9775[0m        [32m0.2333[0m       0.8108      0.8108        0.6781        0.0000  24.4298
     11      [36m0.9806[0m        [32m0.2196[0m       [35m0.8168[0m      [31m0.8168[0m        0.6607        0.0000  24.2552
     12      [36m0.9814[0m        [32m0.2181[0m       [35m0.8210[0m      [31m0.8210[0m        [94m0.6538[0m     +  0.0000  24.4607
     13      [36m0.9819[0m        [32m0.2154[0m       0.8210      0.8210        0.6555        0.0000  24.8997
     14      [36m0.9837[0m        0.2161       0.8196      0.8196        0.6601        0.0000  24.5705
     15      0.9828        [32m0.2104[0m       0.8194      0.8194        0.6604        0.0000  24.5403
     16      [36m0.9845[0m        0.2107       0.8161      0.8161        0.6676        0.0000  24.3490
     17      0.9841        [32m0.2096[0m       0.8155      0.8155        0.6670        0.0000  23.9196
     18      0.9828        [32m0.2064[0m       0.8156      0.8156        0.6695        0.0000  24.1811
     19      [36m0.9850[0m        [32m0.2063[0m       0.8156      0.8156        0.6684        0.0000  23.9768
     20      0.9845        [32m0.2015[0m       0.8148      0.8148        0.6697        0.0000  24.4288
     21      0.9837        [32m0.2012[0m       0.8153      0.8153        0.6698        0.0000  24.1798
     22      0.9828        0.2058       0.8155      0.8155        0.6702        0.0000  24.6943
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8453124999999999
F1 Macro Score after query 8: 0.5364897171243905
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8965[0m        [32m0.4383[0m       [35m0.8149[0m      [31m0.8149[0m        [94m0.5791[0m     +  0.0000  35.1919
      2      [36m0.9208[0m        [32m0.3649[0m       [35m0.8344[0m      [31m0.8344[0m        [94m0.5270[0m     +  0.0000  35.2038
      3      [36m0.9304[0m        [32m0.3259[0m       0.8313      0.8313        0.5463        0.0000  35.0826
      4      [36m0.9436[0m        [32m0.2809[0m       0.8325      0.8325        0.5380        0.0000  35.0805
      5      [36m0.9500[0m        [32m0.2564[0m       0.8151      0.8151        0.5765        0.0000  35.3423
      6      [36m0.9653[0m        [32m0.2050[0m       0.8174      0.8174        0.5884        0.0000  34.9951
      7      [36m0.9745[0m        [32m0.1807[0m       0.7986      0.7986        0.6497        0.0000  35.1083
      8      [36m0.9772[0m        [32m0.1717[0m       0.7979      0.7979        0.6688        0.0000  35.5949
      9      [36m0.9822[0m        [32m0.1608[0m       0.8083      0.8083        0.6468        0.0000  35.2509
     10      [36m0.9832[0m        [32m0.1560[0m       0.8097      0.8097        0.6396        0.0000  35.1893
     11      [36m0.9881[0m        [32m0.1417[0m       0.8236      0.8236        0.6184        0.0000  35.1409
     12      [36m0.9884[0m        [32m0.1376[0m       0.8243      0.8243        0.6227        0.0000  34.4137
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8305555555555556
F1 Macro Score after query 9: 0.532444906359628
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9146[0m        [32m0.3634[0m       [35m0.8127[0m      [31m0.8127[0m        [94m0.6160[0m     +  0.0000  54.5679
      2      [36m0.9304[0m        [32m0.2991[0m       [35m0.8226[0m      [31m0.8226[0m        [94m0.5965[0m     +  0.0000  54.3691
      3      [36m0.9397[0m        [32m0.2603[0m       0.7800      0.7800        0.7426        0.0000  54.4133
      4      [36m0.9471[0m        [32m0.2275[0m       [35m0.8359[0m      [31m0.8359[0m        [94m0.5740[0m     +  0.0000  54.6651
      5      [36m0.9544[0m        [32m0.2067[0m       0.8276      0.8276        0.6510        0.0000  54.8035
      6      [36m0.9664[0m        [32m0.1665[0m       [35m0.8474[0m      [31m0.8474[0m        [94m0.5384[0m     +  0.0000  54.7690
      7      [36m0.9732[0m        [32m0.1464[0m       0.8462      0.8462        0.5543        0.0000  54.3478
      8      [36m0.9796[0m        [32m0.1327[0m       0.8457      0.8457        0.5531        0.0000  55.0826
      9      [36m0.9819[0m        [32m0.1208[0m       0.8425      0.8425        0.5688        0.0000  54.6743
     10      [36m0.9840[0m        [32m0.1141[0m       0.8413      0.8413        0.5717        0.0000  54.2862
     11      [36m0.9889[0m        [32m0.1029[0m       0.8391      0.8391        0.5892        0.0000  54.4907
     12      [36m0.9900[0m        [32m0.0990[0m       0.8361      0.8361        0.5993        0.0000  54.6772
     13      [36m0.9911[0m        [32m0.0949[0m       0.8372      0.8372        0.6022        0.0000  54.5518
     14      [36m0.9912[0m        [32m0.0925[0m       0.8358      0.8358        0.6055        0.0000  54.3308
     15      [36m0.9918[0m        [32m0.0892[0m       0.8344      0.8344        0.6125        0.0000  54.5874
     16      [36m0.9925[0m        [32m0.0864[0m       0.8335      0.8335        0.6231        0.0000  52.7460
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8368055555555556
F1 Macro Score after query 10: 0.529034853774843
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9598[0m        [32m0.1827[0m       [35m0.8516[0m      [31m0.8516[0m        [94m0.5449[0m     +  0.0000  88.9791
      2      [36m0.9638[0m        [32m0.1619[0m       0.8307      0.8307        0.6437        0.0000  88.9406
      3      [36m0.9668[0m        [32m0.1444[0m       0.8408      0.8408        0.5837        0.0000  89.0074
      4      [36m0.9679[0m        [32m0.1344[0m       0.8095      0.8095        0.6375        0.0000  89.5979
      5      [36m0.9729[0m        [32m0.1172[0m       0.8300      0.8300        0.6157        0.0000  88.9595
      6      [36m0.9818[0m        [32m0.0878[0m       0.8455      0.8455        0.5873        0.0000  88.8614
      7      [36m0.9874[0m        [32m0.0714[0m       0.8450      0.8450        0.5944        0.0000  89.4003
      8      [36m0.9895[0m        [32m0.0633[0m       0.8448      0.8448        0.6106        0.0000  89.3226
      9      [36m0.9914[0m        [32m0.0571[0m       0.8432      0.8432        0.6342        0.0000  88.7236
     10      [36m0.9931[0m        [32m0.0527[0m       0.8451      0.8451        0.6295        0.0000  88.9234
     11      [36m0.9950[0m        [32m0.0451[0m       0.8476      0.8476        0.6486        0.0000  89.3049
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8399305555555555
F1 Macro Score after query 11: 0.5229944678136349
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9748[0m        [32m0.1239[0m       [35m0.7835[0m      [31m0.7835[0m        [94m0.8480[0m     +  0.0000  150.2884
      2      [36m0.9761[0m        [32m0.1069[0m       0.7465      0.7465        1.1563        0.0000  150.4765
      3      [36m0.9783[0m        [32m0.0947[0m       [35m0.7870[0m      [31m0.7870[0m        0.9813        0.0000  150.7121
      4      [36m0.9794[0m        [32m0.0828[0m       [35m0.7937[0m      [31m0.7937[0m        0.9519        0.0000  151.3466
      5      0.9793        [32m0.0785[0m       [35m0.8227[0m      [31m0.8227[0m        0.9017        0.0000  150.6715
      6      [36m0.9869[0m        [32m0.0565[0m       [35m0.8372[0m      [31m0.8372[0m        [94m0.6367[0m     +  0.0000  150.3477
      7      [36m0.9906[0m        [32m0.0449[0m       [35m0.8377[0m      [31m0.8377[0m        0.6465        0.0000  149.5971
      8      [36m0.9928[0m        [32m0.0384[0m       0.8332      0.8332        0.6944        0.0000  150.2336
      9      [36m0.9945[0m        [32m0.0332[0m       0.8332      0.8332        0.7246        0.0000  150.4562
     10      [36m0.9955[0m        [32m0.0295[0m       0.8203      0.8203        0.7874        0.0000  150.9053
     11      [36m0.9965[0m        [32m0.0262[0m       0.8259      0.8259        0.7763        0.0000  150.4486
     12      [36m0.9971[0m        [32m0.0245[0m       0.8300      0.8300        0.7652        0.0000  150.7683
     13      [36m0.9976[0m        [32m0.0225[0m       0.8337      0.8337        0.7611        0.0000  150.7360
     14      [36m0.9979[0m        [32m0.0217[0m       0.8351      0.8351        0.7608        0.0000  150.8468
     15      [36m0.9981[0m        [32m0.0204[0m       [35m0.8389[0m      [31m0.8389[0m        0.7612        0.0000  150.3809
     16      [36m0.9985[0m        [32m0.0191[0m       [35m0.8403[0m      [31m0.8403[0m        0.7713        0.0000  150.7211
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8465277777777778
F1 Macro Score after query 12: 0.5497632251109491
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9863[0m        [32m0.0558[0m       [35m0.7590[0m      [31m0.7590[0m        [94m1.2657[0m     +  0.0000  174.5718
      2      [36m0.9870[0m        [32m0.0513[0m       [35m0.7932[0m      [31m0.7932[0m        [94m0.9520[0m     +  0.0000  175.0094
      3      [36m0.9879[0m        [32m0.0452[0m       0.7451      0.7451        1.1705        0.0000  141.6865
      4      [36m0.9880[0m        [32m0.0441[0m       [35m0.8411[0m      [31m0.8411[0m        [94m0.7192[0m     +  0.0000  139.6956
      5      [36m0.9897[0m        [32m0.0404[0m       0.8318      0.8318        0.8478        0.0000  139.5229
      6      [36m0.9934[0m        [32m0.0285[0m       [35m0.8460[0m      [31m0.8460[0m        0.7254        0.0000  139.6590
      7      [36m0.9967[0m        [32m0.0184[0m       0.8425      0.8425        0.7724        0.0000  139.2294
      8      [36m0.9973[0m        [32m0.0153[0m       0.8443      0.8443        0.7788        0.0000  139.6030
      9      [36m0.9983[0m        [32m0.0124[0m       0.8361      0.8361        0.8523        0.0000  139.3354
     10      [36m0.9989[0m        [32m0.0099[0m       0.8389      0.8389        0.8666        0.0000  139.5641
     11      [36m0.9993[0m        [32m0.0085[0m       0.8377      0.8377        0.9180        0.0000  138.8180
     12      [36m0.9995[0m        [32m0.0075[0m       0.8378      0.8378        0.9262        0.0000  139.0502
     13      [36m0.9997[0m        [32m0.0072[0m       0.8384      0.8384        0.9168        0.0000  139.3655
     14      [36m0.9998[0m        [32m0.0066[0m       0.8391      0.8391        0.9295        0.0000  139.3164
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8428819444444444
F1 Macro Score after query 13: 0.5539611886033144
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed44\AL_margin_sampling_results_for_multiclass_classification_s44.pickle
