(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.1250[0m        [32m2.3066[0m       [35m0.1903[0m      [31m0.1903[0m        [94m2.0700[0m     +  0.0000  11.2228
      2      0.1250        [32m2.0493[0m       [35m0.2160[0m      [31m0.2160[0m        2.0935        0.0000  10.6092
      3      0.1250        [32m1.9417[0m       [35m0.2642[0m      [31m0.2642[0m        [94m2.0373[0m     +  0.0000  10.3738
      4      [36m0.3750[0m        [32m1.8097[0m       0.2458      0.2458        2.0832        0.0000  10.5314
      5      0.3750        1.8271       [35m0.3099[0m      [31m0.3099[0m        [94m2.0203[0m     +  0.0000  10.5970
      6      [36m0.6250[0m        [32m1.5837[0m       0.2814      0.2814        2.0302        0.0000  10.6350
      7      [36m0.7500[0m        1.6243       0.2812      0.2812        2.0275        0.0000  10.9095
      8      0.6250        1.6901       0.2780      0.2780        2.0236        0.0000  10.6194
      9      0.6250        [32m1.5773[0m       0.2776      0.2776        2.0253        0.0000  10.7825
     10      0.5000        1.7114       0.2802      0.2802        2.0278        0.0000  10.5618
     11      0.7500        1.6301       0.2809      0.2809        2.0269        0.0000  10.5952
     12      0.6250        1.6136       0.2851      0.2851        2.0255        0.0000  10.7678
     13      0.7500        1.6053       0.2861      0.2861        2.0244        0.0000  10.6042
     14      0.6250        1.6241       0.2875      0.2875        2.0237        0.0000  10.5892
     15      0.6250        1.6527       0.2894      0.2894        2.0225        0.0000  10.6095
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.3057
Pre F1 macro score = 0.1273

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5000[0m        [32m1.8004[0m       [35m0.4479[0m      [31m0.4479[0m        [94m1.8329[0m     +  0.0000  10.8011
      2      0.5000        [32m1.6394[0m       0.4479      0.4479        [94m1.7412[0m     +  0.0000  10.8708
      3      [36m0.5417[0m        [32m1.5200[0m       0.4479      0.4479        [94m1.7198[0m     +  0.0000  10.7601
      4      [36m0.6667[0m        [32m1.4057[0m       0.4479      0.4479        [94m1.6924[0m     +  0.0000  10.6915
      5      0.5833        [32m1.3352[0m       [35m0.4493[0m      [31m0.4493[0m        [94m1.6776[0m     +  0.0000  10.7460
      6      [36m0.7083[0m        [32m1.1982[0m       0.4490      0.4490        1.6778        0.0000  10.8660
      7      [36m0.7500[0m        [32m1.1320[0m       [35m0.4503[0m      [31m0.4503[0m        [94m1.6741[0m     +  0.0000  10.8627
      8      [36m0.7917[0m        [32m1.1113[0m       [35m0.4509[0m      [31m0.4509[0m        [94m1.6679[0m     +  0.0000  10.7886
      9      0.7917        1.1584       [35m0.4517[0m      [31m0.4517[0m        [94m1.6660[0m     +  0.0000  10.7440
     10      [36m0.8333[0m        1.1951       [35m0.4526[0m      [31m0.4526[0m        1.6667        0.0000  10.8322
     11      0.8333        [32m1.0990[0m       0.4526      0.4526        1.6663        0.0000  10.7762
     12      0.8333        [32m1.0761[0m       0.4526      0.4526        1.6674        0.0000  10.4806
     13      [36m0.9167[0m        1.1001       0.4526      0.4526        1.6673        0.0000  10.6868
     14      0.8333        [32m1.0752[0m       [35m0.4530[0m      [31m0.4530[0m        1.6674        0.0000  10.8159
     15      0.8333        1.1014       [35m0.4531[0m      [31m0.4531[0m        1.6671        0.0000  10.4680
     16      0.8750        1.1149       0.4531      0.4531        1.6669        0.0000  10.5629
     17      0.7917        1.0967       0.4531      0.4531        1.6668        0.0000  10.6089
     18      0.9167        1.0778       0.4531      0.4531        1.6667        0.0000  10.9190
     19      0.7500        1.1105       0.4531      0.4531        1.6665        0.0000  10.5813
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.47673611111111114
F1 Macro Score after query 1: 0.08144501127061336
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6429[0m        [32m1.5179[0m       [35m0.5469[0m      [31m0.5469[0m        [94m1.6345[0m     +  0.0000  10.8659
      2      [36m0.6786[0m        [32m1.3237[0m       [35m0.5655[0m      [31m0.5655[0m        [94m1.5666[0m     +  0.0000  10.6876
      3      [36m0.6964[0m        [32m1.2071[0m       [35m0.5813[0m      [31m0.5813[0m        [94m1.5195[0m     +  0.0000  10.9956
      4      [36m0.7321[0m        [32m1.1909[0m       [35m0.5977[0m      [31m0.5977[0m        [94m1.5094[0m     +  0.0000  10.8062
      5      [36m0.7857[0m        [32m1.0079[0m       0.5500      0.5500        [94m1.4407[0m     +  0.0000  10.9164
      6      [36m0.8750[0m        [32m0.9532[0m       0.5429      0.5429        [94m1.4405[0m     +  0.0000  10.8602
      7      0.8214        [32m0.9514[0m       0.5422      0.5422        [94m1.4358[0m     +  0.0000  10.6158
      8      [36m0.8929[0m        [32m0.9101[0m       0.5417      0.5417        [94m1.4300[0m     +  0.0000  10.7889
      9      0.8214        0.9455       0.5399      0.5399        1.4328        0.0000  10.9066
     10      0.8571        [32m0.8975[0m       0.5427      0.5427        [94m1.4256[0m     +  0.0000  10.9046
     11      0.8214        0.9139       0.5439      0.5439        [94m1.4253[0m     +  0.0000  10.8694
     12      [36m0.9107[0m        [32m0.8877[0m       0.5420      0.5420        [94m1.4244[0m     +  0.0000  10.7260
     13      0.8929        [32m0.8585[0m       0.5427      0.5427        [94m1.4238[0m     +  0.0000  10.8501
     14      0.8393        0.8772       0.5420      0.5420        [94m1.4229[0m     +  0.0000  10.7904
     15      0.8929        [32m0.8471[0m       0.5422      0.5422        [94m1.4216[0m     +  0.0000  10.9201
     16      0.8393        0.8923       0.5420      0.5420        [94m1.4215[0m     +  0.0000  10.7500
     17      0.8750        0.9043       0.5418      0.5418        [94m1.4214[0m     +  0.0000  10.8126
     18      0.8571        0.9118       0.5418      0.5418        1.4214        0.0000  11.0179
     19      0.8750        [32m0.8412[0m       0.5413      0.5413        [94m1.4212[0m     +  0.0000  10.8832
     20      0.8571        0.8694       0.5418      0.5418        [94m1.4210[0m     +  0.0000  10.7393
     21      0.8393        0.8778       0.5417      0.5417        [94m1.4210[0m     +  0.0000  10.8346
     22      0.9107        [32m0.8022[0m       0.5417      0.5417        [94m1.4210[0m     +  0.0000  10.9009
     23      0.8929        0.8679       0.5417      0.5417        [94m1.4210[0m     +  0.0000  10.9102
     24      0.9107        0.8974       0.5415      0.5415        [94m1.4210[0m     +  0.0000  10.8638
     25      0.8750        0.8610       0.5415      0.5415        [94m1.4209[0m     +  0.0000  10.7457
     26      0.8929        0.8279       0.5415      0.5415        [94m1.4209[0m     +  0.0000  10.7667
     27      0.8929        0.8529       0.5415      0.5415        [94m1.4209[0m     +  0.0000  10.9745
     28      0.8929        0.8838       0.5415      0.5415        [94m1.4209[0m     +  0.0000  10.6192
     29      0.8571        0.8814       0.5417      0.5417        1.4209        0.0000  10.7665
     30      0.8750        0.8448       0.5417      0.5417        [94m1.4209[0m     +  0.0000  10.7429
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.5760416666666667
F1 Macro Score after query 2: 0.18314925351130823
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5982[0m        [32m1.4082[0m       [35m0.5582[0m      [31m0.5582[0m        [94m1.4223[0m     +  0.0000  11.0565
      2      [36m0.6518[0m        [32m1.2082[0m       [35m0.5828[0m      [31m0.5828[0m        [94m1.3571[0m     +  0.0000  10.9794
      3      [36m0.7054[0m        [32m1.0862[0m       [35m0.6366[0m      [31m0.6366[0m        [94m1.2651[0m     +  0.0000  11.2649
      4      [36m0.7589[0m        [32m1.0402[0m       [35m0.6382[0m      [31m0.6382[0m        [94m1.2458[0m     +  0.0000  11.1096
      5      [36m0.7946[0m        [32m0.9575[0m       [35m0.6547[0m      [31m0.6547[0m        [94m1.2036[0m     +  0.0000  10.9429
      6      [36m0.8482[0m        [32m0.9143[0m       [35m0.6602[0m      [31m0.6602[0m        [94m1.1805[0m     +  0.0000  11.0516
      7      0.8125        [32m0.9047[0m       [35m0.6611[0m      [31m0.6611[0m        [94m1.1793[0m     +  0.0000  11.2600
      8      0.8393        [32m0.8961[0m       [35m0.6637[0m      [31m0.6637[0m        [94m1.1706[0m     +  0.0000  11.2505
      9      0.8482        0.8962       [35m0.6656[0m      [31m0.6656[0m        [94m1.1678[0m     +  0.0000  11.1882
     10      [36m0.8750[0m        [32m0.8577[0m       [35m0.6686[0m      [31m0.6686[0m        [94m1.1661[0m     +  0.0000  10.9318
     11      0.8661        0.8631       [35m0.6689[0m      [31m0.6689[0m        [94m1.1632[0m     +  0.0000  11.1869
     12      0.8482        [32m0.8477[0m       [35m0.6694[0m      [31m0.6694[0m        [94m1.1622[0m     +  0.0000  11.0123
     13      0.8571        [32m0.8250[0m       0.6689      0.6689        [94m1.1615[0m     +  0.0000  11.2879
     14      [36m0.8929[0m        0.8251       [35m0.6701[0m      [31m0.6701[0m        1.1619        0.0000  11.3277
     15      0.8661        0.8495       [35m0.6708[0m      [31m0.6708[0m        1.1617        0.0000  11.1931
     16      0.8750        0.8568       0.6705      0.6705        1.1616        0.0000  11.2158
     17      0.8571        [32m0.8217[0m       0.6705      0.6705        [94m1.1612[0m     +  0.0000  11.0204
     18      0.8750        0.8349       0.6705      0.6705        [94m1.1611[0m     +  0.0000  11.2973
     19      0.8661        0.8512       0.6707      0.6707        [94m1.1610[0m     +  0.0000  11.0810
     20      0.8482        0.8453       0.6708      0.6708        [94m1.1608[0m     +  0.0000  10.8243
     21      0.8839        0.8260       0.6707      0.6707        [94m1.1608[0m     +  0.0000  11.1683
     22      0.8125        0.8850       0.6707      0.6707        [94m1.1607[0m     +  0.0000  10.9002
     23      0.8661        0.8470       0.6707      0.6707        [94m1.1607[0m     +  0.0000  11.2776
     24      0.8571        [32m0.8195[0m       0.6708      0.6708        [94m1.1607[0m     +  0.0000  11.1663
     25      0.8571        0.8218       0.6705      0.6705        [94m1.1606[0m     +  0.0000  11.0883
     26      [36m0.9018[0m        0.8236       0.6705      0.6705        [94m1.1606[0m     +  0.0000  10.9775
     27      0.8661        0.8617       0.6705      0.6705        [94m1.1606[0m     +  0.0000  10.9190
     28      0.8661        0.8701       0.6705      0.6705        [94m1.1606[0m     +  0.0000  11.1515
     29      0.8661        0.8449       0.6705      0.6705        [94m1.1606[0m     +  0.0000  11.0751
     30      0.8482        0.8585       0.6705      0.6705        [94m1.1606[0m     +  0.0000  11.4185
     31      0.8571        0.8911       0.6705      0.6705        1.1606        0.0000  11.1667
     32      0.8304        0.8630       0.6705      0.6705        1.1606        0.0000  11.2137
     33      0.8750        0.8299       0.6705      0.6705        [94m1.1606[0m     +  0.0000  11.1820
     34      0.8661        [32m0.7979[0m       0.6705      0.6705        1.1606        0.0000  11.1363
     35      0.8393        0.8458       0.6705      0.6705        1.1606        0.0000  11.2151
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.6652777777777777
F1 Macro Score after query 3: 0.2353909656980176
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6490[0m        [32m1.2234[0m       [35m0.6630[0m      [31m0.6630[0m        [94m1.1251[0m     +  0.0000  11.5268
      2      [36m0.7404[0m        [32m1.0026[0m       [35m0.6833[0m      [31m0.6833[0m        [94m1.0503[0m     +  0.0000  11.6536
      3      [36m0.8125[0m        [32m0.9319[0m       0.6813      0.6813        [94m1.0473[0m     +  0.0000  11.5736
      4      [36m0.8462[0m        [32m0.8286[0m       0.6781      0.6781        [94m1.0127[0m     +  0.0000  11.6997
      5      [36m0.8558[0m        [32m0.7823[0m       0.6828      0.6828        [94m0.9942[0m     +  0.0000  11.6669
      6      [36m0.8990[0m        [32m0.7283[0m       0.6804      0.6804        [94m0.9841[0m     +  0.0000  11.6203
      7      [36m0.9231[0m        [32m0.6919[0m       0.6788      0.6788        0.9859        0.0000  11.6032
      8      [36m0.9279[0m        [32m0.6788[0m       0.6813      0.6813        0.9845        0.0000  11.4496
      9      0.9279        [32m0.6619[0m       0.6830      0.6830        [94m0.9831[0m     +  0.0000  11.5404
     10      0.9279        0.6800       0.6832      0.6832        [94m0.9799[0m     +  0.0000  11.5874
     11      [36m0.9375[0m        [32m0.6535[0m       0.6826      0.6826        0.9820        0.0000  11.6028
     12      [36m0.9471[0m        0.6585       0.6823      0.6823        0.9809        0.0000  11.5432
     13      0.9327        0.6568       0.6813      0.6813        0.9821        0.0000  11.5101
     14      0.9231        [32m0.6458[0m       0.6819      0.6819        0.9820        0.0000  11.4821
     15      0.9327        [32m0.6369[0m       0.6825      0.6825        0.9800        0.0000  11.5752
     16      0.9375        0.6422       0.6823      0.6823        0.9801        0.0000  11.5883
     17      [36m0.9567[0m        0.6377       0.6819      0.6819        0.9803        0.0000  11.3551
     18      0.9375        [32m0.6220[0m       0.6819      0.6819        0.9800        0.0000  11.3695
     19      0.9471        0.6385       0.6825      0.6825        0.9803        0.0000  11.4496
     20      0.9423        0.6502       0.6819      0.6819        0.9805        0.0000  11.5428
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.7243055555555555
F1 Macro Score after query 4: 0.2850176602528507
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6771[0m        [32m1.1016[0m       [35m0.6557[0m      [31m0.6557[0m        [94m1.0978[0m     +  0.0000  12.3863
      2      [36m0.8073[0m        [32m0.8846[0m       [35m0.7349[0m      [31m0.7349[0m        [94m0.9869[0m     +  0.0000  12.2950
      3      [36m0.8646[0m        [32m0.7860[0m       [35m0.7457[0m      [31m0.7457[0m        [94m0.9432[0m     +  0.0000  12.4332
      4      [36m0.9115[0m        [32m0.7013[0m       [35m0.7470[0m      [31m0.7470[0m        [94m0.9284[0m     +  0.0000  12.5125
      5      [36m0.9193[0m        [32m0.6666[0m       [35m0.7601[0m      [31m0.7601[0m        [94m0.8738[0m     +  0.0000  12.3868
      6      [36m0.9323[0m        [32m0.6005[0m       [35m0.7628[0m      [31m0.7628[0m        [94m0.8608[0m     +  0.0000  12.2943
      7      [36m0.9505[0m        [32m0.5766[0m       [35m0.7658[0m      [31m0.7658[0m        [94m0.8539[0m     +  0.0000  12.4328
      8      0.9401        [32m0.5601[0m       [35m0.7691[0m      [31m0.7691[0m        [94m0.8498[0m     +  0.0000  12.5322
      9      [36m0.9583[0m        [32m0.5461[0m       0.7670      0.7670        [94m0.8482[0m     +  0.0000  12.5598
     10      0.9531        0.5482       0.7602      0.7602        0.8547        0.0000  12.2662
     11      [36m0.9609[0m        [32m0.5262[0m       0.7625      0.7625        0.8512        0.0000  12.4424
     12      0.9557        0.5329       0.7630      0.7630        0.8504        0.0000  12.5122
     13      [36m0.9688[0m        [32m0.5187[0m       0.7616      0.7616        0.8516        0.0000  12.3558
     14      [36m0.9714[0m        0.5284       0.7625      0.7625        0.8507        0.0000  12.2950
     15      0.9661        [32m0.5098[0m       0.7620      0.7620        0.8501        0.0000  12.4176
     16      0.9688        [32m0.5023[0m       0.7625      0.7625        0.8508        0.0000  12.4637
     17      0.9531        0.5139       0.7620      0.7620        0.8507        0.0000  12.5600
     18      0.9635        0.5060       0.7618      0.7618        0.8511        0.0000  12.4203
     19      0.9609        0.5119       0.7613      0.7613        0.8510        0.0000  12.4653
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.7967013888888889
F1 Macro Score after query 5: 0.34630518903869034
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7614[0m        [32m0.9083[0m       [35m0.7483[0m      [31m0.7483[0m        [94m0.8838[0m     +  0.0000  13.9524
      2      [36m0.8636[0m        [32m0.7220[0m       [35m0.7705[0m      [31m0.7705[0m        [94m0.8188[0m     +  0.0000  13.7494
      3      [36m0.9091[0m        [32m0.5956[0m       0.7615      0.7615        [94m0.8165[0m     +  0.0000  13.8127
      4      [36m0.9361[0m        [32m0.5583[0m       0.7648      0.7648        0.8191        0.0000  13.7339
      5      [36m0.9560[0m        [32m0.4963[0m       0.7689      0.7689        [94m0.8020[0m     +  0.0000  14.0293
      6      [36m0.9645[0m        [32m0.4606[0m       0.7648      0.7648        0.8099        0.0000  14.0440
      7      [36m0.9773[0m        [32m0.4349[0m       0.7700      0.7700        [94m0.7966[0m     +  0.0000  13.9203
      8      0.9759        [32m0.4253[0m       [35m0.7717[0m      [31m0.7717[0m        [94m0.7914[0m     +  0.0000  13.9375
      9      [36m0.9787[0m        [32m0.4148[0m       0.7708      0.7708        0.7938        0.0000  14.0773
     10      0.9787        [32m0.4053[0m       [35m0.7731[0m      [31m0.7731[0m        0.7925        0.0000  13.7957
     11      [36m0.9815[0m        [32m0.3864[0m       [35m0.7745[0m      [31m0.7745[0m        [94m0.7893[0m     +  0.0000  13.9829
     12      0.9773        0.3973       [35m0.7755[0m      [31m0.7755[0m        [94m0.7887[0m     +  0.0000  13.8099
     13      0.9801        0.3947       0.7752      0.7752        [94m0.7866[0m     +  0.0000  14.1706
     14      [36m0.9830[0m        0.3907       0.7745      0.7745        0.7883        0.0000  13.9356
     15      0.9815        [32m0.3855[0m       0.7750      0.7750        0.7870        0.0000  14.0153
     16      0.9815        0.3883       [35m0.7757[0m      [31m0.7757[0m        [94m0.7864[0m     +  0.0000  14.0613
     17      [36m0.9844[0m        [32m0.3807[0m       0.7752      0.7752        0.7867        0.0000  14.1244
     18      0.9815        0.3882       0.7750      0.7750        0.7868        0.0000  13.9993
     19      0.9830        [32m0.3681[0m       0.7748      0.7748        0.7867        0.0000  14.0460
     20      0.9801        0.3933       [35m0.7764[0m      [31m0.7764[0m        [94m0.7857[0m     +  0.0000  13.9350
     21      0.9801        0.3796       0.7764      0.7764        [94m0.7856[0m     +  0.0000  14.0009
     22      0.9830        0.3837       0.7764      0.7764        [94m0.7854[0m     +  0.0000  13.8281
     23      0.9830        0.3729       [35m0.7766[0m      [31m0.7766[0m        [94m0.7854[0m     +  0.0000  13.9121
     24      0.9830        0.3812       0.7764      0.7764        0.7855        0.0000  14.0612
     25      0.9844        0.3799       0.7762      0.7762        [94m0.7852[0m     +  0.0000  14.0619
     26      0.9815        0.3826       [35m0.7767[0m      [31m0.7767[0m        [94m0.7852[0m     +  0.0000  13.8766
     27      0.9801        0.3838       0.7767      0.7767        0.7852        0.0000  14.0142
     28      0.9801        0.3821       0.7766      0.7766        0.7852        0.0000  14.0001
     29      0.9815        0.3746       0.7767      0.7767        0.7852        0.0000  13.8574
     30      0.9815        0.3746       0.7766      0.7766        0.7852        0.0000  14.0306
     31      0.9815        0.3785       0.7766      0.7766        0.7852        0.0000  13.9982
     32      0.9844        0.3866       0.7766      0.7766        0.7852        0.0000  14.0169
     33      0.9830        0.3822       0.7766      0.7766        0.7852        0.0000  13.9344
     34      0.9801        0.3794       0.7766      0.7766        0.7852        0.0000  13.8731
     35      0.9830        0.3867       0.7766      0.7766        0.7852        0.0000  13.9025
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8067708333333333
F1 Macro Score after query 6: 0.4058970690820997
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7785[0m        [32m0.8125[0m       [35m0.7302[0m      [31m0.7302[0m        [94m0.8360[0m     +  0.0000  16.8430
      2      [36m0.8679[0m        [32m0.6212[0m       [35m0.7484[0m      [31m0.7484[0m        [94m0.8008[0m     +  0.0000  16.7686
      3      [36m0.8956[0m        [32m0.5428[0m       [35m0.7559[0m      [31m0.7559[0m        [94m0.7844[0m     +  0.0000  16.7509
      4      [36m0.9169[0m        [32m0.4988[0m       [35m0.7568[0m      [31m0.7568[0m        0.7915        0.0000  16.8921
      5      [36m0.9367[0m        [32m0.4402[0m       [35m0.7594[0m      [31m0.7594[0m        [94m0.7796[0m     +  0.0000  16.7347
      6      [36m0.9478[0m        [32m0.3985[0m       [35m0.7661[0m      [31m0.7661[0m        0.7874        0.0000  16.6746
      7      [36m0.9525[0m        [32m0.3734[0m       [35m0.7679[0m      [31m0.7679[0m        0.7888        0.0000  16.8590
      8      [36m0.9589[0m        [32m0.3664[0m       [35m0.7689[0m      [31m0.7689[0m        0.7886        0.0000  16.7340
      9      [36m0.9652[0m        [32m0.3474[0m       [35m0.7694[0m      [31m0.7694[0m        0.7874        0.0000  17.0122
     10      [36m0.9660[0m        [32m0.3446[0m       0.7656      0.7656        0.8004        0.0000  16.8280
     11      [36m0.9747[0m        [32m0.3294[0m       0.7691      0.7691        0.7884        0.0000  16.7636
     12      [36m0.9763[0m        0.3330       [35m0.7701[0m      [31m0.7701[0m        0.7857        0.0000  16.8153
     13      0.9763        [32m0.3261[0m       0.7689      0.7689        0.7883        0.0000  16.9069
     14      0.9747        [32m0.3246[0m       0.7701      0.7701        0.7866        0.0000  16.7902
     15      0.9763        [32m0.3125[0m       [35m0.7703[0m      [31m0.7703[0m        0.7876        0.0000  16.8767
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.8048611111111112
F1 Macro Score after query 7: 0.4704167847959949
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8573[0m        [32m0.6021[0m       [35m0.7668[0m      [31m0.7668[0m        [94m0.7352[0m     +  0.0000  21.6779
      2      [36m0.9046[0m        [32m0.4787[0m       [35m0.7878[0m      [31m0.7878[0m        [94m0.6998[0m     +  0.0000  21.6333
      3      [36m0.9165[0m        [32m0.4272[0m       0.7811      0.7811        [94m0.6992[0m     +  0.0000  21.5536
      4      [36m0.9223[0m        [32m0.3993[0m       0.7795      0.7795        0.7352        0.0000  21.7883
      5      [36m0.9298[0m        [32m0.3740[0m       0.7564      0.7564        0.7958        0.0000  21.8020
      6      [36m0.9563[0m        [32m0.3076[0m       [35m0.7929[0m      [31m0.7929[0m        0.7022        0.0000  21.6481
      7      [36m0.9620[0m        [32m0.2912[0m       [35m0.7939[0m      [31m0.7939[0m        0.7040        0.0000  21.5743
      8      [36m0.9682[0m        [32m0.2693[0m       0.7913      0.7913        0.7017        0.0000  21.6318
      9      [36m0.9700[0m        [32m0.2620[0m       [35m0.7967[0m      [31m0.7967[0m        [94m0.6978[0m     +  0.0000  21.6628
     10      [36m0.9735[0m        [32m0.2531[0m       0.7931      0.7931        0.7065        0.0000  21.6938
     11      [36m0.9784[0m        [32m0.2407[0m       [35m0.7988[0m      [31m0.7988[0m        [94m0.6919[0m     +  0.0000  21.6456
     12      [36m0.9788[0m        [32m0.2324[0m       0.7974      0.7974        0.6990        0.0000  21.6311
     13      [36m0.9801[0m        0.2361       0.7979      0.7979        0.6981        0.0000  21.6473
     14      [36m0.9837[0m        [32m0.2266[0m       0.7974      0.7974        0.7016        0.0000  21.4588
     15      0.9814        [32m0.2265[0m       0.7948      0.7948        0.7046        0.0000  21.6445
     16      0.9832        [32m0.2232[0m       0.7972      0.7972        0.7001        0.0000  21.4869
     17      0.9823        [32m0.2219[0m       0.7984      0.7984        0.6985        0.0000  21.5370
     18      [36m0.9854[0m        [32m0.2208[0m       0.7977      0.7977        0.6994        0.0000  21.5044
     19      [36m0.9863[0m        0.2222       0.7981      0.7981        0.7010        0.0000  21.5678
     20      0.9828        [32m0.2176[0m       0.7977      0.7977        0.6984        0.0000  21.5366
     21      0.9850        0.2183       0.7986      0.7986        0.6983        0.0000  21.4930
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8163194444444445
F1 Macro Score after query 8: 0.4582461290281803
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8787[0m        [32m0.4930[0m       [35m0.7915[0m      [31m0.7915[0m        [94m0.6635[0m     +  0.0000  30.1075
      2      [36m0.9052[0m        [32m0.4017[0m       0.7877      0.7877        0.6737        0.0000  30.4209
      3      [36m0.9223[0m        [32m0.3521[0m       [35m0.7946[0m      [31m0.7946[0m        0.6699        0.0000  30.5189
      4      [36m0.9329[0m        [32m0.3180[0m       0.7859      0.7859        0.6925        0.0000  30.2227
      5      [36m0.9426[0m        [32m0.2919[0m       [35m0.7964[0m      [31m0.7964[0m        0.6899        0.0000  30.2251
      6      [36m0.9599[0m        [32m0.2327[0m       [35m0.8144[0m      [31m0.8144[0m        [94m0.6546[0m     +  0.0000  30.3564
      7      [36m0.9661[0m        [32m0.2148[0m       0.8137      0.8137        0.6630        0.0000  30.3291
      8      [36m0.9748[0m        [32m0.1927[0m       0.8097      0.8097        0.6789        0.0000  30.4184
      9      [36m0.9757[0m        [32m0.1846[0m       0.8125      0.8125        0.6786        0.0000  30.2177
     10      [36m0.9797[0m        [32m0.1754[0m       0.8142      0.8142        0.6794        0.0000  30.2650
     11      [36m0.9844[0m        [32m0.1633[0m       [35m0.8182[0m      [31m0.8182[0m        0.6716        0.0000  30.3813
     12      [36m0.9856[0m        [32m0.1603[0m       0.8182      0.8182        0.6741        0.0000  30.2462
     13      [36m0.9874[0m        [32m0.1563[0m       0.8181      0.8181        0.6759        0.0000  30.4242
     14      [36m0.9889[0m        [32m0.1536[0m       0.8172      0.8172        0.6798        0.0000  30.1874
     15      0.9876        [32m0.1521[0m       0.8170      0.8170        0.6780        0.0000  30.3472
     16      [36m0.9901[0m        [32m0.1467[0m       [35m0.8189[0m      [31m0.8189[0m        0.6741        0.0000  30.3146
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8246527777777778
F1 Macro Score after query 9: 0.4900287365884691
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9293[0m        [32m0.3187[0m       [35m0.8215[0m      [31m0.8215[0m        [94m0.6017[0m     +  0.0000  46.0468
      2      [36m0.9410[0m        [32m0.2758[0m       [35m0.8290[0m      [31m0.8290[0m        [94m0.5605[0m     +  0.0000  46.0772
      3      [36m0.9486[0m        [32m0.2428[0m       0.8113      0.8113        0.6301        0.0000  46.3119
      4      [36m0.9547[0m        [32m0.2172[0m       [35m0.8352[0m      [31m0.8352[0m        0.5677        0.0000  46.1869
      5      [36m0.9601[0m        [32m0.1972[0m       0.8297      0.8297        0.6068        0.0000  46.2045
      6      [36m0.9743[0m        [32m0.1482[0m       0.8175      0.8175        0.6627        0.0000  45.9989
      7      [36m0.9822[0m        [32m0.1256[0m       0.8198      0.8198        0.6814        0.0000  46.1865
      8      [36m0.9853[0m        [32m0.1113[0m       0.8175      0.8175        0.7045        0.0000  46.0275
      9      [36m0.9885[0m        [32m0.1020[0m       0.8189      0.8189        0.7075        0.0000  45.9517
     10      [36m0.9908[0m        [32m0.0954[0m       0.8255      0.8255        0.6973        0.0000  45.9805
     11      [36m0.9942[0m        [32m0.0851[0m       0.8182      0.8182        0.7141        0.0000  46.2801
     12      [36m0.9950[0m        [32m0.0820[0m       0.8207      0.8207        0.7105        0.0000  45.6305
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8220486111111112
F1 Macro Score after query 10: 0.526097920784753
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9510[0m        [32m0.2302[0m       [35m0.7983[0m      [31m0.7983[0m        [94m0.6638[0m     +  0.0000  73.5453
      2      [36m0.9570[0m        [32m0.1964[0m       0.7842      0.7842        0.7733        0.0000  74.1069
      3      [36m0.9613[0m        [32m0.1749[0m       [35m0.8021[0m      [31m0.8021[0m        0.7337        0.0000  73.9185
      4      [36m0.9661[0m        [32m0.1510[0m       0.7941      0.7941        0.7663        0.0000  73.8813
      5      [36m0.9696[0m        [32m0.1317[0m       0.7983      0.7983        0.8292        0.0000  73.9449
      6      [36m0.9797[0m        [32m0.1002[0m       [35m0.8043[0m      [31m0.8043[0m        0.7520        0.0000  73.8233
      7      [36m0.9858[0m        [32m0.0818[0m       0.7974      0.7974        0.7886        0.0000  74.0687
      8      [36m0.9894[0m        [32m0.0727[0m       0.8042      0.8042        0.7775        0.0000  73.8321
      9      [36m0.9919[0m        [32m0.0630[0m       0.8002      0.8002        0.8073        0.0000  73.9622
     10      [36m0.9930[0m        [32m0.0562[0m       0.7960      0.7960        0.8470        0.0000  74.1023
     11      [36m0.9952[0m        [32m0.0503[0m       0.7899      0.7899        0.8752        0.0000  74.0540
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8255208333333334
F1 Macro Score after query 11: 0.5137761534476238
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9720[0m        [32m0.1409[0m       [35m0.8021[0m      [31m0.8021[0m        [94m0.7170[0m     +  0.0000  123.5462
      2      [36m0.9734[0m        [32m0.1192[0m       [35m0.8167[0m      [31m0.8167[0m        [94m0.6853[0m     +  0.0000  123.8359
      3      [36m0.9766[0m        [32m0.1013[0m       0.6842      0.6842        1.4596        0.0000  124.2586
      4      [36m0.9781[0m        [32m0.0919[0m       0.8007      0.8007        0.8160        0.0000  124.0027
      5      [36m0.9782[0m        [32m0.0831[0m       0.7976      0.7976        0.8473        0.0000  124.0527
      6      [36m0.9855[0m        [32m0.0614[0m       [35m0.8283[0m      [31m0.8283[0m        [94m0.6720[0m     +  0.0000  124.1532
      7      [36m0.9898[0m        [32m0.0487[0m       0.8208      0.8208        0.7232        0.0000  124.1844
      8      [36m0.9922[0m        [32m0.0419[0m       0.8267      0.8267        0.7051        0.0000  124.1822
      9      [36m0.9942[0m        [32m0.0363[0m       0.8252      0.8252        0.7139        0.0000  125.2404
     10      [36m0.9955[0m        [32m0.0308[0m       [35m0.8321[0m      [31m0.8321[0m        0.7040        0.0000  124.0507
     11      [36m0.9961[0m        [32m0.0284[0m       0.8208      0.8208        0.7870        0.0000  124.2010
     12      [36m0.9974[0m        [32m0.0247[0m       0.8243      0.8243        0.7886        0.0000  124.5291
     13      [36m0.9982[0m        [32m0.0229[0m       0.8233      0.8233        0.8042        0.0000  123.8263
     14      [36m0.9985[0m        [32m0.0217[0m       0.8257      0.8257        0.8083        0.0000  124.0483
     15      [36m0.9985[0m        [32m0.0207[0m       0.8219      0.8219        0.8236        0.0000  123.8750
     16      [36m0.9986[0m        [32m0.0202[0m       0.8186      0.8186        0.8497        0.0000  123.8953
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.83125
F1 Macro Score after query 12: 0.5131516825471488
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9850[0m        [32m0.0619[0m       [35m0.7488[0m      [31m0.7488[0m        [94m1.0904[0m     +  0.0000  142.9136
      2      [36m0.9853[0m        [32m0.0587[0m       [35m0.7958[0m      [31m0.7958[0m        [94m0.8772[0m     +  0.0000  144.6251
      3      [36m0.9864[0m        [32m0.0533[0m       0.7616      0.7616        1.0133        0.0000  144.4391
      4      [36m0.9875[0m        [32m0.0504[0m       0.7450      0.7450        1.2196        0.0000  144.7662
      5      [36m0.9892[0m        [32m0.0439[0m       [35m0.8045[0m      [31m0.8045[0m        [94m0.8253[0m     +  0.0000  144.0128
      6      [36m0.9917[0m        [32m0.0341[0m       [35m0.8208[0m      [31m0.8208[0m        [94m0.7820[0m     +  0.0000  144.8089
      7      [36m0.9964[0m        [32m0.0208[0m       [35m0.8271[0m      [31m0.8271[0m        0.8276        0.0000  144.3337
      8      [36m0.9976[0m        [32m0.0166[0m       0.8231      0.8231        0.8600        0.0000  144.5838
      9      [36m0.9983[0m        [32m0.0141[0m       [35m0.8293[0m      [31m0.8293[0m        0.8440        0.0000  144.5736
     10      [36m0.9987[0m        [32m0.0124[0m       0.8257      0.8257        0.8898        0.0000  144.6410
     11      0.9986        [32m0.0116[0m       0.8153      0.8153        1.0021        0.0000  144.2876
     12      [36m0.9993[0m        [32m0.0098[0m       0.8165      0.8165        1.0033        0.0000  144.8552
     13      [36m0.9993[0m        [32m0.0088[0m       0.8141      0.8141        1.0137        0.0000  144.3126
     14      [36m0.9994[0m        [32m0.0087[0m       0.8155      0.8155        1.0204        0.0000  144.1950
     15      [36m0.9996[0m        [32m0.0080[0m       0.8177      0.8177        1.0269        0.0000  144.4220
     16      0.9995        [32m0.0079[0m       0.8148      0.8148        1.0374        0.0000  144.0158
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8317708333333333
F1 Macro Score after query 13: 0.5072538722841307
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed47\AL_margin_sampling_results_for_multiclass_classification_s47.pickle
