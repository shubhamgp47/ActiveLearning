(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.1250[0m        [32m2.1358[0m       [35m0.2384[0m      [31m0.2384[0m        [94m2.0094[0m     +  0.0000  11.1568
      2      [36m0.2500[0m        [32m2.0043[0m       [35m0.3585[0m      [31m0.3585[0m        [94m1.9509[0m     +  0.0000  10.5359
      3      [36m0.3750[0m        [32m1.9354[0m       0.3106      0.3106        2.0158        0.0000  10.4815
      4      [36m0.5000[0m        [32m1.9216[0m       0.2099      0.2099        2.0556        0.0000  10.4871
      5      0.5000        [32m1.7965[0m       0.1589      0.1589        2.0920        0.0000  10.6564
      6      [36m0.6250[0m        [32m1.6012[0m       0.1780      0.1780        2.0924        0.0000  10.3284
      7      [36m0.8750[0m        [32m1.5436[0m       0.1892      0.1892        2.0797        0.0000  10.7231
      8      0.8750        [32m1.4628[0m       0.1943      0.1943        2.0763        0.0000  10.7515
      9      0.8750        1.5776       0.1979      0.1979        2.0742        0.0000  10.7545
     10      0.8750        1.4729       0.1910      0.1910        2.0771        0.0000  10.5937
     11      0.6250        [32m1.4077[0m       0.1898      0.1898        2.0782        0.0000  10.6987
     12      0.5000        1.5915       0.1920      0.1920        2.0775        0.0000  10.7668
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.2128
Pre F1 macro score = 0.1279

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.4583[0m        [32m1.8654[0m       [35m0.5302[0m      [31m0.5302[0m        [94m1.7795[0m     +  0.0000  10.8122
      2      [36m0.5833[0m        [32m1.6681[0m       0.4637      0.4637        [94m1.7365[0m     +  0.0000  10.6983
      3      [36m0.7083[0m        [32m1.4812[0m       0.5292      0.5292        [94m1.7338[0m     +  0.0000  10.5654
      4      [36m0.8750[0m        [32m1.3676[0m       0.4953      0.4953        [94m1.7204[0m     +  0.0000  10.4372
      5      0.7917        [32m1.2550[0m       0.4373      0.4373        1.7411        0.0000  10.7866
      6      0.8333        [32m1.0594[0m       0.4547      0.4547        1.7272        0.0000  10.6497
      7      0.7917        [32m1.0457[0m       0.4573      0.4573        1.7220        0.0000  10.6877
      8      0.8750        [32m1.0242[0m       0.4437      0.4437        1.7216        0.0000  10.6261
      9      0.8750        1.0344       0.4292      0.4292        1.7281        0.0000  10.7184
     10      [36m0.9167[0m        1.0347       0.4247      0.4247        1.7267        0.0000  10.7812
     11      0.9167        [32m1.0001[0m       0.4233      0.4233        1.7271        0.0000  10.7752
     12      [36m0.9583[0m        1.0097       0.4238      0.4238        1.7264        0.0000  10.7355
     13      [36m1.0000[0m        [32m0.9335[0m       0.4224      0.4224        1.7257        0.0000  10.7341
     14      0.9583        0.9485       0.4193      0.4193        1.7265        0.0000  10.7377
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.4642361111111111
F1 Macro Score after query 1: 0.17369775510012558
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6250[0m        [32m1.4484[0m       [35m0.4703[0m      [31m0.4703[0m        [94m1.6547[0m     +  0.0000  11.1181
      2      [36m0.6786[0m        [32m1.1780[0m       [35m0.5835[0m      [31m0.5835[0m        [94m1.5221[0m     +  0.0000  10.7579
      3      [36m0.7321[0m        [32m1.0830[0m       [35m0.5995[0m      [31m0.5995[0m        [94m1.4811[0m     +  0.0000  10.7739
      4      [36m0.8036[0m        [32m0.9286[0m       [35m0.6181[0m      [31m0.6181[0m        [94m1.4385[0m     +  0.0000  10.9271
      5      0.7679        [32m0.9169[0m       [35m0.6285[0m      [31m0.6285[0m        [94m1.4310[0m     +  0.0000  10.8527
      6      [36m0.8393[0m        [32m0.8237[0m       [35m0.6450[0m      [31m0.6450[0m        [94m1.4019[0m     +  0.0000  10.7653
      7      0.8214        0.8617       [35m0.6500[0m      [31m0.6500[0m        [94m1.3941[0m     +  0.0000  10.8438
      8      [36m0.8929[0m        [32m0.8077[0m       0.6481      0.6481        [94m1.3871[0m     +  0.0000  10.6978
      9      0.8929        [32m0.7310[0m       [35m0.6533[0m      [31m0.6533[0m        [94m1.3793[0m     +  0.0000  10.6886
     10      0.8750        0.8175       0.6503      0.6503        1.3820        0.0000  10.8438
     11      0.8750        0.7510       0.6498      0.6498        1.3810        0.0000  11.0468
     12      0.8750        0.7455       0.6514      0.6514        [94m1.3790[0m     +  0.0000  10.8282
     13      [36m0.9107[0m        [32m0.7290[0m       0.6524      0.6524        [94m1.3782[0m     +  0.0000  10.9028
     14      0.8750        0.7759       0.6509      0.6509        1.3784        0.0000  10.8313
     15      0.8929        [32m0.6957[0m       0.6516      0.6516        [94m1.3773[0m     +  0.0000  10.7655
     16      0.9107        0.7283       0.6516      0.6516        [94m1.3769[0m     +  0.0000  10.8122
     17      0.9107        0.7398       0.6516      0.6516        [94m1.3765[0m     +  0.0000  10.7724
     18      0.8929        0.7700       0.6516      0.6516        1.3766        0.0000  10.7185
     19      0.8929        [32m0.6866[0m       0.6516      0.6516        1.3766        0.0000  10.7033
     20      0.8929        0.7273       0.6512      0.6512        [94m1.3762[0m     +  0.0000  10.8249
     21      0.9107        0.7291       0.6512      0.6512        [94m1.3762[0m     +  0.0000  10.8595
     22      0.9107        0.7368       0.6512      0.6512        [94m1.3762[0m     +  0.0000  10.7500
     23      0.8571        0.7413       0.6510      0.6510        [94m1.3761[0m     +  0.0000  11.0154
     24      0.9107        0.7230       0.6510      0.6510        1.3761        0.0000  10.7347
     25      0.8750        0.7253       0.6510      0.6510        1.3761        0.0000  10.8283
     26      [36m0.9464[0m        [32m0.6809[0m       0.6510      0.6510        1.3761        0.0000  10.6321
     27      0.9107        0.7158       0.6510      0.6510        1.3761        0.0000  10.6019
     28      0.8571        0.7541       0.6510      0.6510        1.3761        0.0000  10.6716
     29      0.8929        0.7427       0.6510      0.6510        1.3761        0.0000  10.9086
     30      0.8929        0.7358       0.6510      0.6510        1.3761        0.0000  11.0034
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.6590277777777778
F1 Macro Score after query 2: 0.19620018684368412
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7500[0m        [32m1.0941[0m       [35m0.6153[0m      [31m0.6153[0m        [94m1.2586[0m     +  0.0000  11.1046
      2      0.7500        [32m0.9351[0m       [35m0.6597[0m      [31m0.6597[0m        [94m1.1504[0m     +  0.0000  11.0849
      3      [36m0.8750[0m        [32m0.7665[0m       [35m0.6707[0m      [31m0.6707[0m        [94m1.1017[0m     +  0.0000  11.1944
      4      0.8750        [32m0.6789[0m       [35m0.6905[0m      [31m0.6905[0m        [94m1.0730[0m     +  0.0000  11.1155
      5      [36m0.9196[0m        [32m0.6536[0m       [35m0.6972[0m      [31m0.6972[0m        1.0794        0.0000  11.0972
      6      0.9018        [32m0.6269[0m       [35m0.6979[0m      [31m0.6979[0m        [94m1.0719[0m     +  0.0000  10.9376
      7      [36m0.9375[0m        [32m0.5898[0m       [35m0.6993[0m      [31m0.6993[0m        [94m1.0677[0m     +  0.0000  11.1584
      8      [36m0.9464[0m        [32m0.5599[0m       0.6970      0.6970        [94m1.0643[0m     +  0.0000  11.2567
      9      0.9464        [32m0.5351[0m       [35m0.7003[0m      [31m0.7003[0m        [94m1.0593[0m     +  0.0000  11.2660
     10      0.9375        0.5455       0.6991      0.6991        [94m1.0576[0m     +  0.0000  11.1903
     11      0.9464        0.5577       [35m0.7010[0m      [31m0.7010[0m        [94m1.0564[0m     +  0.0000  11.1815
     12      [36m0.9732[0m        0.5574       [35m0.7017[0m      [31m0.7017[0m        [94m1.0558[0m     +  0.0000  11.5733
     13      0.9464        0.5637       0.7005      0.7005        1.0563        0.0000  11.0472
     14      0.9464        0.5730       0.6995      0.6995        1.0569        0.0000  11.0878
     15      0.9643        0.5461       0.7007      0.7007        1.0560        0.0000  10.9684
     16      0.9464        [32m0.4995[0m       0.7010      0.7010        1.0563        0.0000  11.2967
     17      0.9375        0.5651       0.7012      0.7012        1.0561        0.0000  11.1437
     18      0.9643        0.5139       0.7009      0.7009        1.0559        0.0000  11.0891
     19      0.9554        0.5368       0.7012      0.7012        1.0560        0.0000  11.2494
     20      0.9643        0.5397       0.7002      0.7002        [94m1.0557[0m     +  0.0000  11.2474
     21      0.9464        0.5187       0.7002      0.7002        [94m1.0557[0m     +  0.0000  11.0349
     22      0.9375        0.5154       0.7002      0.7002        [94m1.0556[0m     +  0.0000  11.0593
     23      0.9554        0.5408       0.7002      0.7002        [94m1.0555[0m     +  0.0000  11.1739
     24      0.9375        0.5302       0.7002      0.7002        [94m1.0555[0m     +  0.0000  10.9498
     25      0.9554        0.5150       0.7002      0.7002        [94m1.0554[0m     +  0.0000  11.1561
     26      0.9554        0.5263       0.7003      0.7003        1.0554        0.0000  11.1482
     27      0.9643        0.5454       0.7005      0.7005        [94m1.0554[0m     +  0.0000  11.0618
     28      0.9643        0.5459       0.7003      0.7003        1.0554        0.0000  10.8960
     29      0.9732        0.5157       0.7003      0.7003        1.0554        0.0000  10.9843
     30      0.9643        0.5372       0.7002      0.7002        1.0554        0.0000  11.0311
     31      0.9554        0.5036       0.7002      0.7002        1.0554        0.0000  11.1200
     32      0.9643        0.5248       0.7002      0.7002        1.0554        0.0000  11.1452
     33      0.9643        0.5494       0.7002      0.7002        1.0554        0.0000  10.9079
     34      0.9375        0.5067       0.7002      0.7002        1.0554        0.0000  11.1395
     35      0.9464        0.5392       0.7002      0.7002        1.0554        0.0000  11.1437
     36      0.9464        0.5319       0.7002      0.7002        1.0554        0.0000  11.1983
     37      0.9732        0.5080       0.7002      0.7002        1.0554        0.0000  11.3140
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.7104166666666667
F1 Macro Score after query 3: 0.25540840639601636
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6490[0m        [32m1.0820[0m       [35m0.6646[0m      [31m0.6646[0m        [94m1.1710[0m     +  0.0000  11.6580
      2      [36m0.8317[0m        [32m0.8568[0m       [35m0.6981[0m      [31m0.6981[0m        [94m0.9936[0m     +  0.0000  11.5938
      3      [36m0.8702[0m        [32m0.7303[0m       [35m0.7411[0m      [31m0.7411[0m        [94m0.9052[0m     +  0.0000  11.5769
      4      [36m0.9135[0m        [32m0.6348[0m       0.7410      0.7410        [94m0.8832[0m     +  0.0000  11.5293
      5      [36m0.9327[0m        [32m0.5884[0m       [35m0.7467[0m      [31m0.7467[0m        [94m0.8668[0m     +  0.0000  11.5460
      6      [36m0.9519[0m        [32m0.5265[0m       0.7457      0.7457        [94m0.8643[0m     +  0.0000  11.6874
      7      [36m0.9663[0m        [32m0.5019[0m       [35m0.7510[0m      [31m0.7510[0m        [94m0.8556[0m     +  0.0000  11.6101
      8      0.9615        [32m0.4958[0m       [35m0.7550[0m      [31m0.7550[0m        [94m0.8545[0m     +  0.0000  11.5321
      9      [36m0.9712[0m        [32m0.4761[0m       0.7523      0.7523        0.8563        0.0000  11.7065
     10      0.9663        0.4864       [35m0.7568[0m      [31m0.7568[0m        [94m0.8514[0m     +  0.0000  11.5202
     11      0.9663        [32m0.4598[0m       [35m0.7569[0m      [31m0.7569[0m        [94m0.8495[0m     +  0.0000  11.7666
     12      0.9615        0.4617       [35m0.7578[0m      [31m0.7578[0m        [94m0.8488[0m     +  0.0000  11.6962
     13      0.9663        [32m0.4444[0m       0.7576      0.7576        [94m0.8478[0m     +  0.0000  11.4522
     14      0.9712        0.4600       0.7576      0.7576        [94m0.8477[0m     +  0.0000  11.7068
     15      0.9712        0.4607       0.7569      0.7569        [94m0.8476[0m     +  0.0000  11.6406
     16      0.9712        0.4614       0.7573      0.7573        [94m0.8472[0m     +  0.0000  11.6373
     17      0.9615        0.4521       0.7575      0.7575        0.8473        0.0000  11.4553
     18      0.9615        0.4657       0.7578      0.7578        [94m0.8471[0m     +  0.0000  11.5758
     19      [36m0.9760[0m        0.4608       [35m0.7582[0m      [31m0.7582[0m        0.8471        0.0000  11.5942
     20      0.9760        0.4520       0.7580      0.7580        [94m0.8469[0m     +  0.0000  11.5804
     21      0.9663        0.4805       0.7580      0.7580        0.8469        0.0000  11.5625
     22      0.9712        0.4705       0.7582      0.7582        0.8469        0.0000  11.5659
     23      0.9615        0.4621       0.7580      0.7580        [94m0.8469[0m     +  0.0000  11.4878
     24      0.9712        [32m0.4443[0m       0.7580      0.7580        0.8469        0.0000  11.5414
     25      0.9712        0.4671       0.7582      0.7582        [94m0.8468[0m     +  0.0000  11.7762
     26      0.9663        0.4462       0.7580      0.7580        0.8468        0.0000  11.6115
     27      0.9712        0.4511       0.7580      0.7580        [94m0.8468[0m     +  0.0000  11.7204
     28      0.9712        0.4538       0.7578      0.7578        [94m0.8468[0m     +  0.0000  11.5654
     29      0.9760        0.4466       0.7578      0.7578        [94m0.8468[0m     +  0.0000  11.6421
     30      0.9615        0.4530       0.7578      0.7578        0.8468        0.0000  11.4907
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.7564236111111112
F1 Macro Score after query 4: 0.31820319942596687
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7083[0m        [32m0.9549[0m       [35m0.7575[0m      [31m0.7575[0m        [94m0.8580[0m     +  0.0000  12.4219
      2      [36m0.8932[0m        [32m0.6688[0m       [35m0.7660[0m      [31m0.7660[0m        [94m0.7807[0m     +  0.0000  12.5472
      3      [36m0.9245[0m        [32m0.5705[0m       [35m0.7694[0m      [31m0.7694[0m        [94m0.7654[0m     +  0.0000  12.5783
      4      [36m0.9349[0m        [32m0.5209[0m       [35m0.7755[0m      [31m0.7755[0m        [94m0.7544[0m     +  0.0000  12.4980
      5      [36m0.9583[0m        [32m0.4505[0m       [35m0.7759[0m      [31m0.7759[0m        0.7605        0.0000  12.4441
      6      [36m0.9609[0m        [32m0.4070[0m       [35m0.7863[0m      [31m0.7863[0m        [94m0.7502[0m     +  0.0000  12.4054
      7      0.9583        0.4091       0.7839      0.7839        [94m0.7494[0m     +  0.0000  12.4505
      8      0.9609        [32m0.3924[0m       0.7837      0.7837        0.7533        0.0000  12.3904
      9      0.9609        0.4076       0.7847      0.7847        0.7499        0.0000  12.4690
     10      [36m0.9635[0m        [32m0.3849[0m       0.7847      0.7847        0.7500        0.0000  12.2650
     11      [36m0.9661[0m        [32m0.3683[0m       0.7856      0.7856        [94m0.7465[0m     +  0.0000  12.5145
     12      [36m0.9688[0m        [32m0.3601[0m       0.7858      0.7858        0.7479        0.0000  12.4045
     13      0.9661        0.3706       0.7858      0.7858        [94m0.7456[0m     +  0.0000  12.3917
     14      0.9661        0.3728       0.7842      0.7842        0.7464        0.0000  12.3321
     15      [36m0.9740[0m        0.3752       0.7854      0.7854        0.7460        0.0000  12.5034
     16      0.9661        [32m0.3600[0m       0.7845      0.7845        [94m0.7454[0m     +  0.0000  12.2796
     17      0.9661        0.3641       0.7849      0.7849        [94m0.7450[0m     +  0.0000  12.3399
     18      0.9661        [32m0.3562[0m       0.7851      0.7851        [94m0.7450[0m     +  0.0000  12.4028
     19      [36m0.9792[0m        [32m0.3482[0m       0.7847      0.7847        [94m0.7450[0m     +  0.0000  12.5142
     20      0.9714        0.3547       0.7849      0.7849        0.7450        0.0000  12.3598
     21      0.9740        0.3558       0.7849      0.7849        0.7450        0.0000  12.3629
     22      0.9714        0.3581       0.7849      0.7849        0.7451        0.0000  12.4995
     23      0.9766        0.3503       0.7849      0.7849        0.7452        0.0000  12.5092
     24      0.9714        0.3700       0.7849      0.7849        0.7451        0.0000  12.4665
     25      0.9714        0.3712       0.7851      0.7851        [94m0.7448[0m     +  0.0000  12.4476
     26      0.9740        0.3517       0.7851      0.7851        [94m0.7448[0m     +  0.0000  12.3286
     27      0.9714        0.3706       0.7851      0.7851        0.7448        0.0000  12.4690
     28      0.9688        0.3730       0.7851      0.7851        [94m0.7447[0m     +  0.0000  12.3907
     29      0.9766        0.3683       0.7851      0.7851        0.7448        0.0000  12.3825
     30      0.9740        0.3566       0.7851      0.7851        0.7448        0.0000  12.3583
     31      0.9792        0.3486       0.7851      0.7851        0.7448        0.0000  12.5780
     32      0.9688        0.3704       0.7851      0.7851        0.7448        0.0000  12.3790
     33      0.9766        0.3590       0.7851      0.7851        0.7448        0.0000  12.3912
     34      0.9688        0.3590       0.7851      0.7851        0.7448        0.0000  12.5436
     35      0.9740        0.3619       0.7851      0.7851        0.7448        0.0000  12.4224
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.7763888888888889
F1 Macro Score after query 5: 0.32948759944119943
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7869[0m        [32m0.8050[0m       [35m0.7460[0m      [31m0.7460[0m        [94m0.8213[0m     +  0.0000  13.8756
      2      [36m0.8963[0m        [32m0.5939[0m       [35m0.7743[0m      [31m0.7743[0m        [94m0.7374[0m     +  0.0000  14.0973
      3      [36m0.9304[0m        [32m0.4700[0m       [35m0.7833[0m      [31m0.7833[0m        [94m0.7032[0m     +  0.0000  14.2353
      4      [36m0.9432[0m        [32m0.4247[0m       [35m0.7845[0m      [31m0.7845[0m        [94m0.6983[0m     +  0.0000  14.0306
      5      [36m0.9560[0m        [32m0.3917[0m       0.7747      0.7747        0.7134        0.0000  14.0681
      6      [36m0.9716[0m        [32m0.3402[0m       [35m0.8016[0m      [31m0.8016[0m        [94m0.6771[0m     +  0.0000  14.0765
      7      0.9702        [32m0.3212[0m       0.8007      0.8007        0.6804        0.0000  13.9757
      8      0.9688        [32m0.3158[0m       [35m0.8017[0m      [31m0.8017[0m        0.6780        0.0000  14.1095
      9      [36m0.9730[0m        [32m0.3133[0m       0.7995      0.7995        0.6876        0.0000  14.0320
     10      [36m0.9744[0m        [32m0.2996[0m       0.8007      0.8007        0.6825        0.0000  14.2108
     11      [36m0.9815[0m        [32m0.2951[0m       [35m0.8024[0m      [31m0.8024[0m        [94m0.6766[0m     +  0.0000  14.0031
     12      [36m0.9844[0m        [32m0.2893[0m       [35m0.8026[0m      [31m0.8026[0m        [94m0.6765[0m     +  0.0000  13.9970
     13      0.9830        [32m0.2866[0m       [35m0.8030[0m      [31m0.8030[0m        0.6785        0.0000  13.9547
     14      0.9815        0.2936       0.8026      0.8026        0.6776        0.0000  14.1217
     15      0.9844        [32m0.2757[0m       0.8024      0.8024        0.6778        0.0000  13.7691
     16      0.9815        0.2802       0.8030      0.8030        0.6778        0.0000  13.9830
     17      0.9844        0.2944       0.8028      0.8028        0.6783        0.0000  14.0970
     18      0.9830        0.2923       0.8028      0.8028        0.6782        0.0000  14.0616
     19      0.9830        0.2848       0.8021      0.8021        0.6792        0.0000  14.2044
     20      0.9844        0.2858       0.8026      0.8026        0.6788        0.0000  13.9843
     21      [36m0.9872[0m        0.2765       0.8026      0.8026        0.6787        0.0000  14.1111
     22      0.9830        0.2812       0.8026      0.8026        0.6789        0.0000  14.0327
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8027777777777778
F1 Macro Score after query 6: 0.352548248684456
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8054[0m        [32m0.6802[0m       [35m0.7901[0m      [31m0.7901[0m        [94m0.6550[0m     +  0.0000  16.7810
      2      [36m0.8877[0m        [32m0.5021[0m       [35m0.8078[0m      [31m0.8078[0m        [94m0.5979[0m     +  0.0000  16.7502
      3      [36m0.9138[0m        [32m0.4341[0m       0.7969      0.7969        0.6398        0.0000  16.9195
      4      [36m0.9351[0m        [32m0.3752[0m       0.7946      0.7946        0.6416        0.0000  17.0330
      5      [36m0.9430[0m        [32m0.3398[0m       0.8033      0.8033        0.6295        0.0000  16.9040
      6      [36m0.9636[0m        [32m0.2982[0m       [35m0.8115[0m      [31m0.8115[0m        0.6335        0.0000  16.9363
      7      [36m0.9715[0m        [32m0.2728[0m       [35m0.8130[0m      [31m0.8130[0m        0.6385        0.0000  16.9221
      8      [36m0.9723[0m        [32m0.2707[0m       0.8128      0.8128        0.6423        0.0000  16.9097
      9      [36m0.9747[0m        [32m0.2610[0m       0.8064      0.8064        0.6601        0.0000  16.8389
     10      [36m0.9786[0m        [32m0.2507[0m       0.8057      0.8057        0.6537        0.0000  17.1409
     11      [36m0.9818[0m        [32m0.2415[0m       0.8099      0.8099        0.6488        0.0000  16.9479
     12      [36m0.9834[0m        [32m0.2386[0m       0.8102      0.8102        0.6493        0.0000  16.9036
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.81875
F1 Macro Score after query 7: 0.38257862693012773
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8410[0m        [32m0.5944[0m       [35m0.8104[0m      [31m0.8104[0m        [94m0.6184[0m     +  0.0000  21.8448
      2      [36m0.9050[0m        [32m0.4584[0m       0.7892      0.7892        0.6666        0.0000  22.0473
      3      [36m0.9125[0m        [32m0.4022[0m       0.7858      0.7858        0.6823        0.0000  21.7645
      4      [36m0.9254[0m        [32m0.3587[0m       [35m0.8187[0m      [31m0.8187[0m        0.6222        0.0000  22.1039
      5      [36m0.9373[0m        [32m0.3224[0m       0.8083      0.8083        0.6271        0.0000  21.8520
      6      [36m0.9519[0m        [32m0.2878[0m       [35m0.8313[0m      [31m0.8313[0m        [94m0.5940[0m     +  0.0000  21.8753
      7      [36m0.9572[0m        [32m0.2637[0m       0.8307      0.8307        [94m0.5939[0m     +  0.0000  21.9220
      8      [36m0.9625[0m        [32m0.2533[0m       0.8309      0.8309        0.6022        0.0000  21.8318
      9      [36m0.9682[0m        [32m0.2350[0m       0.8273      0.8273        0.6153        0.0000  21.6718
     10      0.9678        [32m0.2339[0m       0.8259      0.8259        0.6229        0.0000  21.8766
     11      [36m0.9708[0m        [32m0.2245[0m       0.8262      0.8262        0.6228        0.0000  21.8259
     12      [36m0.9757[0m        [32m0.2158[0m       0.8259      0.8259        0.6251        0.0000  22.0957
     13      [36m0.9770[0m        [32m0.2109[0m       0.8250      0.8250        0.6297        0.0000  22.1252
     14      [36m0.9775[0m        [32m0.2098[0m       0.8247      0.8247        0.6288        0.0000  22.0778
     15      0.9766        [32m0.2092[0m       0.8248      0.8248        0.6310        0.0000  21.8927
     16      [36m0.9792[0m        [32m0.2064[0m       0.8250      0.8250        0.6311        0.0000  21.9170
     17      [36m0.9797[0m        [32m0.2038[0m       0.8247      0.8247        0.6308        0.0000  21.9203
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8295138888888889
F1 Macro Score after query 8: 0.3946360516709378
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8671[0m        [32m0.4839[0m       [35m0.8384[0m      [31m0.8384[0m        [94m0.5228[0m     +  0.0000  30.6140
      2      [36m0.8980[0m        [32m0.4021[0m       [35m0.8429[0m      [31m0.8429[0m        [94m0.5096[0m     +  0.0000  30.9598
      3      [36m0.9079[0m        [32m0.3651[0m       [35m0.8450[0m      [31m0.8450[0m        [94m0.5071[0m     +  0.0000  30.9698
      4      [36m0.9203[0m        [32m0.3244[0m       0.8300      0.8300        0.5423        0.0000  30.7873
      5      [36m0.9312[0m        [32m0.2926[0m       0.8448      0.8448        0.5206        0.0000  30.9717
      6      [36m0.9507[0m        [32m0.2429[0m       0.8408      0.8408        0.5504        0.0000  30.9836
      7      [36m0.9582[0m        [32m0.2205[0m       0.8399      0.8399        0.5645        0.0000  30.6451
      8      [36m0.9634[0m        [32m0.2101[0m       0.8361      0.8361        0.5719        0.0000  31.0488
      9      [36m0.9683[0m        [32m0.1943[0m       0.8372      0.8372        0.5816        0.0000  30.9198
     10      [36m0.9715[0m        [32m0.1898[0m       0.8375      0.8375        0.5881        0.0000  30.8555
     11      [36m0.9750[0m        [32m0.1749[0m       0.8384      0.8384        0.5909        0.0000  31.0142
     12      [36m0.9775[0m        [32m0.1691[0m       0.8382      0.8382        0.5940        0.0000  30.9982
     13      [36m0.9790[0m        [32m0.1684[0m       0.8378      0.8378        0.5986        0.0000  30.8873
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8440972222222223
F1 Macro Score after query 9: 0.511575845388105
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9081[0m        [32m0.3513[0m       [35m0.8420[0m      [31m0.8420[0m        [94m0.5262[0m     +  0.0000  46.9211
      2      [36m0.9243[0m        [32m0.3024[0m       0.8354      0.8354        0.5668        0.0000  47.0451
      3      [36m0.9343[0m        [32m0.2670[0m       0.8236      0.8236        0.6120        0.0000  46.9159
      4      [36m0.9401[0m        [32m0.2392[0m       0.8160      0.8160        0.6295        0.0000  47.0017
      5      [36m0.9458[0m        [32m0.2175[0m       0.8139      0.8139        0.6595        0.0000  47.2921
      6      [36m0.9625[0m        [32m0.1724[0m       0.8380      0.8380        0.5642        0.0000  47.2328
      7      [36m0.9683[0m        [32m0.1571[0m       0.8345      0.8345        0.5776        0.0000  47.0003
      8      [36m0.9740[0m        [32m0.1430[0m       0.8328      0.8328        0.6037        0.0000  47.2128
      9      [36m0.9768[0m        [32m0.1340[0m       0.8358      0.8358        0.6077        0.0000  46.9813
     10      [36m0.9772[0m        [32m0.1258[0m       0.8347      0.8347        0.6146        0.0000  47.0470
     11      [36m0.9824[0m        [32m0.1158[0m       0.8325      0.8325        0.6432        0.0000  46.7469
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8428819444444444
F1 Macro Score after query 10: 0.5193855499061382
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9405[0m        [32m0.2563[0m       [35m0.8455[0m      [31m0.8455[0m        [94m0.5358[0m     +  0.0000  74.9705
      2      [36m0.9465[0m        [32m0.2161[0m       [35m0.8500[0m      [31m0.8500[0m        [94m0.5244[0m     +  0.0000  75.5479
      3      [36m0.9523[0m        [32m0.1906[0m       0.8436      0.8436        0.5562        0.0000  75.4025
      4      [36m0.9588[0m        [32m0.1653[0m       0.8417      0.8417        0.5534        0.0000  75.5512
      5      [36m0.9609[0m        [32m0.1500[0m       0.8347      0.8347        0.5906        0.0000  75.3622
      6      [36m0.9702[0m        [32m0.1196[0m       0.8375      0.8375        0.5805        0.0000  75.5102
      7      [36m0.9765[0m        [32m0.1041[0m       0.8394      0.8394        0.5880        0.0000  75.3016
      8      [36m0.9801[0m        [32m0.0934[0m       0.8340      0.8340        0.6120        0.0000  75.4841
      9      [36m0.9822[0m        [32m0.0873[0m       0.8337      0.8337        0.6427        0.0000  75.2279
     10      [36m0.9862[0m        [32m0.0786[0m       0.8347      0.8347        0.6502        0.0000  75.6254
     11      [36m0.9890[0m        [32m0.0716[0m       0.8356      0.8356        0.6648        0.0000  75.3525
     12      [36m0.9901[0m        [32m0.0668[0m       0.8368      0.8368        0.6680        0.0000  76.0896
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8380208333333333
F1 Macro Score after query 11: 0.5657112039855459
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9683[0m        [32m0.1363[0m       [35m0.7726[0m      [31m0.7726[0m        [94m0.7894[0m     +  0.0000  125.9874
      2      [36m0.9703[0m        [32m0.1202[0m       [35m0.7785[0m      [31m0.7785[0m        [94m0.7759[0m     +  0.0000  126.8086
      3      [36m0.9732[0m        [32m0.1042[0m       [35m0.8064[0m      [31m0.8064[0m        [94m0.6941[0m     +  0.0000  126.6550
      4      [36m0.9742[0m        [32m0.0956[0m       [35m0.8201[0m      [31m0.8201[0m        [94m0.6584[0m     +  0.0000  126.5509
      5      [36m0.9773[0m        [32m0.0847[0m       [35m0.8203[0m      [31m0.8203[0m        0.7541        0.0000  126.9661
      6      [36m0.9827[0m        [32m0.0674[0m       [35m0.8286[0m      [31m0.8286[0m        0.7073        0.0000  126.5629
      7      [36m0.9869[0m        [32m0.0552[0m       [35m0.8332[0m      [31m0.8332[0m        0.7164        0.0000  126.7283
      8      [36m0.9881[0m        [32m0.0480[0m       0.8313      0.8313        0.7266        0.0000  126.2779
      9      [36m0.9907[0m        [32m0.0436[0m       [35m0.8389[0m      [31m0.8389[0m        0.7157        0.0000  126.5098
     10      [36m0.9928[0m        [32m0.0380[0m       0.8363      0.8363        0.7644        0.0000  126.6216
     11      [36m0.9940[0m        [32m0.0327[0m       [35m0.8418[0m      [31m0.8418[0m        0.7122        0.0000  126.0816
     12      [36m0.9954[0m        [32m0.0304[0m       [35m0.8424[0m      [31m0.8424[0m        0.7139        0.0000  126.4200
     13      [36m0.9962[0m        [32m0.0287[0m       0.8424      0.8424        0.7178        0.0000  126.7965
     14      [36m0.9968[0m        [32m0.0274[0m       0.8410      0.8410        0.7311        0.0000  126.1984
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8305555555555556
F1 Macro Score after query 12: 0.5010969356445811
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9802[0m        [32m0.0740[0m       [35m0.8137[0m      [31m0.8137[0m        [94m0.7539[0m     +  0.0000  146.5050
      2      [36m0.9815[0m        [32m0.0669[0m       0.7804      0.7804        0.9113        0.0000  147.2539
      3      [36m0.9838[0m        [32m0.0601[0m       0.7219      0.7219        1.4086        0.0000  147.3484
      4      [36m0.9846[0m        [32m0.0552[0m       0.8000      0.8000        0.9615        0.0000  147.5486
      5      [36m0.9854[0m        [32m0.0501[0m       0.7776      0.7776        1.0476        0.0000  147.6518
      6      [36m0.9900[0m        [32m0.0373[0m       [35m0.8307[0m      [31m0.8307[0m        0.7621        0.0000  147.4319
      7      [36m0.9938[0m        [32m0.0277[0m       0.8274      0.8274        0.8144        0.0000  147.4476
      8      [36m0.9952[0m        [32m0.0239[0m       0.8302      0.8302        0.8252        0.0000  147.0939
      9      [36m0.9964[0m        [32m0.0206[0m       [35m0.8351[0m      [31m0.8351[0m        0.8390        0.0000  147.6916
     10      [36m0.9969[0m        [32m0.0181[0m       0.8319      0.8319        0.8537        0.0000  147.2330
     11      [36m0.9983[0m        [32m0.0143[0m       0.8307      0.8307        0.8249        0.0000  148.0621
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8309027777777777
F1 Macro Score after query 13: 0.526557376348108
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed49\AL_margin_sampling_results_for_multiclass_classification_s49.pickle
