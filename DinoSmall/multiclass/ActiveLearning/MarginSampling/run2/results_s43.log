(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m1.0000[0m        [32m2.1595[0m       [35m0.1453[0m      [31m0.1453[0m        [94m1.9872[0m     +  0.0000  10.3282
      2      0.1250        [32m2.0908[0m       [35m0.1505[0m      [31m0.1505[0m        2.0840        0.0000  9.6096
      3      0.3750        [32m1.8666[0m       0.1398      0.1398        2.0760        0.0000  9.6104
      4      0.3750        [32m1.7781[0m       [35m0.1905[0m      [31m0.1905[0m        2.0335        0.0000  9.6986
      5      0.6250        [32m1.7384[0m       0.1215      0.1215        2.1399        0.0000  9.5881
      6      0.8750        [32m1.6053[0m       0.1316      0.1316        2.1244        0.0000  10.1551
      7      0.5000        1.6767       0.1554      0.1554        2.1176        0.0000  10.1576
      8      0.6250        [32m1.5302[0m       0.1653      0.1653        2.1099        0.0000  10.1906
      9      0.7500        [32m1.5159[0m       0.1760      0.1760        2.1129        0.0000  10.2934
     10      0.8750        [32m1.5005[0m       [35m0.1953[0m      [31m0.1953[0m        2.1037        0.0000  10.2524
     11      0.7500        1.5941       0.1932      0.1932        2.1058        0.0000  10.2304
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.2418
Pre F1 macro score = 0.1737

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.4167[0m        [32m1.8335[0m       [35m0.2038[0m      [31m0.2038[0m        [94m1.8168[0m     +  0.0000  10.3629
      2      0.2500        [32m1.8105[0m       [35m0.2894[0m      [31m0.2894[0m        [94m1.7500[0m     +  0.0000  10.3160
      3      [36m0.6667[0m        [32m1.5900[0m       [35m0.3359[0m      [31m0.3359[0m        [94m1.7401[0m     +  0.0000  10.2630
      4      0.6667        [32m1.5426[0m       [35m0.3519[0m      [31m0.3519[0m        [94m1.7190[0m     +  0.0000  10.2841
      5      0.5833        [32m1.4221[0m       [35m0.3554[0m      [31m0.3554[0m        [94m1.7120[0m     +  0.0000  10.3631
      6      0.6667        [32m1.2874[0m       [35m0.3750[0m      [31m0.3750[0m        [94m1.6983[0m     +  0.0000  10.3291
      7      0.6667        1.3452       0.3710      0.3710        [94m1.6907[0m     +  0.0000  10.3894
      8      0.6667        1.3582       0.3745      0.3745        [94m1.6880[0m     +  0.0000  10.3471
      9      0.6667        [32m1.2783[0m       [35m0.3792[0m      [31m0.3792[0m        1.6897        0.0000  10.4016
     10      0.6667        [32m1.2339[0m       [35m0.3823[0m      [31m0.3823[0m        [94m1.6845[0m     +  0.0000  10.3007
     11      0.6667        1.3050       0.3811      0.3811        1.6856        0.0000  10.2955
     12      [36m0.7917[0m        [32m1.1970[0m       [35m0.3830[0m      [31m0.3830[0m        1.6857        0.0000  10.2675
     13      0.7500        1.1996       0.3826      0.3826        1.6846        0.0000  10.2776
     14      0.7083        1.2408       0.3814      0.3814        [94m1.6842[0m     +  0.0000  10.2889
     15      0.6667        1.2390       [35m0.3835[0m      [31m0.3835[0m        1.6847        0.0000  10.2995
     16      0.6667        1.2271       [35m0.3839[0m      [31m0.3839[0m        1.6847        0.0000  10.3058
     17      0.7500        1.2899       0.3839      0.3839        1.6848        0.0000  10.2710
     18      0.7917        1.2991       [35m0.3842[0m      [31m0.3842[0m        1.6847        0.0000  10.2658
     19      0.7083        1.2763       0.3842      0.3842        1.6846        0.0000  10.2836
     20      0.7500        1.2063       [35m0.3844[0m      [31m0.3844[0m        [94m1.6842[0m     +  0.0000  10.3400
     21      0.7500        1.2045       0.3844      0.3844        [94m1.6842[0m     +  0.0000  10.4843
     22      [36m0.8333[0m        1.2179       [35m0.3845[0m      [31m0.3845[0m        [94m1.6841[0m     +  0.0000  10.3564
     23      0.7083        1.2537       0.3845      0.3845        [94m1.6841[0m     +  0.0000  10.4062
     24      0.7500        1.2500       0.3844      0.3844        [94m1.6841[0m     +  0.0000  10.5013
     25      0.7083        1.2526       0.3844      0.3844        1.6841        0.0000  10.5338
     26      0.7083        1.2342       0.3844      0.3844        1.6841        0.0000  10.4525
     27      0.6667        [32m1.1792[0m       0.3844      0.3844        1.6841        0.0000  10.7153
     28      0.7083        1.2034       0.3844      0.3844        1.6841        0.0000  10.7045
     29      0.7917        [32m1.1766[0m       0.3844      0.3844        [94m1.6841[0m     +  0.0000  10.5405
     30      0.8333        [32m1.1490[0m       0.3842      0.3842        1.6841        0.0000  10.6888
     31      0.7500        1.2049       0.3842      0.3842        1.6841        0.0000  10.6910
     32      0.7917        1.2346       0.3844      0.3844        1.6841        0.0000  10.7830
     33      0.6667        1.2843       0.3844      0.3844        1.6841        0.0000  10.6398
     34      0.7500        1.2115       0.3844      0.3844        1.6841        0.0000  10.5470
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.45902777777777776
F1 Macro Score after query 1: 0.1675425176572488
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.4643[0m        [32m1.6310[0m       [35m0.4168[0m      [31m0.4168[0m        [94m1.6544[0m     +  0.0000  10.7989
      2      [36m0.5536[0m        [32m1.4445[0m       [35m0.4236[0m      [31m0.4236[0m        [94m1.5902[0m     +  0.0000  10.5027
      3      [36m0.6250[0m        [32m1.3242[0m       0.4165      0.4165        [94m1.5837[0m     +  0.0000  10.6054
      4      [36m0.6607[0m        [32m1.2629[0m       0.3979      0.3979        [94m1.5578[0m     +  0.0000  10.9957
      5      [36m0.7321[0m        [32m1.2016[0m       0.4172      0.4172        [94m1.5392[0m     +  0.0000  10.5945
      6      0.6964        [32m1.1262[0m       0.4128      0.4128        [94m1.5382[0m     +  0.0000  10.7503
      7      0.7143        1.1463       [35m0.4285[0m      [31m0.4285[0m        [94m1.5311[0m     +  0.0000  10.8792
      8      0.6964        [32m1.0995[0m       [35m0.4377[0m      [31m0.4377[0m        [94m1.5247[0m     +  0.0000  10.7974
      9      0.6964        [32m1.0833[0m       0.4328      0.4328        1.5280        0.0000  10.6623
     10      [36m0.7857[0m        [32m1.0699[0m       [35m0.4443[0m      [31m0.4443[0m        1.5285        0.0000  10.6720
     11      0.7500        [32m1.0513[0m       0.4401      0.4401        1.5293        0.0000  10.9218
     12      0.7321        1.0584       0.4420      0.4420        1.5285        0.0000  10.7811
     13      0.6429        1.0969       [35m0.4451[0m      [31m0.4451[0m        1.5271        0.0000  10.7988
     14      0.7321        [32m1.0512[0m       [35m0.4486[0m      [31m0.4486[0m        1.5259        0.0000  10.5300
     15      [36m0.8214[0m        [32m1.0377[0m       [35m0.4526[0m      [31m0.4526[0m        [94m1.5246[0m     +  0.0000  10.6258
     16      0.7500        [32m0.9643[0m       [35m0.4530[0m      [31m0.4530[0m        [94m1.5245[0m     +  0.0000  10.6691
     17      0.7500        1.0204       [35m0.4536[0m      [31m0.4536[0m        [94m1.5243[0m     +  0.0000  10.9270
     18      0.7857        0.9822       [35m0.4538[0m      [31m0.4538[0m        [94m1.5243[0m     +  0.0000  10.6081
     19      0.7321        1.0482       0.4536      0.4536        1.5243        0.0000  10.7967
     20      0.7679        1.0628       [35m0.4542[0m      [31m0.4542[0m        1.5243        0.0000  10.7676
     21      0.8214        1.0037       0.4542      0.4542        [94m1.5242[0m     +  0.0000  10.8773
     22      0.7321        1.0323       0.4542      0.4542        1.5243        0.0000  10.7597
     23      0.7143        1.0132       0.4540      0.4540        1.5243        0.0000  10.7158
     24      0.7679        1.0131       0.4542      0.4542        [94m1.5242[0m     +  0.0000  10.8753
     25      0.6964        1.0800       0.4542      0.4542        [94m1.5241[0m     +  0.0000  10.7044
     26      0.7857        1.0229       0.4542      0.4542        [94m1.5241[0m     +  0.0000  10.9357
     27      0.7500        1.0079       [35m0.4543[0m      [31m0.4543[0m        [94m1.5241[0m     +  0.0000  10.7609
     28      0.7679        1.0021       0.4543      0.4543        [94m1.5241[0m     +  0.0000  10.5174
     29      0.7500        1.0327       [35m0.4545[0m      [31m0.4545[0m        [94m1.5241[0m     +  0.0000  10.7981
     30      0.7857        1.0304       0.4545      0.4545        [94m1.5241[0m     +  0.0000  10.7582
     31      0.7679        1.0330       0.4545      0.4545        [94m1.5241[0m     +  0.0000  10.6564
     32      0.7143        1.0446       0.4545      0.4545        [94m1.5241[0m     +  0.0000  10.8622
     33      0.7679        0.9984       0.4545      0.4545        [94m1.5241[0m     +  0.0000  10.8087
     34      0.8036        1.0365       0.4545      0.4545        1.5241        0.0000  10.7842
     35      0.7321        1.0549       0.4545      0.4545        1.5241        0.0000  10.7925
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.4795138888888889
F1 Macro Score after query 2: 0.21702386351870487
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5982[0m        [32m1.3967[0m       [35m0.5314[0m      [31m0.5314[0m        [94m1.3982[0m     +  0.0000  11.0688
      2      [36m0.6339[0m        [32m1.2194[0m       [35m0.5500[0m      [31m0.5500[0m        [94m1.3574[0m     +  0.0000  11.0225
      3      [36m0.7500[0m        [32m1.0619[0m       [35m0.5576[0m      [31m0.5576[0m        [94m1.3445[0m     +  0.0000  10.9181
      4      [36m0.7679[0m        [32m1.0151[0m       [35m0.5696[0m      [31m0.5696[0m        [94m1.3067[0m     +  0.0000  11.1447
      5      [36m0.8750[0m        [32m0.9070[0m       [35m0.5747[0m      [31m0.5747[0m        [94m1.2954[0m     +  0.0000  10.9115
      6      [36m0.8839[0m        [32m0.8673[0m       0.5691      0.5691        1.3102        0.0000  11.2418
      7      [36m0.9196[0m        [32m0.8324[0m       0.5736      0.5736        1.3075        0.0000  11.0231
      8      0.8929        0.8407       0.5710      0.5710        1.3056        0.0000  10.9268
      9      [36m0.9286[0m        [32m0.7914[0m       0.5719      0.5719        1.3056        0.0000  11.0391
     10      [36m0.9464[0m        0.7953       0.5719      0.5719        1.3049        0.0000  11.0232
     11      0.9464        0.7954       0.5734      0.5734        1.3016        0.0000  10.7716
     12      0.9375        [32m0.7643[0m       0.5731      0.5731        1.3011        0.0000  11.0688
     13      [36m0.9554[0m        0.7795       0.5733      0.5733        1.3019        0.0000  10.8796
     14      0.9286        0.7985       0.5734      0.5734        1.3015        0.0000  11.0837
     15      0.9107        [32m0.7511[0m       0.5727      0.5727        1.3023        0.0000  11.0689
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.6090277777777777
F1 Macro Score after query 3: 0.23279280473938474
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7212[0m        [32m1.1961[0m       [35m0.5875[0m      [31m0.5875[0m        [94m1.2354[0m     +  0.0000  11.3718
      2      [36m0.7885[0m        [32m0.9929[0m       [35m0.6389[0m      [31m0.6389[0m        [94m1.1574[0m     +  0.0000  11.4758
      3      [36m0.8654[0m        [32m0.8521[0m       [35m0.6576[0m      [31m0.6576[0m        [94m1.1270[0m     +  0.0000  11.3670
      4      [36m0.9087[0m        [32m0.7782[0m       0.6536      0.6536        [94m1.1193[0m     +  0.0000  11.6021
      5      0.9038        [32m0.7466[0m       [35m0.6694[0m      [31m0.6694[0m        [94m1.0865[0m     +  0.0000  11.6640
      6      [36m0.9231[0m        [32m0.6691[0m       0.6694      0.6694        [94m1.0807[0m     +  0.0000  11.5366
      7      [36m0.9375[0m        0.6727       0.6672      0.6672        1.0833        0.0000  11.5843
      8      0.9279        [32m0.6392[0m       0.6689      0.6689        [94m1.0797[0m     +  0.0000  11.3816
      9      [36m0.9423[0m        [32m0.6299[0m       [35m0.6708[0m      [31m0.6708[0m        [94m1.0744[0m     +  0.0000  11.8193
     10      0.9183        [32m0.6251[0m       0.6668      0.6668        1.0758        0.0000  11.3820
     11      [36m0.9471[0m        [32m0.6063[0m       0.6656      0.6656        1.0774        0.0000  11.5850
     12      0.9327        0.6090       0.6646      0.6646        1.0790        0.0000  11.7880
     13      0.9375        0.6091       0.6660      0.6660        1.0766        0.0000  11.4140
     14      0.9423        [32m0.5903[0m       0.6668      0.6668        1.0770        0.0000  11.5843
     15      0.9327        [32m0.5889[0m       0.6681      0.6681        [94m1.0741[0m     +  0.0000  11.6009
     16      0.9471        0.6027       0.6679      0.6679        1.0742        0.0000  11.5057
     17      0.9375        0.6016       0.6674      0.6674        1.0747        0.0000  11.6320
     18      0.9471        [32m0.5803[0m       0.6672      0.6672        1.0749        0.0000  11.7100
     19      0.9471        0.5891       0.6674      0.6674        1.0750        0.0000  11.6310
     20      [36m0.9567[0m        [32m0.5777[0m       0.6674      0.6674        1.0750        0.0000  11.2867
     21      0.9279        0.5890       0.6674      0.6674        1.0750        0.0000  11.3510
     22      0.9567        0.5848       0.6674      0.6674        1.0750        0.0000  11.3189
     23      0.9423        0.6099       0.6674      0.6674        1.0750        0.0000  11.1861
     24      0.9375        0.6038       0.6672      0.6672        1.0751        0.0000  11.5699
     25      0.9279        0.6083       0.6672      0.6672        1.0752        0.0000  11.4754
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.6954861111111111
F1 Macro Score after query 4: 0.26320047724790996
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6901[0m        [32m1.0774[0m       [35m0.6819[0m      [31m0.6819[0m        [94m1.0659[0m     +  0.0000  12.4616
      2      [36m0.8021[0m        [32m0.8633[0m       [35m0.7061[0m      [31m0.7061[0m        [94m1.0160[0m     +  0.0000  12.3195
      3      [36m0.8724[0m        [32m0.7568[0m       [35m0.7102[0m      [31m0.7102[0m        [94m0.9988[0m     +  0.0000  12.5393
      4      [36m0.9036[0m        [32m0.7026[0m       0.6970      0.6970        [94m0.9629[0m     +  0.0000  12.4131
      5      [36m0.9167[0m        [32m0.6434[0m       0.6960      0.6960        [94m0.9618[0m     +  0.0000  12.2113
      6      [36m0.9323[0m        [32m0.5959[0m       0.6931      0.6931        [94m0.9606[0m     +  0.0000  12.3204
      7      0.9245        [32m0.5776[0m       0.6927      0.6927        [94m0.9581[0m     +  0.0000  12.6176
      8      [36m0.9349[0m        [32m0.5705[0m       0.6920      0.6920        0.9622        0.0000  12.4751
      9      [36m0.9401[0m        [32m0.5580[0m       0.6851      0.6851        0.9659        0.0000  12.3032
     10      0.9401        [32m0.5423[0m       0.6887      0.6887        0.9600        0.0000  12.3508
     11      0.9375        [32m0.5343[0m       0.6856      0.6856        0.9601        0.0000  12.5082
     12      [36m0.9479[0m        [32m0.5051[0m       0.6858      0.6858        0.9588        0.0000  12.4752
     13      0.9479        0.5155       0.6866      0.6866        0.9589        0.0000  12.5269
     14      0.9479        0.5220       0.6865      0.6865        0.9583        0.0000  12.3351
     15      [36m0.9557[0m        0.5152       0.6859      0.6859        0.9593        0.0000  12.1321
     16      [36m0.9583[0m        0.5107       0.6861      0.6861        [94m0.9573[0m     +  0.0000  12.1000
     17      0.9505        0.5091       0.6858      0.6858        [94m0.9571[0m     +  0.0000  12.3199
     18      0.9531        0.5166       0.6866      0.6866        [94m0.9564[0m     +  0.0000  12.3512
     19      0.9557        0.5357       0.6868      0.6868        [94m0.9559[0m     +  0.0000  12.5850
     20      0.9479        0.5065       0.6885      0.6885        [94m0.9547[0m     +  0.0000  12.6328
     21      0.9479        0.5128       0.6885      0.6885        0.9548        0.0000  12.3675
     22      0.9479        0.5211       0.6885      0.6885        0.9547        0.0000  12.3528
     23      0.9427        0.5058       0.6885      0.6885        0.9548        0.0000  12.4138
     24      0.9531        0.5055       0.6885      0.6885        0.9549        0.0000  12.4603
     25      0.9505        0.5125       0.6885      0.6885        0.9548        0.0000  12.3984
     26      0.9505        0.5149       0.6885      0.6885        0.9548        0.0000  12.5852
     27      0.9401        0.5140       0.6885      0.6885        0.9549        0.0000  12.4129
     28      0.9453        [32m0.5048[0m       0.6885      0.6885        0.9549        0.0000  12.5066
     29      0.9505        0.5235       0.6885      0.6885        0.9549        0.0000  12.1961
     30      0.9479        0.5185       0.6885      0.6885        0.9549        0.0000  12.1322
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.7291666666666665
F1 Macro Score after query 5: 0.31570473251365344
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7486[0m        [32m0.9188[0m       [35m0.7302[0m      [31m0.7302[0m        [94m0.8674[0m     +  0.0000  13.9731
      2      [36m0.8565[0m        [32m0.7112[0m       [35m0.7648[0m      [31m0.7648[0m        [94m0.8153[0m     +  0.0000  13.9459
      3      [36m0.8991[0m        [32m0.6195[0m       0.7615      0.7615        [94m0.7985[0m     +  0.0000  13.8354
      4      [36m0.9205[0m        [32m0.5609[0m       [35m0.7674[0m      [31m0.7674[0m        [94m0.7778[0m     +  0.0000  13.9609
      5      [36m0.9318[0m        [32m0.5191[0m       0.7590      0.7590        0.7982        0.0000  14.0548
      6      [36m0.9588[0m        [32m0.4418[0m       0.7649      0.7649        0.7918        0.0000  13.9923
      7      0.9574        [32m0.4372[0m       0.7556      0.7556        0.8005        0.0000  13.8649
      8      0.9574        [32m0.4245[0m       0.7641      0.7641        0.7922        0.0000  14.0979
      9      [36m0.9616[0m        [32m0.4184[0m       0.7550      0.7550        0.7970        0.0000  14.1606
     10      0.9602        [32m0.4009[0m       0.7608      0.7608        0.7880        0.0000  13.9902
     11      [36m0.9631[0m        0.4044       [35m0.7731[0m      [31m0.7731[0m        [94m0.7676[0m     +  0.0000  13.6752
     12      [36m0.9645[0m        [32m0.3890[0m       0.7703      0.7703        0.7713        0.0000  13.9624
     13      [36m0.9702[0m        [32m0.3876[0m       0.7694      0.7694        0.7706        0.0000  13.8528
     14      0.9673        [32m0.3775[0m       0.7705      0.7705        0.7704        0.0000  14.0221
     15      0.9659        0.3854       0.7708      0.7708        0.7681        0.0000  14.0080
     16      0.9673        0.3794       0.7696      0.7696        [94m0.7666[0m     +  0.0000  13.9296
     17      0.9616        0.3808       0.7689      0.7689        [94m0.7659[0m     +  0.0000  14.1335
     18      0.9631        0.3856       0.7691      0.7691        [94m0.7653[0m     +  0.0000  14.0849
     19      [36m0.9730[0m        0.3776       0.7688      0.7688        0.7653        0.0000  13.7723
     20      0.9645        [32m0.3716[0m       0.7688      0.7688        [94m0.7651[0m     +  0.0000  13.7893
     21      0.9659        0.3810       0.7686      0.7686        [94m0.7650[0m     +  0.0000  13.9929
     22      0.9560        0.3838       0.7681      0.7681        0.7652        0.0000  13.6794
     23      0.9659        0.3815       0.7679      0.7679        0.7653        0.0000  14.0714
     24      0.9730        [32m0.3669[0m       0.7663      0.7663        0.7656        0.0000  14.0070
     25      0.9645        0.3719       0.7674      0.7674        0.7655        0.0000  13.9612
     26      0.9688        [32m0.3645[0m       0.7674      0.7674        0.7656        0.0000  13.7740
     27      0.9688        0.3816       0.7674      0.7674        0.7655        0.0000  13.8668
     28      0.9688        0.3760       0.7672      0.7672        0.7655        0.0000  13.8969
     29      0.9631        0.3825       0.7672      0.7672        0.7655        0.0000  13.9764
     30      0.9659        0.3748       0.7674      0.7674        0.7655        0.0000  13.8830
     31      0.9673        0.3702       0.7674      0.7674        0.7655        0.0000  13.9919
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.7704861111111111
F1 Macro Score after query 6: 0.39473035973020243
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8133[0m        [32m0.6929[0m       [35m0.7457[0m      [31m0.7457[0m        [94m0.8875[0m     +  0.0000  16.4792
      2      [36m0.8948[0m        [32m0.5275[0m       [35m0.7590[0m      [31m0.7590[0m        [94m0.8547[0m     +  0.0000  17.0736
      3      [36m0.9233[0m        [32m0.4622[0m       [35m0.7618[0m      [31m0.7618[0m        0.8560        0.0000  16.5712
      4      [36m0.9399[0m        [32m0.4067[0m       [35m0.7686[0m      [31m0.7686[0m        [94m0.8450[0m     +  0.0000  16.6037
      5      [36m0.9454[0m        [32m0.3674[0m       0.7628      0.7628        0.8688        0.0000  16.5249
      6      [36m0.9636[0m        [32m0.3290[0m       [35m0.7708[0m      [31m0.7708[0m        [94m0.7638[0m     +  0.0000  17.0103
      7      0.9628        [32m0.3159[0m       [35m0.7750[0m      [31m0.7750[0m        [94m0.7620[0m     +  0.0000  16.8695
      8      [36m0.9684[0m        [32m0.3050[0m       [35m0.7757[0m      [31m0.7757[0m        [94m0.7618[0m     +  0.0000  16.6356
      9      [36m0.9715[0m        [32m0.2951[0m       [35m0.7785[0m      [31m0.7785[0m        0.7628        0.0000  16.6191
     10      0.9691        [32m0.2901[0m       0.7766      0.7766        0.7648        0.0000  16.7915
     11      [36m0.9794[0m        [32m0.2773[0m       [35m0.7833[0m      [31m0.7833[0m        [94m0.7296[0m     +  0.0000  16.8713
     12      0.9794        [32m0.2743[0m       [35m0.7866[0m      [31m0.7866[0m        [94m0.7224[0m     +  0.0000  16.5097
     13      0.9771        [32m0.2727[0m       0.7863      0.7863        0.7237        0.0000  16.5878
     14      0.9786        [32m0.2671[0m       0.7849      0.7849        0.7253        0.0000  16.6046
     15      0.9778        [32m0.2650[0m       0.7866      0.7866        0.7228        0.0000  16.7615
     16      0.9778        0.2727       [35m0.7896[0m      [31m0.7896[0m        [94m0.7142[0m     +  0.0000  16.6373
     17      [36m0.9802[0m        [32m0.2597[0m       0.7894      0.7894        [94m0.7140[0m     +  0.0000  16.6390
     18      0.9786        0.2630       0.7894      0.7894        [94m0.7134[0m     +  0.0000  16.8382
     19      [36m0.9810[0m        0.2650       0.7896      0.7896        [94m0.7120[0m     +  0.0000  16.6825
     20      0.9794        0.2607       [35m0.7899[0m      [31m0.7899[0m        0.7121        0.0000  16.6665
     21      [36m0.9834[0m        [32m0.2557[0m       0.7899      0.7899        [94m0.7114[0m     +  0.0000  16.6033
     22      0.9818        0.2639       0.7898      0.7898        [94m0.7109[0m     +  0.0000  16.5578
     23      0.9802        0.2573       0.7898      0.7898        [94m0.7107[0m     +  0.0000  16.8670
     24      0.9826        0.2664       [35m0.7901[0m      [31m0.7901[0m        [94m0.7103[0m     +  0.0000  16.7458
     25      0.9763        0.2638       [35m0.7903[0m      [31m0.7903[0m        0.7106        0.0000  16.4001
     26      0.9818        0.2593       0.7899      0.7899        0.7106        0.0000  16.5559
     27      0.9794        0.2635       0.7899      0.7899        0.7105        0.0000  17.0571
     28      0.9810        0.2559       0.7899      0.7899        0.7103        0.0000  16.6970
     29      0.9826        0.2573       0.7899      0.7899        [94m0.7102[0m     +  0.0000  16.4933
     30      0.9794        0.2600       0.7899      0.7899        0.7102        0.0000  16.6194
     31      0.9802        0.2631       0.7899      0.7899        0.7102        0.0000  16.7117
     32      0.9826        0.2593       0.7899      0.7899        0.7102        0.0000  16.6307
     33      0.9802        0.2596       0.7899      0.7899        0.7102        0.0000  16.4942
     34      0.9818        0.2585       0.7901      0.7901        [94m0.7102[0m     +  0.0000  16.7902
     35      0.9826        0.2635       0.7901      0.7901        0.7102        0.0000  16.6177
     36      0.9818        0.2572       0.7901      0.7901        0.7102        0.0000  16.8064
     37      0.9818        0.2647       0.7901      0.7901        0.7102        0.0000  16.7438
     38      0.9810        0.2584       0.7901      0.7901        0.7102        0.0000  16.4799
     39      0.9794        0.2656       0.7901      0.7901        0.7102        0.0000  16.7631
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.7946180555555555
F1 Macro Score after query 7: 0.39858224104061074
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8644[0m        [32m0.5454[0m       [35m0.8113[0m      [31m0.8113[0m        [94m0.6293[0m     +  0.0000  21.6221
      2      [36m0.9134[0m        [32m0.4106[0m       [35m0.8200[0m      [31m0.8200[0m        [94m0.6157[0m     +  0.0000  21.9505
      3      [36m0.9342[0m        [32m0.3527[0m       0.8196      0.8196        [94m0.5973[0m     +  0.0000  21.8706
      4      [36m0.9408[0m        [32m0.3263[0m       0.7960      0.7960        0.6241        0.0000  21.5135
      5      [36m0.9496[0m        [32m0.2935[0m       [35m0.8281[0m      [31m0.8281[0m        [94m0.5829[0m     +  0.0000  21.8113
      6      [36m0.9633[0m        [32m0.2455[0m       0.8241      0.8241        0.5866        0.0000  22.0933
      7      [36m0.9726[0m        [32m0.2320[0m       0.8215      0.8215        0.6078        0.0000  22.0279
      8      [36m0.9770[0m        [32m0.2109[0m       0.8214      0.8214        0.6125        0.0000  21.5105
      9      [36m0.9806[0m        [32m0.2090[0m       0.8184      0.8184        0.6239        0.0000  21.6514
     10      [36m0.9810[0m        [32m0.2000[0m       0.8203      0.8203        0.6151        0.0000  21.5273
     11      [36m0.9832[0m        [32m0.1901[0m       0.8172      0.8172        0.6271        0.0000  21.5995
     12      [36m0.9841[0m        [32m0.1839[0m       0.8161      0.8161        0.6285        0.0000  21.8875
     13      [36m0.9859[0m        0.1862       0.8165      0.8165        0.6296        0.0000  21.6678
     14      [36m0.9872[0m        [32m0.1821[0m       0.8149      0.8149        0.6343        0.0000  21.6519
     15      0.9867        [32m0.1798[0m       0.8191      0.8191        0.6299        0.0000  21.5764
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8133680555555556
F1 Macro Score after query 8: 0.44157882094739054
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8869[0m        [32m0.4449[0m       [35m0.7792[0m      [31m0.7792[0m        [94m0.6393[0m     +  0.0000  30.6268
      2      [36m0.9168[0m        [32m0.3625[0m       [35m0.7875[0m      [31m0.7875[0m        [94m0.6175[0m     +  0.0000  30.7270
      3      [36m0.9243[0m        [32m0.3236[0m       0.7748      0.7748        0.6588        0.0000  30.6327
      4      [36m0.9394[0m        [32m0.2859[0m       0.7835      0.7835        0.6507        0.0000  30.6107
      5      [36m0.9507[0m        [32m0.2541[0m       0.7773      0.7773        0.6761        0.0000  30.5978
      6      [36m0.9589[0m        [32m0.2145[0m       [35m0.7950[0m      [31m0.7950[0m        0.6459        0.0000  30.9520
      7      [36m0.9700[0m        [32m0.1915[0m       [35m0.7974[0m      [31m0.7974[0m        0.6480        0.0000  30.7680
      8      [36m0.9725[0m        [32m0.1821[0m       0.7931      0.7931        0.6693        0.0000  30.2811
      9      [36m0.9767[0m        [32m0.1689[0m       0.7944      0.7944        0.6728        0.0000  30.5315
     10      [36m0.9785[0m        [32m0.1642[0m       [35m0.7988[0m      [31m0.7988[0m        0.6596        0.0000  30.6236
     11      [36m0.9837[0m        [32m0.1511[0m       0.7986      0.7986        0.6699        0.0000  30.3927
     12      0.9837        [32m0.1481[0m       [35m0.7997[0m      [31m0.7997[0m        0.6698        0.0000  30.5807
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.809375
F1 Macro Score after query 9: 0.4155047125878526
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9076[0m        [32m0.3711[0m       [35m0.7752[0m      [31m0.7752[0m        [94m0.6528[0m     +  0.0000  45.7752
      2      [36m0.9228[0m        [32m0.3092[0m       0.7660      0.7660        0.6602        0.0000  46.7787
      3      [36m0.9342[0m        [32m0.2693[0m       [35m0.7807[0m      [31m0.7807[0m        [94m0.6420[0m     +  0.0000  46.7126
      4      [36m0.9436[0m        [32m0.2386[0m       [35m0.7927[0m      [31m0.7927[0m        [94m0.6146[0m     +  0.0000  46.2471
      5      [36m0.9510[0m        [32m0.2085[0m       [35m0.8009[0m      [31m0.8009[0m        [94m0.6072[0m     +  0.0000  46.5487
      6      [36m0.9676[0m        [32m0.1702[0m       0.7939      0.7939        0.6371        0.0000  46.8143
      7      [36m0.9739[0m        [32m0.1470[0m       0.7955      0.7955        0.6426        0.0000  46.4257
      8      [36m0.9774[0m        [32m0.1378[0m       0.7991      0.7991        0.6486        0.0000  46.5418
      9      [36m0.9810[0m        [32m0.1253[0m       0.7986      0.7986        0.6508        0.0000  46.4950
     10      [36m0.9839[0m        [32m0.1147[0m       0.7976      0.7976        0.6638        0.0000  47.0891
     11      [36m0.9867[0m        [32m0.1055[0m       0.8009      0.8009        0.6665        0.0000  46.6358
     12      [36m0.9886[0m        [32m0.1001[0m       [35m0.8010[0m      [31m0.8010[0m        0.6706        0.0000  46.2428
     13      [36m0.9897[0m        [32m0.0977[0m       [35m0.8012[0m      [31m0.8012[0m        0.6718        0.0000  47.0738
     14      [36m0.9901[0m        [32m0.0969[0m       [35m0.8023[0m      [31m0.8023[0m        0.6708        0.0000  46.4896
     15      [36m0.9907[0m        [32m0.0950[0m       0.8014      0.8014        0.6680        0.0000  46.4449
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8102430555555555
F1 Macro Score after query 10: 0.4256329118351859
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9510[0m        [32m0.2041[0m       [35m0.7977[0m      [31m0.7977[0m        [94m0.6841[0m     +  0.0000  74.4930
      2      [36m0.9561[0m        [32m0.1806[0m       0.7863      0.7863        0.7438        0.0000  74.8212
      3      [36m0.9619[0m        [32m0.1564[0m       0.7682      0.7682        0.8086        0.0000  74.3340
      4      [36m0.9647[0m        [32m0.1412[0m       [35m0.7986[0m      [31m0.7986[0m        0.7093        0.0000  74.6017
      5      [36m0.9691[0m        [32m0.1290[0m       [35m0.8191[0m      [31m0.8191[0m        [94m0.6278[0m     +  0.0000  75.0558
      6      [36m0.9792[0m        [32m0.0954[0m       [35m0.8196[0m      [31m0.8196[0m        0.6280        0.0000  75.2587
      7      [36m0.9847[0m        [32m0.0810[0m       0.8189      0.8189        0.6408        0.0000  74.8792
      8      [36m0.9881[0m        [32m0.0705[0m       0.8142      0.8142        0.6589        0.0000  75.1787
      9      [36m0.9911[0m        [32m0.0631[0m       0.8130      0.8130        0.6742        0.0000  75.1622
     10      [36m0.9930[0m        [32m0.0561[0m       0.8085      0.8085        0.7084        0.0000  75.3996
     11      [36m0.9946[0m        [32m0.0494[0m       0.8144      0.8144        0.7021        0.0000  75.1472
     12      [36m0.9959[0m        [32m0.0445[0m       0.8137      0.8137        0.7000        0.0000  74.7725
     13      [36m0.9963[0m        [32m0.0430[0m       0.8135      0.8135        0.7148        0.0000  74.7885
     14      [36m0.9968[0m        [32m0.0421[0m       0.8120      0.8120        0.7169        0.0000  74.7509
     15      [36m0.9973[0m        [32m0.0402[0m       0.8123      0.8123        0.7232        0.0000  75.0523
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8276041666666667
F1 Macro Score after query 11: 0.44487655686320826
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9803[0m        [32m0.0886[0m       [35m0.8187[0m      [31m0.8187[0m        [94m0.6435[0m     +  0.0000  124.5972
      2      [36m0.9819[0m        [32m0.0785[0m       [35m0.8302[0m      [31m0.8302[0m        [94m0.6327[0m     +  0.0000  125.6346
      3      [36m0.9844[0m        [32m0.0684[0m       0.8132      0.8132        0.8210        0.0000  125.3700
      4      [36m0.9865[0m        [32m0.0607[0m       [35m0.8399[0m      [31m0.8399[0m        0.6963        0.0000  125.3373
      5      [36m0.9874[0m        [32m0.0548[0m       0.8271      0.8271        0.6937        0.0000  124.8017
      6      [36m0.9908[0m        [32m0.0400[0m       0.8333      0.8333        0.6575        0.0000  125.5579
      7      [36m0.9955[0m        [32m0.0285[0m       0.8286      0.8286        0.7003        0.0000  125.7099
      8      [36m0.9972[0m        [32m0.0229[0m       0.8215      0.8215        0.7325        0.0000  125.1156
      9      [36m0.9974[0m        [32m0.0204[0m       0.8234      0.8234        0.7384        0.0000  125.9831
     10      [36m0.9981[0m        [32m0.0171[0m       0.8194      0.8194        0.7778        0.0000  125.8966
     11      [36m0.9989[0m        [32m0.0141[0m       0.8233      0.8233        0.7778        0.0000  125.9109
     12      0.9989        [32m0.0130[0m       0.8227      0.8227        0.7863        0.0000  125.3550
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8381944444444445
F1 Macro Score after query 12: 0.43696216169557983
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9849[0m        [32m0.0627[0m       [35m0.7939[0m      [31m0.7939[0m        [94m0.8030[0m     +  0.0000  145.4121
      2      [36m0.9873[0m        [32m0.0544[0m       [35m0.8156[0m      [31m0.8156[0m        [94m0.7400[0m     +  0.0000  146.2371
      3      [36m0.9875[0m        [32m0.0502[0m       0.8000      0.8000        0.8384        0.0000  145.9401
      4      [36m0.9895[0m        [32m0.0452[0m       0.7997      0.7997        0.8772        0.0000  146.1896
      5      [36m0.9902[0m        [32m0.0408[0m       0.7977      0.7977        0.8688        0.0000  145.8318
      6      [36m0.9938[0m        [32m0.0287[0m       [35m0.8234[0m      [31m0.8234[0m        0.7478        0.0000  142.5072
      7      [36m0.9972[0m        [32m0.0185[0m       0.8182      0.8182        0.7972        0.0000  138.7992
      8      [36m0.9980[0m        [32m0.0156[0m       0.8156      0.8156        0.8339        0.0000  138.5851
      9      [36m0.9985[0m        [32m0.0129[0m       0.8106      0.8106        0.8969        0.0000  138.4320
     10      [36m0.9989[0m        [32m0.0112[0m       [35m0.8292[0m      [31m0.8292[0m        0.7988        0.0000  138.4251
     11      [36m0.9994[0m        [32m0.0097[0m       0.8212      0.8212        0.8776        0.0000  138.4324
     12      [36m0.9995[0m        [32m0.0084[0m       0.8210      0.8210        0.8857        0.0000  138.4163
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8395833333333333
F1 Macro Score after query 13: 0.42840568764422393
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/margin_sampling_seed43\AL_margin_sampling_results_for_multiclass_classification_s43.pickle
