(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.1250[0m        [32m2.3066[0m       [35m0.1903[0m      [31m0.1903[0m        [94m2.0700[0m     +  0.0000  11.4882
      2      0.1250        [32m2.0493[0m       [35m0.2160[0m      [31m0.2160[0m        2.0935        0.0000  10.7190
      3      0.1250        [32m1.9417[0m       [35m0.2642[0m      [31m0.2642[0m        [94m2.0373[0m     +  0.0000  10.6558
      4      [36m0.3750[0m        [32m1.8097[0m       0.2458      0.2458        2.0832        0.0000  10.7623
      5      0.3750        1.8271       [35m0.3099[0m      [31m0.3099[0m        [94m2.0203[0m     +  0.0000  10.9053
      6      [36m0.6250[0m        [32m1.5837[0m       0.2814      0.2814        2.0302        0.0000  10.8809
      7      [36m0.7500[0m        1.6243       0.2812      0.2812        2.0275        0.0000  10.8399
      8      0.6250        1.6901       0.2780      0.2780        2.0236        0.0000  10.8034
      9      0.6250        [32m1.5773[0m       0.2776      0.2776        2.0253        0.0000  10.9437
     10      0.5000        1.7114       0.2802      0.2802        2.0278        0.0000  10.9575
     11      0.7500        1.6301       0.2809      0.2809        2.0269        0.0000  11.0548
     12      0.6250        1.6136       0.2851      0.2851        2.0255        0.0000  11.0390
     13      0.7500        1.6053       0.2861      0.2861        2.0244        0.0000  10.9510
     14      0.6250        1.6241       0.2875      0.2875        2.0237        0.0000  11.2048
     15      0.6250        1.6527       0.2894      0.2894        2.0225        0.0000  11.2043
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.3057
Pre F1 macro score = 0.1273

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6250[0m        [32m1.6865[0m       [35m0.4481[0m      [31m0.4481[0m        [94m1.8673[0m     +  0.0000  11.1084
      2      [36m0.7500[0m        [32m1.2186[0m       0.4479      0.4479        [94m1.7982[0m     +  0.0000  10.8281
      3      [36m0.7917[0m        [32m1.1078[0m       [35m0.4502[0m      [31m0.4502[0m        1.7990        0.0000  10.9377
      4      [36m0.8333[0m        [32m0.9959[0m       [35m0.4531[0m      [31m0.4531[0m        [94m1.7607[0m     +  0.0000  10.9701
      5      [36m0.8750[0m        [32m0.9272[0m       [35m0.4571[0m      [31m0.4571[0m        [94m1.7562[0m     +  0.0000  11.1729
      6      [36m0.9167[0m        [32m0.8122[0m       [35m0.4573[0m      [31m0.4573[0m        [94m1.7491[0m     +  0.0000  10.8664
      7      0.8750        [32m0.7915[0m       [35m0.4602[0m      [31m0.4602[0m        [94m1.7484[0m     +  0.0000  10.9822
      8      0.9167        [32m0.7596[0m       [35m0.4604[0m      [31m0.4604[0m        [94m1.7452[0m     +  0.0000  10.8679
      9      0.8750        0.8295       0.4604      0.4604        [94m1.7417[0m     +  0.0000  11.1889
     10      0.8750        0.8545       [35m0.4608[0m      [31m0.4608[0m        1.7438        0.0000  11.0990
     11      [36m0.9583[0m        [32m0.7526[0m       0.4608      0.4608        1.7429        0.0000  10.9364
     12      0.9167        [32m0.7222[0m       0.4608      0.4608        1.7425        0.0000  11.0212
     13      0.9167        0.7663       0.4608      0.4608        1.7423        0.0000  10.9238
     14      0.9583        0.7681       0.4608      0.4608        1.7419        0.0000  11.0005
     15      0.9167        0.7826       [35m0.4609[0m      [31m0.4609[0m        [94m1.7415[0m     +  0.0000  11.1093
     16      0.9167        0.7965       0.4609      0.4609        1.7415        0.0000  10.9233
     17      0.8333        0.7772       0.4609      0.4609        1.7415        0.0000  10.8168
     18      0.9167        0.7688       0.4609      0.4609        1.7415        0.0000  10.9673
     19      0.9167        0.8000       0.4609      0.4609        [94m1.7414[0m     +  0.0000  11.0472
     20      0.9583        0.8470       0.4609      0.4609        1.7414        0.0000  11.0184
     21      0.9167        0.7228       0.4609      0.4609        [94m1.7414[0m     +  0.0000  10.9640
     22      0.8750        0.8531       0.4609      0.4609        [94m1.7414[0m     +  0.0000  11.0851
     23      0.9583        0.7453       0.4609      0.4609        1.7414        0.0000  11.0146
     24      0.9167        0.7668       0.4609      0.4609        [94m1.7414[0m     +  0.0000  11.0936
     25      0.8333        0.8033       0.4609      0.4609        [94m1.7414[0m     +  0.0000  11.0462
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.46319444444444446
F1 Macro Score after query 1: 0.08906244090260507
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5714[0m        [32m1.4656[0m       [35m0.4342[0m      [31m0.4342[0m        [94m1.6078[0m     +  0.0000  11.2513
      2      [36m0.7679[0m        [32m1.1928[0m       [35m0.4417[0m      [31m0.4417[0m        [94m1.5587[0m     +  0.0000  11.0578
      3      [36m0.8214[0m        [32m1.0274[0m       [35m0.4550[0m      [31m0.4550[0m        1.5818        0.0000  11.2871
      4      [36m0.8571[0m        [32m0.9732[0m       0.4441      0.4441        1.5751        0.0000  11.1628
      5      0.8571        [32m0.8695[0m       [35m0.4653[0m      [31m0.4653[0m        1.5633        0.0000  11.4101
      6      [36m0.8750[0m        [32m0.8134[0m       0.4609      0.4609        1.5660        0.0000  11.2426
      7      [36m0.8929[0m        [32m0.7505[0m       0.4613      0.4613        1.5685        0.0000  11.2234
      8      [36m0.9107[0m        0.7563       [35m0.4674[0m      [31m0.4674[0m        1.5680        0.0000  11.1419
      9      [36m0.9286[0m        [32m0.7390[0m       [35m0.4681[0m      [31m0.4681[0m        1.5678        0.0000  11.0668
     10      0.9107        [32m0.7215[0m       0.4635      0.4635        1.5716        0.0000  11.1703
     11      0.9107        [32m0.7209[0m       0.4639      0.4639        1.5716        0.0000  11.2148
     12      0.8929        [32m0.7168[0m       0.4641      0.4641        1.5712        0.0000  11.1093
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.5105902777777778
F1 Macro Score after query 2: 0.15794198622839006
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7946[0m        [32m1.1056[0m       [35m0.5509[0m      [31m0.5509[0m        [94m1.4308[0m     +  0.0000  11.3497
      2      [36m0.9018[0m        [32m0.7900[0m       [35m0.5623[0m      [31m0.5623[0m        [94m1.3862[0m     +  0.0000  11.2974
      3      [36m0.9375[0m        [32m0.6990[0m       [35m0.5667[0m      [31m0.5667[0m        [94m1.3743[0m     +  0.0000  11.3625
      4      [36m0.9464[0m        [32m0.6192[0m       [35m0.5693[0m      [31m0.5693[0m        [94m1.3715[0m     +  0.0000  11.3281
      5      0.9464        [32m0.5583[0m       [35m0.5760[0m      [31m0.5760[0m        [94m1.3613[0m     +  0.0000  11.2505
      6      0.9464        [32m0.5384[0m       0.5714      0.5714        1.3638        0.0000  11.4660
      7      [36m0.9554[0m        [32m0.5209[0m       0.5687      0.5687        1.3629        0.0000  11.1603
      8      0.9375        0.5322       0.5733      0.5733        [94m1.3601[0m     +  0.0000  11.4846
      9      0.9554        [32m0.4993[0m       0.5724      0.5724        [94m1.3592[0m     +  0.0000  11.5994
     10      0.9554        0.5288       0.5738      0.5738        1.3615        0.0000  11.2063
     11      [36m0.9643[0m        [32m0.4785[0m       0.5731      0.5731        1.3611        0.0000  11.2199
     12      0.9464        0.5050       0.5722      0.5722        1.3617        0.0000  11.2621
     13      0.9464        0.4850       0.5726      0.5726        1.3621        0.0000  11.2866
     14      0.9643        0.4959       0.5724      0.5724        1.3627        0.0000  11.3819
     15      0.9554        [32m0.4767[0m       0.5738      0.5738        1.3620        0.0000  11.2132
     16      0.9375        0.5123       0.5731      0.5731        1.3624        0.0000  11.3202
     17      0.9554        0.4982       0.5727      0.5727        1.3625        0.0000  11.3083
     18      0.9554        0.4845       0.5726      0.5726        1.3627        0.0000  11.4193
     19      0.9554        0.4864       0.5726      0.5726        1.3629        0.0000  11.2354
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.5907986111111111
F1 Macro Score after query 3: 0.183759337408671
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7500[0m        [32m0.9778[0m       [35m0.4380[0m      [31m0.4380[0m        [94m1.5151[0m     +  0.0000  11.9504
      2      [36m0.8462[0m        [32m0.7692[0m       [35m0.6576[0m      [31m0.6576[0m        [94m1.1419[0m     +  0.0000  11.8699
      3      [36m0.9231[0m        [32m0.6124[0m       0.6444      0.6444        [94m1.1276[0m     +  0.0000  11.7189
      4      [36m0.9375[0m        [32m0.5894[0m       [35m0.6639[0m      [31m0.6639[0m        [94m1.0976[0m     +  0.0000  11.9240
      5      [36m0.9423[0m        [32m0.5240[0m       0.6312      0.6312        1.1112        0.0000  12.2502
      6      [36m0.9471[0m        [32m0.4699[0m       0.6578      0.6578        [94m1.0789[0m     +  0.0000  11.8950
      7      [36m0.9519[0m        0.4845       0.6573      0.6573        [94m1.0768[0m     +  0.0000  11.7853
      8      [36m0.9567[0m        0.4727       0.6590      0.6590        [94m1.0761[0m     +  0.0000  11.9896
      9      0.9471        0.4780       0.6573      0.6573        1.0766        0.0000  12.0002
     10      0.9519        0.4876       0.6571      0.6571        [94m1.0755[0m     +  0.0000  11.9275
     11      0.9471        0.4703       0.6580      0.6580        [94m1.0723[0m     +  0.0000  11.7160
     12      0.9519        [32m0.4502[0m       0.6576      0.6576        [94m1.0716[0m     +  0.0000  12.0366
     13      0.9519        0.4553       0.6576      0.6576        1.0722        0.0000  11.7643
     14      [36m0.9615[0m        0.4596       0.6573      0.6573        1.0729        0.0000  11.8529
     15      0.9519        0.4648       0.6589      0.6589        1.0724        0.0000  11.9323
     16      0.9519        0.4538       0.6589      0.6589        1.0721        0.0000  11.6096
     17      0.9471        [32m0.4491[0m       0.6589      0.6589        1.0721        0.0000  11.8784
     18      0.9615        [32m0.4359[0m       0.6589      0.6589        1.0721        0.0000  11.9354
     19      0.9615        0.4509       0.6594      0.6594        1.0717        0.0000  11.7346
     20      0.9615        0.4624       0.6583      0.6583        1.0718        0.0000  12.0059
     21      0.9615        0.4617       0.6582      0.6582        1.0719        0.0000  11.7185
     22      0.9519        0.4492       0.6582      0.6582        1.0718        0.0000  11.9844
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.6678819444444445
F1 Macro Score after query 4: 0.21557433025761896
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8047[0m        [32m0.8492[0m       [35m0.7038[0m      [31m0.7038[0m        [94m1.0145[0m     +  0.0000  12.6029
      2      [36m0.8620[0m        [32m0.6797[0m       [35m0.7188[0m      [31m0.7188[0m        [94m0.9562[0m     +  0.0000  12.7502
      3      [36m0.9036[0m        [32m0.5890[0m       0.7149      0.7149        [94m0.9393[0m     +  0.0000  12.7292
      4      [36m0.9271[0m        [32m0.5323[0m       0.7111      0.7111        0.9587        0.0000  12.7032
      5      [36m0.9297[0m        [32m0.5005[0m       0.7057      0.7057        0.9479        0.0000  12.8004
      6      [36m0.9479[0m        [32m0.4423[0m       0.7165      0.7165        [94m0.9255[0m     +  0.0000  12.8042
      7      [36m0.9505[0m        0.4528       [35m0.7208[0m      [31m0.7208[0m        [94m0.9196[0m     +  0.0000  12.8337
      8      [36m0.9531[0m        [32m0.4308[0m       0.7193      0.7193        0.9204        0.0000  12.7292
      9      [36m0.9609[0m        0.4410       [35m0.7212[0m      [31m0.7212[0m        [94m0.9176[0m     +  0.0000  12.6093
     10      0.9609        [32m0.4137[0m       0.7179      0.7179        [94m0.9162[0m     +  0.0000  12.7035
     11      [36m0.9661[0m        0.4140       0.7168      0.7168        0.9187        0.0000  12.5666
     12      [36m0.9688[0m        0.4159       0.7149      0.7149        0.9211        0.0000  12.9319
     13      [36m0.9740[0m        [32m0.4102[0m       0.7155      0.7155        0.9182        0.0000  12.7383
     14      0.9688        [32m0.4071[0m       0.7144      0.7144        0.9221        0.0000  12.8389
     15      0.9714        [32m0.3926[0m       0.7160      0.7160        0.9203        0.0000  12.6690
     16      [36m0.9766[0m        0.3933       0.7151      0.7151        0.9211        0.0000  12.7587
     17      0.9740        [32m0.3923[0m       0.7137      0.7137        0.9210        0.0000  12.8354
     18      0.9740        [32m0.3915[0m       0.7139      0.7139        0.9216        0.0000  12.9577
     19      0.9714        [32m0.3831[0m       0.7134      0.7134        0.9220        0.0000  12.6718
     20      0.9688        0.3984       0.7132      0.7132        0.9219        0.0000  12.6936
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.7071180555555555
F1 Macro Score after query 5: 0.2655123621944327
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8210[0m        [32m0.7487[0m       [35m0.7453[0m      [31m0.7453[0m        [94m0.8874[0m     +  0.0000  14.3494
      2      [36m0.9062[0m        [32m0.5615[0m       0.7444      0.7444        [94m0.8682[0m     +  0.0000  14.2154
      3      [36m0.9347[0m        [32m0.4910[0m       0.7434      0.7434        [94m0.8531[0m     +  0.0000  14.5345
      4      [36m0.9503[0m        [32m0.4503[0m       [35m0.7543[0m      [31m0.7543[0m        [94m0.8401[0m     +  0.0000  14.3219
      5      [36m0.9631[0m        [32m0.4078[0m       [35m0.7561[0m      [31m0.7561[0m        [94m0.8304[0m     +  0.0000  14.4242
      6      [36m0.9645[0m        [32m0.3774[0m       0.7455      0.7455        0.8515        0.0000  14.2185
      7      [36m0.9744[0m        [32m0.3707[0m       0.7446      0.7446        0.8583        0.0000  14.3290
      8      [36m0.9759[0m        [32m0.3536[0m       0.7432      0.7432        0.8646        0.0000  14.2597
      9      0.9688        0.3590       0.7436      0.7436        0.8618        0.0000  14.3438
     10      [36m0.9801[0m        [32m0.3347[0m       0.7403      0.7403        0.8746        0.0000  14.1542
     11      0.9759        0.3373       0.7410      0.7410        0.8762        0.0000  14.4362
     12      0.9801        [32m0.3293[0m       0.7413      0.7413        0.8755        0.0000  14.3135
     13      0.9787        [32m0.3255[0m       0.7406      0.7406        0.8803        0.0000  14.2946
     14      [36m0.9815[0m        [32m0.3246[0m       0.7401      0.7401        0.8777        0.0000  14.3295
     15      0.9801        0.3247       0.7398      0.7398        0.8776        0.0000  14.3922
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.7440972222222222
F1 Macro Score after query 6: 0.29687982157252324
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8204[0m        [32m0.7408[0m       [35m0.7365[0m      [31m0.7365[0m        [94m0.8237[0m     +  0.0000  17.2331
      2      [36m0.9003[0m        [32m0.5555[0m       [35m0.7642[0m      [31m0.7642[0m        [94m0.7757[0m     +  0.0000  17.2476
      3      [36m0.9193[0m        [32m0.4960[0m       0.7561      0.7561        0.7839        0.0000  17.1095
      4      [36m0.9272[0m        [32m0.4614[0m       0.7616      0.7616        0.7804        0.0000  17.1431
      5      [36m0.9359[0m        [32m0.4096[0m       0.7524      0.7524        0.8142        0.0000  17.1415
      6      [36m0.9581[0m        [32m0.3673[0m       [35m0.7655[0m      [31m0.7655[0m        [94m0.7639[0m     +  0.0000  17.0790
      7      [36m0.9612[0m        [32m0.3485[0m       [35m0.7682[0m      [31m0.7682[0m        [94m0.7563[0m     +  0.0000  17.1589
      8      0.9612        [32m0.3452[0m       [35m0.7693[0m      [31m0.7693[0m        0.7583        0.0000  17.0311
      9      [36m0.9628[0m        [32m0.3403[0m       0.7679      0.7679        0.7575        0.0000  17.1209
     10      [36m0.9676[0m        [32m0.3257[0m       0.7691      0.7691        0.7580        0.0000  17.0303
     11      [36m0.9699[0m        [32m0.3200[0m       [35m0.7707[0m      [31m0.7707[0m        0.7695        0.0000  17.2660
     12      [36m0.9715[0m        [32m0.3173[0m       0.7707      0.7707        0.7742        0.0000  17.0510
     13      0.9707        [32m0.3060[0m       0.7693      0.7693        0.7715        0.0000  17.1659
     14      [36m0.9723[0m        0.3081       0.7701      0.7701        0.7750        0.0000  17.2556
     15      [36m0.9747[0m        [32m0.3032[0m       0.7694      0.7694        0.7768        0.0000  17.0625
     16      0.9723        [32m0.3001[0m       0.7696      0.7696        0.7787        0.0000  17.1069
     17      [36m0.9771[0m        [32m0.2994[0m       0.7693      0.7693        0.7799        0.0000  17.4388
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.7637152777777778
F1 Macro Score after query 7: 0.3314648956311697
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8520[0m        [32m0.6030[0m       [35m0.8101[0m      [31m0.8101[0m        [94m0.6593[0m     +  0.0000  22.1861
      2      [36m0.9090[0m        [32m0.4729[0m       0.7524      0.7524        0.7887        0.0000  22.1692
      3      [36m0.9254[0m        [32m0.4105[0m       [35m0.8120[0m      [31m0.8120[0m        0.6751        0.0000  22.3158
      4      [36m0.9307[0m        [32m0.3878[0m       0.7918      0.7918        0.6881        0.0000  22.3277
      5      [36m0.9364[0m        [32m0.3550[0m       0.8014      0.8014        0.6780        0.0000  22.2343
      6      [36m0.9492[0m        [32m0.3127[0m       0.8064      0.8064        0.6920        0.0000  22.3407
      7      [36m0.9541[0m        [32m0.2965[0m       0.7981      0.7981        0.7038        0.0000  22.1431
      8      [36m0.9598[0m        [32m0.2815[0m       0.7969      0.7969        0.7196        0.0000  22.2234
      9      [36m0.9629[0m        [32m0.2742[0m       0.7972      0.7972        0.7151        0.0000  22.1937
     10      [36m0.9651[0m        [32m0.2668[0m       0.7991      0.7991        0.7183        0.0000  22.1551
     11      [36m0.9655[0m        [32m0.2570[0m       0.7991      0.7991        0.7319        0.0000  22.1540
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.7994791666666666
F1 Macro Score after query 8: 0.4281981734265038
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8705[0m        [32m0.5249[0m       [35m0.7771[0m      [31m0.7771[0m        [94m0.6922[0m     +  0.0000  31.0665
      2      [36m0.9146[0m        [32m0.4121[0m       0.7618      0.7618        0.7575        0.0000  31.3395
      3      [36m0.9257[0m        [32m0.3678[0m       [35m0.7840[0m      [31m0.7840[0m        0.7017        0.0000  31.2239
      4      [36m0.9359[0m        [32m0.3264[0m       0.7719      0.7719        0.7569        0.0000  31.3595
      5      [36m0.9426[0m        [32m0.2966[0m       [35m0.7870[0m      [31m0.7870[0m        [94m0.6555[0m     +  0.0000  31.3718
      6      [36m0.9550[0m        [32m0.2582[0m       [35m0.7913[0m      [31m0.7913[0m        0.6798        0.0000  31.3333
      7      [36m0.9604[0m        [32m0.2405[0m       0.7899      0.7899        0.6875        0.0000  31.1544
      8      [36m0.9621[0m        [32m0.2306[0m       0.7908      0.7908        0.6946        0.0000  31.3751
      9      [36m0.9656[0m        [32m0.2226[0m       0.7870      0.7870        0.7144        0.0000  31.1090
     10      [36m0.9688[0m        [32m0.2088[0m       0.7898      0.7898        0.7215        0.0000  31.0792
     11      [36m0.9755[0m        [32m0.1957[0m       0.7892      0.7892        0.7373        0.0000  31.1877
     12      0.9743        [32m0.1950[0m       [35m0.7917[0m      [31m0.7917[0m        0.7383        0.0000  31.2520
     13      [36m0.9757[0m        [32m0.1913[0m       0.7885      0.7885        0.7425        0.0000  31.3555
     14      [36m0.9787[0m        [32m0.1873[0m       0.7887      0.7887        0.7494        0.0000  31.5152
     15      0.9760        [32m0.1839[0m       0.7898      0.7898        0.7487        0.0000  31.0181
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8029513888888888
F1 Macro Score after query 9: 0.5052872338050082
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9012[0m        [32m0.3842[0m       [35m0.8111[0m      [31m0.8111[0m        [94m0.5913[0m     +  0.0000  46.7342
      2      [36m0.9267[0m        [32m0.3173[0m       0.7958      0.7958        0.6638        0.0000  47.2678
      3      [36m0.9318[0m        [32m0.2830[0m       0.8014      0.8014        0.6584        0.0000  47.2020
      4      [36m0.9425[0m        [32m0.2526[0m       0.7943      0.7943        0.6497        0.0000  47.3125
      5      [36m0.9457[0m        [32m0.2278[0m       0.8012      0.8012        0.6202        0.0000  47.1586
      6      [36m0.9628[0m        [32m0.1856[0m       0.7964      0.7964        0.6647        0.0000  46.8874
      7      [36m0.9692[0m        [32m0.1659[0m       0.7908      0.7908        0.6925        0.0000  47.0017
      8      [36m0.9743[0m        [32m0.1514[0m       0.7811      0.7811        0.7422        0.0000  47.6835
      9      [36m0.9774[0m        [32m0.1432[0m       0.7795      0.7795        0.7508        0.0000  47.1717
     10      [36m0.9807[0m        [32m0.1334[0m       0.7898      0.7898        0.7382        0.0000  47.3002
     11      [36m0.9846[0m        [32m0.1252[0m       0.8090      0.8090        0.6932        0.0000  46.9645
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8137152777777777
F1 Macro Score after query 10: 0.5414602678989282
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9306[0m        [32m0.3066[0m       [35m0.5865[0m      [31m0.5865[0m        [94m1.4281[0m     +  0.0000  75.3686
      2      [36m0.9387[0m        [32m0.2647[0m       [35m0.7988[0m      [31m0.7988[0m        [94m0.6758[0m     +  0.0000  75.4873
      3      [36m0.9439[0m        [32m0.2338[0m       0.7918      0.7918        0.7313        0.0000  75.8311
      4      [36m0.9488[0m        [32m0.2063[0m       0.7906      0.7906        0.7214        0.0000  75.5447
      5      [36m0.9538[0m        [32m0.1862[0m       0.7608      0.7608        0.8477        0.0000  76.0101
      6      [36m0.9666[0m        [32m0.1474[0m       0.7984      0.7984        0.6893        0.0000  75.8474
      7      [36m0.9731[0m        [32m0.1305[0m       [35m0.8017[0m      [31m0.8017[0m        0.6834        0.0000  76.0627
      8      [36m0.9760[0m        [32m0.1208[0m       0.7972      0.7972        0.7131        0.0000  75.5023
      9      [36m0.9788[0m        [32m0.1088[0m       0.7965      0.7965        0.7364        0.0000  75.9396
     10      [36m0.9829[0m        [32m0.0994[0m       0.7984      0.7984        0.7373        0.0000  75.8125
     11      [36m0.9849[0m        [32m0.0885[0m       [35m0.8019[0m      [31m0.8019[0m        0.7499        0.0000  76.0953
     12      [36m0.9871[0m        [32m0.0858[0m       [35m0.8033[0m      [31m0.8033[0m        0.7455        0.0000  75.5423
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8210069444444444
F1 Macro Score after query 11: 0.5134274254577821
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9642[0m        [32m0.1649[0m       [35m0.7321[0m      [31m0.7321[0m        [94m0.9986[0m     +  0.0000  125.9830
      2      [36m0.9681[0m        [32m0.1408[0m       0.7148      0.7148        1.1763        0.0000  126.7499
      3      [36m0.9693[0m        [32m0.1267[0m       [35m0.7715[0m      [31m0.7715[0m        [94m0.8920[0m     +  0.0000  126.7814
      4      [36m0.9724[0m        [32m0.1091[0m       0.7358      0.7358        1.1925        0.0000  126.3655
      5      [36m0.9755[0m        [32m0.0972[0m       0.7710      0.7710        1.0664        0.0000  126.3087
      6      [36m0.9813[0m        [32m0.0775[0m       [35m0.7866[0m      [31m0.7866[0m        0.9080        0.0000  126.2745
      7      [36m0.9850[0m        [32m0.0644[0m       [35m0.7889[0m      [31m0.7889[0m        0.9226        0.0000  126.5205
      8      [36m0.9881[0m        [32m0.0572[0m       [35m0.7917[0m      [31m0.7917[0m        0.9022        0.0000  126.4617
      9      [36m0.9901[0m        [32m0.0503[0m       [35m0.8050[0m      [31m0.8050[0m        [94m0.8327[0m     +  0.0000  126.4055
     10      [36m0.9915[0m        [32m0.0442[0m       [35m0.8104[0m      [31m0.8104[0m        [94m0.8223[0m     +  0.0000  120.5826
     11      [36m0.9933[0m        [32m0.0382[0m       0.7995      0.7995        0.9003        0.0000  119.4933
     12      [36m0.9946[0m        [32m0.0348[0m       0.8016      0.8016        0.9120        0.0000  119.5358
     13      [36m0.9955[0m        [32m0.0325[0m       0.8035      0.8035        0.9159        0.0000  119.5513
     14      [36m0.9958[0m        [32m0.0311[0m       0.8028      0.8028        0.9266        0.0000  119.4191
     15      [36m0.9963[0m        [32m0.0296[0m       0.8012      0.8012        0.9432        0.0000  119.3079
     16      [36m0.9965[0m        [32m0.0283[0m       0.8012      0.8012        0.9488        0.0000  118.8834
     17      [36m0.9966[0m        [32m0.0274[0m       0.8040      0.8040        0.9437        0.0000  119.0316
     18      [36m0.9969[0m        0.0276       0.8043      0.8043        0.9424        0.0000  119.4274
     19      [36m0.9974[0m        [32m0.0270[0m       0.8042      0.8042        0.9447        0.0000  119.1497
     20      0.9972        [32m0.0268[0m       0.8040      0.8040        0.9483        0.0000  119.2266
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8293402777777777
F1 Macro Score after query 12: 0.4902984609299956
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9837[0m        [32m0.0624[0m       [35m0.7606[0m      [31m0.7606[0m        [94m1.1133[0m     +  0.0000  137.3553
      2      [36m0.9848[0m        [32m0.0561[0m       [35m0.7635[0m      [31m0.7635[0m        1.1285        0.0000  138.6646
      3      [36m0.9865[0m        [32m0.0502[0m       [35m0.7653[0m      [31m0.7653[0m        1.1161        0.0000  138.7427
      4      [36m0.9871[0m        [32m0.0452[0m       [35m0.7795[0m      [31m0.7795[0m        [94m1.0238[0m     +  0.0000  138.5363
      5      [36m0.9883[0m        [32m0.0419[0m       [35m0.7833[0m      [31m0.7833[0m        1.0604        0.0000  138.0429
      6      [36m0.9938[0m        [32m0.0263[0m       0.7821      0.7821        1.1077        0.0000  138.9594
      7      [36m0.9973[0m        [32m0.0175[0m       [35m0.7842[0m      [31m0.7842[0m        1.1456        0.0000  138.3042
      8      [36m0.9982[0m        [32m0.0139[0m       0.7760      0.7760        1.2783        0.0000  138.6918
      9      [36m0.9986[0m        [32m0.0122[0m       [35m0.7903[0m      [31m0.7903[0m        1.1254        0.0000  138.4208
     10      [36m0.9991[0m        [32m0.0105[0m       0.7877      0.7877        1.2257        0.0000  138.2752
     11      [36m0.9994[0m        [32m0.0091[0m       [35m0.7997[0m      [31m0.7997[0m        1.1062        0.0000  138.6921
     12      [36m0.9996[0m        [32m0.0084[0m       0.7965      0.7965        1.1348        0.0000  138.5008
     13      0.9996        [32m0.0079[0m       0.7937      0.7937        1.1461        0.0000  138.5347
     14      [36m0.9997[0m        [32m0.0074[0m       0.7967      0.7967        1.1326        0.0000  138.4118
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8302083333333334
F1 Macro Score after query 13: 0.5303898898743756
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed47\AL_uncertainty_sampling_results_for_multiclass_classification_s47.pickle
