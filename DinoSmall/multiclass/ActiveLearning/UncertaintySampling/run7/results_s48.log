(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2500[0m        [32m2.0327[0m       [35m0.2233[0m      [31m0.2233[0m        [94m1.9289[0m     +  0.0000  10.9469
      2      0.2500        [32m1.9712[0m       0.1854      0.1854        1.9898        0.0000  10.3670
      3      [36m0.5000[0m        [32m1.7284[0m       [35m0.3267[0m      [31m0.3267[0m        [94m1.8632[0m     +  0.0000  10.5369
      4      [36m0.6250[0m        [32m1.6674[0m       0.2106      0.2106        1.9695        0.0000  10.3859
      5      0.6250        [32m1.5344[0m       [35m0.3321[0m      [31m0.3321[0m        1.8673        0.0000  10.2335
      6      [36m0.8750[0m        [32m1.3737[0m       [35m0.3359[0m      [31m0.3359[0m        1.8914        0.0000  10.5003
      7      0.7500        1.4372       0.3214      0.3214        1.9118        0.0000  10.4058
      8      0.8750        [32m1.3501[0m       0.3087      0.3087        1.9198        0.0000  10.4446
      9      [36m1.0000[0m        1.3720       0.3149      0.3149        1.9225        0.0000  10.5064
     10      0.8750        [32m1.3006[0m       0.3182      0.3182        1.9235        0.0000  10.5079
     11      0.8750        1.3092       0.3167      0.3167        1.9235        0.0000  10.6398
     12      1.0000        1.3720       0.3158      0.3158        1.9257        0.0000  10.6446
     13      0.7500        1.4509       0.3153      0.3153        1.9249        0.0000  10.5777
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.2668
Pre F1 macro score = 0.1538

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5000[0m        [32m1.7488[0m       [35m0.2142[0m      [31m0.2142[0m        [94m1.8222[0m     +  0.0000  10.8898
      2      [36m0.5417[0m        [32m1.6362[0m       0.2142      0.2142        1.8416        0.0000  10.7255
      3      [36m0.6250[0m        [32m1.3741[0m       0.2142      0.2142        [94m1.8021[0m     +  0.0000  10.8204
      4      0.5833        [32m1.2273[0m       [35m0.2148[0m      [31m0.2148[0m        [94m1.7783[0m     +  0.0000  10.7578
      5      [36m0.6667[0m        [32m1.2001[0m       [35m0.2220[0m      [31m0.2220[0m        1.7783        0.0000  10.6348
      6      [36m0.7083[0m        [32m1.0456[0m       [35m0.2259[0m      [31m0.2259[0m        1.7797        0.0000  10.8753
      7      [36m0.8750[0m        [32m0.9390[0m       [35m0.2300[0m      [31m0.2300[0m        1.7822        0.0000  10.6111
      8      0.7917        1.0139       [35m0.2370[0m      [31m0.2370[0m        1.7794        0.0000  10.7936
      9      0.7500        0.9458       [35m0.2385[0m      [31m0.2385[0m        1.7827        0.0000  10.5441
     10      0.8333        0.9653       [35m0.2434[0m      [31m0.2434[0m        1.7813        0.0000  10.6919
     11      0.8750        [32m0.8574[0m       [35m0.2437[0m      [31m0.2437[0m        1.7822        0.0000  10.7764
     12      [36m0.9167[0m        0.9091       [35m0.2446[0m      [31m0.2446[0m        1.7822        0.0000  10.9532
     13      0.9167        [32m0.8174[0m       0.2439      0.2439        1.7828        0.0000  10.6860
     14      0.8750        0.9268       0.2446      0.2446        1.7820        0.0000  10.6605
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.2659722222222222
F1 Macro Score after query 1: 0.130169106204021
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6964[0m        [32m1.4369[0m       [35m0.4021[0m      [31m0.4021[0m        [94m1.5696[0m     +  0.0000  10.8173
      2      [36m0.7857[0m        [32m1.1299[0m       [35m0.4040[0m      [31m0.4040[0m        [94m1.5610[0m     +  0.0000  10.9952
      3      [36m0.8393[0m        [32m0.9223[0m       0.3958      0.3958        1.5727        0.0000  10.9034
      4      [36m0.9107[0m        [32m0.8442[0m       [35m0.4160[0m      [31m0.4160[0m        1.5711        0.0000  10.8441
      5      0.9107        [32m0.7795[0m       [35m0.4424[0m      [31m0.4424[0m        [94m1.5608[0m     +  0.0000  10.8296
      6      [36m0.9286[0m        [32m0.6842[0m       [35m0.4429[0m      [31m0.4429[0m        1.5628        0.0000  10.9066
      7      0.9107        [32m0.6476[0m       0.4417      0.4417        [94m1.5604[0m     +  0.0000  10.8369
      8      0.9286        0.6513       [35m0.4450[0m      [31m0.4450[0m        1.5605        0.0000  10.7882
      9      [36m0.9464[0m        [32m0.6348[0m       [35m0.4469[0m      [31m0.4469[0m        [94m1.5587[0m     +  0.0000  10.6894
     10      0.9107        0.6499       [35m0.4491[0m      [31m0.4491[0m        1.5594        0.0000  10.9609
     11      [36m0.9821[0m        [32m0.6263[0m       [35m0.4512[0m      [31m0.4512[0m        1.5593        0.0000  10.6888
     12      0.9464        0.6452       [35m0.4524[0m      [31m0.4524[0m        1.5600        0.0000  10.9804
     13      0.9286        [32m0.6107[0m       [35m0.4528[0m      [31m0.4528[0m        1.5587        0.0000  10.8466
     14      0.9286        0.6260       [35m0.4549[0m      [31m0.4549[0m        [94m1.5586[0m     +  0.0000  11.2087
     15      0.9286        0.6225       0.4549      0.4549        1.5587        0.0000  10.7417
     16      0.9643        0.6310       0.4549      0.4549        1.5588        0.0000  11.0310
     17      0.9286        0.6201       0.4549      0.4549        1.5588        0.0000  10.8483
     18      0.9643        [32m0.6049[0m       0.4549      0.4549        1.5590        0.0000  10.8370
     19      0.9286        0.6872       [35m0.4552[0m      [31m0.4552[0m        1.5590        0.0000  10.6808
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.4366319444444444
F1 Macro Score after query 2: 0.15492510182525765
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7679[0m        [32m1.0098[0m       [35m0.4479[0m      [31m0.4479[0m        [94m1.4339[0m     +  0.0000  11.1698
      2      [36m0.8125[0m        [32m0.8602[0m       [35m0.5222[0m      [31m0.5222[0m        [94m1.3965[0m     +  0.0000  11.0721
      3      [36m0.8393[0m        [32m0.7200[0m       [35m0.5425[0m      [31m0.5425[0m        [94m1.3892[0m     +  0.0000  11.2004
      4      0.8393        [32m0.7103[0m       [35m0.5542[0m      [31m0.5542[0m        [94m1.3761[0m     +  0.0000  10.9178
      5      [36m0.9107[0m        [32m0.6121[0m       [35m0.5616[0m      [31m0.5616[0m        [94m1.3685[0m     +  0.0000  11.0941
      6      [36m0.9375[0m        [32m0.5779[0m       [35m0.5642[0m      [31m0.5642[0m        [94m1.3662[0m     +  0.0000  11.0368
      7      [36m0.9464[0m        0.5969       0.5635      0.5635        1.3668        0.0000  11.0937
      8      0.9464        [32m0.5679[0m       0.5635      0.5635        1.3681        0.0000  11.0625
      9      [36m0.9821[0m        [32m0.5350[0m       0.5620      0.5620        1.3685        0.0000  10.9666
     10      0.9375        0.5704       0.5618      0.5618        1.3685        0.0000  11.0188
     11      0.9821        [32m0.5060[0m       0.5615      0.5615        1.3683        0.0000  11.3126
     12      0.9732        0.5350       0.5615      0.5615        1.3684        0.0000  11.2263
     13      0.9732        [32m0.5027[0m       0.5616      0.5616        1.3683        0.0000  11.0770
     14      0.9732        [32m0.4996[0m       0.5618      0.5618        1.3683        0.0000  11.0423
     15      0.9643        0.5295       0.5618      0.5618        1.3673        0.0000  11.1413
     16      0.9554        0.5129       0.5618      0.5618        1.3674        0.0000  11.2047
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.5720486111111112
F1 Macro Score after query 3: 0.19473055804494843
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7115[0m        [32m1.0425[0m       [35m0.5266[0m      [31m0.5266[0m        [94m1.3568[0m     +  0.0000  11.6090
      2      [36m0.8173[0m        [32m0.8434[0m       [35m0.5299[0m      [31m0.5299[0m        [94m1.3535[0m     +  0.0000  11.6689
      3      [36m0.8846[0m        [32m0.7241[0m       [35m0.5892[0m      [31m0.5892[0m        [94m1.2862[0m     +  0.0000  11.7073
      4      [36m0.9231[0m        [32m0.6272[0m       [35m0.5981[0m      [31m0.5981[0m        [94m1.2861[0m     +  0.0000  11.6362
      5      [36m0.9423[0m        [32m0.5885[0m       [35m0.6019[0m      [31m0.6019[0m        [94m1.2783[0m     +  0.0000  11.6517
      6      [36m0.9567[0m        [32m0.5367[0m       [35m0.6538[0m      [31m0.6538[0m        [94m1.2333[0m     +  0.0000  11.6908
      7      [36m0.9615[0m        [32m0.5219[0m       0.6533      0.6533        1.2342        0.0000  11.5814
      8      [36m0.9712[0m        [32m0.5143[0m       [35m0.6547[0m      [31m0.6547[0m        [94m1.2278[0m     +  0.0000  11.7927
      9      0.9615        0.5232       0.6493      0.6493        1.2315        0.0000  11.5198
     10      0.9712        [32m0.4965[0m       0.6521      0.6521        1.2302        0.0000  11.8433
     11      0.9663        0.5087       0.6514      0.6514        1.2305        0.0000  11.6409
     12      [36m0.9760[0m        [32m0.4741[0m       0.6516      0.6516        1.2309        0.0000  11.7173
     13      0.9760        [32m0.4719[0m       0.6524      0.6524        1.2313        0.0000  11.8281
     14      0.9663        0.4926       0.6524      0.6524        1.2302        0.0000  11.5562
     15      0.9712        0.4895       0.6528      0.6528        1.2294        0.0000  11.5828
     16      0.9663        0.4847       0.6519      0.6519        1.2297        0.0000  11.6872
     17      0.9663        0.4867       0.6517      0.6517        1.2297        0.0000  11.6094
     18      0.9712        0.4888       0.6514      0.6514        1.2302        0.0000  11.7542
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.6619791666666667
F1 Macro Score after query 4: 0.2662194007687744
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7969[0m        [32m0.8454[0m       [35m0.7075[0m      [31m0.7075[0m        [94m1.0539[0m     +  0.0000  12.5783
      2      [36m0.8932[0m        [32m0.6146[0m       0.6840      0.6840        [94m1.0528[0m     +  0.0000  12.3674
      3      [36m0.9219[0m        [32m0.5372[0m       0.6696      0.6696        1.0543        0.0000  12.4244
      4      [36m0.9531[0m        [32m0.4713[0m       0.6583      0.6583        1.0643        0.0000  12.5336
      5      [36m0.9583[0m        [32m0.4536[0m       0.6637      0.6637        [94m1.0475[0m     +  0.0000  12.5009
      6      [36m0.9688[0m        [32m0.4083[0m       0.6637      0.6637        [94m1.0423[0m     +  0.0000  12.4812
      7      [36m0.9766[0m        [32m0.3977[0m       0.6655      0.6655        [94m1.0392[0m     +  0.0000  12.5222
      8      0.9766        [32m0.3804[0m       0.6646      0.6646        1.0448        0.0000  12.3639
      9      0.9688        0.3935       0.6655      0.6655        1.0407        0.0000  12.5132
     10      [36m0.9792[0m        [32m0.3704[0m       0.6668      0.6668        [94m1.0389[0m     +  0.0000  12.7781
     11      0.9740        0.3709       0.6691      0.6691        [94m1.0348[0m     +  0.0000  12.6130
     12      0.9766        [32m0.3662[0m       0.6694      0.6694        1.0350        0.0000  12.4694
     13      0.9714        0.3670       0.6691      0.6691        1.0358        0.0000  12.2939
     14      [36m0.9870[0m        [32m0.3463[0m       0.6696      0.6696        1.0355        0.0000  12.2319
     15      0.9766        0.3642       0.6696      0.6696        1.0349        0.0000  12.5254
     16      0.9818        0.3628       0.6694      0.6694        1.0351        0.0000  12.3566
     17      0.9792        0.3568       0.6698      0.6698        1.0351        0.0000  12.5270
     18      0.9792        0.3474       0.6698      0.6698        1.0351        0.0000  12.4331
     19      0.9818        0.3590       0.6696      0.6696        1.0350        0.0000  12.3875
     20      0.9844        0.3534       0.6708      0.6708        [94m1.0348[0m     +  0.0000  12.3091
     21      0.9844        0.3736       0.6707      0.6707        1.0350        0.0000  12.3715
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.743576388888889
F1 Macro Score after query 5: 0.3093248248861077
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7997[0m        [32m0.8101[0m       [35m0.6028[0m      [31m0.6028[0m        [94m1.2154[0m     +  0.0000  14.3732
      2      [36m0.8949[0m        [32m0.6046[0m       [35m0.6405[0m      [31m0.6405[0m        [94m1.1087[0m     +  0.0000  14.1400
      3      [36m0.9247[0m        [32m0.5050[0m       [35m0.6562[0m      [31m0.6562[0m        [94m1.0827[0m     +  0.0000  13.9036
      4      [36m0.9347[0m        [32m0.4664[0m       [35m0.6715[0m      [31m0.6715[0m        [94m1.0441[0m     +  0.0000  13.8591
      5      [36m0.9489[0m        [32m0.4268[0m       0.6559      0.6559        1.0619        0.0000  14.0146
      6      [36m0.9588[0m        [32m0.3877[0m       [35m0.7172[0m      [31m0.7172[0m        [94m0.9085[0m     +  0.0000  14.1237
      7      0.9588        [32m0.3831[0m       [35m0.7198[0m      [31m0.7198[0m        [94m0.9039[0m     +  0.0000  14.1403
      8      [36m0.9602[0m        [32m0.3617[0m       0.7158      0.7158        0.9090        0.0000  14.1550
      9      [36m0.9673[0m        0.3619       0.7193      0.7193        [94m0.9037[0m     +  0.0000  13.8386
     10      0.9631        [32m0.3566[0m       [35m0.7201[0m      [31m0.7201[0m        [94m0.9016[0m     +  0.0000  14.1082
     11      [36m0.9716[0m        [32m0.3437[0m       [35m0.7226[0m      [31m0.7226[0m        [94m0.8941[0m     +  0.0000  13.9979
     12      0.9673        0.3489       [35m0.7240[0m      [31m0.7240[0m        [94m0.8922[0m     +  0.0000  13.8397
     13      0.9716        [32m0.3418[0m       0.7234      0.7234        [94m0.8920[0m     +  0.0000  13.9689
     14      [36m0.9730[0m        0.3433       0.7238      0.7238        0.8926        0.0000  13.9981
     15      0.9716        [32m0.3404[0m       0.7222      0.7222        0.8922        0.0000  13.9660
     16      0.9688        [32m0.3389[0m       0.7238      0.7238        [94m0.8904[0m     +  0.0000  14.1702
     17      [36m0.9744[0m        [32m0.3280[0m       0.7236      0.7236        [94m0.8900[0m     +  0.0000  13.7797
     18      0.9744        0.3333       [35m0.7243[0m      [31m0.7243[0m        [94m0.8900[0m     +  0.0000  13.8415
     19      0.9730        0.3291       0.7240      0.7240        0.8901        0.0000  14.1074
     20      [36m0.9773[0m        [32m0.3277[0m       0.7238      0.7238        0.8905        0.0000  14.0907
     21      0.9773        0.3330       0.7233      0.7233        0.8903        0.0000  14.0597
     22      0.9744        0.3322       0.7233      0.7233        0.8902        0.0000  13.9960
     23      0.9716        0.3338       0.7236      0.7236        0.8902        0.0000  13.9838
     24      0.9730        0.3399       0.7240      0.7240        0.8902        0.0000  14.2907
     25      0.9730        0.3414       0.7241      0.7241        0.8902        0.0000  13.9006
     26      0.9744        0.3279       0.7241      0.7241        0.8902        0.0000  14.1069
     27      0.9773        0.3289       0.7241      0.7241        0.8901        0.0000  13.9364
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.7828125
F1 Macro Score after query 6: 0.4929469653817757
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8671[0m        [32m0.6089[0m       [35m0.7675[0m      [31m0.7675[0m        [94m0.7376[0m     +  0.0000  16.7484
      2      [36m0.9320[0m        [32m0.4490[0m       0.6993      0.6993        0.8809        0.0000  16.7639
      3      [36m0.9415[0m        [32m0.4016[0m       0.7568      0.7568        0.7451        0.0000  16.8275
      4      [36m0.9549[0m        [32m0.3602[0m       0.7641      0.7641        [94m0.7315[0m     +  0.0000  16.9673
      5      [36m0.9604[0m        [32m0.3294[0m       [35m0.7766[0m      [31m0.7766[0m        [94m0.7127[0m     +  0.0000  16.5946
      6      [36m0.9644[0m        [32m0.3018[0m       0.7705      0.7705        0.7223        0.0000  16.8113
      7      [36m0.9691[0m        [32m0.2841[0m       0.7710      0.7710        0.7205        0.0000  16.6886
      8      0.9668        [32m0.2769[0m       0.7710      0.7710        0.7171        0.0000  16.8303
      9      [36m0.9707[0m        [32m0.2730[0m       0.7743      0.7743        [94m0.7125[0m     +  0.0000  16.9234
     10      0.9699        [32m0.2661[0m       0.7750      0.7750        0.7130        0.0000  16.9526
     11      [36m0.9747[0m        [32m0.2586[0m       0.7691      0.7691        0.7231        0.0000  16.8582
     12      0.9747        [32m0.2526[0m       0.7668      0.7668        0.7271        0.0000  16.9552
     13      [36m0.9778[0m        0.2530       0.7701      0.7701        0.7225        0.0000  16.8761
     14      [36m0.9786[0m        [32m0.2473[0m       0.7710      0.7710        0.7213        0.0000  16.7377
     15      0.9763        0.2526       0.7696      0.7696        0.7217        0.0000  16.7975
     16      0.9763        0.2488       0.7691      0.7691        0.7231        0.0000  16.7969
     17      0.9778        [32m0.2434[0m       0.7684      0.7684        0.7237        0.0000  16.7854
     18      0.9778        0.2482       0.7684      0.7684        0.7242        0.0000  16.8777
     19      0.9771        0.2527       0.7691      0.7691        0.7231        0.0000  16.9239
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.8003472222222222
F1 Macro Score after query 7: 0.5125149145350665
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8613[0m        [32m0.5325[0m       [35m0.7955[0m      [31m0.7955[0m        [94m0.6097[0m     +  0.0000  21.9270
      2      [36m0.9055[0m        [32m0.4123[0m       [35m0.7998[0m      [31m0.7998[0m        [94m0.5961[0m     +  0.0000  22.1313
      3      [36m0.9324[0m        [32m0.3477[0m       [35m0.8035[0m      [31m0.8035[0m        [94m0.5857[0m     +  0.0000  22.0592
      4      [36m0.9452[0m        [32m0.3084[0m       0.7976      0.7976        [94m0.5799[0m     +  0.0000  21.6940
      5      [36m0.9492[0m        [32m0.2826[0m       0.7964      0.7964        0.5933        0.0000  21.9429
      6      [36m0.9625[0m        [32m0.2454[0m       0.7953      0.7953        0.6194        0.0000  22.1280
      7      [36m0.9686[0m        [32m0.2267[0m       0.7984      0.7984        0.6222        0.0000  21.9281
      8      [36m0.9704[0m        [32m0.2187[0m       0.8023      0.8023        0.6200        0.0000  21.8810
      9      [36m0.9735[0m        [32m0.2082[0m       [35m0.8057[0m      [31m0.8057[0m        0.6245        0.0000  22.2373
     10      0.9735        [32m0.2024[0m       0.8030      0.8030        0.6272        0.0000  21.8949
     11      [36m0.9770[0m        [32m0.1943[0m       [35m0.8082[0m      [31m0.8082[0m        0.6071        0.0000  21.7035
     12      [36m0.9779[0m        [32m0.1890[0m       [35m0.8089[0m      [31m0.8089[0m        0.6084        0.0000  21.8819
     13      [36m0.9814[0m        [32m0.1839[0m       0.8082      0.8082        0.6090        0.0000  21.9125
     14      [36m0.9872[0m        [32m0.1794[0m       [35m0.8092[0m      [31m0.8092[0m        0.6151        0.0000  21.7884
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8046875
F1 Macro Score after query 8: 0.49345905187814676
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8668[0m        [32m0.4768[0m       [35m0.8030[0m      [31m0.8030[0m        [94m0.5810[0m     +  0.0000  30.7991
      2      [36m0.9084[0m        [32m0.3759[0m       [35m0.8050[0m      [31m0.8050[0m        [94m0.5729[0m     +  0.0000  30.7519
      3      [36m0.9149[0m        [32m0.3358[0m       0.7965      0.7965        0.5779        0.0000  30.8728
      4      [36m0.9309[0m        [32m0.2975[0m       0.8007      0.8007        0.5939        0.0000  30.8599
      5      [36m0.9389[0m        [32m0.2645[0m       0.8038      0.8038        0.5931        0.0000  30.6543
      6      [36m0.9535[0m        [32m0.2251[0m       0.7830      0.7830        0.6663        0.0000  30.9075
      7      [36m0.9611[0m        [32m0.2063[0m       0.7891      0.7891        0.6547        0.0000  30.8245
      8      [36m0.9626[0m        [32m0.1994[0m       0.7856      0.7856        0.6697        0.0000  30.5597
      9      [36m0.9656[0m        [32m0.1891[0m       0.7861      0.7861        0.6798        0.0000  30.6551
     10      [36m0.9696[0m        [32m0.1784[0m       0.7877      0.7877        0.6821        0.0000  30.5340
     11      [36m0.9772[0m        [32m0.1646[0m       0.8028      0.8028        0.6345        0.0000  30.6873
     12      0.9772        [32m0.1638[0m       0.8021      0.8021        0.6425        0.0000  30.7311
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8175347222222222
F1 Macro Score after query 9: 0.5417010518637817
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8951[0m        [32m0.3950[0m       [35m0.7873[0m      [31m0.7873[0m        [94m0.6157[0m     +  0.0000  46.3263
      2      [36m0.9140[0m        [32m0.3316[0m       [35m0.8028[0m      [31m0.8028[0m        [94m0.6048[0m     +  0.0000  46.9059
      3      [36m0.9268[0m        [32m0.2923[0m       [35m0.8155[0m      [31m0.8155[0m        [94m0.5951[0m     +  0.0000  46.7361
      4      [36m0.9331[0m        [32m0.2638[0m       0.7823      0.7823        0.6913        0.0000  46.9976
      5      [36m0.9379[0m        [32m0.2413[0m       0.7826      0.7826        0.6749        0.0000  46.6243
      6      [36m0.9528[0m        [32m0.1989[0m       0.8104      0.8104        0.6090        0.0000  46.7987
      7      [36m0.9585[0m        [32m0.1821[0m       0.8122      0.8122        0.6105        0.0000  46.6875
      8      [36m0.9633[0m        [32m0.1685[0m       0.8113      0.8113        0.6250        0.0000  47.0166
      9      [36m0.9640[0m        [32m0.1596[0m       0.8080      0.8080        0.6343        0.0000  46.7776
     10      [36m0.9678[0m        [32m0.1512[0m       0.8116      0.8116        0.6369        0.0000  46.9234
     11      [36m0.9757[0m        [32m0.1397[0m       0.8092      0.8092        0.6540        0.0000  46.8142
     12      [36m0.9783[0m        [32m0.1325[0m       0.8071      0.8071        0.6561        0.0000  47.0947
     13      0.9769        [32m0.1301[0m       0.8071      0.8071        0.6586        0.0000  46.8723
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8152777777777778
F1 Macro Score after query 10: 0.5704808800219564
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9416[0m        [32m0.2490[0m       [35m0.8054[0m      [31m0.8054[0m        [94m0.5776[0m     +  0.0000  74.4933
      2      [36m0.9488[0m        [32m0.2136[0m       [35m0.8273[0m      [31m0.8273[0m        [94m0.5515[0m     +  0.0000  75.5371
      3      [36m0.9506[0m        [32m0.1954[0m       [35m0.8297[0m      [31m0.8297[0m        0.5681        0.0000  75.3566
      4      [36m0.9556[0m        [32m0.1725[0m       [35m0.8313[0m      [31m0.8313[0m        0.5642        0.0000  75.4632
      5      [36m0.9579[0m        [32m0.1534[0m       0.8264      0.8264        0.6024        0.0000  75.4927
      6      [36m0.9697[0m        [32m0.1259[0m       0.8248      0.8248        0.6085        0.0000  75.3984
      7      [36m0.9733[0m        [32m0.1114[0m       0.8281      0.8281        0.6099        0.0000  75.4291
      8      [36m0.9756[0m        [32m0.1015[0m       0.8224      0.8224        0.6512        0.0000  75.2689
      9      [36m0.9786[0m        [32m0.0948[0m       0.8142      0.8142        0.6870        0.0000  75.2700
     10      [36m0.9828[0m        [32m0.0856[0m       0.8132      0.8132        0.7211        0.0000  75.4479
     11      [36m0.9857[0m        [32m0.0773[0m       0.8257      0.8257        0.6524        0.0000  75.2081
     12      [36m0.9881[0m        [32m0.0718[0m       0.8255      0.8255        0.6527        0.0000  75.5714
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8241319444444445
F1 Macro Score after query 11: 0.5596599547380199
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9684[0m        [32m0.1397[0m       [35m0.7507[0m      [31m0.7507[0m        [94m0.9497[0m     +  0.0000  126.0826
      2      [36m0.9702[0m        [32m0.1201[0m       [35m0.7724[0m      [31m0.7724[0m        [94m0.8652[0m     +  0.0000  126.5428
      3      [36m0.9727[0m        [32m0.1060[0m       0.7675      0.7675        0.9082        0.0000  126.3999
      4      [36m0.9738[0m        [32m0.0948[0m       0.7608      0.7608        0.9047        0.0000  126.7480
      5      [36m0.9752[0m        [32m0.0891[0m       [35m0.7901[0m      [31m0.7901[0m        [94m0.8422[0m     +  0.0000  126.9228
      6      [36m0.9821[0m        [32m0.0693[0m       [35m0.8262[0m      [31m0.8262[0m        [94m0.6779[0m     +  0.0000  126.7121
      7      [36m0.9850[0m        [32m0.0583[0m       0.8260      0.8260        0.6978        0.0000  126.7755
      8      [36m0.9874[0m        [32m0.0518[0m       [35m0.8286[0m      [31m0.8286[0m        0.6874        0.0000  126.6663
      9      [36m0.9897[0m        [32m0.0462[0m       0.8259      0.8259        0.6995        0.0000  126.2560
     10      [36m0.9909[0m        [32m0.0414[0m       0.8250      0.8250        0.7353        0.0000  126.6500
     11      [36m0.9930[0m        [32m0.0356[0m       0.8259      0.8259        0.7038        0.0000  126.3838
     12      [36m0.9942[0m        [32m0.0321[0m       0.8259      0.8259        0.7183        0.0000  126.3251
     13      [36m0.9950[0m        [32m0.0315[0m       0.8266      0.8266        0.7213        0.0000  126.5279
     14      [36m0.9952[0m        [32m0.0291[0m       0.8271      0.8271        0.7346        0.0000  126.6043
     15      [36m0.9961[0m        [32m0.0283[0m       0.8257      0.8257        0.7465        0.0000  126.2892
     16      [36m0.9965[0m        [32m0.0264[0m       [35m0.8297[0m      [31m0.8297[0m        0.7431        0.0000  126.2492
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8126736111111111
F1 Macro Score after query 12: 0.5276309276391293
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9814[0m        [32m0.0671[0m       [35m0.7837[0m      [31m0.7837[0m        [94m0.9294[0m     +  0.0000  146.2124
      2      [36m0.9826[0m        [32m0.0616[0m       0.7562      0.7562        1.1715        0.0000  147.7518
      3      [36m0.9843[0m        [32m0.0540[0m       [35m0.8024[0m      [31m0.8024[0m        [94m0.8308[0m     +  0.0000  147.4664
      4      [36m0.9850[0m        [32m0.0500[0m       0.7814      0.7814        0.9545        0.0000  146.8609
      5      [36m0.9876[0m        [32m0.0442[0m       0.7832      0.7832        0.9934        0.0000  146.9454
      6      [36m0.9919[0m        [32m0.0321[0m       [35m0.8028[0m      [31m0.8028[0m        0.8919        0.0000  147.2101
      7      [36m0.9950[0m        [32m0.0220[0m       [35m0.8170[0m      [31m0.8170[0m        [94m0.8204[0m     +  0.0000  145.1638
      8      [36m0.9969[0m        [32m0.0174[0m       [35m0.8182[0m      [31m0.8182[0m        0.8271        0.0000  138.1206
      9      [36m0.9981[0m        [32m0.0140[0m       0.8082      0.8082        0.8844        0.0000  138.1040
     10      [36m0.9986[0m        [32m0.0115[0m       [35m0.8214[0m      [31m0.8214[0m        0.9025        0.0000  137.7376
     11      [36m0.9991[0m        [32m0.0097[0m       0.8163      0.8163        0.9175        0.0000  137.8278
     12      [36m0.9994[0m        [32m0.0090[0m       0.8165      0.8165        0.9280        0.0000  137.9644
     13      [36m0.9995[0m        [32m0.0087[0m       0.8201      0.8201        0.9310        0.0000  137.8698
     14      [36m0.9996[0m        [32m0.0081[0m       [35m0.8233[0m      [31m0.8233[0m        0.9133        0.0000  137.8501
     15      0.9996        [32m0.0078[0m       0.8231      0.8231        0.9380        0.0000  139.9452
     16      0.9996        0.0078       0.8184      0.8184        0.9469        0.0000  139.4680
     17      [36m0.9997[0m        [32m0.0075[0m       0.8187      0.8187        0.9468        0.0000  139.4848
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8255208333333334
F1 Macro Score after query 13: 0.5478066160997064
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed48\AL_uncertainty_sampling_results_for_multiclass_classification_s48.pickle
