(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2500[0m        [32m2.0239[0m       [35m0.3233[0m      [31m0.3233[0m        [94m1.9518[0m     +  0.0000  11.2359
      2      0.2500        2.0520       0.1965      0.1965        1.9794        0.0000  10.2672
      3      [36m0.3750[0m        [32m1.7789[0m       0.2443      0.2443        1.9609        0.0000  10.4006
      4      0.3750        [32m1.6955[0m       0.2712      0.2712        1.9824        0.0000  10.5559
      5      [36m0.5000[0m        [32m1.6955[0m       0.1828      0.1828        2.0405        0.0000  10.5508
      6      [36m0.6250[0m        [32m1.6262[0m       0.2477      0.2477        2.0203        0.0000  10.4919
      7      [36m0.7500[0m        [32m1.4494[0m       0.2788      0.2788        2.0094        0.0000  10.4257
      8      0.7500        1.4731       0.2892      0.2892        2.0019        0.0000  10.4639
      9      0.7500        [32m1.4338[0m       0.2870      0.2870        2.0048        0.0000  10.6186
     10      0.7500        1.4902       0.3016      0.3016        1.9939        0.0000  10.6330
     11      [36m1.0000[0m        [32m1.3427[0m       0.3005      0.3005        1.9949        0.0000  10.6314
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.3299
Pre F1 macro score = 0.1587

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8333[0m        [32m1.4666[0m       [35m0.4479[0m      [31m0.4479[0m        [94m1.7339[0m     +  0.0000  10.6959
      2      0.7500        [32m1.1782[0m       0.4479      0.4479        [94m1.7076[0m     +  0.0000  10.6030
      3      0.7917        [32m0.9504[0m       0.4479      0.4479        [94m1.6997[0m     +  0.0000  10.6516
      4      0.7917        [32m0.8155[0m       [35m0.4561[0m      [31m0.4561[0m        1.7024        0.0000  10.5570
      5      0.8333        [32m0.7140[0m       [35m0.4774[0m      [31m0.4774[0m        [94m1.6938[0m     +  0.0000  10.5696
      6      [36m0.9167[0m        0.7251       0.4760      0.4760        [94m1.6885[0m     +  0.0000  10.6486
      7      0.9167        0.7239       [35m0.4780[0m      [31m0.4780[0m        [94m1.6879[0m     +  0.0000  10.5396
      8      [36m0.9583[0m        [32m0.6481[0m       [35m0.4795[0m      [31m0.4795[0m        [94m1.6848[0m     +  0.0000  10.4457
      9      0.9583        [32m0.6423[0m       [35m0.4811[0m      [31m0.4811[0m        1.6851        0.0000  10.5558
     10      0.9583        [32m0.5974[0m       [35m0.4882[0m      [31m0.4882[0m        1.6881        0.0000  10.6646
     11      0.9167        0.6369       [35m0.4898[0m      [31m0.4898[0m        1.6880        0.0000  10.6171
     12      [36m1.0000[0m        0.6909       [35m0.4899[0m      [31m0.4899[0m        1.6876        0.0000  10.4412
     13      0.9167        [32m0.5529[0m       [35m0.4908[0m      [31m0.4908[0m        1.6877        0.0000  10.5715
     14      0.9583        0.6058       [35m0.4911[0m      [31m0.4911[0m        1.6882        0.0000  10.5403
     15      0.9583        0.6709       [35m0.4918[0m      [31m0.4918[0m        1.6887        0.0000  10.7265
     16      0.9583        0.6405       0.4918      0.4918        1.6886        0.0000  10.8822
     17      1.0000        0.6498       [35m0.4920[0m      [31m0.4920[0m        1.6886        0.0000  11.3827
     18      0.9167        0.5963       [35m0.4925[0m      [31m0.4925[0m        1.6887        0.0000  11.0816
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.5407986111111112
F1 Macro Score after query 1: 0.17345411245617315
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7321[0m        [32m1.2985[0m       [35m0.3118[0m      [31m0.3118[0m        [94m1.8621[0m     +  0.0000  11.2537
      2      [36m0.7500[0m        [32m1.0086[0m       [35m0.4061[0m      [31m0.4061[0m        [94m1.7595[0m     +  0.0000  11.6805
      3      [36m0.8571[0m        [32m0.8486[0m       [35m0.4415[0m      [31m0.4415[0m        [94m1.7275[0m     +  0.0000  11.2895
      4      [36m0.8750[0m        [32m0.7223[0m       [35m0.4507[0m      [31m0.4507[0m        [94m1.7040[0m     +  0.0000  11.3676
      5      [36m0.9464[0m        [32m0.6578[0m       [35m0.4573[0m      [31m0.4573[0m        [94m1.6934[0m     +  0.0000  11.6654
      6      0.9286        [32m0.6467[0m       0.4545      0.4545        1.7033        0.0000  11.5724
      7      0.9464        [32m0.5788[0m       0.4545      0.4545        1.7030        0.0000  11.2620
      8      [36m0.9643[0m        [32m0.5685[0m       0.4557      0.4557        1.7018        0.0000  11.4151
      9      0.9464        0.6113       0.4549      0.4549        1.7025        0.0000  11.4641
     10      0.9464        0.6088       [35m0.4583[0m      [31m0.4583[0m        1.7029        0.0000  11.8383
     11      0.9643        [32m0.5651[0m       0.4578      0.4578        1.7030        0.0000  11.1643
     12      0.9464        0.5982       0.4583      0.4583        1.7027        0.0000  11.4629
     13      0.9643        [32m0.5623[0m       0.4582      0.4582        1.7017        0.0000  11.4948
     14      0.9286        [32m0.5546[0m       0.4580      0.4580        1.7009        0.0000  11.0397
     15      0.9643        0.5780       0.4582      0.4582        1.7003        0.0000  11.3229
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.5078125
F1 Macro Score after query 2: 0.21096464281002894
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7857[0m        [32m1.1109[0m       [35m0.3021[0m      [31m0.3021[0m        [94m1.8922[0m     +  0.0000  11.1652
      2      [36m0.8214[0m        [32m0.9708[0m       [35m0.3616[0m      [31m0.3616[0m        [94m1.7631[0m     +  0.0000  11.1523
      3      0.8125        [32m0.8502[0m       [35m0.3649[0m      [31m0.3649[0m        [94m1.7011[0m     +  0.0000  11.2754
      4      [36m0.8661[0m        [32m0.7564[0m       [35m0.3774[0m      [31m0.3774[0m        [94m1.6508[0m     +  0.0000  11.5576
      5      [36m0.8839[0m        [32m0.6743[0m       0.3696      0.3696        1.6713        0.0000  11.8232
      6      [36m0.9018[0m        [32m0.6698[0m       [35m0.4318[0m      [31m0.4318[0m        [94m1.6196[0m     +  0.0000  11.3978
      7      [36m0.9107[0m        [32m0.6448[0m       [35m0.4382[0m      [31m0.4382[0m        [94m1.6174[0m     +  0.0000  11.1346
      8      0.9107        [32m0.6053[0m       [35m0.4436[0m      [31m0.4436[0m        [94m1.6115[0m     +  0.0000  11.0241
      9      [36m0.9196[0m        [32m0.5851[0m       0.4411      0.4411        1.6132        0.0000  11.1959
     10      [36m0.9286[0m        0.6465       0.4380      0.4380        [94m1.6052[0m     +  0.0000  11.1036
     11      0.9107        0.5867       0.4417      0.4417        [94m1.6035[0m     +  0.0000  11.1818
     12      [36m0.9375[0m        [32m0.5618[0m       0.4429      0.4429        [94m1.6027[0m     +  0.0000  11.4629
     13      0.9018        0.6121       0.4427      0.4427        1.6029        0.0000  11.9139
     14      0.9375        0.5819       [35m0.4439[0m      [31m0.4439[0m        [94m1.6025[0m     +  0.0000  11.5209
     15      0.9286        0.6067       [35m0.4450[0m      [31m0.4450[0m        [94m1.6009[0m     +  0.0000  11.0878
     16      [36m0.9554[0m        0.5770       [35m0.4451[0m      [31m0.4451[0m        [94m1.6007[0m     +  0.0000  11.1466
     17      0.9196        [32m0.5580[0m       [35m0.4457[0m      [31m0.4457[0m        [94m1.6004[0m     +  0.0000  11.0887
     18      0.9107        0.5675       [35m0.4472[0m      [31m0.4472[0m        [94m1.5999[0m     +  0.0000  11.1688
     19      0.9464        0.5647       [35m0.4474[0m      [31m0.4474[0m        [94m1.5993[0m     +  0.0000  11.1373
     20      0.9286        0.6031       0.4474      0.4474        1.5994        0.0000  11.0716
     21      0.9286        0.5831       0.4474      0.4474        1.5994        0.0000  11.1838
     22      0.9286        0.5976       [35m0.4476[0m      [31m0.4476[0m        [94m1.5993[0m     +  0.0000  11.0702
     23      0.9286        0.5660       0.4474      0.4474        [94m1.5991[0m     +  0.0000  11.1184
     24      0.9375        0.5853       0.4474      0.4474        1.5991        0.0000  11.2147
     25      0.9107        0.5871       0.4476      0.4476        1.5991        0.0000  11.4789
     26      0.9196        0.5635       0.4476      0.4476        1.5991        0.0000  11.6203
     27      0.9375        0.5779       0.4476      0.4476        1.5991        0.0000  11.7009
     28      0.9196        0.6131       0.4476      0.4476        1.5991        0.0000  11.1040
     29      0.9107        0.5871       0.4476      0.4476        1.5991        0.0000  11.1343
     30      0.9286        [32m0.5451[0m       0.4474      0.4474        1.5991        0.0000  11.0724
     31      0.9464        0.5753       0.4474      0.4474        1.5991        0.0000  11.1178
     32      0.9196        0.5891       0.4474      0.4474        1.5991        0.0000  11.0403
     33      0.9196        0.5778       0.4474      0.4474        1.5991        0.0000  11.2135
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.45868055555555554
F1 Macro Score after query 3: 0.2090293716837206
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8462[0m        [32m0.7949[0m       [35m0.5556[0m      [31m0.5556[0m        [94m1.3612[0m     +  0.0000  11.9168
      2      [36m0.9327[0m        [32m0.5699[0m       [35m0.5660[0m      [31m0.5660[0m        [94m1.3250[0m     +  0.0000  10.9849
      3      0.9327        [32m0.4995[0m       [35m0.5863[0m      [31m0.5863[0m        [94m1.3067[0m     +  0.0000  10.7313
      4      [36m0.9519[0m        [32m0.4570[0m       [35m0.5934[0m      [31m0.5934[0m        [94m1.2840[0m     +  0.0000  10.7599
      5      0.9519        [32m0.4318[0m       [35m0.6184[0m      [31m0.6184[0m        [94m1.2832[0m     +  0.0000  10.7141
      6      0.9519        [32m0.4212[0m       [35m0.6248[0m      [31m0.6248[0m        [94m1.2654[0m     +  0.0000  10.8719
      7      [36m0.9567[0m        [32m0.3939[0m       0.6148      0.6148        1.2723        0.0000  10.7154
      8      [36m0.9712[0m        [32m0.3928[0m       0.6130      0.6130        1.2780        0.0000  10.7568
      9      0.9567        0.3992       0.6122      0.6122        1.2781        0.0000  10.6806
     10      0.9663        [32m0.3801[0m       0.6040      0.6040        1.2805        0.0000  10.7606
     11      0.9663        [32m0.3727[0m       0.6049      0.6049        1.2789        0.0000  10.6774
     12      0.9663        [32m0.3606[0m       0.6049      0.6049        1.2787        0.0000  10.6639
     13      0.9663        0.3693       0.6078      0.6078        1.2770        0.0000  10.7412
     14      0.9712        0.3681       0.6047      0.6047        1.2775        0.0000  10.6815
     15      [36m0.9760[0m        [32m0.3519[0m       0.6061      0.6061        1.2784        0.0000  10.7108
     16      [36m0.9808[0m        0.3798       0.6054      0.6054        1.2781        0.0000  10.6628
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.5828125
F1 Macro Score after query 4: 0.22885282194214532
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7839[0m        [32m0.7846[0m       [35m0.4634[0m      [31m0.4634[0m        [94m1.4941[0m     +  0.0000  11.5217
      2      [36m0.8724[0m        [32m0.5944[0m       [35m0.5224[0m      [31m0.5224[0m        [94m1.3436[0m     +  0.0000  11.5275
      3      [36m0.9245[0m        [32m0.5284[0m       [35m0.5462[0m      [31m0.5462[0m        [94m1.3021[0m     +  0.0000  11.5112
      4      [36m0.9453[0m        [32m0.4298[0m       [35m0.5693[0m      [31m0.5693[0m        [94m1.2612[0m     +  0.0000  11.5405
      5      [36m0.9714[0m        [32m0.3802[0m       [35m0.5861[0m      [31m0.5861[0m        [94m1.2247[0m     +  0.0000  11.5441
      6      0.9661        [32m0.3613[0m       [35m0.6057[0m      [31m0.6057[0m        [94m1.1773[0m     +  0.0000  11.5111
      7      0.9661        [32m0.3534[0m       [35m0.6106[0m      [31m0.6106[0m        [94m1.1740[0m     +  0.0000  11.5256
      8      [36m0.9740[0m        [32m0.3424[0m       [35m0.6181[0m      [31m0.6181[0m        [94m1.1642[0m     +  0.0000  11.5420
      9      [36m0.9792[0m        [32m0.3393[0m       [35m0.6248[0m      [31m0.6248[0m        [94m1.1564[0m     +  0.0000  11.5242
     10      0.9766        [32m0.3329[0m       0.6248      0.6248        [94m1.1538[0m     +  0.0000  11.5573
     11      0.9766        [32m0.3212[0m       [35m0.6352[0m      [31m0.6352[0m        [94m1.1306[0m     +  0.0000  11.5880
     12      0.9766        0.3252       0.6349      0.6349        [94m1.1294[0m     +  0.0000  11.5561
     13      0.9766        0.3227       [35m0.6361[0m      [31m0.6361[0m        [94m1.1261[0m     +  0.0000  11.5077
     14      0.9740        [32m0.3147[0m       0.6347      0.6347        1.1296        0.0000  11.4916
     15      0.9792        0.3175       0.6337      0.6337        1.1312        0.0000  11.5863
     16      0.9792        [32m0.3059[0m       0.6342      0.6342        1.1294        0.0000  11.4791
     17      0.9766        0.3184       0.6352      0.6352        [94m1.1260[0m     +  0.0000  11.4968
     18      0.9792        0.3153       0.6358      0.6358        [94m1.1249[0m     +  0.0000  11.5245
     19      0.9740        0.3142       0.6352      0.6352        1.1259        0.0000  11.5256
     20      0.9766        0.3071       0.6347      0.6347        1.1281        0.0000  11.6023
     21      0.9740        0.3099       0.6349      0.6349        1.1276        0.0000  11.5255
     22      0.9766        0.3154       0.6351      0.6351        1.1270        0.0000  11.5430
     23      0.9766        0.3248       0.6352      0.6352        1.1267        0.0000  11.5066
     24      [36m0.9818[0m        0.3245       0.6352      0.6352        1.1268        0.0000  11.5069
     25      0.9792        0.3098       0.6356      0.6356        1.1266        0.0000  11.5574
     26      0.9818        0.3153       0.6356      0.6356        1.1265        0.0000  11.5394
     27      0.9792        [32m0.3051[0m       0.6356      0.6356        1.1266        0.0000  11.4928
     28      0.9792        0.3110       0.6356      0.6356        1.1265        0.0000  11.5715
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.6696180555555555
F1 Macro Score after query 5: 0.2547710473044824
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8097[0m        [32m0.7348[0m       [35m0.6524[0m      [31m0.6524[0m        [94m1.0038[0m     +  0.0000  13.0419
      2      [36m0.8906[0m        [32m0.5619[0m       [35m0.6993[0m      [31m0.6993[0m        [94m0.9548[0m     +  0.0000  13.0369
      3      [36m0.9233[0m        [32m0.4757[0m       [35m0.7142[0m      [31m0.7142[0m        [94m0.9246[0m     +  0.0000  13.0443
      4      [36m0.9389[0m        [32m0.4283[0m       0.7106      0.7106        0.9399        0.0000  13.0612
      5      [36m0.9517[0m        [32m0.3888[0m       0.7116      0.7116        0.9365        0.0000  13.0410
      6      [36m0.9659[0m        [32m0.3498[0m       [35m0.7172[0m      [31m0.7172[0m        [94m0.9242[0m     +  0.0000  13.0875
      7      [36m0.9688[0m        [32m0.3280[0m       0.7149      0.7149        0.9262        0.0000  13.1047
      8      [36m0.9702[0m        [32m0.3249[0m       0.7153      0.7153        0.9329        0.0000  13.0899
      9      0.9688        [32m0.3192[0m       0.7170      0.7170        0.9283        0.0000  13.0909
     10      [36m0.9744[0m        [32m0.3123[0m       0.7153      0.7153        0.9341        0.0000  13.0414
     11      [36m0.9759[0m        0.3133       0.7142      0.7142        0.9424        0.0000  13.1164
     12      0.9759        [32m0.3005[0m       0.7139      0.7139        0.9416        0.0000  13.0569
     13      [36m0.9787[0m        0.3074       0.7141      0.7141        0.9416        0.0000  13.1778
     14      0.9787        [32m0.2993[0m       0.7141      0.7141        0.9423        0.0000  13.3285
     15      0.9730        0.3053       0.7142      0.7142        0.9430        0.0000  13.3268
     16      [36m0.9830[0m        [32m0.2910[0m       0.7137      0.7137        0.9449        0.0000  13.2996
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.7269097222222223
F1 Macro Score after query 6: 0.2936125802704552
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8465[0m        [32m0.6638[0m       [35m0.7391[0m      [31m0.7391[0m        [94m0.8646[0m     +  0.0000  16.7115
      2      [36m0.9256[0m        [32m0.4857[0m       [35m0.7665[0m      [31m0.7665[0m        [94m0.8411[0m     +  0.0000  16.5507
      3      [36m0.9415[0m        [32m0.4044[0m       0.7439      0.7439        0.8948        0.0000  16.6257
      4      [36m0.9454[0m        [32m0.3670[0m       0.7363      0.7363        0.9036        0.0000  16.6859
      5      [36m0.9589[0m        [32m0.3254[0m       0.7248      0.7248        0.9673        0.0000  16.6069
      6      [36m0.9691[0m        [32m0.2984[0m       0.7443      0.7443        0.8593        0.0000  16.6430
      7      0.9691        [32m0.2829[0m       0.7438      0.7438        0.8645        0.0000  16.6385
      8      [36m0.9755[0m        [32m0.2755[0m       0.7425      0.7425        0.8725        0.0000  16.5214
      9      0.9755        [32m0.2711[0m       0.7401      0.7401        0.8752        0.0000  16.7165
     10      0.9747        [32m0.2615[0m       0.7399      0.7399        0.8718        0.0000  16.5831
     11      [36m0.9771[0m        [32m0.2598[0m       0.7543      0.7543        0.8412        0.0000  16.5604
     12      [36m0.9810[0m        [32m0.2524[0m       0.7512      0.7512        0.8425        0.0000  16.6061
     13      0.9810        [32m0.2475[0m       0.7538      0.7538        [94m0.8407[0m     +  0.0000  16.4906
     14      0.9786        0.2509       0.7536      0.7536        0.8418        0.0000  16.5174
     15      0.9802        0.2522       0.7524      0.7524        0.8428        0.0000  16.5346
     16      [36m0.9826[0m        [32m0.2458[0m       0.7526      0.7526        0.8423        0.0000  16.6842
     17      0.9818        [32m0.2448[0m       0.7528      0.7528        0.8431        0.0000  16.5678
     18      0.9826        [32m0.2430[0m       0.7523      0.7523        0.8433        0.0000  16.6045
     19      [36m0.9842[0m        0.2432       0.7524      0.7524        0.8431        0.0000  17.0568
     20      0.9834        [32m0.2429[0m       0.7528      0.7528        0.8433        0.0000  17.3199
     21      0.9842        0.2468       0.7523      0.7523        0.8436        0.0000  17.2639
     22      0.9826        [32m0.2401[0m       0.7524      0.7524        0.8436        0.0000  17.3340
     23      0.9834        0.2492       0.7524      0.7524        0.8436        0.0000  16.9786
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.7753472222222222
F1 Macro Score after query 7: 0.4633023494152262
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8706[0m        [32m0.5339[0m       [35m0.7767[0m      [31m0.7767[0m        [94m0.6833[0m     +  0.0000  22.0161
      2      [36m0.9218[0m        [32m0.3988[0m       [35m0.7870[0m      [31m0.7870[0m        [94m0.6426[0m     +  0.0000  22.5111
      3      [36m0.9448[0m        [32m0.3414[0m       [35m0.7908[0m      [31m0.7908[0m        0.6854        0.0000  22.5598
      4      [36m0.9488[0m        [32m0.3033[0m       [35m0.8010[0m      [31m0.8010[0m        [94m0.6127[0m     +  0.0000  22.1270
      5      [36m0.9541[0m        [32m0.2770[0m       0.7995      0.7995        0.6282        0.0000  22.2384
      6      [36m0.9704[0m        [32m0.2339[0m       0.7887      0.7887        0.6638        0.0000  22.4257
      7      [36m0.9731[0m        [32m0.2175[0m       0.7918      0.7918        0.6727        0.0000  22.4014
      8      [36m0.9784[0m        [32m0.2091[0m       0.7894      0.7894        0.6663        0.0000  22.2544
      9      0.9770        [32m0.2042[0m       0.7970      0.7970        0.6588        0.0000  22.5297
     10      [36m0.9837[0m        [32m0.1983[0m       0.7898      0.7898        0.6616        0.0000  22.3729
     11      0.9819        [32m0.1897[0m       0.8007      0.8007        0.6614        0.0000  22.4225
     12      0.9837        [32m0.1817[0m       [35m0.8017[0m      [31m0.8017[0m        0.6559        0.0000  22.2159
     13      [36m0.9867[0m        0.1821       0.7997      0.7997        0.6618        0.0000  22.3454
     14      0.9863        0.1821       0.8007      0.8007        0.6596        0.0000  22.3591
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8317708333333333
F1 Macro Score after query 8: 0.5651908937188311
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8748[0m        [32m0.4795[0m       [35m0.8099[0m      [31m0.8099[0m        [94m0.5776[0m     +  0.0000  30.8395
      2      [36m0.9077[0m        [32m0.3904[0m       [35m0.8187[0m      [31m0.8187[0m        [94m0.5380[0m     +  0.0000  31.3092
      3      [36m0.9235[0m        [32m0.3384[0m       [35m0.8283[0m      [31m0.8283[0m        0.5527        0.0000  31.0586
      4      [36m0.9354[0m        [32m0.2982[0m       0.8260      0.8260        0.5536        0.0000  31.4023
      5      [36m0.9453[0m        [32m0.2682[0m       [35m0.8365[0m      [31m0.8365[0m        [94m0.5345[0m     +  0.0000  30.9152
      6      [36m0.9609[0m        [32m0.2248[0m       0.8247      0.8247        0.5758        0.0000  31.1371
      7      [36m0.9671[0m        [32m0.2069[0m       0.8243      0.8243        0.5908        0.0000  30.9030
      8      0.9661        [32m0.1959[0m       0.8220      0.8220        0.6000        0.0000  30.9489
      9      [36m0.9715[0m        [32m0.1862[0m       0.8266      0.8266        0.5942        0.0000  31.0267
     10      [36m0.9755[0m        [32m0.1752[0m       0.8271      0.8271        0.6031        0.0000  30.9201
     11      [36m0.9782[0m        [32m0.1627[0m       0.8302      0.8302        0.5879        0.0000  31.4163
     12      [36m0.9829[0m        [32m0.1554[0m       0.8319      0.8319        0.5868        0.0000  30.8876
     13      [36m0.9844[0m        [32m0.1537[0m       0.8328      0.8328        0.5795        0.0000  31.0075
     14      0.9842        [32m0.1492[0m       0.8325      0.8325        0.5824        0.0000  31.0358
     15      0.9842        [32m0.1483[0m       0.8309      0.8309        0.5856        0.0000  31.2473
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8623263888888888
F1 Macro Score after query 9: 0.5980206266381072
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9010[0m        [32m0.3716[0m       [35m0.8236[0m      [31m0.8236[0m        [94m0.5382[0m     +  0.0000  46.9945
      2      [36m0.9257[0m        [32m0.2987[0m       0.8141      0.8141        0.5895        0.0000  46.9555
      3      [36m0.9374[0m        [32m0.2607[0m       0.8130      0.8130        0.5870        0.0000  47.5414
      4      [36m0.9475[0m        [32m0.2302[0m       [35m0.8363[0m      [31m0.8363[0m        0.5419        0.0000  47.1292
      5      [36m0.9553[0m        [32m0.2026[0m       0.8184      0.8184        0.5932        0.0000  47.2553
      6      [36m0.9701[0m        [32m0.1553[0m       [35m0.8382[0m      [31m0.8382[0m        0.5589        0.0000  46.9713
      7      [36m0.9753[0m        [32m0.1363[0m       [35m0.8420[0m      [31m0.8420[0m        0.5600        0.0000  47.0633
      8      [36m0.9807[0m        [32m0.1232[0m       [35m0.8448[0m      [31m0.8448[0m        0.5575        0.0000  47.4757
      9      [36m0.9847[0m        [32m0.1141[0m       0.8398      0.8398        0.5832        0.0000  46.9603
     10      [36m0.9892[0m        [32m0.0996[0m       0.8405      0.8405        0.5902        0.0000  46.8676
     11      [36m0.9915[0m        [32m0.0931[0m       0.8427      0.8427        0.6036        0.0000  47.0540
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.8534722222222222
F1 Macro Score after query 10: 0.585158991486522
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9371[0m        [32m0.2679[0m       [35m0.8450[0m      [31m0.8450[0m        [94m0.4840[0m     +  0.0000  75.3446
      2      [36m0.9471[0m        [32m0.2244[0m       0.8368      0.8368        0.5165        0.0000  75.4057
      3      [36m0.9538[0m        [32m0.1986[0m       0.8420      0.8420        0.4947        0.0000  75.3218
      4      [36m0.9587[0m        [32m0.1697[0m       0.7549      0.7549        0.8009        0.0000  75.7679
      5      [36m0.9633[0m        [32m0.1521[0m       0.8306      0.8306        0.5720        0.0000  75.5914
      6      [36m0.9742[0m        [32m0.1185[0m       0.8344      0.8344        0.5703        0.0000  75.9006
      7      [36m0.9800[0m        [32m0.0985[0m       0.8392      0.8392        0.5611        0.0000  75.5296
      8      [36m0.9835[0m        [32m0.0868[0m       0.8368      0.8368        0.5807        0.0000  74.7802
      9      [36m0.9874[0m        [32m0.0776[0m       0.8323      0.8323        0.5954        0.0000  76.0782
     10      [36m0.9909[0m        [32m0.0695[0m       0.8340      0.8340        0.6056        0.0000  75.8366
     11      [36m0.9927[0m        [32m0.0602[0m       0.8356      0.8356        0.6130        0.0000  75.8268
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.8581597222222223
F1 Macro Score after query 11: 0.619444141424824
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9649[0m        [32m0.1631[0m       [35m0.7766[0m      [31m0.7766[0m        [94m0.6615[0m     +  0.0000  126.2672
      2      [36m0.9671[0m        [32m0.1400[0m       [35m0.8099[0m      [31m0.8099[0m        [94m0.5884[0m     +  0.0000  126.8597
      3      [36m0.9706[0m        [32m0.1208[0m       0.8016      0.8016        0.6547        0.0000  127.1896
      4      [36m0.9744[0m        [32m0.1041[0m       0.7953      0.7953        0.6558        0.0000  127.7906
      5      [36m0.9770[0m        [32m0.0921[0m       [35m0.8102[0m      [31m0.8102[0m        0.6515        0.0000  127.9081
      6      [36m0.9833[0m        [32m0.0694[0m       [35m0.8217[0m      [31m0.8217[0m        0.6322        0.0000  127.3256
      7      [36m0.9877[0m        [32m0.0575[0m       0.8210      0.8210        0.6783        0.0000  127.5166
      8      [36m0.9907[0m        [32m0.0488[0m       0.8174      0.8174        0.7233        0.0000  123.7006
      9      [36m0.9929[0m        [32m0.0422[0m       0.8134      0.8134        0.7478        0.0000  124.2981
     10      [36m0.9940[0m        [32m0.0358[0m       0.8203      0.8203        0.7287        0.0000  124.1385
     11      [36m0.9953[0m        [32m0.0319[0m       0.8170      0.8170        0.7562        0.0000  124.4765
     12      [36m0.9967[0m        [32m0.0293[0m       0.8160      0.8160        0.7632        0.0000  125.4842
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8414930555555555
F1 Macro Score after query 12: 0.5924690099893679
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9751[0m        [32m0.1055[0m       [35m0.8172[0m      [31m0.8172[0m        [94m0.5835[0m     +  0.0000  144.8641
      2      [36m0.9775[0m        [32m0.0896[0m       0.7714      0.7714        0.8275        0.0000  146.4164
      3      [36m0.9814[0m        [32m0.0769[0m       0.7738      0.7738        0.8598        0.0000  145.9723
      4      [36m0.9828[0m        [32m0.0695[0m       0.7825      0.7825        0.8559        0.0000  145.9819
      5      [36m0.9830[0m        [32m0.0626[0m       0.8090      0.8090        0.7213        0.0000  145.9878
      6      [36m0.9868[0m        [32m0.0490[0m       [35m0.8255[0m      [31m0.8255[0m        0.6658        0.0000  145.8948
      7      [36m0.9922[0m        [32m0.0372[0m       [35m0.8382[0m      [31m0.8382[0m        0.6593        0.0000  146.5881
      8      [36m0.9936[0m        [32m0.0314[0m       0.8302      0.8302        0.7418        0.0000  146.2298
      9      [36m0.9955[0m        [32m0.0271[0m       0.8253      0.8253        0.7683        0.0000  145.8684
     10      [36m0.9965[0m        [32m0.0230[0m       0.8273      0.8273        0.7786        0.0000  146.4165
     11      [36m0.9974[0m        [32m0.0198[0m       0.8280      0.8280        0.7973        0.0000  145.5608
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8668402777777777
F1 Macro Score after query 13: 0.6086975273337811
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoS/uncertainty_sampling_seed42\AL_uncertainty_sampling_results_for_multiclass_classification_s42.pickle
