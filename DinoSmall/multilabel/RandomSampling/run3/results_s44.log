Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)

Iteration 1: Using initial samples.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5460[0m        [32m0.7305[0m       [35m0.1863[0m      [31m0.4349[0m        [94m0.7025[0m     +  0.0000  12.5910
      2      [36m0.7190[0m        [32m0.6576[0m       [35m0.2182[0m      0.2878        [94m0.6934[0m     +  0.0000  10.9687
      3      0.6389        [32m0.6449[0m       [35m0.2687[0m      [31m0.4495[0m        [94m0.6918[0m     +  0.0000  10.9533
      4      0.5913        [32m0.6354[0m       [35m0.2983[0m      0.4066        [94m0.6754[0m     +  0.0000  10.7542
      5      [36m0.9048[0m        [32m0.5740[0m       0.2793      [31m0.4647[0m        0.6930        0.0000  10.7965
      6      [36m0.9259[0m        [32m0.5448[0m       0.2785      [31m0.4678[0m        0.6885        0.0000  10.8707
      7      0.8201        [32m0.5390[0m       0.2720      0.4648        0.6880        0.0000  10.7502
      8      0.8320        0.5509       0.2694      [31m0.4776[0m        0.6883        0.0000  10.8748
      9      0.8130        0.5648       0.2823      0.4742        0.6833        0.0000  11.2030
     10      [36m0.9630[0m        [32m0.5210[0m       0.2793      [31m0.4887[0m        0.6835        0.0000  10.9844
     11      0.8796        0.5431       0.2795      0.4866        0.6838        0.0000  11.0779
     12      0.8519        [32m0.5153[0m       0.2839      0.4838        0.6831        0.0000  10.9842
     13      0.9259        [32m0.4990[0m       0.2877      [31m0.4894[0m        0.6845        0.0000  11.1716
     14      0.9259        [32m0.4931[0m       0.2835      [31m0.4896[0m        0.6848        0.0000  11.0782
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 1: Test F1 Micro Score: 0.5245971162001696
Iteration 1: Test F1 Macro Score: 0.5114924216465385
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_0.pt

Iteration 2: Requesting 16 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5805[0m        [32m0.6542[0m       [35m0.1851[0m      [31m0.3709[0m        [94m0.6409[0m     +  0.0000  11.2182
      2      0.4841        [32m0.6158[0m       [35m0.2155[0m      0.3529        [94m0.6229[0m     +  0.0000  11.0000
      3      0.4862        [32m0.5770[0m       [35m0.2247[0m      [31m0.3743[0m        [94m0.6137[0m     +  0.0000  11.1407
      4      0.5477        [32m0.5506[0m       [35m0.2457[0m      [31m0.3746[0m        [94m0.6005[0m     +  0.0000  11.2032
      5      [36m0.7696[0m        [32m0.5248[0m       [35m0.2481[0m      [31m0.4155[0m        [94m0.5922[0m     +  0.0000  10.7600
      6      0.7344        [32m0.4976[0m       [35m0.2575[0m      [31m0.4188[0m        [94m0.5891[0m     +  0.0000  11.0779
      7      0.6862        0.5084       [35m0.2604[0m      [31m0.4360[0m        [94m0.5862[0m     +  0.0000  10.9998
      8      [36m0.7889[0m        [32m0.4669[0m       [35m0.2681[0m      [31m0.4446[0m        [94m0.5824[0m     +  0.0000  11.0000
      9      [36m0.8383[0m        0.4682       [35m0.2724[0m      0.4432        [94m0.5798[0m     +  0.0000  11.0281
     10      0.8333        0.4786       [35m0.2797[0m      0.4368        [94m0.5756[0m     +  0.0000  11.2145
     11      0.7630        [32m0.4351[0m       [35m0.2804[0m      0.4394        [94m0.5745[0m     +  0.0000  11.1718
     12      0.8116        0.4549       [35m0.2809[0m      [31m0.4515[0m        [94m0.5735[0m     +  0.0000  11.0470
     13      0.7889        0.4531       [35m0.2828[0m      [31m0.4518[0m        [94m0.5723[0m     +  0.0000  11.1406
     14      0.7745        0.4570       [35m0.2844[0m      [31m0.4592[0m        [94m0.5713[0m     +  0.0000  11.0228
     15      [36m0.8918[0m        0.4563       [35m0.2852[0m      [31m0.4638[0m        [94m0.5706[0m     +  0.0000  11.1565
     16      0.7981        0.4605       0.2852      [31m0.4661[0m        [94m0.5702[0m     +  0.0000  11.0111
     17      0.7294        0.4567       [35m0.2866[0m      [31m0.4682[0m        [94m0.5698[0m     +  0.0000  10.9685
     18      0.7992        0.4593       [35m0.2870[0m      [31m0.4699[0m        [94m0.5696[0m     +  0.0000  11.0314
     19      0.8063        0.4594       [35m0.2873[0m      0.4693        [94m0.5691[0m     +  0.0000  10.9347
     20      0.7286        0.4429       [35m0.2878[0m      [31m0.4710[0m        [94m0.5688[0m     +  0.0000  11.1561
     21      0.8524        0.4452       [35m0.2884[0m      [31m0.4718[0m        [94m0.5686[0m     +  0.0000  11.0309
     22      0.8190        0.4532       [35m0.2887[0m      [31m0.4733[0m        [94m0.5685[0m     +  0.0000  11.0310
     23      0.8360        0.4363       [35m0.2889[0m      0.4730        [94m0.5683[0m     +  0.0000  10.9842
     24      0.7487        0.4459       [35m0.2894[0m      [31m0.4739[0m        [94m0.5682[0m     +  0.0000  10.9802
     25      0.7877        [32m0.4333[0m       [35m0.2896[0m      [31m0.4750[0m        [94m0.5681[0m     +  0.0000  11.0592
     26      0.7938        0.4534       [35m0.2898[0m      [31m0.4753[0m        [94m0.5680[0m     +  0.0000  11.0940
     27      0.8217        0.4505       [35m0.2899[0m      [31m0.4754[0m        [94m0.5679[0m     +  0.0000  11.0150
     28      0.7918        [32m0.4278[0m       0.2898      [31m0.4764[0m        [94m0.5679[0m     +  0.0000  11.0782
     29      0.8294        0.4591       [35m0.2903[0m      [31m0.4769[0m        [94m0.5679[0m     +  0.0000  10.9544
     30      0.7788        0.4572       [35m0.2906[0m      [31m0.4771[0m        [94m0.5678[0m     +  0.0000  10.9456
     31      0.7593        0.4600       0.2906      [31m0.4772[0m        [94m0.5678[0m     +  0.0000  11.1714
     32      0.7992        0.4378       [35m0.2910[0m      [31m0.4779[0m        [94m0.5678[0m     +  0.0000  10.9999
     33      0.8524        0.4346       0.2910      0.4778        [94m0.5678[0m     +  0.0000  10.9688
     34      0.8106        0.4361       0.2910      0.4779        [94m0.5677[0m     +  0.0000  11.0156
     35      0.7981        0.4693       0.2910      [31m0.4782[0m        [94m0.5677[0m     +  0.0000  10.8904
     36      0.8043        [32m0.4277[0m       0.2910      0.4782        [94m0.5677[0m     +  0.0000  10.9688
     37      0.8018        0.4527       0.2910      0.4782        [94m0.5677[0m     +  0.0000  10.9529
     38      0.8185        0.4416       0.2910      0.4782        [94m0.5677[0m     +  0.0000  10.9687
     39      0.8437        0.4347       0.2910      0.4782        [94m0.5677[0m     +  0.0000  11.0158
     40      0.7841        0.4671       0.2910      0.4782        [94m0.5677[0m     +  0.0000  10.9479
     41      0.7696        0.4409       0.2910      0.4782        [94m0.5677[0m     +  0.0000  10.8995
     42      0.7938        0.4409       0.2910      [31m0.4783[0m        [94m0.5677[0m     +  0.0000  10.8933
     43      0.7841        0.4439       0.2910      0.4783        [94m0.5677[0m     +  0.0000  10.9904
     44      0.7190        0.4586       0.2910      0.4783        [94m0.5677[0m     +  0.0000  10.9218
     45      0.8557        0.4517       0.2910      0.4783        [94m0.5677[0m     +  0.0000  11.0158
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 2: Test F1 Micro Score: 0.5707700866248113
Iteration 2: Test F1 Macro Score: 0.48186311041788965
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_1.pt

Iteration 3: Requesting 32 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6233[0m        [32m0.5709[0m       [35m0.3995[0m      [31m0.6319[0m        [94m0.5253[0m     +  0.0000  11.1094
      2      [36m0.6777[0m        [32m0.5044[0m       [35m0.5238[0m      [31m0.6983[0m        [94m0.4779[0m     +  0.0000  11.1250
      3      [36m0.7822[0m        [32m0.4500[0m       [35m0.5859[0m      [31m0.7547[0m        [94m0.4499[0m     +  0.0000  11.1402
      4      [36m0.8321[0m        [32m0.4210[0m       [35m0.6238[0m      [31m0.7578[0m        [94m0.4305[0m     +  0.0000  11.2029
      5      [36m0.8514[0m        [32m0.4012[0m       [35m0.6295[0m      [31m0.7579[0m        [94m0.4188[0m     +  0.0000  11.1450
      6      [36m0.9003[0m        [32m0.3762[0m       0.6293      [31m0.7600[0m        [94m0.4141[0m     +  0.0000  11.0492
      7      0.8853        [32m0.3759[0m       [35m0.6299[0m      [31m0.7606[0m        [94m0.4116[0m     +  0.0000  11.1555
      8      [36m0.9265[0m        [32m0.3631[0m       [35m0.6321[0m      [31m0.7608[0m        [94m0.4082[0m     +  0.0000  11.0787
      9      0.8794        0.3725       [35m0.6370[0m      [31m0.7700[0m        [94m0.4040[0m     +  0.0000  11.2549
     10      0.9185        [32m0.3575[0m       [35m0.6443[0m      0.7669        [94m0.4019[0m     +  0.0000  11.2164
     11      [36m0.9297[0m        [32m0.3461[0m       0.6438      0.7698        [94m0.4001[0m     +  0.0000  11.2340
     12      0.9161        0.3566       0.6427      0.7698        [94m0.3991[0m     +  0.0000  11.1253
     13      0.9282        0.3547       0.6425      [31m0.7723[0m        [94m0.3980[0m     +  0.0000  11.1004
     14      0.9050        0.3515       [35m0.6450[0m      0.7709        [94m0.3976[0m     +  0.0000  11.2408
     15      0.9177        0.3560       [35m0.6460[0m      [31m0.7770[0m        [94m0.3965[0m     +  0.0000  11.1258
     16      0.9216        [32m0.3459[0m       0.6460      0.7763        [94m0.3961[0m     +  0.0000  10.9996
     17      0.9274        [32m0.3353[0m       [35m0.6470[0m      0.7752        [94m0.3959[0m     +  0.0000  11.1046
     18      0.9275        0.3437       [35m0.6477[0m      0.7751        [94m0.3955[0m     +  0.0000  11.1180
     19      [36m0.9331[0m        0.3375       0.6476      0.7754        [94m0.3953[0m     +  0.0000  11.0389
     20      0.9067        [32m0.3344[0m       [35m0.6490[0m      [31m0.7771[0m        [94m0.3950[0m     +  0.0000  11.1658
     21      0.9274        0.3444       [35m0.6498[0m      [31m0.7784[0m        [94m0.3948[0m     +  0.0000  11.0233
     22      0.9146        0.3498       0.6497      0.7781        [94m0.3947[0m     +  0.0000  11.0697
     23      0.9215        0.3498       [35m0.6505[0m      [31m0.7796[0m        [94m0.3945[0m     +  0.0000  11.0701
     24      [36m0.9388[0m        0.3441       [35m0.6509[0m      0.7794        [94m0.3945[0m     +  0.0000  11.0703
     25      0.9147        0.3432       0.6507      0.7792        [94m0.3944[0m     +  0.0000  11.2420
     26      0.9133        0.3495       0.6507      0.7792        [94m0.3943[0m     +  0.0000  11.0866
     27      [36m0.9486[0m        0.3444       0.6509      0.7794        [94m0.3943[0m     +  0.0000  11.2892
     28      0.9206        0.3434       [35m0.6510[0m      [31m0.7801[0m        [94m0.3942[0m     +  0.0000  11.0698
     29      0.9216        0.3373       [35m0.6516[0m      [31m0.7809[0m        [94m0.3942[0m     +  0.0000  11.1638
     30      0.9336        0.3417       0.6514      0.7805        [94m0.3941[0m     +  0.0000  11.0221
     31      0.9261        0.3389       0.6516      0.7807        [94m0.3941[0m     +  0.0000  11.5710
     32      0.9236        0.3459       0.6516      0.7807        [94m0.3941[0m     +  0.0000  11.0080
     33      0.9129        0.3543       0.6516      0.7807        [94m0.3941[0m     +  0.0000  11.0723
     34      0.9121        0.3452       0.6514      0.7806        [94m0.3940[0m     +  0.0000  11.1465
     35      0.9306        [32m0.3316[0m       [35m0.6517[0m      0.7808        [94m0.3940[0m     +  0.0000  11.0231
     36      0.9336        0.3374       0.6516      0.7806        [94m0.3940[0m     +  0.0000  11.1159
     37      0.9388        0.3461       0.6516      0.7806        [94m0.3940[0m     +  0.0000  11.0246
     38      0.9126        0.3387       0.6514      0.7803        [94m0.3940[0m     +  0.0000  11.1947
     39      0.9137        0.3378       0.6514      0.7803        [94m0.3940[0m     +  0.0000  11.0422
     40      0.9139        0.3515       0.6514      0.7803        [94m0.3940[0m     +  0.0000  11.1176
     41      0.9257        0.3424       0.6514      0.7805        [94m0.3940[0m     +  0.0000  11.0556
     42      [36m0.9495[0m        0.3431       0.6512      0.7803        [94m0.3940[0m     +  0.0000  11.0856
     43      0.9258        0.3405       0.6514      0.7805        [94m0.3940[0m     +  0.0000  10.9792
     44      0.9158        0.3355       0.6512      0.7803        [94m0.3940[0m     +  0.0000  11.0228
     45      0.9086        0.3503       0.6514      0.7805        [94m0.3940[0m     +  0.0000  11.0384
     46      0.8692        0.3640       0.6514      0.7805        [94m0.3940[0m     +  0.0000  11.0088
     47      0.9061        0.3456       0.6514      0.7805        [94m0.3940[0m     +  0.0000  11.3843
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 3: Test F1 Micro Score: 0.8221924078604689
Iteration 3: Test F1 Macro Score: 0.7830148257825172
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_2.pt

Iteration 4: Requesting 56 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8510[0m        [32m0.3871[0m       [35m0.7099[0m      [31m0.8323[0m        [94m0.3764[0m     +  0.0000  11.3346
      2      [36m0.9162[0m        [32m0.3364[0m       [35m0.7132[0m      [31m0.8326[0m        [94m0.3678[0m     +  0.0000  11.2128
      3      0.9068        [32m0.3158[0m       [35m0.7141[0m      [31m0.8356[0m        [94m0.3560[0m     +  0.0000  11.3054
      4      [36m0.9252[0m        [32m0.3013[0m       [35m0.7156[0m      [31m0.8373[0m        [94m0.3499[0m     +  0.0000  11.2894
      5      0.9214        [32m0.2891[0m       [35m0.7184[0m      [31m0.8385[0m        [94m0.3450[0m     +  0.0000  11.4005
      6      [36m0.9260[0m        [32m0.2780[0m       0.7155      0.8375        [94m0.3385[0m     +  0.0000  11.2897
      7      0.9208        0.2835       0.7177      [31m0.8387[0m        [94m0.3381[0m     +  0.0000  11.2584
      8      [36m0.9445[0m        0.2788       0.7132      0.8364        [94m0.3363[0m     +  0.0000  11.3209
      9      0.9348        [32m0.2708[0m       0.7122      0.8357        [94m0.3345[0m     +  0.0000  11.2907
     10      0.9436        [32m0.2707[0m       [35m0.7200[0m      [31m0.8395[0m        [94m0.3337[0m     +  0.0000  11.2417
     11      0.9388        [32m0.2616[0m       0.7158      0.8373        [94m0.3321[0m     +  0.0000  11.3351
     12      0.9408        [32m0.2564[0m       0.7177      0.8382        [94m0.3312[0m     +  0.0000  11.4304
     13      0.9101        0.2702       [35m0.7201[0m      0.8393        [94m0.3307[0m     +  0.0000  11.2896
     14      0.9428        0.2570       0.7172      0.8374        [94m0.3298[0m     +  0.0000  11.6044
     15      0.9327        0.2635       0.7168      0.8370        [94m0.3294[0m     +  0.0000  11.1967
     16      [36m0.9529[0m        [32m0.2533[0m       0.7168      0.8367        [94m0.3289[0m     +  0.0000  11.2419
     17      [36m0.9538[0m        0.2536       0.7168      0.8371        [94m0.3284[0m     +  0.0000  11.2724
     18      0.9499        [32m0.2488[0m       0.7168      0.8369        [94m0.3283[0m     +  0.0000  11.2409
     19      0.9424        0.2569       0.7188      0.8379        0.3285        0.0000  11.2280
     20      [36m0.9589[0m        0.2547       0.7170      0.8373        [94m0.3282[0m     +  0.0000  11.2254
     21      0.9404        0.2535       0.7165      0.8369        [94m0.3280[0m     +  0.0000  11.3830
     22      0.9420        0.2581       0.7175      0.8374        [94m0.3279[0m     +  0.0000  11.2598
     23      0.9420        0.2499       0.7167      0.8369        [94m0.3278[0m     +  0.0000  11.1485
     24      0.9523        0.2583       0.7163      0.8368        [94m0.3277[0m     +  0.0000  11.2602
     25      0.9490        0.2505       0.7167      0.8369        [94m0.3275[0m     +  0.0000  11.2595
     26      0.9486        0.2583       0.7167      0.8369        [94m0.3275[0m     +  0.0000  11.2426
     27      0.9456        0.2550       0.7167      0.8371        [94m0.3275[0m     +  0.0000  11.2732
     28      [36m0.9596[0m        [32m0.2461[0m       0.7167      0.8371        [94m0.3274[0m     +  0.0000  11.2419
     29      0.9450        0.2502       0.7168      0.8371        [94m0.3274[0m     +  0.0000  11.3203
     30      0.9589        0.2539       0.7168      0.8371        [94m0.3273[0m     +  0.0000  11.1961
     31      0.9515        0.2511       0.7167      0.8369        0.3273        0.0000  11.3828
     32      0.9420        0.2477       0.7167      0.8369        [94m0.3273[0m     +  0.0000  11.2121
     33      [36m0.9640[0m        0.2544       0.7168      0.8371        [94m0.3272[0m     +  0.0000  11.1492
     34      0.9296        0.2561       0.7168      0.8371        [94m0.3272[0m     +  0.0000  11.3201
     35      0.9560        0.2490       0.7168      0.8370        [94m0.3272[0m     +  0.0000  11.2425
     36      0.9467        0.2499       0.7168      0.8370        [94m0.3272[0m     +  0.0000  11.2097
     37      0.9454        0.2512       0.7168      0.8370        [94m0.3272[0m     +  0.0000  11.3354
     38      0.9408        0.2507       0.7168      0.8370        [94m0.3272[0m     +  0.0000  11.2898
     39      0.9448        0.2488       0.7170      0.8371        0.3272        0.0000  11.3970
     40      0.9472        0.2611       0.7170      0.8371        [94m0.3272[0m     +  0.0000  11.2719
     41      0.9500        0.2546       0.7170      0.8371        [94m0.3272[0m     +  0.0000  11.2753
     42      0.9414        0.2594       0.7170      0.8371        [94m0.3272[0m     +  0.0000  11.2116
     43      0.9577        0.2525       0.7170      0.8371        [94m0.3272[0m     +  0.0000  11.2106
     44      0.9499        0.2548       0.7170      0.8372        [94m0.3272[0m     +  0.0000  11.2256
     45      0.9445        0.2580       0.7170      0.8372        [94m0.3272[0m     +  0.0000  11.2436
     46      0.9424        0.2618       0.7170      0.8372        [94m0.3272[0m     +  0.0000  11.2727
     47      0.9467        0.2541       0.7170      0.8372        0.3272        0.0000  11.2285
     48      0.9476        0.2475       0.7170      0.8371        0.3272        0.0000  11.4125
     49      0.9610        0.2523       0.7170      0.8372        [94m0.3272[0m     +  0.0000  11.2392
     50      0.9446        0.2496       0.7170      0.8372        [94m0.3272[0m     +  0.0000  11.1964
     51      0.9487        0.2526       0.7170      0.8371        [94m0.3272[0m     +  0.0000  11.2887
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 4: Test F1 Micro Score: 0.8664222105814562
Iteration 4: Test F1 Macro Score: 0.8498486764886448
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_3.pt

Iteration 5: Requesting 96 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8976[0m        [32m0.2924[0m       [35m0.7144[0m      [31m0.8375[0m        [94m0.3185[0m     +  0.0000  11.6625
      2      [36m0.9205[0m        [32m0.2590[0m       [35m0.7217[0m      [31m0.8407[0m        [94m0.3099[0m     +  0.0000  11.8520
      3      0.9133        [32m0.2510[0m       0.7193      0.8372        [94m0.3065[0m     +  0.0000  11.8209
      4      [36m0.9320[0m        [32m0.2390[0m       0.7149      0.8344        [94m0.3039[0m     +  0.0000  11.4954
      5      [36m0.9331[0m        [32m0.2221[0m       0.7069      0.8302        0.3074        0.0000  11.7117
      6      [36m0.9398[0m        0.2230       0.7198      0.8348        [94m0.2959[0m     +  0.0000  11.6154
      7      [36m0.9483[0m        [32m0.2186[0m       [35m0.7243[0m      0.8381        0.2967        0.0000  11.6657
      8      0.9405        0.2203       0.7222      0.8371        0.2984        0.0000  11.5703
      9      0.9460        [32m0.2129[0m       [35m0.7262[0m      0.8394        0.2962        0.0000  11.7110
     10      0.9421        0.2147       [35m0.7288[0m      [31m0.8412[0m        [94m0.2957[0m     +  0.0000  11.7886
     11      [36m0.9514[0m        [32m0.2126[0m       [35m0.7370[0m      [31m0.8453[0m        [94m0.2944[0m     +  0.0000  11.7575
     12      0.9504        [32m0.2121[0m       0.7335      0.8437        [94m0.2935[0m     +  0.0000  11.6179
     13      0.9498        [32m0.2104[0m       [35m0.7377[0m      [31m0.8454[0m        [94m0.2934[0m     +  0.0000  11.6333
     14      [36m0.9581[0m        [32m0.2011[0m       0.7366      0.8448        0.2943        0.0000  11.6012
     15      0.9498        0.2028       0.7368      0.8453        0.2950        0.0000  11.6166
     16      [36m0.9595[0m        0.2079       [35m0.7391[0m      [31m0.8466[0m        0.2946        0.0000  11.6779
     17      [36m0.9599[0m        0.2015       0.7382      0.8455        0.2935        0.0000  11.6335
     18      0.9533        0.2057       0.7384      0.8458        0.2935        0.0000  11.6180
     19      0.9504        0.2033       0.7377      0.8454        [94m0.2934[0m     +  0.0000  11.6958
     20      [36m0.9667[0m        0.2024       0.7378      0.8456        0.2936        0.0000  11.6336
     21      0.9588        [32m0.1990[0m       0.7373      0.8454        0.2935        0.0000  11.7272
     22      0.9565        0.2004       [35m0.7394[0m      [31m0.8466[0m        0.2938        0.0000  11.6662
     23      0.9667        0.2032       [35m0.7398[0m      [31m0.8470[0m        0.2937        0.0000  11.7432
     24      0.9616        0.2026       0.7384      0.8458        [94m0.2933[0m     +  0.0000  11.5876
     25      0.9627        [32m0.1970[0m       0.7394      0.8463        [94m0.2933[0m     +  0.0000  11.6025
     26      0.9578        [32m0.1963[0m       0.7392      0.8461        0.2933        0.0000  11.6341
     27      0.9644        [32m0.1954[0m       0.7392      0.8462        [94m0.2933[0m     +  0.0000  11.8840
     28      0.9621        0.2075       0.7392      0.8462        0.2933        0.0000  11.8224
     29      0.9545        0.2012       0.7391      0.8461        0.2934        0.0000  11.8501
     30      0.9615        0.2002       0.7391      0.8461        0.2933        0.0000  11.5703
     31      0.9499        0.2015       0.7389      0.8460        [94m0.2933[0m     +  0.0000  11.6173
     32      0.9573        0.1990       0.7389      0.8460        [94m0.2933[0m     +  0.0000  11.6336
     33      0.9610        0.2046       0.7394      0.8463        [94m0.2933[0m     +  0.0000  11.5563
     34      [36m0.9699[0m        0.1986       0.7392      0.8462        0.2933        0.0000  11.5542
     35      0.9642        0.1985       0.7394      0.8463        [94m0.2932[0m     +  0.0000  11.6967
     36      0.9536        0.1965       0.7394      0.8463        [94m0.2932[0m     +  0.0000  11.5858
     37      0.9611        0.1970       0.7392      0.8462        0.2932        0.0000  11.7119
     38      0.9600        0.2012       0.7392      0.8463        [94m0.2932[0m     +  0.0000  11.6477
     39      0.9644        [32m0.1947[0m       0.7392      0.8463        0.2932        0.0000  11.8066
     40      0.9599        0.2005       0.7394      0.8463        [94m0.2932[0m     +  0.0000  11.4618
     41      0.9632        0.2022       0.7394      0.8463        [94m0.2932[0m     +  0.0000  11.6176
     42      0.9555        0.2004       0.7394      0.8463        [94m0.2932[0m     +  0.0000  11.6661
     43      0.9582        0.2030       0.7394      0.8463        [94m0.2932[0m     +  0.0000  11.8067
     44      0.9636        0.1957       0.7394      0.8463        0.2932        0.0000  11.6334
     45      0.9670        0.1968       0.7394      0.8463        0.2932        0.0000  11.6799
     46      0.9609        0.2015       0.7394      0.8463        0.2932        0.0000  11.6501
     47      0.9682        0.2012       0.7394      0.8463        [94m0.2932[0m     +  0.0000  11.6785
     48      0.9650        0.2029       0.7394      0.8463        [94m0.2932[0m     +  0.0000  11.6663
     49      0.9611        0.1956       0.7394      0.8463        [94m0.2932[0m     +  0.0000  11.7281
     50      0.9643        0.1952       0.7394      0.8463        0.2932        0.0000  11.6801
     51      0.9665        0.1968       0.7394      0.8463        0.2932        0.0000  11.6188
     52      0.9577        0.2041       0.7394      0.8463        [94m0.2932[0m     +  0.0000  11.7103
     53      [36m0.9716[0m        0.1961       0.7394      0.8463        0.2932        0.0000  11.6651
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 5: Test F1 Micro Score: 0.8689613526570048
Iteration 5: Test F1 Macro Score: 0.8479350935279436
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_4.pt

Iteration 6: Requesting 176 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9104[0m        [32m0.2484[0m       [35m0.7339[0m      [31m0.8520[0m        [94m0.2778[0m     +  0.0000  12.2881
      2      [36m0.9329[0m        [32m0.2176[0m       0.7290      0.8498        [94m0.2741[0m     +  0.0000  12.5718
      3      [36m0.9453[0m        [32m0.2045[0m       [35m0.7434[0m      [31m0.8600[0m        [94m0.2710[0m     +  0.0000  12.3280
      4      [36m0.9489[0m        [32m0.2002[0m       [35m0.7495[0m      [31m0.8644[0m        [94m0.2695[0m     +  0.0000  12.3529
      5      [36m0.9587[0m        [32m0.1930[0m       0.7323      0.8537        [94m0.2693[0m     +  0.0000  12.2908
      6      [36m0.9622[0m        [32m0.1816[0m       0.7361      0.8516        [94m0.2654[0m     +  0.0000  12.2590
      7      0.9599        0.1820       0.7278      0.8484        0.2674        0.0000  12.3692
      8      0.9609        0.1842       0.7394      0.8560        [94m0.2634[0m     +  0.0000  12.3531
      9      [36m0.9626[0m        [32m0.1779[0m       0.7396      0.8530        [94m0.2628[0m     +  0.0000  12.3679
     10      [36m0.9693[0m        [32m0.1730[0m       0.7403      0.8534        [94m0.2620[0m     +  0.0000  12.6030
     11      [36m0.9775[0m        [32m0.1683[0m       0.7424      0.8568        [94m0.2615[0m     +  0.0000  12.3837
     12      0.9767        [32m0.1665[0m       0.7476      0.8598        [94m0.2597[0m     +  0.0000  12.3212
     13      0.9739        0.1700       [35m0.7512[0m      0.8629        [94m0.2591[0m     +  0.0000  12.4473
     14      0.9731        0.1711       0.7484      0.8618        0.2600        0.0000  12.3526
     15      [36m0.9797[0m        [32m0.1640[0m       0.7476      0.8622        0.2604        0.0000  12.4103
     16      0.9792        0.1646       [35m0.7531[0m      [31m0.8654[0m        0.2606        0.0000  12.3831
     17      [36m0.9819[0m        0.1655       [35m0.7564[0m      [31m0.8667[0m        0.2599        0.0000  12.3985
     18      0.9787        [32m0.1633[0m       0.7547      0.8659        0.2597        0.0000  12.3674
     19      [36m0.9824[0m        [32m0.1623[0m       0.7559      0.8667        0.2604        0.0000  12.4299
     20      0.9790        0.1642       0.7517      0.8646        0.2604        0.0000  12.3038
     21      0.9784        [32m0.1607[0m       0.7543      0.8666        0.2606        0.0000  12.5074
     22      0.9764        0.1656       0.7559      [31m0.8673[0m        0.2607        0.0000  12.4134
     23      [36m0.9861[0m        0.1643       0.7554      0.8671        0.2612        0.0000  12.3994
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 6: Test F1 Micro Score: 0.8899833308076981
Iteration 6: Test F1 Macro Score: 0.8732318791505982
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_5.pt

Iteration 7: Requesting 320 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9347[0m        [32m0.2059[0m       [35m0.7842[0m      [31m0.8754[0m        [94m0.2643[0m     +  0.0000  13.6955
      2      [36m0.9516[0m        [32m0.1819[0m       [35m0.7948[0m      [31m0.8822[0m        [94m0.2501[0m     +  0.0000  13.7588
      3      [36m0.9651[0m        [32m0.1702[0m       [35m0.7974[0m      [31m0.8833[0m        [94m0.2402[0m     +  0.0000  13.5881
      4      [36m0.9698[0m        [32m0.1628[0m       [35m0.8003[0m      [31m0.8842[0m        [94m0.2346[0m     +  0.0000  13.6517
      5      [36m0.9726[0m        [32m0.1577[0m       [35m0.8059[0m      [31m0.8866[0m        [94m0.2288[0m     +  0.0000  13.7434
      6      [36m0.9793[0m        [32m0.1490[0m       0.8024      [31m0.8869[0m        0.2292        0.0000  13.6039
      7      [36m0.9831[0m        [32m0.1424[0m       0.8052      [31m0.8879[0m        [94m0.2265[0m     +  0.0000  13.6209
      8      [36m0.9840[0m        [32m0.1416[0m       0.8023      0.8871        0.2282        0.0000  13.6517
      9      [36m0.9848[0m        [32m0.1387[0m       [35m0.8078[0m      [31m0.8892[0m        [94m0.2236[0m     +  0.0000  13.6959
     10      [36m0.9883[0m        [32m0.1355[0m       0.8068      0.8885        [94m0.2226[0m     +  0.0000  13.6348
     11      0.9873        [32m0.1315[0m       0.8047      0.8876        0.2228        0.0000  13.7297
     12      [36m0.9894[0m        [32m0.1294[0m       0.8075      0.8892        [94m0.2218[0m     +  0.0000  13.7925
     13      [36m0.9905[0m        [32m0.1288[0m       [35m0.8095[0m      [31m0.8898[0m        [94m0.2203[0m     +  0.0000  13.7628
     14      0.9887        [32m0.1267[0m       0.8085      0.8897        0.2211        0.0000  13.5882
     15      0.9894        0.1289       0.8076      0.8893        [94m0.2203[0m     +  0.0000  13.5864
     16      [36m0.9913[0m        [32m0.1256[0m       [35m0.8099[0m      [31m0.8903[0m        [94m0.2189[0m     +  0.0000  13.5871
     17      0.9907        [32m0.1234[0m       0.8090      0.8898        0.2193        0.0000  13.5101
     18      0.9908        0.1263       0.8087      0.8895        0.2192        0.0000  13.6033
     19      [36m0.9924[0m        0.1247       0.8080      0.8892        0.2194        0.0000  13.7280
     20      0.9921        0.1238       0.8073      0.8890        0.2196        0.0000  13.8069
     21      0.9916        0.1256       0.8076      0.8892        0.2194        0.0000  13.4790
     22      0.9910        [32m0.1233[0m       0.8073      0.8890        0.2195        0.0000  13.6495
     23      0.9919        [32m0.1201[0m       0.8071      0.8889        0.2194        0.0000  13.6176
     24      [36m0.9939[0m        0.1220       0.8090      0.8899        [94m0.2184[0m     +  0.0000  13.6030
     25      0.9926        0.1254       0.8069      0.8888        0.2197        0.0000  13.6296
     26      0.9930        0.1248       0.8069      0.8887        0.2193        0.0000  13.6053
     27      0.9922        0.1231       0.8063      0.8885        0.2195        0.0000  13.6644
     28      0.9910        0.1250       0.8071      0.8889        0.2193        0.0000  13.7749
     29      0.9938        0.1231       0.8071      0.8888        0.2195        0.0000  13.6022
     30      0.9927        0.1233       0.8069      0.8889        0.2193        0.0000  13.7123
     31      0.9931        0.1223       0.8063      0.8886        0.2194        0.0000  13.6486
     32      0.9930        0.1207       0.8061      0.8884        0.2196        0.0000  13.6519
     33      [36m0.9946[0m        0.1214       0.8061      0.8884        0.2196        0.0000  13.6792
     34      0.9922        0.1237       0.8063      0.8885        0.2196        0.0000  13.6653
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 7: Test F1 Micro Score: 0.9120728929384965
Iteration 7: Test F1 Macro Score: 0.8971862067153601
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_6.pt

Iteration 8: Requesting 560 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9541[0m        [32m0.1617[0m       [35m0.8010[0m      [31m0.8888[0m        [94m0.2079[0m     +  0.0000  15.7288
      2      [36m0.9652[0m        [32m0.1437[0m       [35m0.8248[0m      [31m0.8989[0m        [94m0.1973[0m     +  0.0000  15.9175
      3      [36m0.9758[0m        [32m0.1326[0m       [35m0.8278[0m      [31m0.9037[0m        [94m0.1954[0m     +  0.0000  15.8089
      4      [36m0.9798[0m        [32m0.1257[0m       [35m0.8339[0m      0.9019        [94m0.1931[0m     +  0.0000  15.8233
      5      [36m0.9841[0m        [32m0.1166[0m       0.8238      0.9010        0.1946        0.0000  15.8696
      6      [36m0.9876[0m        [32m0.1092[0m       [35m0.8373[0m      [31m0.9046[0m        [94m0.1870[0m     +  0.0000  15.8952
      7      [36m0.9908[0m        [32m0.1060[0m       0.8358      [31m0.9054[0m        [94m0.1867[0m     +  0.0000  15.7921
      8      [36m0.9914[0m        [32m0.1017[0m       0.8276      0.9011        0.1912        0.0000  15.8072
      9      0.9913        0.1023       0.8319      0.9041        0.1908        0.0000  15.8392
     10      [36m0.9939[0m        [32m0.0969[0m       0.8297      0.9029        0.1882        0.0000  15.8374
     11      0.9935        [32m0.0951[0m       0.8326      0.9048        0.1880        0.0000  15.8368
     12      [36m0.9951[0m        [32m0.0941[0m       0.8340      0.9051        0.1874        0.0000  15.7465
     13      [36m0.9952[0m        [32m0.0923[0m       0.8311      0.9036        0.1875        0.0000  15.7765
     14      0.9946        [32m0.0913[0m       0.8292      0.9031        0.1881        0.0000  15.7126
     15      [36m0.9960[0m        [32m0.0899[0m       0.8309      0.9036        0.1869        0.0000  16.0725
     16      0.9959        0.0910       0.8347      0.9043        [94m0.1836[0m     +  0.0000  15.8857
     17      [36m0.9965[0m        [32m0.0877[0m       0.8330      0.9040        0.1852        0.0000  15.2631
     18      0.9964        [32m0.0872[0m       0.8339      0.9049        0.1852        0.0000  15.2149
     19      [36m0.9968[0m        0.0904       0.8354      0.9047        0.1839        0.0000  15.2147
     20      0.9962        0.0879       0.8340      0.9038        0.1838        0.0000  15.1977
     21      0.9964        0.0886       0.8340      0.9041        0.1838        0.0000  15.0587
     22      0.9968        0.0885       0.8349      0.9043        [94m0.1834[0m     +  0.0000  15.1207
     23      0.9947        0.0887       0.8342      0.9039        0.1836        0.0000  15.1821
     24      0.9962        0.0880       0.8351      0.9044        0.1839        0.0000  15.0562
     25      0.9964        0.0883       0.8356      0.9041        [94m0.1831[0m     +  0.0000  15.0739
     26      [36m0.9969[0m        [32m0.0864[0m       0.8344      0.9039        0.1839        0.0000  15.1511
     27      0.9965        0.0882       0.8340      0.9039        0.1839        0.0000  14.9160
     28      0.9960        0.0865       0.8335      0.9038        0.1838        0.0000  15.0702
     29      [36m0.9975[0m        0.0873       0.8347      0.9043        0.1837        0.0000  14.9777
     30      0.9961        0.0865       0.8328      0.9036        0.1840        0.0000  15.0703
     31      0.9969        0.0878       0.8330      0.9036        0.1841        0.0000  15.1353
     32      0.9971        [32m0.0856[0m       0.8330      0.9034        0.1842        0.0000  14.9941
     33      0.9974        0.0864       0.8328      0.9035        0.1844        0.0000  15.0582
     34      0.9963        0.0874       0.8335      0.9037        0.1841        0.0000  15.1046
     35      0.9973        0.0857       0.8335      0.9037        0.1838        0.0000  15.0572
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 8: Test F1 Micro Score: 0.9189767086674302
Iteration 8: Test F1 Macro Score: 0.9051224672355621
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_7.pt

Iteration 9: Requesting 1000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9729[0m        [32m0.1126[0m       [35m0.8286[0m      [31m0.8934[0m        [94m0.1836[0m     +  0.0000  19.0276
      2      [36m0.9823[0m        [32m0.0975[0m       0.8200      0.8833        0.1895        0.0000  18.8876
      3      [36m0.9846[0m        [32m0.0906[0m       0.8102      0.8663        0.2046        0.0000  18.9481
      4      [36m0.9890[0m        [32m0.0845[0m       [35m0.8290[0m      0.8923        [94m0.1808[0m     +  0.0000  18.7121
      5      0.9879        [32m0.0789[0m       0.8215      0.8840        0.1848        0.0000  18.8915
      6      [36m0.9923[0m        [32m0.0721[0m       [35m0.8316[0m      [31m0.9001[0m        [94m0.1715[0m     +  0.0000  18.6646
      7      [36m0.9938[0m        [32m0.0692[0m       [35m0.8406[0m      [31m0.9043[0m        [94m0.1648[0m     +  0.0000  18.8097
      8      0.9930        [32m0.0671[0m       0.8330      0.9011        0.1693        0.0000  18.8110
      9      [36m0.9962[0m        [32m0.0646[0m       0.8321      0.9020        0.1708        0.0000  18.8896
     10      0.9956        [32m0.0624[0m       0.8344      0.9018        0.1704        0.0000  18.6513
     11      [36m0.9970[0m        [32m0.0601[0m       0.8354      0.9037        0.1674        0.0000  18.8565
     12      0.9967        [32m0.0593[0m       0.8332      0.9031        0.1707        0.0000  18.9034
     13      [36m0.9971[0m        [32m0.0589[0m       0.8340      0.9032        0.1695        0.0000  18.6838
     14      0.9967        [32m0.0573[0m       0.8359      [31m0.9044[0m        0.1676        0.0000  18.8869
     15      0.9970        [32m0.0563[0m       0.8337      0.9036        0.1703        0.0000  18.7302
     16      [36m0.9973[0m        [32m0.0563[0m       0.8359      0.9042        0.1686        0.0000  18.8707
     17      0.9971        [32m0.0559[0m       0.8340      0.9040        0.1713        0.0000  18.7451
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 9: Test F1 Micro Score: 0.925359437136739
Iteration 9: Test F1 Macro Score: 0.9149038706012407
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_8.pt

Iteration 10: Requesting 1776 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9782[0m        [32m0.0861[0m       [35m0.8582[0m      [31m0.9104[0m        [94m0.1596[0m     +  0.0000  25.4698
      2      [36m0.9811[0m        [32m0.0771[0m       [35m0.8587[0m      [31m0.9117[0m        [94m0.1555[0m     +  0.0000  25.2707
      3      [36m0.9860[0m        [32m0.0693[0m       0.8484      0.9075        0.1595        0.0000  25.5515
      4      [36m0.9872[0m        [32m0.0634[0m       0.8568      0.9103        [94m0.1547[0m     +  0.0000  25.4145
      5      [36m0.9880[0m        [32m0.0583[0m       [35m0.8606[0m      0.9114        [94m0.1506[0m     +  0.0000  25.5658
      6      [36m0.9907[0m        [32m0.0514[0m       0.8557      0.9112        [94m0.1502[0m     +  0.0000  25.7035
      7      [36m0.9917[0m        [32m0.0484[0m       0.8491      0.9087        0.1533        0.0000  25.5343
      8      [36m0.9936[0m        [32m0.0460[0m       0.8505      0.9107        0.1544        0.0000  25.5819
      9      [36m0.9948[0m        [32m0.0434[0m       0.8460      0.9098        0.1590        0.0000  25.5048
     10      0.9945        [32m0.0418[0m       0.8436      0.9075        0.1612        0.0000  25.6273
     11      [36m0.9957[0m        [32m0.0402[0m       0.8491      0.9103        0.1565        0.0000  25.4709
     12      [36m0.9965[0m        [32m0.0381[0m       0.8474      0.9091        0.1572        0.0000  25.6279
     13      [36m0.9972[0m        [32m0.0371[0m       0.8474      0.9100        0.1574        0.0000  25.4893
     14      [36m0.9973[0m        [32m0.0363[0m       0.8474      0.9117        0.1577        0.0000  25.7060
     15      0.9969        [32m0.0356[0m       0.8481      0.9099        0.1565        0.0000  25.5175
     16      0.9970        [32m0.0352[0m       0.8462      0.9099        0.1591        0.0000  25.5503
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 10: Test F1 Micro Score: 0.9357219744733201
Iteration 10: Test F1 Macro Score: 0.9248425643549334
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_9.pt

Iteration 11: Requesting 3160 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9753[0m        [32m0.0688[0m       [35m0.8712[0m      [31m0.9182[0m        [94m0.1396[0m     +  0.0000  37.3712
      2      [36m0.9808[0m        [32m0.0590[0m       0.8651      0.9085        0.1441        0.0000  37.5895
      3      [36m0.9832[0m        [32m0.0531[0m       0.8665      0.9138        0.1406        0.0000  37.6062
      4      [36m0.9855[0m        [32m0.0483[0m       0.8708      0.9088        0.1420        0.0000  37.3722
      5      [36m0.9862[0m        [32m0.0438[0m       0.8616      0.9080        0.1511        0.0000  37.5606
      6      [36m0.9885[0m        [32m0.0389[0m       0.8649      0.9033        0.1575        0.0000  37.5250
      7      [36m0.9913[0m        [32m0.0350[0m       0.8630      0.8989        0.1587        0.0000  37.4660
      8      [36m0.9937[0m        [32m0.0325[0m       0.8601      0.8963        0.1568        0.0000  37.6515
      9      [36m0.9945[0m        [32m0.0300[0m       0.8556      0.8910        0.1606        0.0000  37.2953
     10      0.9940        [32m0.0289[0m       0.8509      0.8882        0.1691        0.0000  37.4015
     11      [36m0.9953[0m        [32m0.0266[0m       0.8562      0.9043        0.1620        0.0000  37.7451
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 11: Test F1 Micro Score: 0.9367748046412503
Iteration 11: Test F1 Macro Score: 0.9196617289940842
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_10.pt

Iteration 12: Requesting 5624 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9727[0m        [32m0.0685[0m       [35m0.7714[0m      [31m0.8867[0m        [94m0.2128[0m     +  0.0000  58.4500
      2      [36m0.9770[0m        [32m0.0598[0m       [35m0.7880[0m      [31m0.8895[0m        0.2155        0.0000  58.6702
      3      [36m0.9793[0m        [32m0.0529[0m       [35m0.7964[0m      [31m0.8945[0m        [94m0.2060[0m     +  0.0000  58.5115
      4      [36m0.9822[0m        [32m0.0474[0m       0.7964      0.8921        0.2179        0.0000  58.9792
      5      [36m0.9843[0m        [32m0.0426[0m       [35m0.8038[0m      [31m0.8969[0m        [94m0.2060[0m     +  0.0000  58.5561
      6      [36m0.9878[0m        [32m0.0355[0m       [35m0.8410[0m      [31m0.9107[0m        [94m0.1743[0m     +  0.0000  59.0093
      7      [36m0.9906[0m        [32m0.0315[0m       0.8234      0.9007        0.1931        0.0000  58.5005
      8      [36m0.9920[0m        [32m0.0291[0m       [35m0.8418[0m      0.9094        0.1834        0.0000  58.6502
      9      [36m0.9929[0m        [32m0.0270[0m       0.8300      0.9031        0.1987        0.0000  59.0114
     10      [36m0.9947[0m        [32m0.0246[0m       0.8290      0.9052        0.2007        0.0000  58.6841
     11      [36m0.9952[0m        [32m0.0225[0m       [35m0.8505[0m      [31m0.9112[0m        0.1767        0.0000  58.5767
     12      [36m0.9961[0m        [32m0.0212[0m       [35m0.8510[0m      [31m0.9131[0m        0.1793        0.0000  58.5398
     13      [36m0.9965[0m        [32m0.0202[0m       [35m0.8533[0m      0.9125        0.1757        0.0000  58.7428
     14      [36m0.9968[0m        [32m0.0194[0m       0.8516      0.9128        0.1831        0.0000  58.8672
     15      [36m0.9973[0m        [32m0.0183[0m       0.8507      0.9123        0.1848        0.0000  58.7918
     16      [36m0.9974[0m        [32m0.0176[0m       0.8517      0.9122        0.1831        0.0000  58.5597
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 12: Test F1 Micro Score: 0.9358206663595886
Iteration 12: Test F1 Macro Score: 0.9251247794158597
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_11.pt

Iteration 13: Requesting 10000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9796[0m        [32m0.0460[0m       [35m0.8406[0m      [31m0.9057[0m        [94m0.1674[0m     +  0.0000  96.1851
      2      [36m0.9822[0m        [32m0.0407[0m       [35m0.8639[0m      [31m0.9126[0m        [94m0.1485[0m     +  0.0000  96.4597
      3      [36m0.9840[0m        [32m0.0369[0m       0.8326      0.9023        0.1788        0.0000  96.2489
      4      [36m0.9865[0m        [32m0.0328[0m       0.8524      0.9097        0.1622        0.0000  96.6414
      5      [36m0.9876[0m        [32m0.0294[0m       0.8372      0.9021        0.1784        0.0000  96.1027
      6      [36m0.9901[0m        [32m0.0244[0m       0.8479      0.9062        0.1785        0.0000  96.5840
      7      [36m0.9924[0m        [32m0.0213[0m       0.8431      0.9042        0.1918        0.0000  95.9560
      8      [36m0.9936[0m        [32m0.0188[0m       0.8458      0.9060        0.1907        0.0000  96.2648
      9      [36m0.9946[0m        [32m0.0173[0m       0.8467      0.9049        0.1996        0.0000  96.5724
     10      [36m0.9951[0m        [32m0.0160[0m       0.8333      0.8950        0.2193        0.0000  96.4575
     11      [36m0.9962[0m        [32m0.0139[0m       0.8450      0.9068        0.2104        0.0000  96.4744
     12      [36m0.9970[0m        [32m0.0127[0m       0.8401      0.9034        0.2162        0.0000  96.4475
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 13: Test F1 Micro Score: 0.9297809538604941
Iteration 13: Test F1 Macro Score: 0.9182145956007717
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_12.pt

Iteration 14: Requesting all remaining samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9821[0m        [32m0.0385[0m       [35m0.8512[0m      [31m0.9083[0m        [94m0.1616[0m     +  0.0000  113.6308
      2      [36m0.9848[0m        [32m0.0340[0m       [35m0.8720[0m      [31m0.9171[0m        [94m0.1495[0m     +  0.0000  116.0918
      3      [36m0.9859[0m        [32m0.0314[0m       0.8314      0.9004        0.1993        0.0000  114.7172
      4      [36m0.9878[0m        [32m0.0274[0m       0.8313      0.8960        0.2093        0.0000  113.4215
      5      [36m0.9886[0m        [32m0.0256[0m       0.8248      0.8955        0.2106        0.0000  112.9208
      6      [36m0.9917[0m        [32m0.0205[0m       0.8234      0.8938        0.2323        0.0000  114.9017
      7      [36m0.9938[0m        [32m0.0172[0m       0.8262      0.8965        0.2347        0.0000  114.9422
      8      [36m0.9949[0m        [32m0.0153[0m       0.8448      0.9073        0.2134        0.0000  114.9063
      9      [36m0.9956[0m        [32m0.0136[0m       0.8339      0.9004        0.2339        0.0000  114.6228
     10      [36m0.9966[0m        [32m0.0123[0m       0.8380      0.9043        0.2322        0.0000  114.6565
     11      [36m0.9973[0m        [32m0.0110[0m       0.8436      0.9050        0.2315        0.0000  114.4297
     12      [36m0.9978[0m        [32m0.0096[0m       0.8436      0.9067        0.2383        0.0000  115.0336
Stopping since valid_loss has not improved in the last 11 epochs.
Iteration 14: Test F1 Micro Score: 0.9301611665387568
Iteration 14: Test F1 Macro Score: 0.919565887935506
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR/model_checkpoint_iteration_13.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multilabel/DinoS/seed_44_config2_lowLR\random_sampling_results_for_multilabel_classification_s44.pickle
