Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6963[0m        [32m0.6694[0m       [35m0.0210[0m      [31m0.2447[0m        [94m0.7251[0m     +  0.0000  12.3724
      2      0.6035        [32m0.6429[0m       [35m0.1413[0m      [31m0.4842[0m        [94m0.7204[0m     +  0.0000  18.1147
      3      [36m0.7090[0m        0.6429       [35m0.2264[0m      0.4404        [94m0.6974[0m     +  0.0000  21.1580
      4      [36m0.8320[0m        [32m0.6066[0m       0.1587      0.4439        0.7094        0.0000  21.7012
      5      0.7389        [32m0.5923[0m       [35m0.2753[0m      0.4530        0.6996        0.0000  22.2416
      6      0.8320        [32m0.5545[0m       0.2490      0.4541        0.7084        0.0000  22.3534
      7      [36m0.8889[0m        [32m0.5539[0m       0.2568      0.4521        0.7083        0.0000  22.4859
      8      0.8333        [32m0.5391[0m       0.2441      0.4534        0.7119        0.0000  22.8235
      9      0.8333        [32m0.5271[0m       0.2625      0.4558        0.7121        0.0000  22.7107
     10      0.8333        [32m0.5047[0m       0.2462      0.4523        0.7132        0.0000  22.6172
     11      0.8333        0.5390       0.2391      0.4512        0.7137        0.0000  22.5442
     12      0.8796        0.5228       0.2403      0.4510        0.7143        0.0000  22.5322
     13      0.8796        0.5083       0.2385      0.4500        0.7141        0.0000  22.3578
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.4609
Pre F1 macro score = 0.4592
Pre Accuracy = 0.2559

Iteration: 1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5419[0m        [32m0.6308[0m       [35m0.3931[0m      [31m0.1831[0m        [94m0.6258[0m     +  0.0000  22.4722
      2      [36m0.6667[0m        [32m0.5876[0m       0.3460      [31m0.2919[0m        [94m0.6151[0m     +  0.0000  22.6832
      3      0.4744        [32m0.5735[0m       [35m0.3957[0m      [31m0.3421[0m        [94m0.6058[0m     +  0.0000  22.3582
      4      0.5428        [32m0.5243[0m       0.3939      [31m0.3730[0m        [94m0.5918[0m     +  0.0000  22.4068
      5      [36m0.6705[0m        [32m0.5187[0m       [35m0.3981[0m      [31m0.3939[0m        [94m0.5851[0m     +  0.0000  22.5960
      6      0.6627        [32m0.4933[0m       [35m0.4059[0m      [31m0.4431[0m        [94m0.5818[0m     +  0.0000  22.4687
      7      [36m0.7528[0m        [32m0.4753[0m       [35m0.4135[0m      [31m0.4522[0m        [94m0.5803[0m     +  0.0000  22.5024
      8      [36m0.7861[0m        [32m0.4649[0m       0.4106      [31m0.4549[0m        [94m0.5761[0m     +  0.0000  22.6106
      9      0.7775        [32m0.4530[0m       0.4108      [31m0.4730[0m        [94m0.5717[0m     +  0.0000  22.6394
     10      0.7345        [32m0.4406[0m       0.4132      0.4651        [94m0.5711[0m     +  0.0000  22.6131
     11      0.7514        0.4578       [35m0.4182[0m      [31m0.4857[0m        [94m0.5693[0m     +  0.0000  22.2714
     12      [36m0.8242[0m        [32m0.4360[0m       [35m0.4219[0m      [31m0.4911[0m        [94m0.5682[0m     +  0.0000  22.1855
     13      [36m0.8475[0m        0.4363       [35m0.4231[0m      [31m0.4946[0m        [94m0.5669[0m     +  0.0000  22.6456
     14      [36m0.8725[0m        [32m0.4336[0m       [35m0.4250[0m      [31m0.5010[0m        [94m0.5658[0m     +  0.0000  22.1746
     15      [36m0.9198[0m        [32m0.4282[0m       [35m0.4274[0m      [31m0.5013[0m        [94m0.5655[0m     +  0.0000  22.5480
     16      0.8714        [32m0.4155[0m       [35m0.4286[0m      [31m0.5049[0m        [94m0.5651[0m     +  0.0000  22.3260
     17      0.8754        0.4277       0.4283      [31m0.5087[0m        [94m0.5646[0m     +  0.0000  22.4998
     18      0.9057        0.4316       0.4283      [31m0.5092[0m        [94m0.5642[0m     +  0.0000  22.3603
     19      0.8496        0.4408       0.4286      [31m0.5093[0m        [94m0.5640[0m     +  0.0000  22.6079
     20      0.8283        0.4286       [35m0.4292[0m      0.5087        [94m0.5636[0m     +  0.0000  22.4930
     21      [36m0.9369[0m        0.4221       [35m0.4300[0m      0.5087        [94m0.5634[0m     +  0.0000  22.3101
     22      0.8268        0.4439       0.4300      0.5087        [94m0.5633[0m     +  0.0000  22.4690
     23      0.8968        0.4388       [35m0.4306[0m      [31m0.5103[0m        [94m0.5630[0m     +  0.0000  22.3356
     24      0.8440        0.4255       [35m0.4316[0m      [31m0.5110[0m        [94m0.5629[0m     +  0.0000  22.5037
     25      0.8386        0.4449       [35m0.4319[0m      [31m0.5121[0m        [94m0.5627[0m     +  0.0000  22.3158
     26      0.7758        0.4379       0.4319      0.5121        [94m0.5626[0m     +  0.0000  22.1597
     27      0.8887        0.4279       [35m0.4321[0m      [31m0.5126[0m        [94m0.5625[0m     +  0.0000  22.4778
     28      0.8730        0.4377       0.4321      [31m0.5129[0m        [94m0.5624[0m     +  0.0000  22.3787
     29      0.8203        0.4487       0.4321      0.5129        [94m0.5623[0m     +  0.0000  22.9289
     30      0.8596        [32m0.4077[0m       0.4321      0.5129        [94m0.5623[0m     +  0.0000  22.1990
     31      0.8020        0.4263       0.4319      0.5128        [94m0.5623[0m     +  0.0000  22.2994
     32      0.8776        0.4121       0.4319      0.5128        [94m0.5623[0m     +  0.0000  22.3270
     33      0.8786        0.4157       0.4318      0.5127        [94m0.5622[0m     +  0.0000  22.2623
     34      0.8778        0.4361       0.4319      0.5126        [94m0.5622[0m     +  0.0000  22.6917
     35      0.7946        0.4385       0.4321      0.5128        [94m0.5622[0m     +  0.0000  22.4223
     36      0.8009        0.4401       [35m0.4323[0m      0.5128        [94m0.5622[0m     +  0.0000  22.3144
     37      0.8727        0.4329       0.4323      0.5128        [94m0.5622[0m     +  0.0000  22.2642
     38      0.7584        0.4511       0.4323      0.5128        [94m0.5622[0m     +  0.0000  22.3764
     39      0.8615        0.4223       0.4321      0.5128        [94m0.5622[0m     +  0.0000  22.0293
     40      0.8727        0.4296       0.4321      0.5128        [94m0.5621[0m     +  0.0000  22.7521
     41      0.8112        0.4211       0.4321      0.5128        [94m0.5621[0m     +  0.0000  23.0804
     42      0.9107        0.4242       0.4321      0.5128        [94m0.5621[0m     +  0.0000  22.9922
     43      0.8078        0.4264       0.4321      0.5128        [94m0.5621[0m     +  0.0000  22.6222
     44      0.8999        0.4155       0.4321      0.5128        [94m0.5621[0m     +  0.0000  22.5233
     45      0.8571        0.4215       0.4321      0.5128        [94m0.5621[0m     +  0.0000  22.4879
     46      0.8859        0.4359       0.4321      0.5128        [94m0.5621[0m     +  0.0000  22.5682
     47      0.9302        0.4303       0.4321      0.5128        [94m0.5621[0m     +  0.0000  22.4735
     48      0.8482        0.4229       0.4321      0.5128        [94m0.5621[0m     +  0.0000  22.7419
     49      0.8424        0.4235       0.4321      0.5128        [94m0.5621[0m     +  0.0000  22.5044
Stopping since valid_loss has not improved in the last 11 epochs.
[24]
F1 Micro Score after query 1: 0.5423005565862709
F1 Macro Score after query 1: 0.5242426579179489
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\model_checkpoint_iteration_0.pt

Iteration: 2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6504[0m        [32m0.5406[0m       [35m0.5203[0m      [31m0.5014[0m        [94m0.5338[0m     +  0.0000  22.6115
      2      [36m0.8093[0m        [32m0.4520[0m       [35m0.5823[0m      [31m0.6591[0m        [94m0.4847[0m     +  0.0000  22.9916
      3      [36m0.9150[0m        [32m0.3989[0m       [35m0.6372[0m      [31m0.7657[0m        [94m0.4526[0m     +  0.0000  22.6921
      4      [36m0.9345[0m        [32m0.3848[0m       [35m0.6576[0m      [31m0.8001[0m        [94m0.4369[0m     +  0.0000  22.6273
      5      0.9196        [32m0.3533[0m       [35m0.6655[0m      [31m0.8092[0m        [94m0.4222[0m     +  0.0000  22.7839
      6      [36m0.9374[0m        [32m0.3427[0m       [35m0.6783[0m      [31m0.8154[0m        [94m0.4158[0m     +  0.0000  22.5177
      7      [36m0.9652[0m        [32m0.3250[0m       [35m0.6821[0m      [31m0.8194[0m        [94m0.4112[0m     +  0.0000  22.6004
      8      0.9512        0.3313       [35m0.6856[0m      [31m0.8217[0m        [94m0.4083[0m     +  0.0000  22.5681
      9      0.9570        [32m0.3140[0m       0.6845      0.8215        [94m0.4034[0m     +  0.0000  22.7221
     10      0.9549        0.3277       0.6828      0.8179        [94m0.4013[0m     +  0.0000  22.4874
     11      0.9502        [32m0.3135[0m       [35m0.6880[0m      0.8215        [94m0.4000[0m     +  0.0000  22.7566
     12      [36m0.9696[0m        [32m0.3061[0m       0.6870      0.8217        [94m0.3993[0m     +  0.0000  22.5836
     13      0.9592        0.3163       [35m0.6885[0m      [31m0.8244[0m        [94m0.3986[0m     +  0.0000  22.7837
     14      [36m0.9863[0m        [32m0.3005[0m       0.6872      0.8227        [94m0.3980[0m     +  0.0000  22.4886
     15      0.9554        [32m0.3004[0m       0.6880      0.8240        [94m0.3964[0m     +  0.0000  22.5496
     16      0.9642        0.3045       [35m0.6896[0m      [31m0.8251[0m        [94m0.3963[0m     +  0.0000  22.6139
     17      0.9708        0.3009       [35m0.6917[0m      [31m0.8260[0m        [94m0.3957[0m     +  0.0000  22.4583
     18      0.9475        0.3254       [35m0.6936[0m      [31m0.8273[0m        [94m0.3951[0m     +  0.0000  22.5398
     19      0.9863        0.3091       0.6910      0.8263        0.3951        0.0000  22.3949
     20      0.9625        [32m0.2976[0m       0.6922      0.8266        [94m0.3947[0m     +  0.0000  22.8937
     21      0.9577        0.3104       0.6929      [31m0.8273[0m        [94m0.3945[0m     +  0.0000  22.3940
     22      0.9708        0.3021       0.6936      [31m0.8276[0m        [94m0.3942[0m     +  0.0000  22.3809
     23      0.9617        0.3097       0.6932      0.8274        [94m0.3941[0m     +  0.0000  22.4100
     24      0.9589        0.3052       0.6918      0.8261        [94m0.3939[0m     +  0.0000  22.7384
     25      0.9630        0.2990       0.6920      0.8263        [94m0.3937[0m     +  0.0000  22.5676
     26      0.9707        0.3057       0.6920      0.8262        [94m0.3936[0m     +  0.0000  22.4480
     27      0.9637        0.3137       0.6920      0.8263        [94m0.3935[0m     +  0.0000  22.4168
     28      0.9725        0.3139       0.6920      0.8263        [94m0.3934[0m     +  0.0000  22.5216
     29      0.9571        0.3067       0.6922      0.8263        [94m0.3934[0m     +  0.0000  22.5210
     30      0.9630        0.3023       0.6922      0.8263        [94m0.3933[0m     +  0.0000  22.5071
     31      0.9773        0.3039       0.6922      0.8264        [94m0.3933[0m     +  0.0000  22.3153
     32      0.9696        0.2982       0.6920      0.8263        [94m0.3932[0m     +  0.0000  22.4250
     33      0.9773        0.3109       0.6915      0.8260        [94m0.3932[0m     +  0.0000  22.3506
     34      0.9863        0.3015       0.6917      0.8261        [94m0.3932[0m     +  0.0000  22.3304
     35      0.9696        0.3060       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.5029
     36      0.9540        [32m0.2965[0m       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.4129
     37      0.9552        [32m0.2963[0m       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.5801
     38      0.9630        [32m0.2879[0m       0.6917      0.8261        [94m0.3931[0m     +  0.0000  23.2866
     39      0.9696        0.2984       0.6918      0.8262        [94m0.3931[0m     +  0.0000  23.2284
     40      0.9786        0.3037       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.6750
     41      0.9577        0.3051       0.6917      0.8261        [94m0.3931[0m     +  0.0000  23.0500
     42      0.9652        0.2998       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.5219
     43      0.9613        0.3029       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.9085
     44      0.9712        0.3139       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.6930
     45      0.9802        0.3024       0.6918      0.8262        [94m0.3931[0m     +  0.0000  22.7071
     46      0.9647        0.3127       0.6918      0.8262        [94m0.3931[0m     +  0.0000  22.6439
     47      0.9720        0.3001       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.6756
     48      0.9693        0.3030       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.8492
     49      0.9504        0.3118       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.7088
     50      0.9613        0.3002       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.7238
     51      0.9708        0.3047       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.6422
     52      0.9620        0.3001       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.6934
     53      0.9737        0.3037       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.9434
     54      0.9630        0.3016       0.6917      0.8261        [94m0.3931[0m     +  0.0000  23.0490
     55      0.9660        0.2917       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.8014
     56      0.9647        0.3103       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.6597
     57      0.9667        0.3134       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.6785
     58      0.9798        0.3003       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.7206
     59      0.9484        0.3195       0.6917      0.8261        [94m0.3931[0m     +  0.0000  22.6594
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56]
F1 Micro Score after query 2: 0.8414717757294127
F1 Macro Score after query 2: 0.824778333196864
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\model_checkpoint_iteration_1.pt

Iteration: 3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9032[0m        [32m0.3357[0m       [35m0.7134[0m      [31m0.8398[0m        [94m0.3637[0m     +  0.0000  23.0820
      2      [36m0.9223[0m        [32m0.2969[0m       [35m0.7182[0m      [31m0.8441[0m        [94m0.3447[0m     +  0.0000  22.9104
      3      [36m0.9395[0m        [32m0.2790[0m       [35m0.7219[0m      0.8408        0.3455        0.0000  23.0838
      4      0.9383        [32m0.2635[0m       [35m0.7220[0m      0.8431        [94m0.3408[0m     +  0.0000  22.8837
      5      [36m0.9645[0m        [32m0.2450[0m       [35m0.7332[0m      [31m0.8496[0m        [94m0.3298[0m     +  0.0000  23.3336
      6      0.9636        [32m0.2417[0m       0.7252      0.8473        [94m0.3276[0m     +  0.0000  23.0213
      7      [36m0.9670[0m        [32m0.2384[0m       0.7248      0.8479        [94m0.3268[0m     +  0.0000  23.3779
      8      0.9648        [32m0.2296[0m       0.7219      0.8462        [94m0.3255[0m     +  0.0000  23.4565
      9      [36m0.9872[0m        [32m0.2240[0m       0.7295      [31m0.8496[0m        [94m0.3243[0m     +  0.0000  23.3790
     10      0.9764        0.2259       0.7269      0.8478        [94m0.3221[0m     +  0.0000  22.8794
     11      0.9769        0.2286       0.7149      0.8404        0.3221        0.0000  23.5035
     12      0.9801        [32m0.2235[0m       0.7210      0.8449        [94m0.3211[0m     +  0.0000  23.4847
     13      0.9801        0.2288       0.7247      0.8469        0.3215        0.0000  23.0972
     14      0.9844        [32m0.2215[0m       0.7234      0.8464        0.3211        0.0000  22.9688
     15      0.9719        0.2238       0.7200      0.8424        [94m0.3202[0m     +  0.0000  22.9411
     16      0.9691        [32m0.2212[0m       0.7241      0.8460        0.3202        0.0000  23.4361
     17      0.9833        [32m0.2211[0m       0.7231      0.8452        0.3203        0.0000  23.6419
     18      0.9712        [32m0.2146[0m       0.7194      0.8435        0.3204        0.0000  23.5352
     19      0.9719        0.2183       0.7203      0.8435        [94m0.3201[0m     +  0.0000  23.2936
     20      0.9764        [32m0.2133[0m       0.7160      0.8401        [94m0.3200[0m     +  0.0000  23.6289
     21      0.9796        0.2198       0.7168      0.8406        [94m0.3199[0m     +  0.0000  23.3477
     22      0.9833        0.2194       0.7201      0.8429        [94m0.3197[0m     +  0.0000  23.8330
     23      0.9775        0.2202       0.7194      0.8426        [94m0.3196[0m     +  0.0000  23.8284
     24      0.9682        0.2321       0.7217      0.8440        [94m0.3196[0m     +  0.0000  23.5503
     25      0.9844        0.2178       0.7238      0.8452        [94m0.3194[0m     +  0.0000  23.7102
     26      0.9765        0.2209       0.7236      0.8451        [94m0.3194[0m     +  0.0000  23.4738
     27      0.9771        0.2190       0.7240      0.8453        [94m0.3194[0m     +  0.0000  23.5240
     28      0.9750        0.2142       0.7220      0.8439        [94m0.3193[0m     +  0.0000  23.5230
     29      0.9787        0.2268       0.7224      0.8441        0.3194        0.0000  23.3485
     30      0.9746        [32m0.2115[0m       0.7236      0.8452        0.3194        0.0000  23.4237
     31      0.9802        0.2217       0.7233      0.8450        0.3194        0.0000  23.4861
     32      0.9763        0.2250       0.7234      0.8451        0.3194        0.0000  23.3627
     33      0.9682        0.2250       0.7233      0.8450        0.3194        0.0000  23.3653
     34      [36m0.9881[0m        0.2236       0.7231      0.8449        0.3194        0.0000  23.6618
     35      0.9838        0.2165       0.7231      0.8449        0.3194        0.0000  23.5997
     36      0.9805        0.2276       0.7231      0.8449        0.3194        0.0000  23.8375
     37      0.9770        0.2224       0.7231      0.8449        0.3194        0.0000  23.7868
     38      0.9837        0.2166       0.7233      0.8450        0.3194        0.0000  23.2884
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112]
F1 Micro Score after query 3: 0.8602298850574712
F1 Macro Score after query 3: 0.8448273126844699
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\model_checkpoint_iteration_2.pt

Iteration: 4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9132[0m        [32m0.2743[0m       [35m0.6859[0m      [31m0.8074[0m        [94m0.3227[0m     +  0.0000  24.3663
      2      [36m0.9330[0m        [32m0.2439[0m       0.6840      0.7992        [94m0.3201[0m     +  0.0000  23.8185
      3      [36m0.9520[0m        [32m0.2324[0m       [35m0.6965[0m      [31m0.8090[0m        [94m0.3114[0m     +  0.0000  24.3655
      4      [36m0.9668[0m        [32m0.2228[0m       [35m0.7167[0m      [31m0.8302[0m        [94m0.2971[0m     +  0.0000  23.8029
      5      0.9641        [32m0.2106[0m       [35m0.7273[0m      [31m0.8395[0m        [94m0.2917[0m     +  0.0000  23.7415
      6      [36m0.9716[0m        [32m0.2046[0m       [35m0.7590[0m      [31m0.8597[0m        [94m0.2795[0m     +  0.0000  23.7243
      7      [36m0.9717[0m        0.2061       0.7519      0.8526        0.2825        0.0000  23.7878
      8      [36m0.9767[0m        [32m0.1971[0m       [35m0.7656[0m      0.8582        0.2797        0.0000  23.5998
      9      [36m0.9787[0m        0.2025       0.7618      [31m0.8603[0m        [94m0.2789[0m     +  0.0000  24.1770
     10      [36m0.9816[0m        0.1983       0.7634      [31m0.8613[0m        [94m0.2777[0m     +  0.0000  24.1764
     11      [36m0.9827[0m        0.1989       [35m0.7674[0m      [31m0.8673[0m        [94m0.2736[0m     +  0.0000  23.6774
     12      [36m0.9859[0m        [32m0.1920[0m       0.7651      0.8655        0.2747        0.0000  23.8321
     13      0.9784        0.2000       0.7660      0.8666        0.2746        0.0000  24.1940
     14      0.9803        0.1945       0.7674      [31m0.8673[0m        0.2738        0.0000  24.2362
     15      [36m0.9869[0m        [32m0.1894[0m       [35m0.7693[0m      [31m0.8697[0m        [94m0.2723[0m     +  0.0000  24.3025
     16      0.9837        0.1934       [35m0.7701[0m      [31m0.8737[0m        [94m0.2711[0m     +  0.0000  24.3812
     17      0.9859        0.1911       0.7691      0.8732        0.2718        0.0000  24.3350
     18      0.9800        [32m0.1863[0m       0.7700      [31m0.8738[0m        0.2713        0.0000  24.2428
     19      0.9869        [32m0.1846[0m       0.7698      0.8738        0.2714        0.0000  24.1137
     20      0.9869        0.1895       0.7694      0.8737        0.2714        0.0000  24.2530
     21      0.9836        0.1942       0.7701      [31m0.8741[0m        0.2712        0.0000  24.1460
     22      0.9853        0.1881       0.7693      0.8739        [94m0.2711[0m     +  0.0000  24.0523
     23      0.9849        0.1880       0.7691      [31m0.8743[0m        [94m0.2709[0m     +  0.0000  24.3080
     24      0.9869        0.1893       0.7693      0.8740        0.2713        0.0000  24.5481
     25      0.9860        0.1941       0.7682      0.8738        0.2712        0.0000  24.2712
     26      0.9859        0.1925       0.7684      0.8740        0.2711        0.0000  24.1454
     27      0.9853        0.1892       0.7686      0.8741        0.2710        0.0000  24.1339
     28      0.9853        0.1884       0.7686      0.8742        [94m0.2709[0m     +  0.0000  24.1914
     29      0.9853        [32m0.1813[0m       0.7688      0.8742        0.2709        0.0000  24.5402
     30      0.9853        0.1863       0.7689      0.8741        0.2710        0.0000  24.0392
     31      [36m0.9879[0m        0.1839       0.7688      0.8740        0.2709        0.0000  24.1005
     32      0.9869        0.1845       0.7686      0.8740        0.2709        0.0000  24.0655
     33      [36m0.9895[0m        0.1860       0.7684      0.8739        [94m0.2709[0m     +  0.0000  24.3171
     34      0.9847        0.1880       0.7686      0.8740        [94m0.2709[0m     +  0.0000  24.0712
     35      0.9826        0.1849       0.7684      0.8739        [94m0.2708[0m     +  0.0000  24.1800
     36      [36m0.9911[0m        0.1853       0.7681      0.8738        [94m0.2708[0m     +  0.0000  24.1176
     37      0.9822        0.1898       0.7679      0.8737        [94m0.2708[0m     +  0.0000  24.0354
     38      0.9854        0.1933       0.7679      0.8737        [94m0.2708[0m     +  0.0000  24.5541
     39      [36m0.9921[0m        0.1952       0.7675      0.8735        [94m0.2707[0m     +  0.0000  24.0671
     40      0.9911        0.1834       0.7675      0.8735        [94m0.2707[0m     +  0.0000  24.0376
     41      0.9849        0.1862       0.7675      0.8735        0.2707        0.0000  24.1139
     42      0.9840        0.1882       0.7675      0.8735        0.2707        0.0000  24.2863
     43      0.9844        0.1920       0.7675      0.8735        0.2707        0.0000  24.0495
     44      0.9869        0.1860       0.7675      0.8735        0.2707        0.0000  24.2250
     45      0.9869        0.1872       0.7675      0.8735        0.2707        0.0000  23.9733
     46      0.9879        0.1820       0.7675      0.8735        0.2707        0.0000  24.3494
     47      0.9838        0.1881       0.7675      0.8735        0.2707        0.0000  24.4106
     48      0.9869        0.1890       0.7675      0.8735        0.2707        0.0000  23.9264
     49      0.9836        0.1859       0.7675      0.8735        0.2707        0.0000  24.0026
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208]
F1 Micro Score after query 4: 0.8978248655590336
F1 Macro Score after query 4: 0.8852146747982159
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\model_checkpoint_iteration_3.pt

Iteration: 5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9365[0m        [32m0.2340[0m       [35m0.7852[0m      [31m0.8816[0m        [94m0.2596[0m     +  0.0000  25.7262
      2      [36m0.9568[0m        [32m0.2066[0m       [35m0.7872[0m      [31m0.8840[0m        [94m0.2548[0m     +  0.0000  25.8520
      3      [36m0.9620[0m        [32m0.1945[0m       [35m0.7931[0m      [31m0.8855[0m        [94m0.2521[0m     +  0.0000  25.6323
      4      [36m0.9684[0m        [32m0.1917[0m       [35m0.7941[0m      [31m0.8861[0m        [94m0.2494[0m     +  0.0000  26.0383
      5      [36m0.9781[0m        [32m0.1849[0m       0.7868      [31m0.8864[0m        [94m0.2484[0m     +  0.0000  26.2092
      6      [36m0.9786[0m        [32m0.1758[0m       0.7905      [31m0.8881[0m        [94m0.2459[0m     +  0.0000  25.7707
      7      [36m0.9796[0m        [32m0.1721[0m       0.7906      [31m0.8884[0m        0.2472        0.0000  25.6122
      8      [36m0.9850[0m        [32m0.1708[0m       0.7932      [31m0.8890[0m        [94m0.2441[0m     +  0.0000  26.0383
      9      0.9844        [32m0.1697[0m       [35m0.7943[0m      [31m0.8896[0m        [94m0.2430[0m     +  0.0000  25.9011
     10      [36m0.9872[0m        [32m0.1659[0m       0.7906      0.8884        0.2461        0.0000  25.9914
     11      0.9854        [32m0.1598[0m       0.7884      0.8872        [94m0.2425[0m     +  0.0000  25.7883
     12      [36m0.9899[0m        0.1631       0.7896      0.8877        [94m0.2423[0m     +  0.0000  26.0123
     13      0.9881        0.1642       0.7903      0.8873        [94m0.2418[0m     +  0.0000  25.5370
     14      0.9855        0.1603       0.7880      0.8870        0.2422        0.0000  25.6322
     15      0.9873        0.1622       0.7882      0.8867        0.2419        0.0000  26.0531
     16      0.9883        [32m0.1564[0m       0.7891      0.8860        [94m0.2398[0m     +  0.0000  25.7243
     17      0.9896        [32m0.1560[0m       0.7887      0.8862        [94m0.2397[0m     +  0.0000  25.7564
     18      0.9899        0.1614       0.7866      0.8852        0.2399        0.0000  25.6169
     19      0.9899        0.1595       0.7861      0.8850        0.2400        0.0000  25.7412
     20      0.9881        0.1611       0.7885      0.8857        0.2397        0.0000  26.0699
     21      0.9883        [32m0.1558[0m       0.7878      0.8858        [94m0.2395[0m     +  0.0000  25.7706
     22      [36m0.9907[0m        0.1571       0.7873      0.8856        0.2396        0.0000  25.4920
     23      0.9899        0.1566       0.7875      0.8856        0.2396        0.0000  25.5224
     24      0.9890        0.1582       0.7861      0.8850        0.2397        0.0000  26.0840
     25      0.9899        0.1566       0.7858      0.8848        0.2396        0.0000  26.0826
     26      0.9907        [32m0.1541[0m       0.7868      0.8852        0.2396        0.0000  26.0208
     27      0.9907        0.1559       0.7878      0.8856        0.2395        0.0000  25.6312
     28      0.9899        0.1575       0.7877      0.8855        [94m0.2395[0m     +  0.0000  25.7719
     29      0.9883        0.1589       0.7875      0.8855        [94m0.2395[0m     +  0.0000  25.9297
     30      0.9899        0.1577       0.7878      0.8856        [94m0.2394[0m     +  0.0000  25.9890
     31      0.9899        0.1578       0.7880      0.8857        [94m0.2394[0m     +  0.0000  26.2735
     32      0.9890        0.1579       0.7875      0.8855        0.2395        0.0000  25.8130
     33      0.9899        0.1568       0.7873      0.8853        0.2395        0.0000  25.5215
     34      0.9888        0.1561       0.7872      0.8856        0.2395        0.0000  26.0238
     35      0.9899        0.1550       0.7873      0.8854        0.2395        0.0000  25.4285
     36      0.9907        0.1577       0.7875      0.8855        0.2395        0.0000  25.7398
     37      0.9896        0.1584       0.7875      0.8855        0.2395        0.0000  25.7740
     38      [36m0.9916[0m        0.1548       0.7872      0.8853        0.2395        0.0000  25.5972
     39      0.9890        0.1571       0.7873      0.8855        0.2395        0.0000  25.7700
     40      0.9907        0.1563       0.7873      0.8857        0.2395        0.0000  25.9604
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.9095289911394372
F1 Macro Score after query 5: 0.8954535395438722
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\model_checkpoint_iteration_4.pt

Iteration: 6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9441[0m        [32m0.2053[0m       [35m0.7851[0m      [31m0.8735[0m        [94m0.2432[0m     +  0.0000  28.8507
      2      [36m0.9534[0m        [32m0.1835[0m       0.7788      0.8707        0.2438        0.0000  28.6044
      3      [36m0.9687[0m        [32m0.1717[0m       0.7833      0.8610        0.2437        0.0000  28.7359
      4      [36m0.9721[0m        [32m0.1633[0m       [35m0.7863[0m      0.8601        [94m0.2418[0m     +  0.0000  28.5394
      5      [36m0.9738[0m        [32m0.1585[0m       0.7839      0.8613        [94m0.2390[0m     +  0.0000  28.7598
      6      [36m0.9783[0m        [32m0.1522[0m       0.7840      0.8631        [94m0.2372[0m     +  0.0000  28.4480
      7      [36m0.9790[0m        [32m0.1505[0m       0.7851      0.8595        0.2395        0.0000  28.6474
      8      [36m0.9836[0m        [32m0.1463[0m       0.7818      0.8550        0.2414        0.0000  28.4614
      9      [36m0.9842[0m        0.1463       0.7804      0.8608        [94m0.2369[0m     +  0.0000  28.8719
     10      [36m0.9878[0m        [32m0.1412[0m       0.7776      0.8588        [94m0.2369[0m     +  0.0000  28.6511
     11      0.9849        0.1414       0.7701      0.8637        [94m0.2357[0m     +  0.0000  28.6979
     12      0.9851        [32m0.1401[0m       0.7696      0.8615        0.2366        0.0000  28.8545
     13      0.9860        [32m0.1390[0m       0.7701      0.8637        0.2358        0.0000  29.0823
     14      0.9860        [32m0.1376[0m       0.7712      0.8647        [94m0.2357[0m     +  0.0000  28.9617
     15      0.9877        [32m0.1371[0m       0.7707      0.8637        [94m0.2355[0m     +  0.0000  28.7750
     16      0.9870        [32m0.1345[0m       0.7682      0.8680        0.2358        0.0000  28.5418
     17      0.9870        [32m0.1311[0m       0.7682      0.8678        0.2357        0.0000  28.4946
     18      [36m0.9879[0m        0.1370       0.7688      0.8681        [94m0.2353[0m     +  0.0000  28.7255
     19      0.9874        0.1333       0.7670      0.8670        0.2356        0.0000  29.0282
     20      [36m0.9901[0m        0.1333       0.7689      0.8692        0.2357        0.0000  29.0869
     21      0.9888        0.1350       0.7682      0.8707        0.2361        0.0000  28.6039
     22      [36m0.9910[0m        0.1329       0.7694      0.8713        0.2359        0.0000  28.6463
     23      0.9902        0.1330       0.7696      0.8713        0.2359        0.0000  28.9234
     24      0.9874        0.1328       0.7694      0.8716        0.2358        0.0000  28.5370
     25      0.9884        0.1320       0.7696      0.8714        0.2356        0.0000  29.0107
     26      0.9879        [32m0.1295[0m       0.7696      0.8713        0.2357        0.0000  28.7417
     27      0.9884        0.1323       0.7703      0.8717        0.2358        0.0000  28.2444
     28      0.9910        0.1320       0.7703      0.8718        0.2357        0.0000  28.5545
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.9160807092632223
F1 Macro Score after query 6: 0.9042387823912094
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\model_checkpoint_iteration_5.pt

Iteration: 7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9500[0m        [32m0.1673[0m       [35m0.7819[0m      [31m0.8580[0m        [94m0.2232[0m     +  0.0000  33.6671
      2      [36m0.9650[0m        [32m0.1476[0m       [35m0.7896[0m      [31m0.8592[0m        [94m0.2192[0m     +  0.0000  33.4044
      3      [36m0.9728[0m        [32m0.1378[0m       0.7873      [31m0.8608[0m        [94m0.2164[0m     +  0.0000  33.4190
      4      [36m0.9803[0m        [32m0.1295[0m       [35m0.7941[0m      [31m0.8752[0m        [94m0.2113[0m     +  0.0000  33.4194
      5      [36m0.9829[0m        [32m0.1238[0m       [35m0.7957[0m      0.8746        [94m0.2101[0m     +  0.0000  32.8890
      6      [36m0.9889[0m        [32m0.1170[0m       [35m0.8026[0m      [31m0.8878[0m        [94m0.2040[0m     +  0.0000  34.1795
      7      [36m0.9898[0m        [32m0.1137[0m       0.8012      0.8855        0.2045        0.0000  33.5108
      8      [36m0.9914[0m        [32m0.1099[0m       0.7981      0.8836        [94m0.2037[0m     +  0.0000  33.2913
      9      [36m0.9914[0m        [32m0.1093[0m       0.7998      0.8822        [94m0.2029[0m     +  0.0000  33.8568
     10      [36m0.9938[0m        [32m0.1063[0m       0.7981      0.8836        [94m0.2029[0m     +  0.0000  34.4171
     11      0.9935        [32m0.1035[0m       0.7991      0.8872        [94m0.2023[0m     +  0.0000  33.9515
     12      0.9933        [32m0.1024[0m       0.7965      0.8842        [94m0.2021[0m     +  0.0000  33.8861
     13      [36m0.9943[0m        [32m0.1011[0m       0.8002      0.8876        [94m0.2021[0m     +  0.0000  33.8722
     14      [36m0.9946[0m        0.1011       0.7960      0.8845        0.2030        0.0000  33.5926
     15      0.9942        0.1012       0.7977      0.8850        0.2023        0.0000  33.5759
     16      0.9940        [32m0.0987[0m       0.7965      0.8823        [94m0.2020[0m     +  0.0000  34.1541
     17      0.9942        0.1000       0.7962      0.8829        0.2022        0.0000  33.9221
     18      [36m0.9948[0m        0.0999       0.7974      0.8830        [94m0.2013[0m     +  0.0000  33.6686
     19      [36m0.9958[0m        [32m0.0985[0m       0.7981      0.8826        [94m0.2011[0m     +  0.0000  33.5452
     20      0.9950        [32m0.0976[0m       0.7965      0.8830        0.2021        0.0000  33.4682
     21      0.9951        [32m0.0975[0m       0.7988      0.8830        0.2019        0.0000  33.6513
     22      0.9956        0.0976       0.7984      0.8832        0.2017        0.0000  34.2471
     23      0.9953        [32m0.0958[0m       0.7967      0.8825        0.2020        0.0000  34.1504
     24      0.9955        0.0973       0.7967      0.8823        0.2023        0.0000  34.0723
     25      0.9946        0.0960       0.7960      0.8822        0.2023        0.0000  34.0579
     26      0.9958        0.0961       0.7953      0.8825        0.2024        0.0000  33.8396
     27      0.9953        0.0963       0.7957      0.8824        0.2020        0.0000  33.4961
     28      0.9948        0.0967       0.7957      0.8823        0.2021        0.0000  33.6542
     29      [36m0.9961[0m        0.0959       0.7955      0.8822        0.2021        0.0000  34.3733
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.9161389961389962
F1 Macro Score after query 7: 0.9039194005458698
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\model_checkpoint_iteration_6.pt

Iteration: 8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9721[0m        [32m0.1197[0m       [35m0.7984[0m      [31m0.8901[0m        [94m0.2132[0m     +  0.0000  42.3325
      2      [36m0.9827[0m        [32m0.1046[0m       [35m0.8238[0m      [31m0.8981[0m        [94m0.1912[0m     +  0.0000  43.5541
      3      [36m0.9874[0m        [32m0.0973[0m       0.8135      0.8948        0.1961        0.0000  43.2406
      4      [36m0.9884[0m        [32m0.0907[0m       0.8217      0.8976        0.1924        0.0000  42.4073
      5      [36m0.9908[0m        [32m0.0852[0m       0.8189      0.8974        0.1924        0.0000  42.4880
      6      [36m0.9913[0m        [32m0.0798[0m       0.8085      0.8903        0.1944        0.0000  43.2832
      7      [36m0.9928[0m        [32m0.0771[0m       0.8047      0.8900        0.1968        0.0000  43.3491
      8      [36m0.9941[0m        [32m0.0743[0m       0.8064      0.8922        0.1956        0.0000  42.8331
      9      [36m0.9945[0m        [32m0.0722[0m       0.8000      0.8895        0.2002        0.0000  42.3766
     10      [36m0.9952[0m        [32m0.0710[0m       0.7962      0.8848        0.2000        0.0000  42.5218
     11      [36m0.9958[0m        [32m0.0686[0m       0.7960      0.8872        0.2005        0.0000  43.8802
     12      [36m0.9961[0m        [32m0.0679[0m       0.7977      0.8880        0.2005        0.0000  43.1893
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.9116839536302622
F1 Macro Score after query 8: 0.8995658670205531
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\model_checkpoint_iteration_7.pt

Iteration: 9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9698[0m        [32m0.1104[0m       [35m0.8224[0m      [31m0.8961[0m        [94m0.1826[0m     +  0.0000  59.2334
      2      [36m0.9763[0m        [32m0.0974[0m       [35m0.8266[0m      [31m0.8980[0m        [94m0.1755[0m     +  0.0000  58.7045
      3      [36m0.9812[0m        [32m0.0880[0m       [35m0.8417[0m      [31m0.9018[0m        [94m0.1692[0m     +  0.0000  57.7027
      4      [36m0.9840[0m        [32m0.0808[0m       0.8321      0.8968        0.1719        0.0000  57.9070
      5      [36m0.9848[0m        [32m0.0741[0m       0.8401      0.8955        [94m0.1676[0m     +  0.0000  60.1604
      6      [36m0.9880[0m        [32m0.0680[0m       0.8319      0.8973        0.1719        0.0000  58.0896
      7      [36m0.9901[0m        [32m0.0649[0m       0.8302      0.8946        0.1750        0.0000  57.7053
      8      [36m0.9904[0m        [32m0.0622[0m       0.8234      0.8865        0.1795        0.0000  59.4567
      9      [36m0.9926[0m        [32m0.0592[0m       0.8198      0.8846        0.1827        0.0000  58.9693
     10      0.9924        [32m0.0582[0m       0.8201      0.8884        0.1823        0.0000  57.9710
     11      [36m0.9936[0m        [32m0.0552[0m       0.8177      0.8916        0.1828        0.0000  58.0484
     12      [36m0.9945[0m        [32m0.0537[0m       0.8132      0.8904        0.1843        0.0000  60.1728
     13      0.9941        [32m0.0523[0m       0.8182      0.8922        0.1827        0.0000  58.3007
     14      [36m0.9950[0m        [32m0.0522[0m       0.8170      0.8916        0.1835        0.0000  58.1104
     15      [36m0.9953[0m        [32m0.0506[0m       0.8146      0.8886        0.1839        0.0000  59.2797
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.9228741957987754
F1 Macro Score after query 9: 0.9070252001519202
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\model_checkpoint_iteration_8.pt

Iteration: 10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9766[0m        [32m0.0785[0m       [35m0.8226[0m      [31m0.8941[0m        [94m0.1804[0m     +  0.0000  85.8465
      2      [36m0.9798[0m        [32m0.0690[0m       0.8194      [31m0.8941[0m        0.1823        0.0000  86.2671
      3      [36m0.9826[0m        [32m0.0626[0m       0.8052      0.8838        0.1963        0.0000  83.7796
      4      [36m0.9848[0m        [32m0.0561[0m       0.8120      0.8886        0.1870        0.0000  86.5023
      5      [36m0.9855[0m        [32m0.0517[0m       0.8149      0.8908        0.1964        0.0000  85.5511
      6      [36m0.9891[0m        [32m0.0449[0m       0.8172      0.8910        0.2004        0.0000  87.6854
      7      [36m0.9911[0m        [32m0.0424[0m       0.8201      0.8916        0.2028        0.0000  85.4517
      8      [36m0.9914[0m        [32m0.0397[0m       0.8179      0.8899        0.2031        0.0000  37.9845
      9      [36m0.9932[0m        [32m0.0369[0m       0.8146      0.8892        0.2193        0.0000  38.3750
     10      [36m0.9937[0m        [32m0.0352[0m       0.8163      0.8885        0.2082        0.0000  38.1715
     11      [36m0.9939[0m        [32m0.0333[0m       0.8134      0.8862        0.2145        0.0000  38.4133
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.9342166076105376
F1 Macro Score after query 10: 0.9241515928006442
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\model_checkpoint_iteration_9.pt

Iteration: 11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9734[0m        [32m0.0769[0m       [35m0.7984[0m      [31m0.8598[0m        [94m0.1873[0m     +  0.0000  59.2713
      2      [36m0.9779[0m        [32m0.0663[0m       [35m0.8026[0m      [31m0.8667[0m        0.1953        0.0000  59.4414
      3      [36m0.9804[0m        [32m0.0576[0m       [35m0.8142[0m      [31m0.8746[0m        [94m0.1804[0m     +  0.0000  61.7705
      4      [36m0.9826[0m        [32m0.0526[0m       [35m0.8207[0m      [31m0.8854[0m        [94m0.1774[0m     +  0.0000  60.8047
      5      [36m0.9837[0m        [32m0.0471[0m       [35m0.8240[0m      0.8811        0.1902        0.0000  60.5270
      6      [36m0.9871[0m        [32m0.0411[0m       0.8231      0.8850        0.1902        0.0000  60.4844
      7      [36m0.9892[0m        [32m0.0376[0m       0.8170      0.8826        0.1978        0.0000  60.3991
      8      [36m0.9902[0m        [32m0.0352[0m       0.8139      0.8771        0.2088        0.0000  60.3652
      9      [36m0.9910[0m        [32m0.0331[0m       0.8109      0.8797        0.2128        0.0000  60.4247
     10      [36m0.9915[0m        [32m0.0316[0m       0.8071      0.8733        0.2215        0.0000  60.4385
     11      [36m0.9920[0m        [32m0.0290[0m       0.8099      0.8832        0.2180        0.0000  60.3787
     12      [36m0.9928[0m        [32m0.0282[0m       0.8082      0.8814        0.2224        0.0000  60.3305
     13      [36m0.9935[0m        [32m0.0266[0m       0.8078      0.8814        0.2270        0.0000  60.3597
     14      [36m0.9941[0m        [32m0.0261[0m       0.8095      0.8834        0.2265        0.0000  60.5991
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.9249461704091049
F1 Macro Score after query 11: 0.9145212077549761
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\model_checkpoint_iteration_10.pt

Iteration: 12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9787[0m        [32m0.0545[0m       [35m0.8451[0m      [31m0.9065[0m        [94m0.1515[0m     +  0.0000  99.3925
      2      [36m0.9798[0m        [32m0.0491[0m       [35m0.8470[0m      0.8979        0.1612        0.0000  99.2474
      3      [36m0.9822[0m        [32m0.0428[0m       [35m0.8535[0m      0.9005        0.1519        0.0000  99.4549
      4      [36m0.9832[0m        [32m0.0395[0m       0.8493      0.8998        0.1658        0.0000  99.1896
      5      [36m0.9843[0m        [32m0.0358[0m       0.8408      0.8924        0.1776        0.0000  99.4127
      6      [36m0.9881[0m        [32m0.0292[0m       0.8347      0.8903        0.1936        0.0000  99.4184
      7      [36m0.9901[0m        [32m0.0266[0m       0.8372      0.8921        0.1916        0.0000  99.5599
      8      [36m0.9906[0m        [32m0.0249[0m       0.8424      0.8963        0.1873        0.0000  99.3439
      9      [36m0.9919[0m        [32m0.0227[0m       0.8431      0.8958        0.1966        0.0000  99.5667
     10      [36m0.9928[0m        [32m0.0211[0m       0.8377      0.8921        0.2002        0.0000  99.1944
     11      [36m0.9941[0m        [32m0.0190[0m       0.8335      0.8924        0.2123        0.0000  99.1862
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.9327724546233545
F1 Macro Score after query 12: 0.9202879835109744
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\model_checkpoint_iteration_11.pt

Iteration: 13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9793[0m        [32m0.0497[0m       [35m0.8038[0m      [31m0.8919[0m        [94m0.2078[0m     +  0.0000  114.4999
      2      [36m0.9813[0m        [32m0.0440[0m       0.8014      0.8837        0.2159        0.0000  115.1876
      3      [36m0.9831[0m        [32m0.0391[0m       [35m0.8042[0m      0.8862        0.2426        0.0000  115.3590
      4      [36m0.9847[0m        [32m0.0352[0m       [35m0.8059[0m      0.8815        0.2202        0.0000  115.2921
      5      [36m0.9861[0m        [32m0.0324[0m       [35m0.8061[0m      0.8812        0.2413        0.0000  115.0984
      6      [36m0.9887[0m        [32m0.0266[0m       [35m0.8174[0m      0.8823        0.2082        0.0000  115.0184
      7      [36m0.9905[0m        [32m0.0241[0m       [35m0.8280[0m      0.8877        0.2087        0.0000  115.3547
      8      [36m0.9915[0m        [32m0.0225[0m       [35m0.8335[0m      0.8901        [94m0.1981[0m     +  0.0000  115.2398
      9      [36m0.9925[0m        [32m0.0206[0m       0.8299      0.8874        0.2073        0.0000  114.9698
     10      [36m0.9925[0m        [32m0.0193[0m       0.8311      0.8908        0.2180        0.0000  115.0859
     11      [36m0.9934[0m        [32m0.0175[0m       [35m0.8358[0m      [31m0.8974[0m        0.2156        0.0000  115.0664
     12      [36m0.9946[0m        [32m0.0161[0m       0.8319      0.8962        0.2208        0.0000  115.3576
     13      [36m0.9951[0m        [32m0.0154[0m       [35m0.8359[0m      [31m0.8999[0m        0.2238        0.0000  115.0770
     14      [36m0.9954[0m        [32m0.0145[0m       [35m0.8373[0m      0.8997        0.2246        0.0000  115.0979
     15      [36m0.9962[0m        [32m0.0138[0m       0.8352      0.8998        0.2292        0.0000  115.4996
     16      [36m0.9963[0m        [32m0.0131[0m       0.8352      [31m0.9001[0m        0.2343        0.0000  115.1784
     17      [36m0.9968[0m        [32m0.0124[0m       0.8333      0.8994        0.2343        0.0000  115.1849
     18      [36m0.9969[0m        [32m0.0120[0m       0.8337      0.8992        0.2375        0.0000  114.8329
Stopping since valid_loss has not improved in the last 11 epochs.
[24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.9256679170175304
F1 Macro Score after query 13: 0.9123109526164863
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multilabel/DinoS/average_confidence_seed42_lowLR\AL_average_confidence_results_for_multilabel_classification.pickle
