{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:01:34.642035Z",
     "iopub.status.busy": "2024-07-18T05:01:34.641701Z",
     "iopub.status.idle": "2024-07-18T05:01:42.903629Z",
     "shell.execute_reply": "2024-07-18T05:01:42.902768Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import modAL\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image \n",
    "from plotly import graph_objects, subplots\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import one_hot\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Scorer function and training setup imports\n",
    "from skorch.callbacks import EpochScoring\n",
    "from sklearn.metrics import f1_score, make_scorer, accuracy_score\n",
    "from skorch.helper import predefined_split\n",
    "from skorch.dataset import Dataset\n",
    "from skorch.classifier import NeuralNetClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:01:42.907297Z",
     "iopub.status.busy": "2024-07-18T05:01:42.906937Z",
     "iopub.status.idle": "2024-07-18T05:01:43.526625Z",
     "shell.execute_reply": "2024-07-18T05:01:43.525863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38400"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir = os.path.abspath(r\"/home/woody/iwfa/iwfa044h/CleanLab_Test/1_all_winding_images/\")\n",
    "len(os.listdir(image_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:01:43.559497Z",
     "iopub.status.busy": "2024-07-18T05:01:43.559219Z",
     "iopub.status.idle": "2024-07-18T05:01:43.598524Z",
     "shell.execute_reply": "2024-07-18T05:01:43.597722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26880, 5)\n",
      "(5760, 5)\n",
      "(5760, 5)\n"
     ]
    }
   ],
   "source": [
    "# df_dir = os.path.abspath(r\"/home/woody/iwfa/iwfa045h/labelling/1_all_winding_images/\")\n",
    "\n",
    "df_dir = os.path.abspath(r\"/home/woody/iwfa/iwfa044h/CleanLab_Test/2_labels/Updated_Labels/\")\n",
    "train_df = pd.read_csv(df_dir + \"/train_v2024-03-18.csv\")\n",
    "val_df = pd.read_csv(df_dir + \"/validation_v2024-03-18.csv\")\n",
    "test_df = pd.read_csv(df_dir + \"/test_v2024-03-18.csv\")\n",
    "\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:01:43.600794Z",
     "iopub.status.busy": "2024-07-18T05:01:43.600554Z",
     "iopub.status.idle": "2024-07-18T05:01:44.029051Z",
     "shell.execute_reply": "2024-07-18T05:01:44.028410Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26880/26880 [00:00<00:00, 89776.31it/s]\n",
      "100%|██████████| 5760/5760 [00:00<00:00, 100563.57it/s]\n",
      "100%|██████████| 5760/5760 [00:00<00:00, 100301.79it/s]\n"
     ]
    }
   ],
   "source": [
    "list_data_frame = [train_df, test_df, val_df]                       # List of data frames\n",
    "multiclass_labels = []\n",
    "\n",
    "for x in range(len(list_data_frame)):                               # Iterating to the list of data frames\n",
    "    labels = []\n",
    "    for y in tqdm(range(list_data_frame[x].shape[0])):              # Iterating to all the images of selected data frame and assigning labels\n",
    "        if list_data_frame[x]['multi-label_double_winding'][y] == 0:\n",
    "        \n",
    "            if list_data_frame[x]['multi-label_gap'][y] == 0:\n",
    "                \n",
    "                if list_data_frame[x]['multi-label_crossing'][y] == 0:\n",
    "                    labels.append('0')\n",
    "                else:\n",
    "                    labels.append('1')\n",
    "\n",
    "            else:\n",
    "                if list_data_frame[x]['multi-label_crossing'][y] == 0:\n",
    "                    labels.append('2')\n",
    "                else:\n",
    "                    labels.append('3')\n",
    "        \n",
    "        else:\n",
    "            if list_data_frame[x]['multi-label_gap'][y] == 0:\n",
    "\n",
    "                if list_data_frame[x]['multi-label_crossing'][y] == 0:\n",
    "                    labels.append('4')\n",
    "                else:\n",
    "                    labels.append('5')\n",
    "\n",
    "            else:\n",
    "                if list_data_frame[x]['multi-label_crossing'][y] == 0:\n",
    "                    labels.append('6')\n",
    "                else:\n",
    "                    labels.append('7')\n",
    "    multiclass_labels.append(labels)                                # Collecting list of train, val and test labels in another list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:01:44.031933Z",
     "iopub.status.busy": "2024-07-18T05:01:44.031601Z",
     "iopub.status.idle": "2024-07-18T05:01:44.049126Z",
     "shell.execute_reply": "2024-07-18T05:01:44.048494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(multiclass_labels))\n",
    "# MultiClass training data frame \n",
    "multiclass_train_df = train_df.assign(multiclass = multiclass_labels[0])\n",
    "multiclass_train_df = multiclass_train_df[['image', 'multiclass']].dropna()\n",
    "\n",
    "# MultiClass test data frame \n",
    "multiclass_test_df = test_df.assign(multiclass = multiclass_labels[1])\n",
    "multiclass_test_df = multiclass_test_df[['image', 'multiclass']].dropna()\n",
    "\n",
    "# MultiClass validation data frame \n",
    "multiclass_val_df = val_df.assign(multiclass = multiclass_labels[2])\n",
    "multiclass_val_df = multiclass_val_df[['image', 'multiclass']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:01:44.051834Z",
     "iopub.status.busy": "2024-07-18T05:01:44.051635Z",
     "iopub.status.idle": "2024-07-18T05:01:44.055620Z",
     "shell.execute_reply": "2024-07-18T05:01:44.055027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26880, 2), (5760, 2), (5760, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_train_df.shape, multiclass_test_df.shape, multiclass_val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:01:44.058358Z",
     "iopub.status.busy": "2024-07-18T05:01:44.058140Z",
     "iopub.status.idle": "2024-07-18T05:01:44.061775Z",
     "shell.execute_reply": "2024-07-18T05:01:44.061214Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# epochs = 100\n",
    "batch_size =8\n",
    "# layer_freeze= 69\n",
    "\n",
    "# learning_rate = 0.1\n",
    "# momentum_term = 0.2280969903050278\n",
    "\n",
    "# dropout_rate = 0.49809628309801696\n",
    "optimizer = 'SGD'\n",
    "\n",
    "\n",
    "# Initialising Active learner and query strategy using modAL\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import margin_sampling\n",
    "\n",
    "query_strategy = margin_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:01:44.064225Z",
     "iopub.status.busy": "2024-07-18T05:01:44.063990Z",
     "iopub.status.idle": "2024-07-18T05:01:44.068496Z",
     "shell.execute_reply": "2024-07-18T05:01:44.067857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated train_size: 2688\n"
     ]
    }
   ],
   "source": [
    "# Function to find the nearest multiple of base for a given number\n",
    "def batch(number, base):                                   \n",
    "    return base * round(number / base)\n",
    "\n",
    "# Directly set the training size based on the size of the dataset and batch size\n",
    "# Calculate initial training size as 10% of the dataset\n",
    "train_size = batch(int(0.1 * len(multiclass_train_df)), batch_size)\n",
    "\n",
    "print(f\"Calculated train_size: {train_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:01:44.071135Z",
     "iopub.status.busy": "2024-07-18T05:01:44.070739Z",
     "iopub.status.idle": "2024-07-18T05:01:44.081777Z",
     "shell.execute_reply": "2024-07-18T05:01:44.081284Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Shuffling the data frame \n",
    "multiclass_train_df = multiclass_train_df.sample(frac = 1, random_state = 1234)\n",
    "\n",
    "# Intial set must contain sample from each class\n",
    "initial_df = multiclass_train_df.groupby('multiclass').head(1).head(train_size)\n",
    "\n",
    "# Assigning remaining samples as the pool of data\n",
    "pool_df = multiclass_train_df.drop(initial_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:01:44.083829Z",
     "iopub.status.busy": "2024-07-18T05:01:44.083707Z",
     "iopub.status.idle": "2024-07-18T05:01:44.300298Z",
     "shell.execute_reply": "2024-07-18T05:01:44.299641Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 43.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training data shape: torch.Size([8, 224, 224, 3])\n",
      "X_train_initial shape: torch.Size([8, 224, 224, 3]), y_train_initial shape: torch.Size([8, 8])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define the target size for resizing images\n",
    "target_size = (224, 224)\n",
    "\n",
    "# Initialize empty lists for storing images and labels\n",
    "initial_train_image = []\n",
    "\n",
    "# Define a transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "# Load and preprocess images for initial training set\n",
    "for i in tqdm(range(initial_df.shape[0])):\n",
    "    image_path = os.path.join(image_dir, initial_df[\"image\"].iloc[i])\n",
    "    img = Image.open(image_path).convert(\"RGB\")  # Ensure the image is in RGB format\n",
    "    img = transform(img)\n",
    "    initial_train_image.append(img)\n",
    "\n",
    "# Convert the list of images to a PyTorch tensor and then permute\n",
    "X_train_initial = torch.stack(initial_train_image).permute(0, 2, 3, 1)  # Move the channel to the last dimension\n",
    "\n",
    "# Ensure the shape is [batch_size, 224, 224, 3]\n",
    "print(f\"Initial training data shape: {X_train_initial.shape}\")\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_multiclass = initial_df['multiclass'].astype(np.int64).to_numpy()  # Convert to NumPy array\n",
    "num_classes = len(np.unique(y_multiclass))\n",
    "y_train_initial = F.one_hot(torch.tensor(y_multiclass), num_classes=num_classes).float()\n",
    "\n",
    "# Print the shape of the resulting tensors\n",
    "print(f\"X_train_initial shape: {X_train_initial.shape}, y_train_initial shape: {y_train_initial.shape}\")\n",
    "print(y_train_initial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:01:44.301809Z",
     "iopub.status.busy": "2024-07-18T05:01:44.301597Z",
     "iopub.status.idle": "2024-07-18T05:05:33.887739Z",
     "shell.execute_reply": "2024-07-18T05:05:33.887336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_pool shape: torch.Size([26872, 224, 224, 3]), y_pool_initial shape: torch.Size([26872, 8])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize empty lists for storing images and labels\n",
    "pool_train_image = []\n",
    "\n",
    "# Load and preprocess images in batches\n",
    "for batch_start in range(0, pool_df.shape[0], batch_size):\n",
    "    batch_end = min(batch_start + batch_size, pool_df.shape[0])\n",
    "    batch_images = []\n",
    "\n",
    "    for i in range(batch_start, batch_end):\n",
    "        image_path = os.path.join(image_dir, pool_df[\"image\"].iloc[i])\n",
    "        img = Image.open(image_path).convert(\"RGB\")  # Ensures the image is in RGB format\n",
    "        img = transform(img)\n",
    "        img_rgb = img.permute(1, 2, 0)  # Change shape from [C, H, W] to [H, W, C]\n",
    "        batch_images.append(img_rgb)\n",
    "\n",
    "    # Convert the list of images to a PyTorch tensor\n",
    "    X_batch = torch.stack(batch_images)\n",
    "    pool_train_image.append(X_batch)\n",
    "\n",
    "# Concatenate all batches to create the final X_pool tensor\n",
    "X_pool = torch.cat(pool_train_image)\n",
    "\n",
    "# Convert multiclass labels to one-hot encoding and ensure proper shape\n",
    "y_multiclass = pool_df['multiclass'].astype(np.int64).to_numpy()\n",
    "num_classes = len(np.unique(y_multiclass))\n",
    "y_pool_initial = F.one_hot(torch.tensor(y_multiclass), num_classes=num_classes).float()\n",
    "\n",
    "# Ensure the tensor is in the shape [n_samples, n_classes]\n",
    "y_pool_initial = y_pool_initial.squeeze()  # This removes any singleton dimensions if present\n",
    "\n",
    "\n",
    "# Print the shape of the resulting tensors\n",
    "print(f\"X_pool shape: {X_pool.shape}, y_pool_initial shape: {y_pool_initial.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:05:33.889919Z",
     "iopub.status.busy": "2024-07-18T05:05:33.889405Z",
     "iopub.status.idle": "2024-07-18T05:06:23.386040Z",
     "shell.execute_reply": "2024-07-18T05:06:23.385648Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5760/5760 [00:48<00:00, 117.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val shape: torch.Size([5760, 224, 224, 3]), y_val shape: torch.Size([5760, 8])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize empty lists for storing images and labels\n",
    "val_images = []\n",
    "\n",
    "# Load and preprocess images\n",
    "for i in tqdm(range(multiclass_val_df.shape[0])):\n",
    "    image_path = os.path.join(image_dir, multiclass_val_df[\"image\"].iloc[i])\n",
    "    img = Image.open(image_path).convert(\"RGB\")  # Ensure the image is in RGB format\n",
    "    img = transform(img)\n",
    "    img_rgb = img.permute(1, 2, 0)  # Change shape from [C, H, W] to [H, W, C]\n",
    "    val_images.append(img_rgb)\n",
    "\n",
    "# Convert the list of images to a PyTorch tensor\n",
    "X_val = torch.stack(val_images)\n",
    "\n",
    "# Convert multiclass labels to a numpy array\n",
    "y_multiclass = multiclass_val_df['multiclass'].astype(np.int64).to_numpy()\n",
    "num_classes = len(np.unique(y_multiclass))\n",
    "y_val = F.one_hot(torch.tensor(y_multiclass), num_classes=num_classes).float()\n",
    "\n",
    "# Print the shape of the resulting tensors\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:06:23.387797Z",
     "iopub.status.busy": "2024-07-18T05:06:23.387552Z",
     "iopub.status.idle": "2024-07-18T05:07:12.504786Z",
     "shell.execute_reply": "2024-07-18T05:07:12.504373Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5760/5760 [00:48<00:00, 118.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: torch.Size([5760, 224, 224, 3]), y_test shape: torch.Size([5760, 8])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize empty lists for storing images and labels\n",
    "test_images = []\n",
    "\n",
    "# Load and preprocess images\n",
    "for i in tqdm(range(multiclass_test_df.shape[0])):\n",
    "    image_path = os.path.join(image_dir, multiclass_test_df[\"image\"].iloc[i])\n",
    "    img = Image.open(image_path).convert(\"RGB\")  # Ensure the image is in RGB format\n",
    "    img = transform(img)\n",
    "    img_rgb = img.permute(1, 2, 0)  # Change shape from [C, H, W] to [H, W, C]\n",
    "    test_images.append(img_rgb)\n",
    "\n",
    "# Convert the list of images to a PyTorch tensor\n",
    "X_test = torch.stack(test_images)\n",
    "\n",
    "# Convert multiclass labels to a numpy array\n",
    "y_multiclass = multiclass_test_df['multiclass'].astype(np.int64).to_numpy()\n",
    "num_classes = len(np.unique(y_multiclass))\n",
    "\n",
    "# Convert to one-hot encoding\n",
    "y_test = F.one_hot(torch.tensor(y_multiclass), num_classes=num_classes).float()\n",
    "\n",
    "# Print the shape of the resulting tensors\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:07:12.507341Z",
     "iopub.status.busy": "2024-07-18T05:07:12.506763Z",
     "iopub.status.idle": "2024-07-18T05:07:12.514288Z",
     "shell.execute_reply": "2024-07-18T05:07:12.514011Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import time\n",
    "from skorch.callbacks import Callback\n",
    "\n",
    "class CSVLogger(Callback):\n",
    "    \"\"\"Log epoch data to a CSV file.\"\"\"\n",
    "    def __init__(self, filename, fieldnames):\n",
    "        self.filename = filename\n",
    "        self.fieldnames = fieldnames\n",
    "        self.file_exist = os.path.exists(filename)  # Check if file already exists\n",
    "\n",
    "    def on_epoch_end(self, net, **kwargs):\n",
    "        logs = {key: net.history[-1, key] for key in self.fieldnames}\n",
    "\n",
    "        if not self.file_exist:\n",
    "            # Write headers to CSV\n",
    "            with open(self.filename, mode='w', newline='') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=self.fieldnames)\n",
    "                writer.writeheader()\n",
    "            self.file_exist = True\n",
    "        \n",
    "        # Write data to CSV\n",
    "        with open(self.filename, mode='a', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=self.fieldnames)\n",
    "            writer.writerow(logs)\n",
    "\n",
    "# Initialize unique identifier for the current run\n",
    "run_id = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Create directories for saving the results\n",
    "save_dir = f\"/home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/results/margin_sampling/{run_id}\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Field names for the logger\n",
    "fieldnames = ['epoch', 'train_f1', 'train_loss', 'valid_acc', 'valid_f1', 'valid_loss', 'dur']\n",
    "\n",
    "# Initialize CSVLogger with the path and fieldnames\n",
    "csv_logger = CSVLogger(os.path.join(save_dir, \"training_history.csv\"), fieldnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:07:12.516349Z",
     "iopub.status.busy": "2024-07-18T05:07:12.515791Z",
     "iopub.status.idle": "2024-07-18T05:07:12.518427Z",
     "shell.execute_reply": "2024-07-18T05:07:12.518150Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set proxy if necessary\n",
    "os.environ['http_proxy'] = 'http://proxy:80'\n",
    "os.environ['https_proxy'] = 'http://proxy:80'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:07:12.521265Z",
     "iopub.status.busy": "2024-07-18T05:07:12.520201Z",
     "iopub.status.idle": "2024-07-18T05:07:13.637940Z",
     "shell.execute_reply": "2024-07-18T05:07:13.637437Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.dataset import Dataset\n",
    "from skorch.callbacks import EpochScoring\n",
    "from sklearn.metrics import f1_score, make_scorer, accuracy_score\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import margin_sampling\n",
    "\n",
    "\n",
    "# Custom model class\n",
    "class CustomDINONormModel(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_rate, layer_freeze):\n",
    "        super(CustomDINONormModel, self).__init__()\n",
    "\n",
    "        # Add the local DINO repo to the Python path\n",
    "        dino_repo_path = Path('/home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches')\n",
    "        sys.path.insert(0, str(dino_repo_path))\n",
    "\n",
    "        # Import the VisionTransformer class directly from vision_transformer.py\n",
    "        from vision_transformer import vit_small\n",
    "\n",
    "        # Initialize the DINO model and load weights\n",
    "        self.dino_model = vit_small()\n",
    "        model_state = torch.load(dino_repo_path / \"/home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/dino_deitsmall16_pretrain(3).pth\", map_location=\"cpu\")\n",
    "        self.dino_model.load_state_dict(model_state, strict=False)\n",
    "\n",
    "        # Create the classifier layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(384, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "        self._freeze_layers(layer_freeze)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.shape[-1] == 3:\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x = self.dino_model(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _freeze_layers(self, num_freeze_layers):\n",
    "        for param in list(self.dino_model.parameters())[:num_freeze_layers]:\n",
    "            param.requires_grad = False\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 0.002\n",
    "momentum_term = 0.24729309193472406\n",
    "dropout_rate = 0.49709490164030934\n",
    "num_classes = 8\n",
    "layer_freeze = 65\n",
    "\n",
    "# Setup the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize the model\n",
    "model = CustomDINONormModel(num_classes=num_classes, dropout_rate=dropout_rate, layer_freeze=layer_freeze).to(device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:07:13.640907Z",
     "iopub.status.busy": "2024-07-18T05:07:13.640546Z",
     "iopub.status.idle": "2024-07-18T05:07:14.997537Z",
     "shell.execute_reply": "2024-07-18T05:07:14.997160Z"
    }
   },
   "outputs": [],
   "source": [
    "from skorch.callbacks import EarlyStopping, Checkpoint, Callback\n",
    "\n",
    "# Function to convert one-hot encoded labels to integer labels\n",
    "def convert_one_hot_to_labels(y):\n",
    "    return np.argmax(y, axis=1) if len(y.shape) > 1 else y\n",
    "\n",
    "# Ensure that y_train_initial, y_pool_initial, y_val, and y_test are in the correct format\n",
    "y_train_initial_np = convert_one_hot_to_labels(y_train_initial.clone().detach().cpu().numpy())\n",
    "y_pool_initial_np = convert_one_hot_to_labels(y_pool_initial.clone().detach().cpu().numpy())\n",
    "y_val_np = convert_one_hot_to_labels(y_val.clone().detach().cpu().numpy())\n",
    "y_test_np = convert_one_hot_to_labels(y_test.clone().detach().cpu().numpy())\n",
    "\n",
    "# Convert initial datasets to NumPy\n",
    "X_train_initial_np = X_train_initial.clone().detach().cpu().numpy()\n",
    "X_pool_np = X_pool.clone().detach().cpu().numpy()\n",
    "X_val_np = X_val.clone().detach().cpu().numpy()\n",
    "X_test_np = X_test.clone().detach().cpu().numpy()\n",
    "\n",
    "# Initialize cumulative datasets\n",
    "X_cumulative = X_train_initial_np.copy()\n",
    "y_cumulative = y_train_initial_np.copy()\n",
    "\n",
    "# Define scoring functions\n",
    "f1_scorer = make_scorer(f1_score, average='micro', zero_division=1)\n",
    "train_f1 = EpochScoring(f1_scorer, on_train=True, name='train_f1', lower_is_better=False)\n",
    "valid_f1 = EpochScoring(f1_scorer, on_train=False, name='valid_f1', lower_is_better=False)\n",
    "\n",
    "# Define a validation split\n",
    "valid_ds = Dataset(X_val_np, y_val_np)\n",
    "train_split = predefined_split(valid_ds)\n",
    "\n",
    "# Early stopping\n",
    "es = EarlyStopping(monitor='valid_loss', patience=8, lower_is_better=True)\n",
    "cp = Checkpoint(dirname='model_checkpoints', monitor='valid_loss_best')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:07:14.999527Z",
     "iopub.status.busy": "2024-07-18T05:07:14.999334Z",
     "iopub.status.idle": "2024-07-18T05:07:15.001778Z",
     "shell.execute_reply": "2024-07-18T05:07:15.001496Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = NeuralNetClassifier(\n",
    "    module=model,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    optimizer=optim.SGD,\n",
    "    optimizer__momentum=momentum_term,\n",
    "    lr=learning_rate,\n",
    "    max_epochs=100,\n",
    "    train_split=train_split,\n",
    "    device=device,\n",
    "    callbacks=[train_f1, valid_f1, es,csv_logger,cp],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:07:15.003329Z",
     "iopub.status.busy": "2024-07-18T05:07:15.003119Z",
     "iopub.status.idle": "2024-07-18T05:08:42.652440Z",
     "shell.execute_reply": "2024-07-18T05:08:42.652017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur\n",
      "-------  ----------  ------------  -----------  ----------  ------------  ----  ------\n",
      "      1      \u001b[36m0.1250\u001b[0m        \u001b[32m2.1870\u001b[0m       \u001b[35m0.1205\u001b[0m      \u001b[31m0.1205\u001b[0m        \u001b[94m2.0982\u001b[0m     +  5.4352\n",
      "      2      0.1250        \u001b[32m2.1322\u001b[0m       0.1205      0.1205        \u001b[94m2.0929\u001b[0m     +  4.9035\n",
      "      3      0.1250        \u001b[32m2.0572\u001b[0m       0.1205      0.1205        \u001b[94m2.0764\u001b[0m     +  4.7242\n",
      "      4      \u001b[36m0.2500\u001b[0m        \u001b[32m2.0525\u001b[0m       0.1205      0.1205        2.1010        4.7198\n",
      "      5      0.0000        2.1624       \u001b[35m0.2012\u001b[0m      \u001b[31m0.2012\u001b[0m        2.1067        4.7232\n",
      "      6      0.2500        \u001b[32m2.0371\u001b[0m       \u001b[35m0.2142\u001b[0m      \u001b[31m0.2142\u001b[0m        2.1079        4.7237\n",
      "      7      0.1250        2.0702       0.2142      0.2142        2.1070        4.7178\n",
      "      8      0.1250        2.1183       0.2142      0.2142        2.0952        4.7186\n",
      "      9      0.1250        2.1139       0.2142      0.2142        2.0845        4.7253\n",
      "     10      0.0000        2.0847       0.2142      0.2142        \u001b[94m2.0750\u001b[0m     +  4.7203\n",
      "     11      0.2500        2.1321       0.2142      0.2142        2.0795        4.7245\n",
      "     12      0.0000        2.1400       0.2142      0.2142        2.0851        4.7301\n",
      "     13      0.0000        2.1659       0.2142      0.2142        2.1098        4.7279\n",
      "     14      0.1250        \u001b[32m2.0188\u001b[0m       0.2142      0.2142        2.1303        4.7243\n",
      "     15      0.1250        2.0855       \u001b[35m0.2146\u001b[0m      \u001b[31m0.2146\u001b[0m        2.1327        4.8968\n",
      "     16      0.1250        \u001b[32m2.0017\u001b[0m       0.0606      0.0606        2.1414        4.7380\n",
      "     17      0.2500        2.1036       0.1441      0.1441        2.1321        4.7951\n",
      "Stopping since valid_loss has not improved in the last 8 epochs.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the ActiveLearner\n",
    "learner = ActiveLearner(\n",
    "    estimator=classifier,\n",
    "    query_strategy=margin_sampling,\n",
    "    X_training=X_cumulative,\n",
    "    y_training=y_cumulative\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:08:42.654246Z",
     "iopub.status.busy": "2024-07-18T05:08:42.653896Z",
     "iopub.status.idle": "2024-07-18T05:08:42.656122Z",
     "shell.execute_reply": "2024-07-18T05:08:42.655823Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize EarlyStopping and other callbacks\n",
    "total_samples = X_train_initial.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:08:42.657515Z",
     "iopub.status.busy": "2024-07-18T05:08:42.657312Z",
     "iopub.status.idle": "2024-07-18T05:08:47.548697Z",
     "shell.execute_reply": "2024-07-18T05:08:47.548350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing initial performance on test set...\n",
      "Initial F1 score: 0.18680555555555556\n",
      "Initial accuracy: 0.18680555555555556\n"
     ]
    }
   ],
   "source": [
    "# List to keep record of number of samples\n",
    "no_of_samples = [X_train_initial.shape[0]]\n",
    "performance_test_data = []\n",
    "performance_val_data = []\n",
    "acc_test_data = []\n",
    "f1_test_data = []\n",
    "\n",
    "# Function to get class indices from predictions\n",
    "def get_class_indices(y_pred):\n",
    "    if len(y_pred.shape) > 1 and y_pred.shape[1] > 1:\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "    return y_pred\n",
    "\n",
    "# Initial performance calculation\n",
    "print(\"Computing initial performance on test set...\")\n",
    "initial_y_pred = learner.predict(X_test.numpy())\n",
    "initial_y_pred = get_class_indices(initial_y_pred)\n",
    "\n",
    "# Convert y_test to class indices\n",
    "y_test_class_indices = get_class_indices(y_test.numpy())\n",
    "\n",
    "# Calculate initial F1 score and accuracy\n",
    "initial_f1 = f1_score(y_test_class_indices, initial_y_pred, average='micro')\n",
    "initial_acc = accuracy_score(y_test_class_indices, initial_y_pred)\n",
    "print(f\"Initial F1 score: {initial_f1}\")\n",
    "print(f\"Initial accuracy: {initial_acc}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T05:08:47.550358Z",
     "iopub.status.busy": "2024-07-18T05:08:47.550144Z",
     "iopub.status.idle": "2024-07-18T06:01:41.301148Z",
     "shell.execute_reply": "2024-07-18T06:01:41.299782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 1: Requesting 8 samples.\n",
      "Number of samples in pool before query: 26872\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur\n",
      "-------  ----------  ------------  -----------  ----------  ------------  ----  ------\n",
      "      1      \u001b[36m0.1875\u001b[0m        \u001b[32m2.0789\u001b[0m       \u001b[35m0.2144\u001b[0m      \u001b[31m0.2144\u001b[0m        \u001b[94m2.0756\u001b[0m     +  4.9367\n",
      "      2      0.1875        \u001b[32m2.0735\u001b[0m       \u001b[35m0.4285\u001b[0m      \u001b[31m0.4285\u001b[0m        \u001b[94m2.0115\u001b[0m     +  4.8784\n",
      "      3      \u001b[36m0.2500\u001b[0m        \u001b[32m2.0254\u001b[0m       \u001b[35m0.4479\u001b[0m      \u001b[31m0.4479\u001b[0m        \u001b[94m1.9699\u001b[0m     +  4.9001\n",
      "      4      0.1250        2.0716       0.4479      0.4479        \u001b[94m1.9365\u001b[0m     +  5.0326\n",
      "      5      0.1875        \u001b[32m2.0070\u001b[0m       0.4479      0.4479        \u001b[94m1.8963\u001b[0m     +  4.8801\n",
      "      6      \u001b[36m0.3125\u001b[0m        \u001b[32m1.9548\u001b[0m       0.4479      0.4479        \u001b[94m1.8650\u001b[0m     +  4.8885\n",
      "      7      \u001b[36m0.3750\u001b[0m        \u001b[32m1.9258\u001b[0m       0.4479      0.4479        \u001b[94m1.8324\u001b[0m     +  5.0371\n",
      "      8      0.3125        1.9787       0.4479      0.4479        \u001b[94m1.8177\u001b[0m     +  4.9088\n",
      "      9      0.3125        1.9761       0.4479      0.4479        \u001b[94m1.8003\u001b[0m     +  5.0097\n",
      "     10      \u001b[36m0.4375\u001b[0m        \u001b[32m1.8660\u001b[0m       0.4479      0.4479        \u001b[94m1.7742\u001b[0m     +  4.9460\n",
      "     11      0.3750        1.8931       0.4479      0.4479        \u001b[94m1.7440\u001b[0m     +  4.8918\n",
      "     12      0.2500        1.9660       0.4479      0.4479        \u001b[94m1.7332\u001b[0m     +  5.0549\n",
      "     13      0.3750        \u001b[32m1.8432\u001b[0m       0.4479      0.4479        \u001b[94m1.7229\u001b[0m     +  4.8968\n",
      "     14      0.3750        \u001b[32m1.8226\u001b[0m       0.4479      0.4479        \u001b[94m1.7080\u001b[0m     +  4.9296\n",
      "     15      0.3750        1.9166       0.4479      0.4479        \u001b[94m1.7068\u001b[0m     +  5.0331\n",
      "     16      0.3750        1.8713       0.4479      0.4479        \u001b[94m1.7044\u001b[0m     +  4.9007\n",
      "     17      0.3750        \u001b[32m1.8120\u001b[0m       0.4479      0.4479        \u001b[94m1.7033\u001b[0m     +  5.0547\n",
      "     18      0.3125        1.8736       0.4479      0.4479        \u001b[94m1.7006\u001b[0m     +  4.8865\n",
      "     19      0.3750        1.8580       0.4479      0.4479        \u001b[94m1.6940\u001b[0m     +  4.8969\n",
      "     20      0.3750        \u001b[32m1.7670\u001b[0m       0.4479      0.4479        \u001b[94m1.6874\u001b[0m     +  5.0803\n",
      "     21      0.4375        1.7899       0.4479      0.4479        \u001b[94m1.6851\u001b[0m     +  4.9026\n",
      "     22      0.3750        1.8767       0.4479      0.4479        \u001b[94m1.6789\u001b[0m     +  5.0118\n",
      "     23      0.3750        1.8866       0.4479      0.4479        \u001b[94m1.6762\u001b[0m     +  4.9550\n",
      "     24      0.3750        1.9046       0.4479      0.4479        \u001b[94m1.6739\u001b[0m     +  4.8759\n",
      "     25      0.3750        1.8066       0.4479      0.4479        \u001b[94m1.6697\u001b[0m     +  5.0393\n",
      "     26      0.3750        1.8501       0.4479      0.4479        \u001b[94m1.6688\u001b[0m     +  4.8759\n",
      "     27      0.3125        1.9114       0.4479      0.4479        1.6695        4.8897\n",
      "     28      0.3125        1.8687       0.4479      0.4479        1.6702        5.0006\n",
      "     29      0.3750        1.9575       0.4479      0.4479        1.6715        4.8414\n",
      "     30      0.3750        1.7922       0.4479      0.4479        1.6701        4.9484\n",
      "     31      0.3125        1.8372       0.4479      0.4479        \u001b[94m1.6679\u001b[0m     +  4.8646\n",
      "     32      0.3750        1.8987       0.4479      0.4479        1.6697        4.8680\n",
      "     33      0.3750        1.8855       0.4479      0.4479        1.6687        4.9868\n",
      "     34      0.3750        1.7730       0.4479      0.4479        \u001b[94m1.6658\u001b[0m     +  4.8253\n",
      "     35      0.4375        1.8980       0.4479      0.4479        \u001b[94m1.6634\u001b[0m     +  4.8367\n",
      "     36      0.3750        1.8841       0.4479      0.4479        1.6660        5.0044\n",
      "     37      0.3750        1.8862       0.4479      0.4479        1.6637        4.8120\n",
      "     38      0.3750        1.8212       0.4479      0.4479        \u001b[94m1.6594\u001b[0m     +  4.8970\n",
      "     39      0.3750        1.9418       0.4479      0.4479        \u001b[94m1.6578\u001b[0m     +  4.9097\n",
      "     40      0.3750        1.8199       0.4479      0.4479        \u001b[94m1.6561\u001b[0m     +  4.8697\n",
      "     41      0.3750        1.7779       0.4479      0.4479        \u001b[94m1.6512\u001b[0m     +  4.9952\n",
      "     42      0.3750        1.8834       0.4479      0.4479        \u001b[94m1.6483\u001b[0m     +  4.8825\n",
      "     43      0.3125        1.8942       0.4479      0.4479        \u001b[94m1.6481\u001b[0m     +  4.8375\n",
      "     44      0.3750        1.8021       0.4479      0.4479        \u001b[94m1.6449\u001b[0m     +  4.9961\n",
      "     45      0.3750        1.8285       0.4479      0.4479        1.6481        4.8682\n",
      "     46      0.3750        \u001b[32m1.6794\u001b[0m       0.4479      0.4479        1.6467        5.0078\n",
      "     47      0.3125        1.8660       0.4479      0.4479        1.6467        4.8617\n",
      "     48      0.3750        1.9930       0.4479      0.4479        1.6539        4.8245\n",
      "     49      0.3750        1.8112       0.4479      0.4479        1.6546        4.9687\n",
      "     50      0.3125        1.9078       0.4479      0.4479        1.6584        4.8220\n",
      "     51      0.3750        1.8657       0.4479      0.4479        1.6620        4.7978\n",
      "Stopping since valid_loss has not improved in the last 8 epochs.\n",
      "Accuracy after query 1: 0.4795138888888889\n",
      "F1 Score after query 1: 0.4795138888888889\n",
      "Number of samples used for retraining: 8\n",
      "Number of samples in pool after query: 26864\n",
      "\n",
      "Query 2: Requesting 16 samples.\n",
      "Number of samples in pool before query: 26864\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur\n",
      "-------  ----------  ------------  -----------  ----------  ------------  ----  ------\n",
      "      1      \u001b[36m0.4000\u001b[0m        \u001b[32m1.6285\u001b[0m       \u001b[35m0.4479\u001b[0m      \u001b[31m0.4479\u001b[0m        \u001b[94m1.6565\u001b[0m     +  4.9896\n",
      "      2      \u001b[36m0.4250\u001b[0m        \u001b[32m1.6243\u001b[0m       0.4479      0.4479        \u001b[94m1.6487\u001b[0m     +  4.8982\n",
      "      3      0.4250        \u001b[32m1.5493\u001b[0m       0.4479      0.4479        \u001b[94m1.6420\u001b[0m     +  4.9023\n",
      "      4      \u001b[36m0.4750\u001b[0m        \u001b[32m1.4308\u001b[0m       0.4479      0.4479        \u001b[94m1.6379\u001b[0m     +  4.8795\n",
      "      5      0.4750        1.4950       0.4479      0.4479        \u001b[94m1.6344\u001b[0m     +  5.0676\n",
      "      6      0.4500        1.4707       0.4479      0.4479        \u001b[94m1.6313\u001b[0m     +  4.9194\n",
      "      7      0.3500        1.5175       0.4479      0.4479        1.6344        4.9060\n",
      "      8      0.4000        \u001b[32m1.4289\u001b[0m       0.4479      0.4479        1.6368        5.0428\n",
      "      9      0.4750        1.4476       0.4479      0.4479        1.6374        4.8972\n",
      "     10      0.4500        1.4909       0.4479      0.4479        1.6414        4.8689\n",
      "     11      0.4750        1.4680       0.4479      0.4479        1.6452        4.8604\n",
      "     12      0.4000        1.5536       0.4479      0.4479        1.6471        4.9092\n",
      "     13      0.3250        1.5251       0.4479      0.4479        1.6487        5.0273\n",
      "Stopping since valid_loss has not improved in the last 8 epochs.\n",
      "Accuracy after query 2: 0.4795138888888889\n",
      "F1 Score after query 2: 0.4795138888888889\n",
      "Number of samples used for retraining: 24\n",
      "Number of samples in pool after query: 26848\n",
      "\n",
      "Query 3: Requesting 32 samples.\n",
      "Number of samples in pool before query: 26848\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur\n",
      "-------  ----------  ------------  -----------  ----------  ------------  ----  ------\n",
      "      1      \u001b[36m0.4271\u001b[0m        \u001b[32m1.3324\u001b[0m       \u001b[35m0.4479\u001b[0m      \u001b[31m0.4479\u001b[0m        \u001b[94m1.6543\u001b[0m     +  4.9478\n",
      "      2      \u001b[36m0.4583\u001b[0m        \u001b[32m1.3080\u001b[0m       0.4479      0.4479        1.6580        4.9745\n",
      "      3      0.4062        1.3466       0.4479      0.4479        1.6626        4.9409\n",
      "      4      0.3958        1.3476       0.4479      0.4479        1.6679        4.9310\n",
      "      5      0.3854        1.3106       0.4479      0.4479        1.6744        5.0988\n",
      "      6      0.3646        1.3310       0.4479      0.4479        1.6819        4.9380\n",
      "      7      0.4271        \u001b[32m1.3033\u001b[0m       0.4479      0.4479        1.6875        4.9436\n",
      "      8      0.4167        1.3273       0.4479      0.4479        1.6890        4.9275\n",
      "Stopping since valid_loss has not improved in the last 8 epochs.\n",
      "Accuracy after query 3: 0.4795138888888889\n",
      "F1 Score after query 3: 0.4795138888888889\n",
      "Number of samples used for retraining: 56\n",
      "Number of samples in pool after query: 26816\n",
      "\n",
      "Query 4: Requesting 56 samples.\n",
      "Number of samples in pool before query: 26816\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur\n",
      "-------  ----------  ------------  -----------  ----------  ------------  ----  ------\n",
      "      1      \u001b[36m0.4183\u001b[0m        \u001b[32m1.3754\u001b[0m       \u001b[35m0.2354\u001b[0m      \u001b[31m0.2354\u001b[0m        \u001b[94m1.7035\u001b[0m     +  5.1178\n",
      "      2      \u001b[36m0.4279\u001b[0m        \u001b[32m1.3257\u001b[0m       0.2142      0.2142        1.7170        5.1705\n",
      "      3      0.4279        \u001b[32m1.3011\u001b[0m       0.2142      0.2142        1.7228        5.1550\n",
      "      4      \u001b[36m0.4375\u001b[0m        1.3368       0.2142      0.2142        1.7291        5.1418\n",
      "      5      \u001b[36m0.4423\u001b[0m        1.3051       0.2142      0.2142        1.7290        5.1350\n",
      "      6      \u001b[36m0.4712\u001b[0m        \u001b[32m1.2952\u001b[0m       0.2142      0.2142        1.7298        5.2444\n",
      "      7      \u001b[36m0.4808\u001b[0m        1.3223       0.2142      0.2142        1.7309        5.1630\n",
      "      8      0.4663        1.3072       0.2142      0.2142        1.7301        5.1131\n",
      "Stopping since valid_loss has not improved in the last 8 epochs.\n",
      "Accuracy after query 4: 0.22152777777777777\n",
      "F1 Score after query 4: 0.22152777777777777\n",
      "Number of samples used for retraining: 112\n",
      "Number of samples in pool after query: 26760\n",
      "\n",
      "Query 5: Requesting 96 samples.\n",
      "Number of samples in pool before query: 26760\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur\n",
      "-------  ----------  ------------  -----------  ----------  ------------  ----  ------\n",
      "      1      \u001b[36m0.4279\u001b[0m        \u001b[32m1.2279\u001b[0m       \u001b[35m0.4479\u001b[0m      \u001b[31m0.4479\u001b[0m        \u001b[94m1.6876\u001b[0m     +  5.4646\n",
      "      2      \u001b[36m0.5096\u001b[0m        \u001b[32m1.2044\u001b[0m       0.4479      0.4479        1.7037        5.5101\n",
      "      3      0.4952        1.2046       0.4479      0.4479        1.7181        5.4965\n",
      "      4      0.5000        \u001b[32m1.2032\u001b[0m       0.4479      0.4479        1.7249        5.4740\n",
      "      5      0.5072        1.2521       0.4479      0.4479        1.7307        5.4887\n",
      "      6      0.5096        1.2038       0.4479      0.4479        1.7384        5.4893\n",
      "      7      0.4904        1.2298       0.4479      0.4479        1.7468        5.4862\n",
      "      8      0.5024        \u001b[32m1.1922\u001b[0m       0.4479      0.4479        1.7516        5.6515\n",
      "Stopping since valid_loss has not improved in the last 8 epochs.\n",
      "Accuracy after query 5: 0.4795138888888889\n",
      "F1 Score after query 5: 0.4795138888888889\n",
      "Number of samples used for retraining: 208\n",
      "Number of samples in pool after query: 26664\n",
      "\n",
      "Query 6: Requesting 176 samples.\n",
      "Number of samples in pool before query: 26664\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur\n",
      "-------  ----------  ------------  -----------  ----------  ------------  ----  ------\n",
      "      1      \u001b[36m0.5537\u001b[0m        \u001b[32m1.1932\u001b[0m       \u001b[35m0.4479\u001b[0m      \u001b[31m0.4479\u001b[0m        \u001b[94m1.6945\u001b[0m     +  6.0934\n",
      "      2      \u001b[36m0.5575\u001b[0m        1.2025       0.4479      0.4479        \u001b[94m1.6345\u001b[0m     +  6.1592\n",
      "      3      \u001b[36m0.5625\u001b[0m        \u001b[32m1.1863\u001b[0m       0.4479      0.4479        \u001b[94m1.5934\u001b[0m     +  6.1685\n",
      "      4      \u001b[36m0.5763\u001b[0m        \u001b[32m1.1741\u001b[0m       0.4479      0.4479        \u001b[94m1.5738\u001b[0m     +  6.1598\n",
      "      5      0.5587        1.1848       0.4479      0.4479        \u001b[94m1.5575\u001b[0m     +  6.1587\n",
      "      6      0.5625        1.1803       0.4479      0.4479        1.5634        6.3048\n",
      "      7      0.5575        1.1818       0.4479      0.4479        \u001b[94m1.5531\u001b[0m     +  6.1658\n",
      "      8      0.5650        \u001b[32m1.1589\u001b[0m       0.4479      0.4479        \u001b[94m1.5500\u001b[0m     +  6.1834\n",
      "      9      0.5600        \u001b[32m1.1510\u001b[0m       0.4479      0.4479        \u001b[94m1.5334\u001b[0m     +  6.1706\n",
      "     10      0.5663        \u001b[32m1.1503\u001b[0m       0.4479      0.4479        1.5341        6.1799\n",
      "     11      0.5687        \u001b[32m1.1449\u001b[0m       0.4479      0.4479        1.5419        6.2997\n",
      "     12      0.5637        1.1692       0.4479      0.4479        \u001b[94m1.5211\u001b[0m     +  6.1438\n",
      "     13      0.5737        1.1620       0.4479      0.4479        1.5334        6.1875\n",
      "     14      0.5713        \u001b[32m1.1356\u001b[0m       0.4479      0.4479        \u001b[94m1.5145\u001b[0m     +  6.1575\n",
      "     15      0.5625        1.1661       0.4479      0.4479        1.5207        6.3217\n",
      "     16      0.5737        1.1435       0.4479      0.4479        1.5227        6.1668\n",
      "     17      0.5713        1.1398       0.4479      0.4479        1.5280        6.1615\n",
      "     18      0.5750        1.1518       0.4479      0.4479        1.5254        6.1200\n",
      "     19      0.5675        \u001b[32m1.1347\u001b[0m       0.4479      0.4479        1.5304        6.2585\n",
      "     20      0.5650        1.1348       0.4479      0.4479        1.5159        6.1031\n",
      "     21      \u001b[36m0.5775\u001b[0m        1.1352       0.4479      0.4479        1.5326        6.1027\n",
      "Stopping since valid_loss has not improved in the last 8 epochs.\n",
      "Accuracy after query 6: 0.4795138888888889\n",
      "F1 Score after query 6: 0.4795138888888889\n",
      "Number of samples used for retraining: 384\n",
      "Number of samples in pool after query: 26488\n",
      "\n",
      "Query 7: Requesting 320 samples.\n",
      "Number of samples in pool before query: 26488\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur\n",
      "-------  ----------  ------------  -----------  ----------  ------------  ----  ------\n",
      "      1      \u001b[36m0.5485\u001b[0m        \u001b[32m1.2075\u001b[0m       \u001b[35m0.4479\u001b[0m      \u001b[31m0.4479\u001b[0m        \u001b[94m1.4097\u001b[0m     +  7.4305\n",
      "      2      0.5426        1.2271       0.4479      0.4479        1.4125        7.3541\n",
      "      3      \u001b[36m0.5525\u001b[0m        1.2221       0.4479      0.4479        \u001b[94m1.4056\u001b[0m     +  7.4604\n",
      "      4      0.5432        1.2139       0.4479      0.4479        \u001b[94m1.4050\u001b[0m     +  7.4088\n",
      "      5      0.5459        \u001b[32m1.2068\u001b[0m       0.4479      0.4479        \u001b[94m1.3994\u001b[0m     +  7.5226\n",
      "      6      0.5459        \u001b[32m1.1909\u001b[0m       0.4479      0.4479        1.4001        7.3938\n",
      "      7      0.5386        \u001b[32m1.1883\u001b[0m       0.4479      0.4479        \u001b[94m1.3978\u001b[0m     +  7.5062\n",
      "      8      0.5459        \u001b[32m1.1779\u001b[0m       0.4479      0.4479        \u001b[94m1.3873\u001b[0m     +  7.3747\n",
      "      9      \u001b[36m0.5605\u001b[0m        1.1899       0.4479      0.4479        1.3904        7.5226\n",
      "     10      0.5439        \u001b[32m1.1735\u001b[0m       0.4479      0.4479        \u001b[94m1.3824\u001b[0m     +  7.3292\n",
      "     11      0.5505        1.1763       0.4479      0.4479        \u001b[94m1.3822\u001b[0m     +  7.5795\n",
      "     12      \u001b[36m0.5618\u001b[0m        \u001b[32m1.1620\u001b[0m       0.4479      0.4479        \u001b[94m1.3807\u001b[0m     +  7.3772\n",
      "     13      0.5492        1.1709       0.4479      0.4479        \u001b[94m1.3752\u001b[0m     +  7.5242\n",
      "     14      0.5612        1.1745       0.4462      0.4462        \u001b[94m1.3716\u001b[0m     +  7.4097\n",
      "     15      0.5559        1.1680       0.4479      0.4479        1.3791        7.3810\n",
      "     16      \u001b[36m0.5652\u001b[0m        \u001b[32m1.1608\u001b[0m       0.4479      0.4479        \u001b[94m1.3708\u001b[0m     +  7.4928\n",
      "     17      0.5638        1.1683       0.4337      0.4337        1.3785        7.3750\n",
      "     18      \u001b[36m0.5751\u001b[0m        \u001b[32m1.1587\u001b[0m       0.4479      0.4479        1.3838        7.3458\n",
      "     19      0.5658        1.1640       0.4479      0.4479        1.3822        7.3176\n",
      "     20      0.5711        1.1828       0.4188      0.4188        1.3821        7.4597\n",
      "     21      0.5665        1.1836       0.4455      0.4455        1.3727        7.3158\n",
      "     22      \u001b[36m0.5964\u001b[0m        \u001b[32m1.1502\u001b[0m       0.4401      0.4401        \u001b[94m1.3697\u001b[0m     +  7.2825\n",
      "     23      0.5738        1.1751       0.4151      0.4151        1.3861        7.3624\n",
      "     24      0.5791        1.1746       0.4214      0.4214        1.3951        7.4676\n",
      "     25      0.5904        1.1544       \u001b[35m0.4481\u001b[0m      \u001b[31m0.4481\u001b[0m        1.3739        7.3216\n",
      "     26      0.5831        1.1515       0.4481      0.4481        1.3750        7.3028\n",
      "     27      \u001b[36m0.6011\u001b[0m        1.1601       0.4462      0.4462        1.3742        7.2786\n",
      "     28      0.5891        1.1570       0.4189      0.4189        1.3799        7.4451\n",
      "     29      0.5818        1.1605       0.4467      0.4467        \u001b[94m1.3686\u001b[0m     +  7.3035\n",
      "     30      \u001b[36m0.6097\u001b[0m        \u001b[32m1.1371\u001b[0m       \u001b[35m0.4483\u001b[0m      \u001b[31m0.4483\u001b[0m        1.3798        7.3701\n",
      "     31      0.5904        1.1464       0.4477      0.4477        1.3761        7.3457\n",
      "     32      0.5984        1.1410       0.4460      0.4460        1.3699        7.4637\n",
      "     33      0.6004        1.1519       \u001b[35m0.4486\u001b[0m      \u001b[31m0.4486\u001b[0m        1.3782        7.3023\n",
      "     34      \u001b[36m0.6144\u001b[0m        1.1526       0.4481      0.4481        1.3766        7.2962\n",
      "     35      0.6090        1.1410       0.4479      0.4479        1.3903        7.2908\n",
      "     36      0.6084        1.1519       0.4486      0.4486        1.3817        7.4258\n",
      "Stopping since valid_loss has not improved in the last 8 epochs.\n",
      "Accuracy after query 7: 0.4795138888888889\n",
      "F1 Score after query 7: 0.4795138888888889\n",
      "Number of samples used for retraining: 704\n",
      "Number of samples in pool after query: 26168\n",
      "\n",
      "Query 8: Requesting 560 samples.\n",
      "Number of samples in pool before query: 26168\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur\n",
      "-------  ----------  ------------  -----------  ----------  ------------  ----  ------\n",
      "      1      \u001b[36m0.5574\u001b[0m        \u001b[32m1.2096\u001b[0m       \u001b[35m0.2635\u001b[0m      \u001b[31m0.2635\u001b[0m        \u001b[94m1.5375\u001b[0m     +  9.3992\n",
      "      2      0.5300        1.2387       0.2464      0.2464        1.5488        9.6517\n",
      "      3      0.5289        1.2344       \u001b[35m0.3010\u001b[0m      \u001b[31m0.3010\u001b[0m        \u001b[94m1.5115\u001b[0m     +  9.4690\n",
      "      4      0.5397        1.2329       \u001b[35m0.3370\u001b[0m      \u001b[31m0.3370\u001b[0m        \u001b[94m1.4951\u001b[0m     +  9.5579\n",
      "      5      0.5405        1.2215       0.2825      0.2825        1.5214        9.4931\n",
      "      6      0.5289        1.2275       0.2582      0.2582        1.5344        9.4469\n",
      "      7      0.5383        1.2242       0.3312      0.3312        1.5003        9.4326\n",
      "      8      0.5538        1.2121       0.3066      0.3066        1.5114        9.5592\n",
      "      9      0.5527        1.2322       \u001b[35m0.3641\u001b[0m      \u001b[31m0.3641\u001b[0m        \u001b[94m1.4669\u001b[0m     +  9.4380\n",
      "     10      \u001b[36m0.5676\u001b[0m        1.2152       \u001b[35m0.3917\u001b[0m      \u001b[31m0.3917\u001b[0m        \u001b[94m1.4374\u001b[0m     +  9.5062\n",
      "     11      \u001b[36m0.5824\u001b[0m        \u001b[32m1.2091\u001b[0m       0.3644      0.3644        1.4721        9.5321\n",
      "     12      0.5477        1.2309       \u001b[35m0.3920\u001b[0m      \u001b[31m0.3920\u001b[0m        1.4422        9.6050\n",
      "     13      0.5560        1.2349       0.3689      0.3689        1.4679        9.4712\n",
      "     14      0.5766        \u001b[32m1.2079\u001b[0m       \u001b[35m0.4059\u001b[0m      \u001b[31m0.4059\u001b[0m        \u001b[94m1.4128\u001b[0m     +  9.4216\n",
      "     15      0.5665        1.2194       0.3922      0.3922        1.4268        9.5085\n",
      "     16      0.5423        1.2585       0.3601      0.3601        1.4743        9.4726\n",
      "     17      0.5759        \u001b[32m1.1926\u001b[0m       0.4042      0.4042        \u001b[94m1.4055\u001b[0m     +  9.4424\n",
      "     18      0.5267        1.2638       0.2934      0.2934        1.5137        9.6353\n",
      "     19      0.5390        1.1960       0.3889      0.3889        1.4353        9.4665\n",
      "     20      0.5419        1.2324       0.3814      0.3814        1.4564        9.4395\n",
      "     21      0.5679        1.2072       0.3929      0.3929        1.4203        9.4343\n",
      "     22      0.5491        1.2390       0.3903      0.3903        1.4347        9.4270\n",
      "     23      \u001b[36m0.5979\u001b[0m        \u001b[32m1.1781\u001b[0m       \u001b[35m0.4319\u001b[0m      \u001b[31m0.4319\u001b[0m        \u001b[94m1.3654\u001b[0m     +  9.4104\n",
      "     24      0.5014        1.2536       0.3594      0.3594        1.4755        9.6273\n",
      "     25      0.5434        1.1866       0.3908      0.3908        1.4327        9.4434\n",
      "     26      0.5419        1.1806       0.3972      0.3972        1.3856        9.4209\n",
      "     27      0.5502        \u001b[32m1.1666\u001b[0m       0.2884      0.2884        1.5324        9.4312\n",
      "     28      0.5376        \u001b[32m1.1659\u001b[0m       0.3932      0.3932        1.3780        9.4144\n",
      "     29      0.5719        \u001b[32m1.1635\u001b[0m       0.2142      0.2142        1.8753        9.4060\n",
      "     30      0.4946        1.2414       0.3139      0.3139        1.4903        9.4041\n",
      "Stopping since valid_loss has not improved in the last 8 epochs.\n",
      "Accuracy after query 8: 0.3463541666666667\n",
      "F1 Score after query 8: 0.3463541666666667\n",
      "Number of samples used for retraining: 1264\n",
      "Number of samples in pool after query: 25608\n",
      "\n",
      "Query 9: Requesting 1000 samples.\n",
      "Number of samples in pool before query: 25608\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur\n",
      "-------  ----------  ------------  -----------  ----------  ------------  ----  -------\n",
      "      1      \u001b[36m0.5236\u001b[0m        \u001b[32m1.2910\u001b[0m       \u001b[35m0.4479\u001b[0m      \u001b[31m0.4479\u001b[0m        \u001b[94m1.3457\u001b[0m     +  13.3440\n",
      "      2      \u001b[36m0.5352\u001b[0m        \u001b[32m1.2478\u001b[0m       \u001b[35m0.4507\u001b[0m      \u001b[31m0.4507\u001b[0m        1.3459        13.2957\n",
      "      3      \u001b[36m0.5419\u001b[0m        \u001b[32m1.2420\u001b[0m       \u001b[35m0.4556\u001b[0m      \u001b[31m0.4556\u001b[0m        \u001b[94m1.3375\u001b[0m     +  13.2490\n",
      "      4      0.5312        1.2479       0.4460      0.4460        1.3561        13.3212\n",
      "      5      \u001b[36m0.5550\u001b[0m        \u001b[32m1.2397\u001b[0m       0.4498      0.4498        1.3418        13.2563\n",
      "      6      \u001b[36m0.5592\u001b[0m        \u001b[32m1.2253\u001b[0m       0.4507      0.4507        1.3536        13.2288\n",
      "      7      0.5439        1.2417       0.4479      0.4479        \u001b[94m1.3243\u001b[0m     +  13.2318\n",
      "      8      0.5409        1.2393       0.4535      0.4535        \u001b[94m1.3170\u001b[0m     +  13.3074\n",
      "      9      0.5298        1.2440       0.4446      0.4446        \u001b[94m1.3162\u001b[0m     +  13.3263\n",
      "     10      0.5451        1.2402       \u001b[35m0.4559\u001b[0m      \u001b[31m0.4559\u001b[0m        1.3441        13.4426\n",
      "     11      0.5562        \u001b[32m1.2075\u001b[0m       \u001b[35m0.4568\u001b[0m      \u001b[31m0.4568\u001b[0m        1.3621        13.2601\n",
      "     12      0.5340        1.2256       0.4535      0.4535        1.3387        13.2364\n",
      "     13      0.5473        1.2190       \u001b[35m0.4571\u001b[0m      \u001b[31m0.4571\u001b[0m        1.3344        13.2375\n",
      "     14      0.5574        \u001b[32m1.1963\u001b[0m       0.4531      0.4531        1.3601        13.2259\n",
      "     15      0.5205        1.2586       0.4479      0.4479        1.3560        13.2411\n",
      "     16      0.4996        1.2474       0.4479      0.4479        1.3425        13.3297\n",
      "Stopping since valid_loss has not improved in the last 8 epochs.\n",
      "Accuracy after query 9: 0.5032986111111111\n",
      "F1 Score after query 9: 0.5032986111111111\n",
      "Number of samples used for retraining: 2264\n",
      "Number of samples in pool after query: 24608\n",
      "\n",
      "Query 10: Requesting 1776 samples.\n",
      "Number of samples in pool before query: 24608\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur\n",
      "-------  ----------  ------------  -----------  ----------  ------------  ----  -------\n",
      "      1      \u001b[36m0.5058\u001b[0m        \u001b[32m1.2933\u001b[0m       \u001b[35m0.4479\u001b[0m      \u001b[31m0.4479\u001b[0m        \u001b[94m1.3922\u001b[0m     +  20.2012\n",
      "      2      0.4848        1.2958       0.4479      0.4479        \u001b[94m1.3898\u001b[0m     +  20.1593\n",
      "      3      0.4959        \u001b[32m1.2801\u001b[0m       0.4479      0.4479        \u001b[94m1.3756\u001b[0m     +  20.1896\n",
      "      4      \u001b[36m0.5146\u001b[0m        \u001b[32m1.2640\u001b[0m       0.4479      0.4479        1.3959        20.1897\n",
      "      5      \u001b[36m0.5181\u001b[0m        1.2656       0.4479      0.4479        1.3814        20.0193\n",
      "      6      \u001b[36m0.5230\u001b[0m        \u001b[32m1.2604\u001b[0m       0.4479      0.4479        1.4033        20.0370\n",
      "      7      \u001b[36m0.5254\u001b[0m        \u001b[32m1.2527\u001b[0m       0.4479      0.4479        1.3911        20.1642\n",
      "      8      0.5188        1.2577       0.4479      0.4479        1.4001        20.0336\n",
      "      9      \u001b[36m0.5439\u001b[0m        \u001b[32m1.2249\u001b[0m       \u001b[35m0.4483\u001b[0m      \u001b[31m0.4483\u001b[0m        1.3792        20.1780\n",
      "     10      0.5298        1.2512       0.4481      0.4481        1.3781        20.0415\n",
      "Stopping since valid_loss has not improved in the last 8 epochs.\n",
      "Accuracy after query 10: 0.4795138888888889\n",
      "F1 Score after query 10: 0.4795138888888889\n",
      "Number of samples used for retraining: 4040\n",
      "Number of samples in pool after query: 22832\n",
      "\n",
      "Query 11: Requesting 3160 samples.\n",
      "Number of samples in pool before query: 22832\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur\n",
      "-------  ----------  ------------  -----------  ----------  ------------  ----  -------\n",
      "      1      \u001b[36m0.4768\u001b[0m        \u001b[32m1.2795\u001b[0m       \u001b[35m0.4589\u001b[0m      \u001b[31m0.4589\u001b[0m        \u001b[94m1.3350\u001b[0m     +  32.2561\n",
      "      2      \u001b[36m0.4983\u001b[0m        \u001b[32m1.2663\u001b[0m       \u001b[35m0.4628\u001b[0m      \u001b[31m0.4628\u001b[0m        \u001b[94m1.3249\u001b[0m     +  32.3454\n",
      "      3      0.4944        1.2693       0.4602      0.4602        1.3837        32.3875\n",
      "      4      \u001b[36m0.5012\u001b[0m        \u001b[32m1.2560\u001b[0m       \u001b[35m0.4734\u001b[0m      \u001b[31m0.4734\u001b[0m        1.3892        32.4901\n",
      "      5      0.4961        \u001b[32m1.2541\u001b[0m       0.4524      0.4524        1.4435        32.5057\n",
      "      6      \u001b[36m0.5080\u001b[0m        \u001b[32m1.2406\u001b[0m       \u001b[35m0.5038\u001b[0m      \u001b[31m0.5038\u001b[0m        \u001b[94m1.2918\u001b[0m     +  32.4429\n",
      "      7      0.5027        \u001b[32m1.2350\u001b[0m       \u001b[35m0.5061\u001b[0m      \u001b[31m0.5061\u001b[0m        1.3816        32.4633\n",
      "      8      0.4958        1.2608       0.4479      0.4479        1.4905        32.5401\n",
      "      9      0.5024        1.2469       0.4915      0.4915        1.4803        32.4819\n",
      "     10      \u001b[36m0.5088\u001b[0m        1.2362       0.4655      0.4655        1.4409        32.4655\n",
      "     11      0.5088        1.2441       \u001b[35m0.5219\u001b[0m      \u001b[31m0.5219\u001b[0m        1.3122        32.4474\n",
      "     12      \u001b[36m0.5160\u001b[0m        \u001b[32m1.2335\u001b[0m       0.4727      0.4727        1.4551        32.3806\n",
      "     13      \u001b[36m0.5175\u001b[0m        \u001b[32m1.2210\u001b[0m       0.4769      0.4769        1.4131        32.3600\n",
      "Stopping since valid_loss has not improved in the last 8 epochs.\n",
      "Accuracy after query 11: 0.42413194444444446\n",
      "F1 Score after query 11: 0.42413194444444446\n",
      "Number of samples used for retraining: 7200\n",
      "Number of samples in pool after query: 19672\n",
      "\n",
      "Query 12: Requesting 5624 samples.\n",
      "Number of samples in pool before query: 19672\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur\n",
      "-------  ----------  ------------  -----------  ----------  ------------  ----  -------\n",
      "      1      \u001b[36m0.5287\u001b[0m        \u001b[32m1.2051\u001b[0m       \u001b[35m0.4809\u001b[0m      \u001b[31m0.4809\u001b[0m        \u001b[94m1.3531\u001b[0m     +  54.7924\n",
      "      2      0.5274        \u001b[32m1.2038\u001b[0m       \u001b[35m0.5651\u001b[0m      \u001b[31m0.5651\u001b[0m        \u001b[94m1.2768\u001b[0m     +  54.1406\n",
      "      3      \u001b[36m0.5391\u001b[0m        \u001b[32m1.1819\u001b[0m       0.3736      0.3736        1.4808        54.0496\n",
      "      4      0.5291        1.1868       \u001b[35m0.5677\u001b[0m      \u001b[31m0.5677\u001b[0m        \u001b[94m1.2401\u001b[0m     +  53.8148\n",
      "      5      0.5227        1.2048       \u001b[35m0.5892\u001b[0m      \u001b[31m0.5892\u001b[0m        \u001b[94m1.1529\u001b[0m     +  54.2758\n",
      "      6      0.4996        1.2281       0.3861      0.3861        1.4031        54.1647\n",
      "      7      0.4687        1.3050       0.5255      0.5255        1.2263        54.1706\n",
      "      8      \u001b[36m0.5404\u001b[0m        \u001b[32m1.1568\u001b[0m       0.5257      0.5257        1.2673        54.2401\n",
      "      9      0.5398        \u001b[32m1.1493\u001b[0m       \u001b[35m0.6014\u001b[0m      \u001b[31m0.6014\u001b[0m        \u001b[94m1.1528\u001b[0m     +  54.0666\n",
      "     10      \u001b[36m0.5449\u001b[0m        \u001b[32m1.1459\u001b[0m       0.4163      0.4163        1.4345        54.0488\n",
      "     11      0.5358        1.1653       0.4844      0.4844        1.2720        54.1219\n",
      "     12      0.5396        1.1539       0.5901      0.5901        1.2087        54.0091\n",
      "Stopping since valid_loss has not improved in the last 8 epochs.\n",
      "Accuracy after query 12: 0.26666666666666666\n",
      "F1 Score after query 12: 0.26666666666666666\n",
      "Number of samples used for retraining: 12824\n",
      "Number of samples in pool after query: 14048\n",
      "Final F1 scores across iterations: [0.4795138888888889, 0.4795138888888889, 0.4795138888888889, 0.22152777777777777, 0.4795138888888889, 0.4795138888888889, 0.4795138888888889, 0.3463541666666667, 0.5032986111111111, 0.4795138888888889, 0.42413194444444446, 0.26666666666666666]\n",
      "Final accuracies across iterations: [0.4795138888888889, 0.4795138888888889, 0.4795138888888889, 0.22152777777777777, 0.4795138888888889, 0.4795138888888889, 0.4795138888888889, 0.3463541666666667, 0.5032986111111111, 0.4795138888888889, 0.42413194444444446, 0.26666666666666666]\n",
      "Performance results saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/results/performance_resultsMS.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Initialize tracking for Early Stopping\n",
    "best_f1_score = 0.0\n",
    "patience = 8  # Number of rounds to continue without improvement\n",
    "wait = 0  # Current wait time\n",
    "\n",
    "# Active learning loop parameters\n",
    "n_queries = 12\n",
    "initial_fraction = 0.1  # 10% of the dataset initially selected\n",
    "start_point = 2000  # Initial number of instances selected\n",
    "acc_test_data = []\n",
    "f1_test_data = []\n",
    "power=1\n",
    "\n",
    "for i in range(n_queries):\n",
    "    # Determine the number of samples to query\n",
    "    if i == 0:\n",
    "        n_instances = 8\n",
    "    else:\n",
    "        power += 0.25\n",
    "        n_instances = batch(int(np.ceil(np.power(10, power))), batch_size)\n",
    "    print(f\"\\nQuery {i + 1}: Requesting {n_instances} samples.\")\n",
    "    print(f\"Number of samples in pool before query: {X_pool_np.shape[0]}\")\n",
    "\n",
    "    # Perform the query\n",
    "    query_idx, query_instance = learner.query(X_pool_np, n_instances=n_instances)\n",
    "    X_query, y_query = X_pool_np[query_idx], y_pool_initial_np[query_idx]\n",
    "    y_query = convert_one_hot_to_labels(y_query)\n",
    "\n",
    "    # Update the cumulative datasets\n",
    "    X_cumulative = np.vstack((X_cumulative, X_query)) if i > 0 else X_query\n",
    "    y_cumulative = np.concatenate((y_cumulative, y_query)) if i > 0 else y_query\n",
    "\n",
    "    # Retrain the learner with the cumulative data\n",
    "    learner.teach(X=X_cumulative, y=y_cumulative, only_new=False)\n",
    "\n",
    "    # Evaluate the learner's performance\n",
    "    y_pred = learner.predict(X_test_np)\n",
    "    accuracy = accuracy_score(y_test_np, y_pred)\n",
    "    f1 = f1_score(y_test_np, y_pred, average='micro')\n",
    "    acc_test_data.append(accuracy)\n",
    "    f1_test_data.append(f1)\n",
    "\n",
    "    # Output the performance metrics\n",
    "    print(f\"Accuracy after query {i + 1}: {accuracy}\")\n",
    "    print(f\"F1 Score after query {i + 1}: {f1}\")\n",
    "    print(f\"Number of samples used for retraining: {len(X_cumulative)}\")\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if f1 > best_f1_score:\n",
    "        best_f1_score = f1\n",
    "        wait = 0  # reset the wait counter\n",
    "    else:\n",
    "        wait += 1  # increment the wait counter\n",
    "        if wait >= patience:\n",
    "            print(\"Stopping early due to no improvement in F1 score.\")\n",
    "            break\n",
    "\n",
    "    # Remove queried instances from the pool\n",
    "    X_pool_np = np.delete(X_pool_np, query_idx, axis=0)\n",
    "    y_pool_initial_np = np.delete(y_pool_initial_np, query_idx, axis=0)\n",
    "    print(f\"Number of samples in pool after query: {X_pool_np.shape[0]}\")\n",
    "\n",
    "# Log the final performance across all queries\n",
    "print(f\"Final F1 scores across iterations: {f1_test_data}\")\n",
    "print(f\"Final accuracies across iterations: {acc_test_data}\")\n",
    "\n",
    "# Save the performance results\n",
    "performance_filename = \"/home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/results/performance_resultsMS.npy\"\n",
    "np.save(performance_filename, {\"f1_scores\": f1_test_data, \"accuracies\": acc_test_data})\n",
    "print(f\"Performance results saved to {performance_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:01:41.340642Z",
     "iopub.status.busy": "2024-07-18T06:01:41.340328Z",
     "iopub.status.idle": "2024-07-18T06:01:41.347741Z",
     "shell.execute_reply": "2024-07-18T06:01:41.347116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4795138888888889,\n",
       " 0.4795138888888889,\n",
       " 0.4795138888888889,\n",
       " 0.22152777777777777,\n",
       " 0.4795138888888889,\n",
       " 0.4795138888888889,\n",
       " 0.4795138888888889,\n",
       " 0.3463541666666667,\n",
       " 0.5032986111111111,\n",
       " 0.4795138888888889,\n",
       " 0.42413194444444446,\n",
       " 0.26666666666666666]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_test_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ActiveLearning01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
