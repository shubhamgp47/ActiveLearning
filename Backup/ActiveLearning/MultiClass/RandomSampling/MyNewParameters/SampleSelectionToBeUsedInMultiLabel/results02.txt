python .\FixmulticlassRSmicroResults.py
(26880, 5)
(5760, 5)
(5760, 5)
100%|████████████████████████████████████████████████████████████████████████████████| 26880/26880 [00:00<00:00, 123690.63it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 5760/5760 [00:00<00:00, 123654.22it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 5760/5760 [00:00<00:00, 121992.70it/s]
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
Using cache found in C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main
C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3) y_initial_np: (8,)
X_train_np: (26880, 224, 224, 3) y_train_np: (26880,)
X_pool_np: (26872, 224, 224, 3) y_pool_np: (26872,)
X_test_np: (5760, 224, 224, 3) y_test_np: (5760,)
X_val_np: (5760, 224, 224, 3) y_val_np: (5760,)

Iteration 1: Using the initial 8 samples already in X_train_initial_np and y_train_initial_np.
Number of samples in training set: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.1562        2.1355       0.2917      0.3481        2.0132     +  7.7344
      2      0.3333        1.9733       0.1599      0.3376        2.0867        6.9729
      3      0.5208        1.9788       0.1938      0.4529        1.9928     +  6.9255
      4      0.4250        1.8812       0.2028      0.3280        1.9951        6.9621
      5      0.5208        1.8033       0.2214      0.1955        2.0114        6.9930
      6      0.5833        1.8121       0.2814      0.4893        1.9696     +  6.9990
      7      0.5208        1.7228       0.1812      0.3494        2.0475        7.0064
      8      0.6667        1.6421       0.1920      0.4828        2.0661        7.0766
      9      0.8333        1.6067       0.1988      0.3585        2.1124        7.0760
     10      0.6667        1.5262       0.2260      0.3639        1.9965        7.1264
     11      0.8333        1.4831       0.2168      0.3705        2.0614        7.1515
     12      1.0000        1.4420       0.2160      0.2428        2.0879        7.1494
     13      0.8333        1.4156       0.2009      0.3637        2.0876        7.1910
     14      0.6667        1.4264       0.2144      0.3608        2.0701        7.1645
     15      1.0000        1.2840       0.2122      0.4925        2.0253        7.1841
     16      1.0000        1.3320       0.2073      0.3663        2.0673        7.1893
     17      0.8333        1.2895       0.2207      0.3638        2.0367        7.2160
     18      1.0000        1.2312       0.2026      0.3653        2.1436        7.2124
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.2300347222222222
Test Accuracy: 0.2300347222222222
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_0.pt

Iteration 2: Requesting 16 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      1.0000        1.1369       0.1335      0.3195        2.2159     +  7.2005
      2      1.0000        1.4925       0.2420      0.5121        1.9754     +  7.1971
      3      1.0000        1.2655       0.1976      0.3631        2.0961        7.2029
      4      1.0000        1.1888       0.2271      0.2544        2.0224        7.2211
      5      1.0000        1.0584       0.2332      0.3788        2.0198        7.2332
      6      1.0000        0.9757       0.2405      0.3878        2.0410        7.2412
      7      1.0000        0.9798       0.2318      0.3903        2.0418        7.2426
      8      1.0000        0.9341       0.2358      0.3848        2.0543        7.2556
      9      1.0000        0.9259       0.2309      0.3874        2.0537        7.2431
     10      1.0000        0.8985       0.2245      0.3815        2.0786        7.2566
     11      1.0000        0.8527       0.2297      0.3913        2.0458        7.2431
     12      1.0000        0.8532       0.2054      0.3718        2.0951        7.2562
     13      1.0000        0.8710       0.2328      0.3877        2.0397        7.2435
     14      1.0000        0.8218       0.2177      0.3856        2.1052        7.2361
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.23524305555555555
Test Accuracy: 0.23524305555555555
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_1.pt

Iteration 3: Requesting 32 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.5030        1.6837       0.4799      0.3994        1.6240     +  7.2593
      2      0.5254        1.4663       0.3950      0.4117        1.7704        7.2404
      3      0.7247        1.3967       0.4628      0.2228        1.6768        7.3008
      4      0.5978        1.4867       0.4188      0.5384        1.6200     +  7.2716
      5      0.8542        1.2859       0.5205      0.5507        1.5707     +  7.2884
      6      0.7817        1.1981       0.4392      0.5465        1.6041        7.2635
      7      0.8628        1.1215       0.5470      0.5756        1.5586     +  7.2756
      8      0.8665        1.0929       0.5495      0.5850        1.5435     +  7.2579
      9      0.8665        1.0386       0.5470      0.7074        1.5315     +  7.2779
     10      0.8642        0.9762       0.4977      0.5743        1.5856        7.2538
     11      0.8854        0.9631       0.5528      0.6960        1.5040     +  7.2684
     12      0.9470        0.9386       0.4939      0.5749        1.5927        7.2614
     13      0.8854        0.9362       0.5396      0.2978        1.4789     +  7.2784
     14      0.8958        0.9816       0.4090      0.6700        1.7479        7.2702
     15      0.8854        0.9920       0.5325      0.4146        1.4745     +  7.2529
     16      0.8980        0.9473       0.5123      0.8326        1.6254        7.2571
     17      1.0000        0.8714       0.5660      0.5936        1.4892        7.2636
     18      0.8854        0.8523       0.5602      0.7076        1.4893        7.2472
     19      1.0000        0.8004       0.5465      0.5897        1.5017        7.2295
     20      1.0000        0.7991       0.5828      0.7163        1.4645     +  7.2485
     21      1.0000        0.8087       0.4887      0.4494        1.5289        7.2424
     22      1.0000        0.7943       0.5863      0.7168        1.4575     +  7.2776
     23      1.0000        0.8053       0.5102      0.5784        1.5004        7.2708
     24      1.0000        0.7829       0.6059      0.7301        1.4445     +  7.2669
     25      1.0000        0.7470       0.5325      0.5891        1.5142        7.2716
     26      1.0000        0.7531       0.5983      0.7291        1.4279     +  7.2823
     27      1.0000        0.7259       0.5401      0.5870        1.4660        7.2687
     28      1.0000        0.7115       0.5913      0.7281        1.4441        7.2773
     29      1.0000        0.7385       0.5634      0.7179        1.4437        7.2961
     30      1.0000        0.7067       0.5823      0.7290        1.4568        7.2754
     31      1.0000        0.6712       0.5786      0.7231        1.4333        7.2822
     32      1.0000        0.6783       0.5757      0.7254        1.4602        7.2878
     33      1.0000        0.6683       0.5648      0.7245        1.4685        7.2829
     34      1.0000        0.6706       0.5818      0.7259        1.4389        7.2557
     35      1.0000        0.6885       0.5840      0.7289        1.4442        7.2669
     36      1.0000        0.6623       0.5842      0.7267        1.4300        7.2867
     37      1.0000        0.6384       0.5845      0.7294        1.4489        7.2746
     38      1.0000        0.6361       0.5668      0.8442        1.4271     +  7.2818
     39      1.0000        0.6285       0.5946      0.7309        1.4432        7.2793
     40      1.0000        0.6189       0.5476      0.7167        1.4629        7.2884
     41      1.0000        0.6186       0.5898      0.7276        1.4376        7.2760
     42      1.0000        0.6449       0.5446      0.7120        1.4473        7.2951
     43      1.0000        0.6128       0.5977      0.7332        1.4221     +  7.2839
     44      1.0000        0.6162       0.5502      0.7128        1.4385        7.2690
     45      1.0000        0.6030       0.6007      0.7339        1.4214     +  7.2901
     46      1.0000        0.6059       0.5337      0.5898        1.4555        7.2563
     47      1.0000        0.6311       0.5934      0.7292        1.4401        7.2759
     48      1.0000        0.6186       0.5316      0.7114        1.4554        7.2779
     49      1.0000        0.6205       0.6016      0.7365        1.4319        7.2641
     50      1.0000        0.6093       0.5457      0.7167        1.4459        7.2550
     51      1.0000        0.5888       0.5915      0.7343        1.4308        7.2566
     52      1.0000        0.5908       0.5658      0.7220        1.4108     +  7.2568
     53      1.0000        0.5731       0.5906      0.7315        1.4278        7.2455
     54      1.0000        0.5715       0.5934      0.7341        1.4031     +  7.2798
     55      1.0000        0.5769       0.5767      0.7214        1.4142        7.2524
     56      1.0000        0.5762       0.6002      0.7353        1.3912     +  7.2853
     57      1.0000        0.5725       0.5707      0.7200        1.4208        7.2724
     58      1.0000        0.5559       0.5988      0.7362        1.4033        7.2581
     59      1.0000        0.5562       0.5859      0.7307        1.4205        7.2567
     60      1.0000        0.5433       0.5976      0.7351        1.4009        7.2688
     61      1.0000        0.5631       0.5762      0.7292        1.4219        7.2738
     62      1.0000        0.5494       0.5905      0.7334        1.4033        7.2738
     63      1.0000        0.5522       0.6031      0.7371        1.3980        7.2707
     64      1.0000        0.5445       0.5674      0.7274        1.4310        7.2770
     65      1.0000        0.5366       0.6043      0.7355        1.3946        7.2798
     66      1.0000        0.5465       0.5578      0.7217        1.4352        7.2651
     67      1.0000        0.5458       0.6061      0.7363        1.3972        7.2413
     68      1.0000        0.5519       0.5472      0.7054        1.4274        7.2444
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.5348958333333333
Test Accuracy: 0.5348958333333333
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_2.pt

Iteration 4: Requesting 56 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.7204        1.1365       0.4479      0.0773        1.6712     +  7.4054
      2      0.0705        1.6096       0.4189      0.1655        1.5928     +  7.3550
      3      0.3493        1.4203       0.5257      0.2809        1.3374     +  7.3357
      4      0.6398        1.1017       0.7378      0.2795        1.1308     +  7.3561
      5      0.8530        0.9207       0.6750      0.5052        1.1293     +  7.3584
      6      0.7948        0.8611       0.6623      0.3217        1.1733        7.3525
      7      0.8325        0.8709       0.6175      0.4758        1.2100        7.3569
      8      0.8071        0.8710       0.6622      0.5714        1.1439        7.3514
      9      0.8233        0.8359       0.7488      0.4125        1.0344     +  7.3735
     10      0.8906        0.7231       0.6972      0.5096        1.0564        7.3535
     11      0.9189        0.7122       0.7493      0.4131        1.0106     +  7.3723
     12      0.8530        0.6919       0.6995      0.7939        1.0895        7.3808
     13      0.9418        0.6963       0.7439      0.2832        1.0193        7.3337
     14      0.8530        0.6825       0.7002      0.7943        1.0735        7.3205
     15      0.9418        0.6504       0.7465      0.4107        0.9997     +  7.3423
     16      0.8530        0.6301       0.7156      0.7922        1.0368        7.3229
     17      0.9722        0.6152       0.7340      0.5309        1.0004        7.3722
     18      0.9189        0.6137       0.7373      0.6744        0.9999        7.3682
     19      0.9571        0.5877       0.7372      0.6684        0.9961     +  7.3663
     20      1.0000        0.5818       0.7349      0.7991        0.9997        7.3591
     21      1.0000        0.5645       0.7285      0.6651        1.0057        7.3736
     22      1.0000        0.5688       0.7326      0.7987        1.0028        7.3704
     23      0.9722        0.5582       0.7340      0.6639        0.9982        7.3652
     24      1.0000        0.5481       0.7339      0.8060        1.0136        7.3723
     25      1.0000        0.5485       0.7368      0.5394        0.9865     +  7.3670
     26      1.0000        0.5363       0.7351      0.8032        0.9950        7.3323
     27      1.0000        0.5327       0.7372      0.5424        0.9907        7.3600
     28      1.0000        0.5332       0.7351      0.8042        0.9869        7.3652
     29      1.0000        0.5269       0.7354      0.6675        0.9894        7.3333
     30      1.0000        0.5239       0.7361      0.6733        0.9845     +  7.3294
     31      1.0000        0.5204       0.7349      0.5428        0.9855        7.3247
     32      1.0000        0.5137       0.7321      0.6722        0.9888        7.3267
     33      1.0000        0.5118       0.7358      0.5434        0.9818     +  7.3734
     34      1.0000        0.5056       0.7226      0.6638        0.9971        7.3514
     35      1.0000        0.4944       0.7427      0.6754        0.9767     +  7.3592
     36      1.0000        0.4964       0.7306      0.6664        0.9870        7.3395
     37      1.0000        0.5014       0.7384      0.6737        0.9805        7.3326
     38      1.0000        0.4833       0.7333      0.5455        0.9773        7.3519
     39      1.0000        0.4964       0.7436      0.6760        0.9781        7.3470
     40      1.0000        0.4841       0.7326      0.6715        0.9747     +  7.3463
     41      1.0000        0.4892       0.7451      0.6768        0.9749        7.3560
     42      1.0000        0.4820       0.7233      0.6685        0.9918        7.3525
     43      1.0000        0.4812       0.7417      0.6737        0.9734     +  7.3382
     44      1.0000        0.4744       0.7309      0.7961        0.9846        7.3360
     45      1.0000        0.4744       0.7401      0.6753        0.9702     +  7.3268
     46      1.0000        0.4553       0.7319      0.6687        0.9802        7.3205
     47      1.0000        0.4687       0.7425      0.5523        0.9661     +  7.3161
     48      1.0000        0.4593       0.7347      0.5439        0.9729        7.3061
     49      1.0000        0.4653       0.7417      0.6805        0.9673        7.3415
     50      1.0000        0.4696       0.7328      0.4190        0.9712        7.3576
     51      1.0000        0.4568       0.7378      0.6760        0.9704        7.3548
     52      1.0000        0.4497       0.7316      0.7951        0.9739        7.3672
     53      1.0000        0.4569       0.7418      0.6757        0.9620     +  7.3661
     54      1.0000        0.4455       0.7328      0.6719        0.9662        7.3409
     55      1.0000        0.4388       0.7295      0.7938        0.9773        7.3500
     56      1.0000        0.4467       0.7368      0.4205        0.9624        7.3723
     57      1.0000        0.4390       0.7349      0.6743        0.9727        7.3672
     58      1.0000        0.4370       0.7398      0.5481        0.9599     +  7.3696
     59      1.0000        0.4425       0.7278      0.6711        0.9772        7.3605
     60      1.0000        0.4335       0.7352      0.5460        0.9623        7.3799
     61      1.0000        0.4382       0.7323      0.6718        0.9652        7.3611
     62      1.0000        0.4375       0.7262      0.5391        0.9744        7.3203
     63      1.0000        0.4298       0.7332      0.5503        0.9573     +  7.3226
     64      1.0000        0.4353       0.7276      0.5383        0.9745        7.3191
     65      1.0000        0.4319       0.7297      0.6764        0.9709        7.3351
     66      1.0000        0.4298       0.7288      0.5386        0.9708        7.3686
     67      1.0000        0.4273       0.7385      0.6854        0.9570     +  7.3520
     68      1.0000        0.4339       0.7161      0.5261        0.9878        7.3622
     69      1.0000        0.4365       0.7401      0.5589        0.9512     +  7.3618
     70      1.0000        0.4266       0.7092      0.5209        0.9909        7.3557
     71      1.0000        0.4300       0.7370      0.5561        0.9538        7.3590
     72      1.0000        0.4283       0.7128      0.5285        0.9837        7.3703
     73      1.0000        0.4167       0.7457      0.6812        0.9440     +  7.3859
     74      1.0000        0.4157       0.7220      0.5385        0.9738        7.3442
     75      1.0000        0.4111       0.7370      0.6762        0.9499        7.3392
     76      1.0000        0.4111       0.7306      0.5414        0.9622        7.3679
     77      1.0000        0.4182       0.7358      0.6747        0.9536        7.3683
     78      1.0000        0.4159       0.7306      0.5427        0.9601        7.3271
     79      1.0000        0.4071       0.7352      0.6765        0.9575        7.3211
     80      1.0000        0.4023       0.7363      0.4214        0.9512        7.3288
     81      1.0000        0.4104       0.7290      0.6730        0.9683        7.3301
     82      1.0000        0.4036       0.7372      0.5481        0.9464        7.3547
     83      1.0000        0.4134       0.7351      0.6772        0.9596        7.3678
     84      1.0000        0.4155       0.7358      0.5465        0.9495        7.3491
     85      1.0000        0.3980       0.7318      0.6741        0.9606        7.3342
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.7385416666666665
Test Accuracy: 0.7385416666666667
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_3.pt

Iteration 5: Requesting 96 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.9120        0.6345       0.4901      0.2458        1.4774     +  7.5853
      2      0.1726        1.2992       0.2333      0.0634        2.2031        7.5194
      3      0.1012        1.9221       0.6807      0.2659        1.1296     +  7.5008
      4      0.4524        1.0329       0.6616      0.1939        1.1255     +  7.4974
      5      0.3476        0.9125       0.7174      0.4007        0.9237     +  7.5067
      6      0.9167        0.6122       0.7385      0.4223        0.8898     +  7.5051
      7      0.9631        0.5304       0.7455      0.4237        0.8917        7.4956
      8      0.9748        0.5058       0.7441      0.4403        0.8785     +  7.4969
      9      0.9773        0.5000       0.7399      0.4097        0.9268        7.4611
     10      0.9422        0.5264       0.6766      0.2921        1.0169        7.4809
     11      0.9292        0.6256       0.6878      0.3656        1.0810        7.5008
     12      0.8202        0.6754       0.7224      0.4100        0.9194        7.4971
     13      0.9835        0.4750       0.7576      0.4399        0.8487     +  7.5322
     14      0.9801        0.4577       0.7356      0.4216        0.8888        7.5358
     15      0.9912        0.4402       0.7476      0.4336        0.8645        7.5392
     16      1.0000        0.4367       0.7432      0.4284        0.8746        7.5114
     17      0.9912        0.4293       0.7472      0.4316        0.8689        7.5071
     18      1.0000        0.4213       0.7464      0.4313        0.8698        7.5037
     19      1.0000        0.4223       0.7441      0.4289        0.8748        7.4937
     20      1.0000        0.4252       0.7484      0.4334        0.8665        7.4939
     21      1.0000        0.4099       0.7427      0.4279        0.8779        7.5122
     22      1.0000        0.4072       0.7472      0.4314        0.8699        7.5085
     23      1.0000        0.4075       0.7415      0.4279        0.8811        7.4819
     24      1.0000        0.4027       0.7472      0.4305        0.8672        7.4833
     25      1.0000        0.3929       0.7410      0.4271        0.8801        7.4652
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.7552083333333334
Test Accuracy: 0.7552083333333334
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_4.pt

Iteration 6: Requesting 176 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.7587        1.1027       0.6464      0.2472        1.1461     +  7.8685
      2      0.3621        1.1028       0.6873      0.2655        0.9907     +  7.7764
      3      0.6185        0.7659       0.7285      0.3036        0.8208     +  7.7738
      4      0.8564        0.6615       0.7391      0.3175        0.8238        7.7867
      5      0.9166        0.6208       0.7524      0.3289        0.7915     +  7.8056
      6      0.9211        0.5685       0.7441      0.3248        0.8054        7.7806
      7      0.9258        0.5437       0.7502      0.3268        0.7892     +  7.7678
      8      0.9302        0.5149       0.7533      0.3292        0.7877     +  7.7797
      9      0.9416        0.5040       0.7509      0.3294        0.7875     +  7.7787
     10      0.9417        0.4941       0.7425      0.3240        0.8082        7.7572
     11      0.9487        0.4727       0.7503      0.3299        0.7937        7.7660
     12      0.9487        0.4639       0.7455      0.3293        0.8013        7.7451
     13      0.9487        0.4536       0.7470      0.3297        0.8008        7.7631
     14      0.9640        0.4372       0.7611      0.3305        0.7897        7.7460
     15      0.9640        0.4197       0.7443      0.3122        0.8218        7.7742
     16      0.9640        0.4222       0.7498      0.3195        0.8093        7.7622
     17      0.9640        0.4090       0.7439      0.3163        0.8193        7.7944
     18      0.9640        0.4017       0.7451      0.3182        0.8136        7.7562
     19      0.9640        0.3979       0.7524      0.3220        0.8091        7.7675
     20      0.9676        0.3872       0.7601      0.3262        0.7919        7.7753
     21      0.9687        0.3788       0.7585      0.3253        0.7939        7.8024
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.7831597222222222
Test Accuracy: 0.7831597222222222
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_5.pt

Iteration 7: Requesting 320 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.7248        1.0992       0.7422      0.3285        0.8268     +  8.3628
      2      0.6537        0.7257       0.7585      0.3072        0.8067     +  8.2698
      3      0.6586        0.6186       0.7391      0.3338        0.8056     +  8.3561
      4      0.8708        0.5537       0.8017      0.3609        0.6837     +  8.2661
      5      0.9028        0.4715       0.8026      0.3720        0.6925        8.3024
      6      0.9144        0.4422       0.8087      0.3730        0.6772     +  8.2765
      7      0.9143        0.4252       0.8050      0.3677        0.6914        8.2611
      8      0.9367        0.4055       0.8076      0.3718        0.6929        8.3068
      9      0.9251        0.3945       0.8092      0.3735        0.6855        8.2975
     10      0.9522        0.3841       0.8111      0.3772        0.6881        8.3087
     11      0.9539        0.3771       0.8076      0.3758        0.6844        8.2925
     12      0.9563        0.3676       0.8005      0.3727        0.6985        8.3044
     13      0.9663        0.3586       0.8115      0.3744        0.6695     +  8.3060
     14      0.9670        0.3484       0.8068      0.3754        0.6805        8.2808
     15      0.9859        0.3427       0.8149      0.3795        0.6659     +  8.3038
     16      0.9876        0.3378       0.7990      0.3680        0.6913        8.2540
     17      0.9765        0.3347       0.8101      0.3781        0.6691        8.3121
     18      0.9876        0.3257       0.8030      0.4993        0.6825        8.2791
     19      0.9895        0.3193       0.8108      0.3774        0.6628     +  8.2592
     20      0.9895        0.3170       0.8019      0.4981        0.6850        8.2687
     21      0.9895        0.3110       0.8019      0.3716        0.6807        8.2887
     22      0.9895        0.3097       0.8030      0.3726        0.6818        8.3155
     23      0.9895        0.3065       0.8139      0.3776        0.6542     +  8.3225
     24      0.9981        0.2976       0.7941      0.4931        0.6995        8.2869
     25      1.0000        0.2930       0.8061      0.3728        0.6716        8.2927
     26      0.9981        0.2942       0.7924      0.4934        0.7055        8.3086
     27      1.0000        0.2910       0.8111      0.3718        0.6574        8.3428
     28      1.0000        0.2867       0.7861      0.4875        0.7131        8.5467
     29      1.0000        0.2843       0.8144      0.3768        0.6548        9.3752
     30      1.0000        0.2804       0.7965      0.3665        0.6930        9.2001
     31      1.0000        0.2818       0.8146      0.3769        0.6535     +  8.8193
     32      1.0000        0.2752       0.8082      0.3713        0.6623        8.2728
     33      1.0000        0.2742       0.8005      0.3689        0.6844        8.3329
     34      1.0000        0.2701       0.8163      0.3777        0.6453     +  8.3244
     35      1.0000        0.2692       0.7995      0.3661        0.6810        8.2702
     36      1.0000        0.2667       0.8156      0.3742        0.6486        8.3239
     37      1.0000        0.2665       0.7965      0.3631        0.6844        8.3154
     38      1.0000        0.2630       0.8082      0.3712        0.6602        8.3584
     39      1.0000        0.2621       0.8033      0.3685        0.6724        8.3874
     40      1.0000        0.2592       0.8214      0.5080        0.6350     +  8.3776
     41      1.0000        0.2614       0.8054      0.4988        0.6705        8.2824
     42      1.0000        0.2569       0.8167      0.3773        0.6424        8.3500
     43      1.0000        0.2565       0.8099      0.5010        0.6629        8.3912
     44      1.0000        0.2533       0.8179      0.3796        0.6422        8.3464
     45      1.0000        0.2522       0.7990      0.3676        0.6857        8.3474
     46      1.0000        0.2503       0.8165      0.3766        0.6395        8.2650
     47      1.0000        0.2491       0.8064      0.4996        0.6672        8.2703
     48      1.0000        0.2470       0.8137      0.3736        0.6478        8.2906
     49      1.0000        0.2457       0.8064      0.4996        0.6671        8.2934
     50      1.0000        0.2427       0.8167      0.3778        0.6433        8.2605
     51      1.0000        0.2411       0.8179      0.3799        0.6397        8.3032
     52      1.0000        0.2419       0.8116      0.3727        0.6507        8.3195
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.7862847222222222
Test Accuracy: 0.7862847222222222
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_6.pt

Iteration 8: Requesting 560 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.6892        0.7857       0.7826      0.3631        0.7018     +  9.2433
      2      0.5128        0.5346       0.8328      0.3916        0.5965     +  9.1611
      3      0.8218        0.4451       0.8292      0.3917        0.6051        9.2636
      4      0.8395        0.3901       0.8151      0.3842        0.6317        9.1983
      5      0.8687        0.3658       0.8392      0.3941        0.5797     +  9.2461
      6      0.8794        0.3467       0.8314      0.3880        0.5998        9.1705
      7      0.9027        0.3260       0.8469      0.4014        0.5602     +  9.1728
      8      0.8957        0.3091       0.8295      0.5188        0.5901        9.2045
      9      0.9034        0.2988       0.8300      0.3952        0.6006        9.1837
     10      0.9109        0.2865       0.8408      0.6483        0.5719        9.2532
     11      0.9199        0.2734       0.8429      0.6461        0.5688        9.1810
     12      0.9231        0.2653       0.8427      0.5260        0.5690        9.2694
     13      0.9359        0.2586       0.8212      0.5029        0.6193        9.1788
     14      0.9317        0.2503       0.8234      0.6289        0.6174        9.1417
     15      0.9575        0.2398       0.8280      0.5094        0.5983        9.1910
     16      0.9492        0.2348       0.8292      0.7601        0.6025        9.1202
     17      0.9651        0.2284       0.8269      0.6308        0.6129        9.0876
     18      0.9579        0.2251       0.8332      0.6367        0.5949        9.0987
     19      0.9865        0.2187       0.8339      0.6380        0.5971        9.1101
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.8105902777777778
Test Accuracy: 0.8105902777777778
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_7.pt

Iteration 9: Requesting 1000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.6354        0.6966       0.8283      0.5098        0.5707     +  11.6722
      2      0.7490        0.3449       0.8299      0.3926        0.5678     +  11.2571
      3      0.8701        0.3062       0.8410      0.5124        0.5588     +  10.8144
      4      0.8924        0.2794       0.8347      0.7671        0.5510     +  10.6405
      5      0.8995        0.2571       0.8436      0.7718        0.5334     +  10.6220
      6      0.9088        0.2446       0.8444      0.6464        0.5718        10.6317
      7      0.9092        0.2332       0.8488      0.6551        0.5363        10.5833
      8      0.9209        0.2224       0.8408      0.5304        0.5637        10.6348
      9      0.9212        0.2129       0.8368      0.6567        0.5698        10.6065
     10      0.9325        0.2063       0.8394      0.6528        0.5704        10.6023
     11      0.9163        0.1985       0.8007      0.6257        0.6598        10.5401
     12      0.9157        0.2008       0.8484      0.6653        0.5232     +  10.6095
     13      0.9175        0.1857       0.8481      0.6658        0.5242        10.6675
     14      0.9382        0.1813       0.8483      0.6617        0.5262        10.5837
     15      0.9340        0.1787       0.8470      0.6607        0.5332        10.6559
     16      0.9429        0.1744       0.8347      0.6405        0.6163        10.5930
     17      0.9389        0.1713       0.8458      0.6570        0.5397        10.6344
     18      0.9435        0.1658       0.8411      0.6562        0.5516        10.6027
     19      0.9488        0.1622       0.8429      0.6552        0.5496        10.6311
     20      0.9397        0.1600       0.8248      0.6231        0.6856        10.6071
     21      0.9482        0.1562       0.8450      0.5347        0.5423        10.5957
     22      0.9480        0.1514       0.8391      0.6564        0.5598        10.5578
     23      0.9480        0.1503       0.8422      0.6577        0.5526        10.5934
     24      0.9462        0.1479       0.8427      0.5295        0.5543        10.5911
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.8527777777777777
Test Accuracy: 0.8527777777777777
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_8.pt

Iteration 10: Requesting 1776 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.7077        0.5748       0.8474      0.6491        0.5052     +  14.5962
      2      0.8461        0.2405       0.8462      0.6574        0.5083        13.7992
      3      0.8551        0.2027       0.8375      0.6447        0.5477        13.2187
      4      0.8680        0.1824       0.8460      0.6652        0.5259        13.2916
      5      0.8724        0.1710       0.8476      0.6581        0.5256        13.2292
      6      0.8830        0.1633       0.8345      0.6376        0.5910        13.1619
      7      0.8801        0.1556       0.8420      0.6555        0.5479        13.2585
      8      0.8815        0.1838       0.8486      0.7721        0.5441        13.2528
      9      0.8972        0.1538       0.8352      0.7646        0.5791        13.2548
     10      0.9389        0.1395       0.8345      0.6457        0.5813        13.3244
     11      0.9632        0.1344       0.8347      0.6479        0.5735        13.3222
     12      0.9397        0.1301       0.8398      0.6512        0.5555        13.3626
     13      0.9640        0.1264       0.8405      0.6504        0.5639        13.2717
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.8557291666666667
Test Accuracy: 0.8557291666666667
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_9.pt

Iteration 11: Requesting 3160 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.7960        0.3185       0.8451      0.6480        0.5285     +  19.5679
      2      0.8600        0.1829       0.8389      0.6476        0.5500        17.9032
      3      0.9164        0.1671       0.8207      0.7633        0.6417        17.9423
      4      0.9197        0.1542       0.8356      0.7690        0.5786        17.9187
      5      0.9256        0.1424       0.8420      0.7763        0.5647        17.9683
      6      0.9290        0.1432       0.8444      0.7751        0.5673        17.9406
      7      0.9244        0.1399       0.8280      0.7678        0.6016        17.9377
      8      0.9169        0.1227       0.8405      0.7744        0.5783        17.9522
      9      0.9383        0.1163       0.8417      0.6529        0.5866        18.0839
     10      0.9376        0.1155       0.8340      0.7708        0.6295        18.0286
     11      0.9444        0.1114       0.8351      0.7717        0.6151        17.9621
     12      0.9244        0.1087       0.8309      0.7694        0.6138        17.9912
     13      0.9526        0.0973       0.8325      0.7654        0.6291        17.9467
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.8397569444444445
Test Accuracy: 0.8397569444444445
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_10.pt

Iteration 12: Requesting 5624 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.8001        0.2237       0.8299      0.7600        0.6010     +  28.5061
      2      0.8600        0.1394       0.8030      0.7390        0.7203        27.6391
      3      0.8452        0.1273       0.8342      0.7572        0.6161        26.5200
      4      0.8961        0.1149       0.8424      0.7654        0.5927     +  26.4786
      5      0.9196        0.1055       0.8394      0.6396        0.5981        26.5447
      6      0.9070        0.0964       0.8372      0.6347        0.6323        26.3743
      7      0.9113        0.0865       0.8472      0.7695        0.5925     +  26.3396
      8      0.9364        0.0856       0.8267      0.7491        0.6994        26.3336
      9      0.9312        0.0720       0.8368      0.6449        0.6485        26.3282
     10      0.9754        0.0677       0.8389      0.7625        0.6538        26.3622
     11      0.9320        0.0968       0.8243      0.7542        0.6896        26.3748
     12      0.9619        0.0639       0.8446      0.7723        0.6266        26.3366
     13      0.9774        0.0554       0.8436      0.7734        0.6419        26.2595
     14      0.9680        0.0521       0.8361      0.7635        0.6853        26.3949
     15      0.9694        0.0505       0.8415      0.7683        0.6747        26.3505
     16      0.9632        0.0549       0.8417      0.7653        0.7039        26.3057
     17      0.9553        0.0481       0.8457      0.7654        0.7323        26.3290
     18      0.9534        0.0568       0.8392      0.7656        0.6954        26.2940
     19      0.9828        0.0446       0.8373      0.7605        0.7151        26.3133
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.8496527777777778
Test Accuracy: 0.8496527777777778
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_11.pt

Iteration 13: Requesting 10000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.8549        0.1330       0.8168      0.6375        0.6624     +  41.4222
      2      0.8863        0.0932       0.8495      0.5742        0.5789     +  41.2502
      3      0.9072        0.0792       0.8384      0.6513        0.6321        41.3040
      4      0.9083        0.0677       0.8359      0.6487        0.6339        41.2144
      5      0.9120        0.0607       0.8474      0.7887        0.6077        41.3451
      6      0.9267        0.0559       0.8408      0.6507        0.6570        41.3114
      7      0.9329        0.0494       0.8420      0.6530        0.6627        41.2654
      8      0.9416        0.0489       0.8326      0.6446        0.7186        41.3028
      9      0.9653        0.0436       0.8342      0.6426        0.7012        41.3428
     10      0.9654        0.0391       0.8259      0.6441        0.7575        41.3178
     11      0.9510        0.0371       0.8361      0.6485        0.7240        41.3899
     12      0.9524        0.0354       0.8342      0.6417        0.7302        41.3439
     13      0.9759        0.0384       0.8309      0.6421        0.7598        41.3278
     14      0.9719        0.0321       0.8417      0.6530        0.7125        41.4374
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.8583333333333333
Test Accuracy: 0.8583333333333333
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_12.pt

Iteration 14: Requesting all remaining samples.
Number of samples in training set (final iteration): 26880
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.8207        0.1107       0.8024      0.7384        0.7777     +  79.0116
      2      0.8594        0.0857       0.8035      0.4924        0.7668     +  78.9100
      3      0.8992        0.0695       0.8134      0.5077        0.7504     +  78.8063
      4      0.9139        0.0599       0.8082      0.5071        0.7708        78.6983
      5      0.9315        0.0524       0.8167      0.5131        0.7712        78.6227
      6      0.9286        0.0459       0.8163      0.5144        0.8050        78.6612
      7      0.9480        0.0405       0.8092      0.6327        0.8676        78.6741
      8      0.9384        0.0374       0.8373      0.6531        0.7424     +  78.6528
      9      0.9576        0.0321       0.8184      0.6392        0.8529        78.6533
     10      0.9577        0.0323       0.8240      0.5239        0.8245        78.5881
     11      0.9590        0.0272       0.8387      0.6576        0.7738        78.6828
     12      0.9590        0.0272       0.8333      0.7766        0.8040        78.6010
     13      0.9665        0.0257       0.8224      0.6461        0.9175        78.5596
     14      0.9816        0.0216       0.8354      0.6433        0.8647        78.5861
     15      0.9774        0.0212       0.8293      0.5239        0.8590        78.7719
     16      0.9722        0.0202       0.8252      0.6470        0.8969        78.6126
     17      0.9740        0.0173       0.8073      0.7601        1.0336        78.5786
     18      0.9739        0.0180       0.8326      0.7822        0.8138        78.6020
     19      0.9798        0.0173       0.8113      0.7582        0.9974        78.6945
     20      0.9821        0.0149       0.8014      0.6419        1.0330        78.5511
Stopping since valid_loss has not improved in the last 13 epochs.
Final Test F1 Score: 0.845138888888889
Final Test Accuracy: 0.8451388888888889

Random sampling loop ended successfully!
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_13.pt
F1 Test Data: [0.2300347222222222, 0.23524305555555555, 0.5348958333333333, 0.7385416666666665, 0.7552083333333334, 0.7831597222222222, 0.7862847222222222, 0.8105902777777778, 0.8527777777777777, 0.8557291666666667, 0.8397569444444445, 0.8496527777777778, 0.8583333333333333, 0.845138888888889]
Accuracy Test Data: [0.2300347222222222, 0.23524305555555555, 0.5348958333333333, 0.7385416666666667, 0.7552083333333334, 0.7831597222222222, 0.7862847222222222, 0.8105902777777778, 0.8527777777777777, 0.8557291666666667, 0.8397569444444445, 0.8496527777777778, 0.8583333333333333, 0.8451388888888889]
Performance Test Data: [[0.2300347222222222, 0.23524305555555555, 0.5348958333333333, 0.7385416666666667, 0.7552083333333334, 0.7831597222222222, 0.7862847222222222, 0.8105902777777778, 0.8527777777777777, 0.8557291666666667, 0.8397569444444445, 0.8496527777777778, 0.8583333333333333, 0.8451388888888889], [0.2300347222222222, 0.23524305555555555, 0.5348958333333333, 0.7385416666666665, 0.7552083333333334, 0.7831597222222222, 0.7862847222222222, 0.8105902777777778, 0.8527777777777777, 0.8557291666666667, 0.8397569444444445, 0.8496527777777778, 0.8583333333333333, 0.845138888888889]]
PS C:\Users\localuserSG\ActiveLearning\MultiClass\FixmulticlassRSmicroResults> 