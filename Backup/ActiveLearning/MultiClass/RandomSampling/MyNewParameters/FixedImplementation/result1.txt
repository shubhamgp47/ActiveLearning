 python .\FixmulticlassRSmicroResults.py
(26880, 5)
(5760, 5)
(5760, 5)
100%|████████████████████████████████████████████████████████████████████████████████| 26880/26880 [00:00<00:00, 125156.27it/s] 
100%|██████████████████████████████████████████████████████████████████████████████████| 5760/5760 [00:00<00:00, 127297.01it/s] 
100%|██████████████████████████████████████████████████████████████████████████████████| 5760/5760 [00:00<00:00, 129055.51it/s] 
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
Using cache found in C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main
C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3) y_initial_np: (8,)
X_train_np: (26880, 224, 224, 3) y_train_np: (26880,)
X_pool_np: (26872, 224, 224, 3) y_pool_np: (26872,)
X_test_np: (5760, 224, 224, 3) y_test_np: (5760,)
X_val_np: (5760, 224, 224, 3) y_val_np: (5760,)

Iteration 1: Using the initial 8 samples already in X_train_initial_np and y_train_initial_np.
Number of samples in training set: 8
Selected samples in Iteration 1: ['Spule003_Image0001.jpg', 'Spule003_Image0002.jpg', 'Spule003_Image0003.jpg', 'Spule003_Image0004.jpg', 'Spule003_Image0005.jpg', 'Spule003_Image0006.jpg', 'Spule003_Image0007.jpg', 'Spule003_Image0008.jpg']
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.3333        2.1297       0.1849      0.4344        2.0666     +  7.5031
      2      0.5500        2.0231       0.1189      0.6717        2.1735        6.9821
      3      0.3833        1.9087       0.1479      0.5638        2.1284        6.9863
      4      0.3958        1.8727       0.1354      0.7040        2.1416        7.0096
      5      0.8333        1.8155       0.1212      0.4475        2.1854        7.0446
      6      0.6875        1.6725       0.1064      0.3135        2.2154        7.0956
      7      0.2167        1.7623       0.1168      0.4358        2.1800        7.1681
      8      0.6875        1.6131       0.1708      0.4774        2.1749        7.1806
      9      0.8333        1.5450       0.1366      0.4553        2.1609        7.1602
     10      1.0000        1.4454       0.1427      0.3406        2.1649        7.1771
     11      1.0000        1.4789       0.1380      0.4578        2.1486        7.2127
     12      0.8333        1.4086       0.1691      0.4802        2.1977        7.2254
     13      1.0000        1.3627       0.1519      0.4651        2.2000        7.2049
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.18333333333333332
Test Accuracy: 0.18333333333333332
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_0.pt

Iteration 2: Requesting 16 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      1.0000        1.2860       0.1689      0.4512        1.9626     +  7.2408
      2      0.6875        1.5598       0.1205      0.3290        2.2905        7.2082
      3      0.8333        1.4225       0.1385      0.5822        2.2024        7.2457
      4      1.0000        1.2236       0.1311      0.4531        2.2483        7.2283
      5      1.0000        1.1343       0.1437      0.4593        2.2274        7.2250
      6      1.0000        1.1157       0.1326      0.4591        2.2209        7.2436
      7      1.0000        1.0634       0.1512      0.4638        2.2298        7.2418
      8      1.0000        1.0076       0.1378      0.4642        2.2197        7.2620
      9      1.0000        0.9729       0.1510      0.4641        2.2599        7.2592
     10      1.0000        0.9871       0.1484      0.4664        2.2309        7.2694
     11      1.0000        0.9535       0.1557      0.4721        2.2323        7.2650
     12      1.0000        0.9090       0.1510      0.4642        2.2428        7.2632
     13      1.0000        0.9123       0.1616      0.4741        2.2001        7.2604
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.19114583333333335
Test Accuracy: 0.19114583333333332
Number of samples in pool after split: (26856, 224, 224, 3)
Number of samples in X_add: (16, 224, 224, 3)
Number of samples in y_add: (16,)
Number of samples in training set: 24
Number of samples added in this iteration: 16
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_1.pt

Iteration 3: Requesting 32 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.5371        1.8721       0.4443      0.2034        1.7486     +  7.4999
      2      0.4012        1.5260       0.5241      0.2673        1.6623     +  7.3399
      3      0.6725        1.3797       0.4477      0.3291        1.6718        7.2877
      4      0.8933        1.3237       0.5269      0.5168        1.6208     +  7.3124
      5      0.7862        1.2269       0.4590      0.0903        1.5830     +  7.3121
      6      0.6399        1.2009       0.5186      0.6710        1.6701        7.3376
      7      0.9696        1.2083       0.4837      0.1145        1.5701     +  7.2592
      8      0.9138        1.1266       0.6163      0.4340        1.4800     +  7.3292
      9      0.9487        1.0526       0.4852      0.3697        1.5478        7.3788
     10      1.0000        0.9946       0.6429      0.3268        1.4488     +  7.3336
     11      1.0000        0.9663       0.4809      0.4947        1.5689        7.3528
     12      1.0000        0.9516       0.6472      0.5852        1.4200     +  7.3133
     13      1.0000        0.9358       0.5062      0.5247        1.5205        7.3065
     14      1.0000        0.8949       0.6446      0.5815        1.4134     +  7.3129
     15      1.0000        0.8589       0.5168      0.5333        1.4996        7.3022
     16      1.0000        0.8556       0.6302      0.7073        1.4320        7.3038
     17      1.0000        0.8319       0.5267      0.5306        1.4758        7.3403
     18      1.0000        0.7999       0.6123      0.5799        1.4121     +  7.3238
     19      1.0000        0.8088       0.5477      0.6694        1.4356        7.3389
     20      1.0000        0.7669       0.5917      0.6999        1.4138        7.3282
     21      1.0000        0.7540       0.5590      0.6819        1.4407        7.3031
     22      1.0000        0.7258       0.5807      0.6950        1.4035     +  7.3023
     23      1.0000        0.7265       0.5865      0.6916        1.4178        7.3020
     24      1.0000        0.7292       0.5780      0.6886        1.3944     +  7.3211
     25      1.0000        0.7199       0.5878      0.6970        1.4097        7.3005
     26      1.0000        0.6934       0.5575      0.6822        1.4176        7.3217
     27      1.0000        0.6892       0.5851      0.6819        1.4123        7.3130
     28      1.0000        0.6698       0.5753      0.6901        1.3975        7.3192
     29      1.0000        0.6997       0.5648      0.6815        1.4130        7.3003
     30      1.0000        0.6866       0.6019      0.6978        1.3828     +  7.3100
     31      1.0000        0.6776       0.5576      0.6813        1.4158        7.3184
     32      1.0000        0.6613       0.5785      0.6871        1.4035        7.3087
     33      1.0000        0.6522       0.5632      0.6832        1.4091        7.2954
     34      1.0000        0.6635       0.5898      0.6946        1.3960        7.3020
     35      1.0000        0.6514       0.5380      0.6745        1.4244        7.3016
     36      1.0000        0.6520       0.5858      0.6896        1.4044        7.3177
     37      1.0000        0.6519       0.5753      0.6926        1.3915        7.3021
     38      1.0000        0.6457       0.5771      0.6820        1.4000        7.2912
     39      1.0000        0.6214       0.5920      0.7020        1.3679     +  7.2803
     40      1.0000        0.6213       0.5634      0.6813        1.4226        7.2712
     41      1.0000        0.6370       0.5566      0.6744        1.4102        7.2856
     42      1.0000        0.6262       0.5917      0.6948        1.3815        7.3274
     43      1.0000        0.6179       0.5554      0.6787        1.4073        7.3240
     44      1.0000        0.6151       0.5953      0.7007        1.3724        7.3055
     45      1.0000        0.6251       0.5523      0.6814        1.4044        7.2973
     46      1.0000        0.6211       0.5889      0.6860        1.3851        7.3156
     47      1.0000        0.6113       0.5601      0.6791        1.4021        7.2961
     48      1.0000        0.5939       0.5710      0.6837        1.4110        7.2933
     49      1.0000        0.5927       0.5865      0.6944        1.3723        7.2948
     50      1.0000        0.5991       0.5790      0.6956        1.3875        7.3024
     51      1.0000        0.5999       0.5927      0.6909        1.3696        7.3090
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.6272569444444445
Test Accuracy: 0.6272569444444445
Number of samples in pool after split: (26824, 224, 224, 3)
Number of samples in X_add: (32, 224, 224, 3)
Number of samples in y_add: (32,)
Number of samples in training set: 56
Number of samples added in this iteration: 32
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_2.pt

Iteration 4: Requesting 56 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.8179        0.9397       0.5260      0.1494        1.3636     +  7.5542
      2      0.3107        1.0628       0.3748      0.1176        1.6832        7.3058
      3      0.2301        1.5907       0.4656      0.0978        1.6380        7.3445
      4      0.2770        1.0918       0.6533      0.4666        1.2086     +  7.3632
      5      0.7046        0.9106       0.6196      0.3474        1.2238        7.3687
      6      0.7775        0.8158       0.6318      0.4745        1.2024     +  7.3803
      7      0.7567        0.7680       0.6059      0.5907        1.2205        7.3703
      8      0.9395        0.7217       0.6276      0.6010        1.1955     +  7.3959
      9      0.9395        0.7052       0.6023      0.5898        1.2106        7.3597
     10      0.9544        0.6826       0.6361      0.6037        1.1879     +  7.3747
     11      0.9395        0.6777       0.5903      0.7074        1.2269        7.3746
     12      0.9490        0.6670       0.6425      0.5994        1.1859     +  7.3872
     13      0.9544        0.6574       0.5861      0.7042        1.2325        7.4272
     14      0.9802        0.6538       0.6528      0.6002        1.1636     +  7.4436
     15      0.9802        0.6482       0.6054      0.7226        1.2147        7.3668
     16      0.9802        0.6221       0.6309      0.7343        1.1771        7.4027
     17      1.0000        0.6093       0.6175      0.7312        1.1905        7.3497
     18      1.0000        0.5912       0.6311      0.6112        1.1763        7.3545
     19      1.0000        0.5901       0.6217      0.7339        1.1833        7.3437
     20      1.0000        0.5848       0.6207      0.7326        1.1811        7.3294
     21      1.0000        0.5814       0.6304      0.7354        1.1640        7.3674
     22      1.0000        0.5733       0.6165      0.7305        1.1785        7.3878
     23      1.0000        0.5768       0.6304      0.7376        1.1519     +  7.3609
     24      1.0000        0.5723       0.6236      0.7352        1.1660        7.3528
     25      1.0000        0.5652       0.6309      0.7362        1.1655        7.3679
     26      1.0000        0.5537       0.6224      0.7346        1.1717        7.4126
     27      1.0000        0.5568       0.6267      0.7354        1.1688        7.4093
     28      1.0000        0.5542       0.6248      0.7365        1.1663        7.3681
     29      1.0000        0.5507       0.6337      0.7369        1.1566        7.3401
     30      1.0000        0.5402       0.6158      0.7321        1.1786        7.3436
     31      1.0000        0.5350       0.6306      0.7384        1.1554        7.3607
     32      1.0000        0.5289       0.6319      0.7395        1.1557        7.3386
     33      1.0000        0.5264       0.6330      0.7387        1.1524        7.3281
     34      1.0000        0.5217       0.6285      0.7355        1.1704        7.2965
     35      1.0000        0.5205       0.6314      0.7400        1.1591        7.3211
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.6689236111111111
Test Accuracy: 0.6689236111111111
Number of samples in pool after split: (26768, 224, 224, 3)
Number of samples in X_add: (56, 224, 224, 3)
Number of samples in y_add: (56,)
Number of samples in training set: 112
Number of samples added in this iteration: 56
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_3.pt

Iteration 5: Requesting 96 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.7737        0.8573       0.4613      0.2236        1.3970     +  7.7339
      2      0.3929        1.3872       0.4766      0.3590        1.5394        7.4613
      3      0.2173        1.2531       0.6889      0.2436        1.1259     +  7.4853
      4      0.3831        0.9745       0.6082      0.2256        1.1091     +  7.4748
      5      0.4527        0.8240       0.7111      0.2803        0.9878     +  7.4817
      6      0.7553        0.7837       0.6451      0.3858        1.0703        7.4994
      7      0.8837        0.7196       0.7128      0.2856        0.9796     +  7.4899
      8      0.9017        0.7073       0.6727      0.4088        1.0245        7.4757
      9      0.9162        0.6847       0.7076      0.2960        0.9667     +  7.4781
     10      0.9162        0.6693       0.6878      0.4207        0.9989        7.5084
     11      0.9227        0.6503       0.7170      0.3079        0.9536     +  7.4656
     12      0.9162        0.6444       0.6974      0.3024        0.9900        7.4552
     13      0.9227        0.6212       0.7193      0.3086        0.9476     +  7.4515
     14      0.9227        0.6195       0.6972      0.4281        0.9918        7.4629
     15      0.9301        0.6071       0.7222      0.3101        0.9454     +  7.4948
     16      0.9370        0.6009       0.7023      0.3065        0.9719        7.4924
     17      0.9370        0.6010       0.7243      0.3127        0.9398     +  7.5091
     18      0.9434        0.5782       0.7031      0.3059        0.9687        7.4896
     19      0.9431        0.5785       0.7220      0.3127        0.9454        7.4970
     20      0.9434        0.5704       0.7021      0.3056        0.9678        7.5118
     21      0.9434        0.5713       0.7236      0.3124        0.9393     +  7.4979
     22      0.9434        0.5588       0.7050      0.3075        0.9600        7.5477
     23      0.9434        0.5617       0.7207      0.3124        0.9373     +  7.5783
     24      0.9434        0.5448       0.7122      0.3113        0.9496        7.5590
     25      0.9434        0.5345       0.7203      0.3132        0.9315     +  7.5634
     26      0.9431        0.5327       0.7181      0.3136        0.9415        7.5435
     27      0.9434        0.5306       0.7127      0.3095        0.9333        7.5136
     28      0.9434        0.5269       0.7205      0.3146        0.9359        7.5128
     29      0.9434        0.5178       0.7120      0.3095        0.9363        7.5051
     30      0.9434        0.5208       0.7217      0.3144        0.9302     +  7.5055
     31      0.9434        0.5120       0.7141      0.3113        0.9299     +  7.5223
     32      0.9882        0.5103       0.7201      0.3144        0.9317        7.5364
     33      0.9434        0.5085       0.7163      0.3121        0.9221     +  7.5159
     34      0.9882        0.5092       0.7250      0.3182        0.9265        7.5292
     35      0.9434        0.4953       0.7175      0.3128        0.9233        7.5094
     36      0.9882        0.4945       0.7226      0.3161        0.9191     +  7.5342
     37      0.9422        0.4956       0.7207      0.3146        0.9186     +  7.4957
     38      0.9422        0.4865       0.7278      0.3204        0.9186        7.5130
     39      0.9434        0.4836       0.7203      0.3148        0.9135     +  7.5013
     40      0.9422        0.4793       0.7212      0.3155        0.9234        7.4872
     41      0.9882        0.4880       0.7306      0.3211        0.9071     +  7.4851
     42      0.9942        0.4740       0.7229      0.3159        0.9154        7.5009
     43      0.9422        0.4678       0.7309      0.3220        0.9046     +  7.4709
     44      1.0000        0.4654       0.7196      0.3149        0.9159        7.4855
     45      1.0000        0.4614       0.7337      0.3233        0.9065        7.4764
     46      1.0000        0.4615       0.7208      0.3158        0.9123        7.4548
     47      1.0000        0.4584       0.7311      0.3224        0.8998     +  7.4878
     48      1.0000        0.4543       0.7267      0.3199        0.9068        7.4752
     49      1.0000        0.4489       0.7335      0.3224        0.9025        7.4987
     50      1.0000        0.4486       0.7260      0.3201        0.9055        7.4880
     51      1.0000        0.4448       0.7325      0.3205        0.8968     +  7.4948
     52      1.0000        0.4459       0.7238      0.3197        0.9141        7.4747
     53      1.0000        0.4419       0.7344      0.3228        0.8937     +  7.4597
     54      1.0000        0.4427       0.7260      0.3203        0.9117        7.4951
     55      1.0000        0.4374       0.7307      0.3224        0.8991        7.4923
     56      1.0000        0.4360       0.7273      0.3208        0.9083        7.5063
     57      1.0000        0.4372       0.7312      0.3215        0.8940        7.4928
     58      1.0000        0.4354       0.7307      0.3228        0.9031        7.4931
     59      1.0000        0.4249       0.7312      0.3225        0.8984        7.4523
     60      1.0000        0.4306       0.7278      0.3213        0.9034        7.4460
     61      1.0000        0.4265       0.7325      0.3226        0.8913     +  7.4903
     62      1.0000        0.4294       0.7267      0.3203        0.9034        7.4610
     63      1.0000        0.4165       0.7337      0.3242        0.8932        7.4845
     64      1.0000        0.4224       0.7288      0.3218        0.9001        7.4805
     65      1.0000        0.4163       0.7330      0.3232        0.8997        7.4845
     66      1.0000        0.4240       0.7262      0.3199        0.9010        7.4856
     67      1.0000        0.4238       0.7321      0.3238        0.9008        7.5115
     68      1.0000        0.4161       0.7252      0.3195        0.9040        7.4821
     69      1.0000        0.4157       0.7330      0.3231        0.8920        7.5028
     70      1.0000        0.4134       0.7240      0.3195        0.9103        7.4864
     71      1.0000        0.4119       0.7304      0.3217        0.8968        7.4946
     72      1.0000        0.4086       0.7285      0.3211        0.8995        7.4845
     73      1.0000        0.4083       0.7326      0.3237        0.8946        7.4840
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.7557291666666668
Test Accuracy: 0.7557291666666667
Number of samples in pool after split: (26672, 224, 224, 3)
Number of samples in X_add: (96, 224, 224, 3)
Number of samples in y_add: (96,)
Number of samples in training set: 208
Number of samples added in this iteration: 96
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_4.pt

Iteration 6: Requesting 176 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.8453        0.9293       0.6293      0.2423        1.1712     +  7.8809
      2      0.3283        0.8530       0.7156      0.2864        0.9467     +  7.7022
      3      0.4147        0.6223       0.7491      0.2942        0.9588        7.7375
      4      0.6894        0.6726       0.7535      0.3252        0.8809     +  7.7436
      5      0.7728        0.5068       0.7080      0.3145        0.9438        7.7723
      6      0.9428        0.4836       0.7191      0.3199        0.9216        7.7552
      7      0.9467        0.4585       0.7378      0.3264        0.8851        7.7685
      8      0.9499        0.4409       0.7325      0.3236        0.8964        7.7562
      9      0.9499        0.4269       0.7387      0.3258        0.8853        7.7619
     10      0.9530        0.4239       0.7378      0.3265        0.8885        7.7492
     11      0.9530        0.4166       0.7372      0.3256        0.8877        7.7558
     12      0.9530        0.4119       0.7392      0.3274        0.8847        7.7405
     13      0.9530        0.4061       0.7391      0.3270        0.8850        7.7357
     14      0.9530        0.3939       0.7406      0.3272        0.8874        7.7530
     15      0.9530        0.3984       0.7408      0.3278        0.8847        7.7491
     16      0.9530        0.3946       0.7427      0.3288        0.8851        7.7278
     17      0.9303        0.3916       0.7413      0.3295        0.8800     +  7.7472
     18      0.9530        0.3853       0.7444      0.3301        0.8769     +  7.7351
     19      0.9530        0.3802       0.7470      0.3318        0.8706     +  7.7567
     20      0.9303        0.3753       0.7474      0.3324        0.8689     +  7.7375
     21      0.9560        0.3670       0.7448      0.3311        0.8720        7.7535
     22      0.9560        0.3661       0.7446      0.3300        0.8791        7.7553
     23      1.0000        0.3649       0.7462      0.3309        0.8743        7.7556
     24      1.0000        0.3600       0.7432      0.3297        0.8780        7.7382
     25      1.0000        0.3604       0.7451      0.3302        0.8770        7.7503
     26      1.0000        0.3566       0.7427      0.3291        0.8765        7.7650
     27      1.0000        0.3549       0.7457      0.3311        0.8737        7.7391
     28      1.0000        0.3511       0.7443      0.3300        0.8743        7.7384
     29      1.0000        0.3497       0.7436      0.3293        0.8797        7.7455
     30      1.0000        0.3480       0.7470      0.3304        0.8741        7.7371
     31      1.0000        0.3460       0.7422      0.3284        0.8832        7.7232
     32      1.0000        0.3410       0.7436      0.3289        0.8779        7.7209
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.7661458333333333
Test Accuracy: 0.7661458333333333
Number of samples in pool after split: (26496, 224, 224, 3)
Number of samples in X_add: (176, 224, 224, 3)
Number of samples in y_add: (176,)
Number of samples in training set: 384
Number of samples added in this iteration: 176
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_5.pt

Iteration 7: Requesting 320 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.6581        0.9177       0.6361      0.2258        1.2308     +  8.4312
      2      0.6449        0.6597       0.7080      0.3008        0.8942     +  8.2081
      3      0.7946        0.5113       0.7344      0.2725        0.9145        8.2005
      4      0.7305        0.5245       0.6682      0.2815        0.9751        8.2109
      5      0.9094        0.4865       0.7517      0.4408        0.8449     +  8.2272
      6      0.9472        0.4228       0.7281      0.4492        0.8601        8.2198
      7      0.9567        0.3927       0.7241      0.4479        0.8746        8.2029
      8      0.9833        0.3805       0.7323      0.4527        0.8661        8.2106
      9      0.9624        0.3687       0.7483      0.4593        0.8305     +  8.2256
     10      0.9928        0.3596       0.7472      0.4575        0.8377        8.1960
     11      0.9908        0.3501       0.7460      0.4596        0.8379        8.2049
     12      0.9946        0.3427       0.7467      0.4602        0.8423        8.1864
     13      0.9946        0.3364       0.7484      0.4599        0.8392        8.1871
     14      0.9946        0.3342       0.7509      0.4601        0.8341        8.2163
     15      0.9946        0.3327       0.7516      0.4612        0.8358        8.2212
     16      0.9946        0.3257       0.7564      0.4631        0.8243     +  8.2453
     17      0.9946        0.3232       0.7747      0.4628        0.8222     +  8.2405
     18      0.9946        0.3192       0.7644      0.4645        0.8183     +  8.2028
     19      0.9966        0.3119       0.7467      0.4609        0.8504        8.2413
     20      0.9966        0.3136       0.7535      0.4631        0.8351        8.2370
     21      0.9966        0.3078       0.7528      0.4629        0.8356        8.2364
     22      0.9966        0.3081       0.7523      0.4623        0.8365        8.2009
     23      0.9966        0.3043       0.7533      0.4635        0.8349        8.2032
     24      0.9966        0.3016       0.7557      0.4643        0.8330        8.2297
     25      0.9966        0.3030       0.7582      0.4647        0.8297        8.1848
     26      0.9966        0.2971       0.7566      0.4648        0.8347        8.1914
     27      0.9966        0.2966       0.7583      0.4650        0.8293        8.1726
     28      0.9966        0.2937       0.7571      0.4643        0.8315        8.1991
     29      0.9966        0.2929       0.7602      0.4655        0.8274        8.2849
     30      0.9966        0.2928       0.7585      0.4651        0.8256        8.2929
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.7767361111111111
Test Accuracy: 0.7767361111111111
Number of samples in pool after split: (26176, 224, 224, 3)
Number of samples in X_add: (320, 224, 224, 3)
Number of samples in y_add: (320,)
Number of samples in training set: 704
Number of samples added in this iteration: 320
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_6.pt

Iteration 8: Requesting 560 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.6391        0.8306       0.7431      0.2899        0.9011     +  9.3283
      2      0.5633        0.5665       0.7795      0.3298        0.8008     +  9.0796
      3      0.7316        0.4556       0.7773      0.4531        0.8207        9.0810
      4      0.7443        0.4166       0.7774      0.4548        0.8131        9.0914
      5      0.8056        0.3680       0.7962      0.4822        0.7099     +  9.1021
      6      0.9352        0.3422       0.7944      0.4693        0.7835        9.1070
      7      0.8072        0.3428       0.7979      0.4801        0.7150        9.0791
      8      0.9432        0.3064       0.7965      0.4847        0.7148        9.0718
      9      0.9461        0.2950       0.7960      0.4913        0.7208        9.0864
     10      0.9483        0.2865       0.7910      0.4876        0.7382        9.0819
     11      0.9493        0.2780       0.7851      0.4846        0.7415        9.1199
     12      0.9508        0.2738       0.7899      0.4870        0.7421        9.1217
     13      0.9503        0.2687       0.7854      0.4854        0.7465        9.1105
     14      0.9501        0.2672       0.7807      0.4828        0.7577        9.1013
     15      0.9503        0.2618       0.7769      0.4819        0.7576        9.1168
     16      0.9508        0.2615       0.7750      0.4805        0.7646        9.0948
     17      0.9503        0.2564       0.7757      0.4805        0.7612        9.0991
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.7880208333333333
Test Accuracy: 0.7880208333333333
Number of samples in pool after split: (25616, 224, 224, 3)
Number of samples in X_add: (560, 224, 224, 3)
Number of samples in y_add: (560,)
Number of samples in training set: 1264
Number of samples added in this iteration: 560
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_7.pt

Iteration 9: Requesting 1000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.6055        0.6795       0.7559      0.3129        0.8650     +  10.7179
      2      0.5521        0.4202       0.8075      0.3760        0.6634     +  10.5409
      3      0.7613        0.3322       0.8078      0.5013        0.6699        10.5742
      4      0.7600        0.3506       0.8102      0.6064        0.6331     +  10.6286
      5      0.7893        0.3290       0.8259      0.5123        0.6172     +  10.5911
      6      0.8476        0.2780       0.8260      0.5094        0.6219        10.5588
      7      0.9001        0.2592       0.8201      0.5035        0.6362        10.5507
      8      0.9069        0.2458       0.8170      0.5023        0.6495        10.5706
      9      0.9182        0.2398       0.8161      0.5026        0.6398        10.5500
     10      0.9205        0.2319       0.8134      0.6221        0.6709        10.5600
     11      0.9208        0.2267       0.8144      0.6228        0.6672        10.5605
     12      0.9167        0.2219       0.8156      0.6242        0.6643        10.5273
     13      0.9230        0.2160       0.8137      0.6226        0.6729        10.5223
     14      0.9208        0.2116       0.8113      0.6219        0.6838        10.5563
     15      0.9171        0.2077       0.8165      0.6255        0.6672        10.5611
     16      0.9231        0.2054       0.8134      0.6229        0.6798        10.5449
     17      0.9170        0.2018       0.8141      0.6248        0.6749        10.5612
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.8027777777777778
Test Accuracy: 0.8027777777777778
Number of samples in pool after split: (24616, 224, 224, 3)
Number of samples in X_add: (1000, 224, 224, 3)
Number of samples in y_add: (1000,)
Number of samples in training set: 2264
Number of samples added in this iteration: 1000
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_8.pt

Iteration 10: Requesting 1776 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.7677        0.4378       0.7878      0.6168        0.6540     +  13.4193
      2      0.7397        0.2985       0.7967      0.4976        0.6412     +  13.1834
      3      0.7676        0.2485       0.8354      0.5171        0.5583     +  13.1462
      4      0.9070        0.2234       0.8252      0.5092        0.5974        13.1432
      5      0.9077        0.2157       0.8165      0.5064        0.6260        13.1507
      6      0.9064        0.2219       0.8210      0.5040        0.5948        13.2217
      7      0.9141        0.1945       0.8186      0.7593        0.6301        13.2226
      8      0.9259        0.1816       0.8269      0.6369        0.6104        13.2082
      9      0.9258        0.1757       0.8280      0.6373        0.6061        13.2173
     10      0.9345        0.1716       0.8281      0.6367        0.6144        13.2281
     11      0.9440        0.1651       0.8276      0.6371        0.6119        13.2205
     12      0.9475        0.1606       0.8328      0.6398        0.6018        13.2138
     13      0.9453        0.1610       0.7771      0.5800        0.9308        13.1995
     14      0.8082        0.1919       0.8398      0.6444        0.5760        13.1758
     15      0.9550        0.1469       0.8359      0.5163        0.5975        13.2389
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.8097222222222222
Test Accuracy: 0.8097222222222222
Number of samples in pool after split: (22840, 224, 224, 3)
Number of samples in X_add: (1776, 224, 224, 3)
Number of samples in y_add: (1776,)
Number of samples in training set: 4040
Number of samples added in this iteration: 1776
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_9.pt

Iteration 11: Requesting 3160 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.7549        0.2949       0.7972      0.7528        0.6825     +  18.1179
      2      0.8208        0.2029       0.8092      0.7588        0.6477     +  17.8703
      3      0.8472        0.1776       0.8168      0.7589        0.6359     +  17.8639
      4      0.8497        0.1594       0.7660      0.7293        0.8101        17.8774
      5      0.8503        0.1554       0.8028      0.7512        0.7066        17.8984
      6      0.8581        0.1402       0.8274      0.7631        0.6202     +  17.9146
      7      0.8518        0.1333       0.8245      0.6389        0.6525        17.8948
      8      0.8818        0.1255       0.8219      0.7594        0.6558        17.9274
      9      0.8309        0.1161       0.8332      0.6396        0.6451        17.9228
     10      0.8882        0.1116       0.8172      0.6535        0.6966        17.8838
     11      0.8152        0.1372       0.8342      0.7624        0.5941     +  17.8618
     12      0.8923        0.1111       0.8064      0.6341        0.7125        17.9490
     13      0.8409        0.1076       0.8231      0.6349        0.6543        17.9564
     14      0.8952        0.1015       0.8102      0.5139        0.7079        17.9156
     15      0.8923        0.0981       0.8328      0.6407        0.6459        17.9286
     16      0.9011        0.0911       0.8354      0.6411        0.6460        17.9249
     17      0.9041        0.0897       0.8252      0.6379        0.6559        17.8889
     18      0.8937        0.0883       0.8293      0.6384        0.6809        17.8769
     19      0.9007        0.0827       0.8365      0.6450        0.6440        17.9485
     20      0.9075        0.0798       0.8290      0.7567        0.6831        17.9308
     21      0.8798        0.1005       0.8274      0.5219        0.6523        17.9388
     22      0.8983        0.0782       0.8300      0.5101        0.6888        17.9126
     23      0.9036        0.0722       0.8314      0.6414        0.6845        17.9391
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.8074652777777778
Test Accuracy: 0.8074652777777778
Number of samples in pool after split: (19680, 224, 224, 3)
Number of samples in X_add: (3160, 224, 224, 3)
Number of samples in y_add: (3160,)
Number of samples in training set: 7200
Number of samples added in this iteration: 3160
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_10.pt

Iteration 12: Requesting 5624 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.8122        0.2071       0.8264      0.4961        0.6342     +  26.4849
      2      0.8142        0.1336       0.8361      0.6432        0.5829     +  26.2645
      3      0.8129        0.1151       0.8457      0.6513        0.5616     +  26.3019
      4      0.8263        0.1096       0.8311      0.5164        0.6445        26.2167
      5      0.8251        0.0999       0.8444      0.6538        0.5809        26.2723
      6      0.8298        0.0930       0.8342      0.6488        0.6297        26.3003
      7      0.8705        0.0888       0.8464      0.5326        0.5794        26.3188
      8      0.8330        0.0846       0.8342      0.6507        0.6063        26.3465
      9      0.8476        0.0746       0.8323      0.6472        0.6280        26.2670
     10      0.8803        0.0763       0.8307      0.6473        0.6388        26.3470
     11      0.8870        0.0678       0.8411      0.6549        0.6037        26.3143
     12      0.8501        0.0646       0.8394      0.6528        0.5904        26.2905
     13      0.8541        0.0567       0.8391      0.6518        0.6220        26.2443
     14      0.8439        0.0602       0.8434      0.6583        0.6004        26.2487
     15      0.8581        0.0581       0.8377      0.5346        0.6304        26.2632
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.8239583333333333
Test Accuracy: 0.8239583333333333
Number of samples in pool after split: (14056, 224, 224, 3)
Number of samples in X_add: (5624, 224, 224, 3)
Number of samples in y_add: (5624,)
Number of samples in training set: 12824
Number of samples added in this iteration: 5624
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_11.pt

Iteration 13: Requesting 10000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.8306        0.1451       0.8318      0.6408        0.6377     +  41.2566
      2      0.8146        0.0951       0.8403      0.5304        0.6069     +  41.1734
      3      0.8443        0.0820       0.8453      0.5418        0.5818     +  41.2371
      4      0.8608        0.0765       0.8438      0.5483        0.5874        41.2014
      5      0.8322        0.0688       0.8316      0.5383        0.6547        41.2384
      6      0.8330        0.0653       0.8299      0.5210        0.6259        41.2339
      7      0.8742        0.0565       0.8340      0.5412        0.6564        41.1296
      8      0.8824        0.0505       0.8340      0.5248        0.6921        41.1776
      9      0.8802        0.0518       0.8290      0.3993        0.6933        41.1845
     10      0.8828        0.0484       0.8389      0.5300        0.6597        41.1456
     11      0.8873        0.0435       0.8380      0.5247        0.6892        41.1941
     12      0.8893        0.0386       0.8313      0.5238        0.7100        41.2539
     13      0.8914        0.0394       0.8340      0.5208        0.6980        41.1793
     14      0.8748        0.0382       0.8363      0.6472        0.6608        41.2216
     15      0.8952        0.0316       0.8278      0.5222        0.7573        41.2878
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.8015625
Test Accuracy: 0.8015625
Number of samples in pool after split: (4056, 224, 224, 3)
Number of samples in X_add: (10000, 224, 224, 3)
Number of samples in y_add: (10000,)
Number of samples in training set: 22824
Number of samples added in this iteration: 10000
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_12.pt

Iteration 14: Requesting all remaining samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.8176        0.1054       0.8410      0.5331        0.6011     +  67.7777
      2      0.8339        0.0770       0.8377      0.4082        0.6143        67.6615
      3      0.8405        0.0646       0.8339      0.4071        0.6225        67.7339
      4      0.8519        0.0558       0.8262      0.5198        0.6757        67.7854
      5      0.8865        0.0507       0.8427      0.6545        0.5947     +  67.6499
      6      0.8745        0.0465       0.8457      0.5313        0.5988        67.6938
      7      0.9050        0.0413       0.8286      0.5217        0.6745        67.6476
      8      0.9141        0.0379       0.8389      0.6540        0.6692        67.7182
      9      0.9207        0.0353       0.8405      0.6573        0.6664        67.6949
     10      0.9294        0.0326       0.8313      0.5270        0.7074        67.6805
     11      0.9256        0.0306       0.8510      0.5473        0.6224        67.6305
     12      0.9497        0.0278       0.8382      0.6508        0.7139        67.6998
     13      0.9407        0.0267       0.8462      0.7837        0.6915        67.8687
     14      0.9405        0.0236       0.8530      0.5428        0.6958        67.7325
     15      0.9458        0.0225       0.8323      0.5286        0.7388        67.7265
     16      0.9588        0.0240       0.8509      0.5384        0.6662        67.6969
     17      0.9676        0.0225       0.8434      0.6570        0.6835        67.8254
Stopping since valid_loss has not improved in the last 13 epochs.
Test F1 Score: 0.8112847222222223
Test Accuracy: 0.8112847222222223
Final iteration: Added the remaining 4056 samples to the training set.
Number of samples in training set (final iteration): 26880
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.9171        0.0566       0.8411      0.5299        0.6225     +  78.5791
      2      0.9338        0.0377       0.8526      0.5369        0.6026     +  78.6066
      3      0.9366        0.0338       0.8609      0.5404        0.5722     +  79.0024
      4      0.9529        0.0278       0.8514      0.6621        0.6241        78.5979
      5      0.9598        0.0254       0.8585      0.5576        0.5948        78.5221
      6      0.9748        0.0192       0.8601      0.6665        0.6226        78.4921
      7      0.9754        0.0216       0.8384      0.5327        0.7272        78.3728
      8      0.9721        0.0194       0.8458      0.5426        0.6644        78.6148
      9      0.9705        0.0188       0.8521      0.5684        0.6923        78.3843
     10      0.9790        0.0171       0.8550      0.5757        0.6977        78.4313
     11      0.9809        0.0161       0.8486      0.5770        0.7061        78.4815
     12      0.9906        0.0142       0.8326      0.5599        0.7652        78.5147
     13      0.9802        0.0171       0.8365      0.5724        0.8176        78.3901
     14      0.9886        0.0145       0.8517      0.5705        0.7174        78.4743
     15      0.9882        0.0126       0.8424      0.5678        0.7854        78.5994
Stopping since valid_loss has not improved in the last 13 epochs.
Final Test F1 Score: 0.800173611111111
Final Test Accuracy: 0.8001736111111111

Random sampling loop ended successfully!
Model checkpoint saved to D:/Shubham/results/FixmulticlassRSmicroResults/model_checkpoint_iteration_13.pt
F1 Test Data: [0.18333333333333332, 0.19114583333333335, 0.6272569444444445, 0.6689236111111111, 0.7557291666666668, 0.7661458333333333, 0.7767361111111111, 0.7880208333333333, 0.8027777777777778, 0.8097222222222222, 0.8074652777777778, 0.8239583333333333, 0.8015625, 0.8112847222222223, 0.800173611111111]
Accuracy Test Data: [0.18333333333333332, 0.19114583333333332, 0.6272569444444445, 0.6689236111111111, 0.7557291666666667, 0.7661458333333333, 0.7767361111111111, 0.7880208333333333, 0.8027777777777778, 0.8097222222222222, 0.8074652777777778, 0.8239583333333333, 0.8015625, 0.8112847222222223, 0.8001736111111111]
Performance Test Data: [[0.18333333333333332, 0.19114583333333332, 0.6272569444444445, 0.6689236111111111, 0.7557291666666667, 0.7661458333333333, 0.7767361111111111, 0.7880208333333333, 0.8027777777777778, 0.8097222222222222, 0.8074652777777778, 0.8239583333333333, 0.8015625, 0.8112847222222223, 0.8001736111111111], [0.18333333333333332, 0.19114583333333335, 0.6272569444444445, 0.6689236111111111, 0.7557291666666668, 0.7661458333333333, 0.7767361111111111, 0.7880208333333333, 0.8027777777777778, 0.8097222222222222, 0.8074652777777778, 0.8239583333333333, 0.8015625, 0.8112847222222223, 0.800173611111111]]
PS C:\Users\localuserSG\ActiveLearning\MultiClass\FixmulticlassRSmicroResults> 