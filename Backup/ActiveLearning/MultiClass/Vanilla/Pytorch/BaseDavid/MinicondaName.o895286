### Starting TaskPrologue of job 895286 on tg097 at Wed 25 Sep 2024 12:58:31 AM CEST
Running on cores 32-63 with governor ondemand
Wed Sep 25 00:58:31 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:41:00.0 Off |                    0 |
| N/A   47C    P0             64W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

/home/hpc/iwfa/iwfa044h/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).
  from pandas.core.computation.check import NUMEXPR_INSTALLED
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
/home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
/home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
/home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
Epoch 1/30, Training Loss: 0.3274, Training F1-score: 0.6134, Validation Loss: 0.5076, Validation F1-score: 0.4029
Epoch 2/30, Training Loss: 0.1753, Training F1-score: 0.7314, Validation Loss: 0.4750, Validation F1-score: 0.4453
Epoch 3/30, Training Loss: 0.1477, Training F1-score: 0.7642, Validation Loss: 0.3955, Validation F1-score: 0.4595
Epoch 4/30, Training Loss: 0.1335, Training F1-score: 0.7912, Validation Loss: 0.4653, Validation F1-score: 0.4500
Epoch 5/30, Training Loss: 0.1201, Training F1-score: 0.7816, Validation Loss: 0.5796, Validation F1-score: 0.4493
Epoch 6/30, Training Loss: 0.1054, Training F1-score: 0.8320, Validation Loss: 0.5692, Validation F1-score: 0.5277
Epoch 7/30, Training Loss: 0.1064, Training F1-score: 0.8291, Validation Loss: 0.5337, Validation F1-score: 0.3874
Epoch 8/30, Training Loss: 0.0972, Training F1-score: 0.8096, Validation Loss: 0.5511, Validation F1-score: 0.4528
Epoch 9/30, Training Loss: 0.0897, Training F1-score: 0.8537, Validation Loss: 0.5363, Validation F1-score: 0.4979
Epoch 10/30, Training Loss: 0.0868, Training F1-score: 0.8442, Validation Loss: 0.6051, Validation F1-score: 0.4905
Epoch 11/30, Training Loss: 0.0837, Training F1-score: 0.8541, Validation Loss: 0.5569, Validation F1-score: 0.5506
Epoch 12/30, Training Loss: 0.0787, Training F1-score: 0.8705, Validation Loss: 0.5723, Validation F1-score: 0.4077
Epoch 13/30, Training Loss: 0.0768, Training F1-score: 0.8638, Validation Loss: 0.6352, Validation F1-score: 0.4390
Epoch 14/30, Training Loss: 0.0749, Training F1-score: 0.8658, Validation Loss: 0.6819, Validation F1-score: 0.4205
Epoch 15/30, Training Loss: 0.0704, Training F1-score: 0.8603, Validation Loss: 0.6594, Validation F1-score: 0.4926
Epoch 16/30, Training Loss: 0.0664, Training F1-score: 0.8816, Validation Loss: 0.7253, Validation F1-score: 0.4395
Early stopping triggered after 16 epochs.
Test F1-score: 0.5271
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3577, Training F1-score: 0.5936, Validation Loss: 0.5805, Validation F1-score: 0.4375
Epoch 2/30, Training Loss: 0.1842, Training F1-score: 0.7266, Validation Loss: 0.4475, Validation F1-score: 0.4639
Epoch 3/30, Training Loss: 0.1442, Training F1-score: 0.7516, Validation Loss: 0.6155, Validation F1-score: 0.4036
Epoch 4/30, Training Loss: 0.1330, Training F1-score: 0.7645, Validation Loss: 0.5557, Validation F1-score: 0.4542
Epoch 5/30, Training Loss: 0.1243, Training F1-score: 0.7935, Validation Loss: 0.5516, Validation F1-score: 0.4295
Epoch 6/30, Training Loss: 0.1104, Training F1-score: 0.8098, Validation Loss: 0.5809, Validation F1-score: 0.4428
Epoch 7/30, Training Loss: 0.1038, Training F1-score: 0.8187, Validation Loss: 0.5434, Validation F1-score: 0.5216
Epoch 8/30, Training Loss: 0.0983, Training F1-score: 0.8392, Validation Loss: 0.4945, Validation F1-score: 0.4307
Epoch 9/30, Training Loss: 0.0936, Training F1-score: 0.8380, Validation Loss: 0.5692, Validation F1-score: 0.4465
Epoch 10/30, Training Loss: 0.0883, Training F1-score: 0.8544, Validation Loss: 0.6089, Validation F1-score: 0.4025
Epoch 11/30, Training Loss: 0.0844, Training F1-score: 0.8426, Validation Loss: 0.7457, Validation F1-score: 0.3862
Epoch 12/30, Training Loss: 0.0795, Training F1-score: 0.8574, Validation Loss: 0.5969, Validation F1-score: 0.4327
Early stopping triggered after 12 epochs.
Test F1-score: 0.5910
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3335, Training F1-score: 0.6231, Validation Loss: 0.4801, Validation F1-score: 0.4080
Epoch 2/30, Training Loss: 0.1820, Training F1-score: 0.7329, Validation Loss: 0.5820, Validation F1-score: 0.4649
Epoch 3/30, Training Loss: 0.1481, Training F1-score: 0.7411, Validation Loss: 0.5605, Validation F1-score: 0.4109
Epoch 4/30, Training Loss: 0.1304, Training F1-score: 0.7687, Validation Loss: 0.5284, Validation F1-score: 0.4404
Epoch 5/30, Training Loss: 0.1194, Training F1-score: 0.8105, Validation Loss: 0.5905, Validation F1-score: 0.3988
Epoch 6/30, Training Loss: 0.1144, Training F1-score: 0.7916, Validation Loss: 0.4747, Validation F1-score: 0.4609
Epoch 7/30, Training Loss: 0.1034, Training F1-score: 0.8171, Validation Loss: 0.6574, Validation F1-score: 0.3883
Early stopping triggered after 7 epochs.
Test F1-score: 0.5734
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3404, Training F1-score: 0.6236, Validation Loss: 0.4354, Validation F1-score: 0.4615
Epoch 2/30, Training Loss: 0.1770, Training F1-score: 0.7286, Validation Loss: 0.4538, Validation F1-score: 0.4327
Epoch 3/30, Training Loss: 0.1477, Training F1-score: 0.7573, Validation Loss: 0.4765, Validation F1-score: 0.4222
Epoch 4/30, Training Loss: 0.1298, Training F1-score: 0.7715, Validation Loss: 0.4909, Validation F1-score: 0.4157
Epoch 5/30, Training Loss: 0.1167, Training F1-score: 0.8077, Validation Loss: 0.5689, Validation F1-score: 0.4312
Epoch 6/30, Training Loss: 0.1098, Training F1-score: 0.8127, Validation Loss: 0.4392, Validation F1-score: 0.4625
Epoch 7/30, Training Loss: 0.1040, Training F1-score: 0.8283, Validation Loss: 0.5525, Validation F1-score: 0.4021
Epoch 8/30, Training Loss: 0.0976, Training F1-score: 0.8287, Validation Loss: 0.5928, Validation F1-score: 0.4365
Epoch 9/30, Training Loss: 0.0917, Training F1-score: 0.8364, Validation Loss: 0.7749, Validation F1-score: 0.3874
Epoch 10/30, Training Loss: 0.0866, Training F1-score: 0.8453, Validation Loss: 0.5892, Validation F1-score: 0.4923
Epoch 11/30, Training Loss: 0.0824, Training F1-score: 0.8545, Validation Loss: 0.6147, Validation F1-score: 0.4332
Epoch 12/30, Training Loss: 0.0806, Training F1-score: 0.8558, Validation Loss: 0.5791, Validation F1-score: 0.4617
Epoch 13/30, Training Loss: 0.0753, Training F1-score: 0.8630, Validation Loss: 0.6481, Validation F1-score: 0.4560
Epoch 14/30, Training Loss: 0.0712, Training F1-score: 0.8636, Validation Loss: 0.6438, Validation F1-score: 0.4996
Epoch 15/30, Training Loss: 0.0691, Training F1-score: 0.8941, Validation Loss: 0.7426, Validation F1-score: 0.4023
Epoch 16/30, Training Loss: 0.0659, Training F1-score: 0.8885, Validation Loss: 0.8209, Validation F1-score: 0.4312
Epoch 17/30, Training Loss: 0.0632, Training F1-score: 0.8822, Validation Loss: 0.7700, Validation F1-score: 0.4106
Epoch 18/30, Training Loss: 0.0574, Training F1-score: 0.9037, Validation Loss: 0.7592, Validation F1-score: 0.4440
Epoch 19/30, Training Loss: 0.0544, Training F1-score: 0.9201, Validation Loss: 0.5936, Validation F1-score: 0.4429
Early stopping triggered after 19 epochs.
Test F1-score: 0.5979
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3474, Training F1-score: 0.5992, Validation Loss: 0.5576, Validation F1-score: 0.4319
Epoch 2/30, Training Loss: 0.1749, Training F1-score: 0.7279, Validation Loss: 0.6165, Validation F1-score: 0.3706
Epoch 3/30, Training Loss: 0.1496, Training F1-score: 0.7440, Validation Loss: 0.4470, Validation F1-score: 0.4671
Epoch 4/30, Training Loss: 0.1300, Training F1-score: 0.7767, Validation Loss: 0.5451, Validation F1-score: 0.4396
Epoch 5/30, Training Loss: 0.1192, Training F1-score: 0.8082, Validation Loss: 0.4856, Validation F1-score: 0.4552
Epoch 6/30, Training Loss: 0.1108, Training F1-score: 0.8103, Validation Loss: 0.5987, Validation F1-score: 0.5917
Epoch 7/30, Training Loss: 0.1065, Training F1-score: 0.8299, Validation Loss: 0.4730, Validation F1-score: 0.4282
Epoch 8/30, Training Loss: 0.0978, Training F1-score: 0.8262, Validation Loss: 0.5598, Validation F1-score: 0.3903
Epoch 9/30, Training Loss: 0.0914, Training F1-score: 0.8264, Validation Loss: 0.6243, Validation F1-score: 0.5712
Epoch 10/30, Training Loss: 0.0892, Training F1-score: 0.8449, Validation Loss: 0.4325, Validation F1-score: 0.4995
Epoch 11/30, Training Loss: 0.0825, Training F1-score: 0.8498, Validation Loss: 0.7386, Validation F1-score: 0.4443
Early stopping triggered after 11 epochs.
Test F1-score: 0.6183
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3329, Training F1-score: 0.6061, Validation Loss: 0.4270, Validation F1-score: 0.4771
Epoch 2/30, Training Loss: 0.1792, Training F1-score: 0.7310, Validation Loss: 0.4305, Validation F1-score: 0.5463
Epoch 3/30, Training Loss: 0.1483, Training F1-score: 0.7565, Validation Loss: 0.6739, Validation F1-score: 0.4262
Epoch 4/30, Training Loss: 0.1339, Training F1-score: 0.7923, Validation Loss: 0.4700, Validation F1-score: 0.4738
Epoch 5/30, Training Loss: 0.1205, Training F1-score: 0.8276, Validation Loss: 0.4400, Validation F1-score: 0.4276
Epoch 6/30, Training Loss: 0.1166, Training F1-score: 0.8003, Validation Loss: 0.5861, Validation F1-score: 0.4465
Epoch 7/30, Training Loss: 0.1066, Training F1-score: 0.8138, Validation Loss: 0.5447, Validation F1-score: 0.4576
Early stopping triggered after 7 epochs.
Test F1-score: 0.6486
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3257, Training F1-score: 0.6206, Validation Loss: 0.5317, Validation F1-score: 0.3921
Epoch 2/30, Training Loss: 0.1811, Training F1-score: 0.7300, Validation Loss: 0.5392, Validation F1-score: 0.4212
Epoch 3/30, Training Loss: 0.1428, Training F1-score: 0.7701, Validation Loss: 0.5045, Validation F1-score: 0.4135
Epoch 4/30, Training Loss: 0.1280, Training F1-score: 0.7790, Validation Loss: 0.5636, Validation F1-score: 0.3933
Epoch 5/30, Training Loss: 0.1200, Training F1-score: 0.7869, Validation Loss: 0.5421, Validation F1-score: 0.4034
Epoch 6/30, Training Loss: 0.1096, Training F1-score: 0.7972, Validation Loss: 0.5380, Validation F1-score: 0.4754
Epoch 7/30, Training Loss: 0.1026, Training F1-score: 0.8240, Validation Loss: 0.6155, Validation F1-score: 0.4244
Epoch 8/30, Training Loss: 0.0990, Training F1-score: 0.8278, Validation Loss: 0.5771, Validation F1-score: 0.5461
Epoch 9/30, Training Loss: 0.0942, Training F1-score: 0.8365, Validation Loss: 0.5478, Validation F1-score: 0.4829
Epoch 10/30, Training Loss: 0.0870, Training F1-score: 0.8516, Validation Loss: 0.5405, Validation F1-score: 0.4373
Epoch 11/30, Training Loss: 0.0835, Training F1-score: 0.8348, Validation Loss: 0.6041, Validation F1-score: 0.4631
Epoch 12/30, Training Loss: 0.0830, Training F1-score: 0.8699, Validation Loss: 0.6461, Validation F1-score: 0.4527
Epoch 13/30, Training Loss: 0.0768, Training F1-score: 0.8760, Validation Loss: 0.5556, Validation F1-score: 0.4929
Early stopping triggered after 13 epochs.
Test F1-score: 0.6082
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3373, Training F1-score: 0.6123, Validation Loss: 0.4621, Validation F1-score: 0.4022
slurmstepd: error: *** JOB 895286 ON tg097 CANCELLED AT 2024-09-26T00:58:52 DUE TO TIME LIMIT ***
=== JOB_STATISTICS ===
=== current date     : Thu 26 Sep 2024 12:58:54 AM CEST
= Job-ID             : 895286 on tinygpu
= Job-Name           : MinicondaName
= Job-Command        : /home/woody/iwfa/iwfa044h/runner.sh
= Initial workdir    : /home/woody/iwfa/iwfa044h
= Queue/Partition    : a100
= Slurm account      : iwfa with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 1-00:00:25
= Total RAM usage    : 3.0 GiB of requested  GiB (%)   
= Node list          : tg097
= Subm/Elig/Start/End: 2024-09-24T22:58:01 / 2024-09-24T22:58:01 / 2024-09-25T00:58:27 / 2024-09-26T00:58:52
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           56.8G   104.9G   209.7G        N/A     142K     500K   1,000K        N/A    
    /home/woody        823.0G  1000.0G  1500.0G        N/A   1,811K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:41:00.0, 719118, 99 %, 22 %, 14176 MiB, 86398831 ms
