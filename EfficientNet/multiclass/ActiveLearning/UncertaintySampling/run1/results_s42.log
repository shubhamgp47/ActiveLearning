(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m1.0000[0m        [32m2.2493[0m       [35m0.1559[0m      [31m0.1559[0m        [94m2.0774[0m     +  0.0000  21.5047
      2      0.5000        [32m1.5295[0m       0.0587      0.0587        2.1161        0.0000  20.4170
      3      0.8750        [32m1.3080[0m       0.1408      0.1408        [94m2.0734[0m     +  0.0000  20.1871
      4      1.0000        [32m1.0106[0m       0.0757      0.0757        2.1026        0.0000  20.1786
      5      0.8750        [32m0.9081[0m       0.1153      0.1153        2.0736        0.0000  20.3371
      6      1.0000        [32m0.7363[0m       [35m0.1741[0m      [31m0.1741[0m        [94m2.0444[0m     +  0.0000  20.4122
      7      0.8750        0.8869       [35m0.2068[0m      [31m0.2068[0m        [94m2.0256[0m     +  0.0000  20.1312
      8      1.0000        [32m0.5914[0m       [35m0.2215[0m      [31m0.2215[0m        [94m2.0173[0m     +  0.0000  20.4678
      9      1.0000        [32m0.4875[0m       0.2191      0.2191        2.0199        0.0000  20.5249
     10      1.0000        0.6878       0.2116      0.2116        2.0282        0.0000  20.1178
     11      1.0000        [32m0.4122[0m       0.2120      0.2120        2.0348        0.0000  20.2281
     12      1.0000        0.6120       0.2071      0.2071        2.0510        0.0000  20.2937
     13      1.0000        [32m0.3978[0m       0.2017      0.2017        2.0635        0.0000  20.3444
     14      1.0000        [32m0.3400[0m       0.1944      0.1944        2.0793        0.0000  20.3567
     15      1.0000        0.5829       0.2148      0.2148        2.0802        0.0000  20.5340
     16      1.0000        0.4328       0.2057      0.2057        2.0957        0.0000  20.5426
     17      1.0000        [32m0.2343[0m       0.1984      0.1984        2.1065        0.0000  20.4460
     18      0.8750        0.6312       0.1696      0.1696        2.1325        0.0000  20.2103
Stopping since valid_loss has not improved in the last 11 epochs.
Pre F1 micro score = 0.1632
Pre F1 macro score = 0.1199

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5417[0m        [32m1.4958[0m       [35m0.2637[0m      [31m0.2637[0m        [94m1.9986[0m     +  0.0000  21.0695
      2      [36m0.8333[0m        [32m1.0444[0m       [35m0.2998[0m      [31m0.2998[0m        [94m1.9270[0m     +  0.0000  20.8799
      3      [36m0.9167[0m        [32m0.7759[0m       [35m0.3337[0m      [31m0.3337[0m        [94m1.8397[0m     +  0.0000  21.9342
      4      0.9167        [32m0.6483[0m       [35m0.3523[0m      [31m0.3523[0m        [94m1.7826[0m     +  0.0000  23.0937
      5      0.8750        0.7881       [35m0.3920[0m      [31m0.3920[0m        [94m1.7230[0m     +  0.0000  20.8725
      6      0.8750        [32m0.5820[0m       [35m0.4174[0m      [31m0.4174[0m        [94m1.6777[0m     +  0.0000  20.8898
      7      0.9167        [32m0.5127[0m       [35m0.4392[0m      [31m0.4392[0m        [94m1.6558[0m     +  0.0000  20.7816
      8      0.8750        0.5337       [35m0.4410[0m      [31m0.4410[0m        [94m1.6483[0m     +  0.0000  20.8843
      9      0.8750        0.5173       0.4387      0.4387        [94m1.6433[0m     +  0.0000  20.7437
     10      [36m1.0000[0m        [32m0.4143[0m       0.4375      0.4375        [94m1.6349[0m     +  0.0000  20.9008
     11      0.9583        [32m0.3146[0m       0.4382      0.4382        [94m1.6304[0m     +  0.0000  20.8706
     12      0.8750        0.4826       [35m0.4437[0m      [31m0.4437[0m        [94m1.6229[0m     +  0.0000  20.7189
     13      0.9583        0.3601       [35m0.4462[0m      [31m0.4462[0m        [94m1.6159[0m     +  0.0000  21.0253
     14      0.9167        0.4304       0.4413      0.4413        [94m1.6159[0m     +  0.0000  21.0268
     15      0.9167        [32m0.3115[0m       0.4365      0.4365        [94m1.6124[0m     +  0.0000  21.0226
     16      0.9583        0.3845       0.4344      0.4344        [94m1.6057[0m     +  0.0000  21.0355
     17      0.9583        0.3315       0.4309      0.4309        1.6131        0.0000  20.7346
     18      1.0000        [32m0.2798[0m       0.4340      0.4340        1.6082        0.0000  20.6613
     19      0.8750        0.3984       0.4345      0.4345        [94m1.6056[0m     +  0.0000  20.9158
     20      1.0000        [32m0.2698[0m       0.4299      0.4299        1.6161        0.0000  20.9631
     21      1.0000        [32m0.2476[0m       0.4266      0.4266        1.6158        0.0000  20.7307
     22      1.0000        0.2968       0.4259      0.4259        1.6170        0.0000  20.7735
     23      1.0000        0.3622       0.4285      0.4285        1.6149        0.0000  20.9783
     24      1.0000        0.2777       0.4292      0.4292        1.6153        0.0000  21.1219
     25      1.0000        [32m0.2156[0m       0.4274      0.4274        1.6127        0.0000  20.8300
     26      0.9583        0.3304       0.4231      0.4231        1.6218        0.0000  20.8406
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24]
F1 Micro Score after query 1: 0.38697916666666665
F1 Macro Score after query 1: 0.21575763757943717
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5179[0m        [32m1.2521[0m       [35m0.5644[0m      [31m0.5644[0m        [94m1.3984[0m     +  0.0000  21.8128
      2      [36m0.8393[0m        [32m0.7127[0m       [35m0.5951[0m      [31m0.5951[0m        [94m1.3498[0m     +  0.0000  21.7931
      3      [36m0.8929[0m        [32m0.6041[0m       [35m0.6099[0m      [31m0.6099[0m        [94m1.3327[0m     +  0.0000  24.0622
      4      [36m0.9643[0m        [32m0.4447[0m       [35m0.6205[0m      [31m0.6205[0m        [94m1.3174[0m     +  0.0000  22.4884
      5      0.9643        [32m0.3901[0m       [35m0.6413[0m      [31m0.6413[0m        [94m1.2930[0m     +  0.0000  21.9063
      6      0.9643        [32m0.3504[0m       0.6403      0.6403        [94m1.2878[0m     +  0.0000  21.8742
      7      0.9643        0.3688       0.6373      0.6373        1.2908        0.0000  22.2721
      8      [36m0.9821[0m        [32m0.3200[0m       0.6375      0.6375        [94m1.2867[0m     +  0.0000  22.0106
      9      0.9821        [32m0.3140[0m       0.6328      0.6328        1.2895        0.0000  21.8883
     10      0.9464        0.3326       0.6286      0.6286        1.2951        0.0000  21.8053
     11      [36m1.0000[0m        [32m0.2748[0m       0.6314      0.6314        1.2962        0.0000  22.0139
     12      0.9821        [32m0.2532[0m       0.6314      0.6314        1.2954        0.0000  21.8392
     13      0.9821        [32m0.2505[0m       0.6266      0.6266        1.2960        0.0000  21.9113
     14      0.9643        0.2767       0.6267      0.6267        1.2966        0.0000  22.2898
     15      1.0000        [32m0.2237[0m       0.6234      0.6234        1.3030        0.0000  22.0951
     16      1.0000        [32m0.1905[0m       0.6278      0.6278        1.2938        0.0000  21.8421
     17      1.0000        0.2077       0.6267      0.6267        1.2944        0.0000  22.2128
     18      0.9821        0.2263       0.6314      0.6314        1.2912        0.0000  22.1143
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.6239583333333333
F1 Macro Score after query 2: 0.35131712343999494
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 64 informative samples: 

Training started with 120 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7167[0m        [32m0.9351[0m       [35m0.6568[0m      [31m0.6568[0m        [94m1.1323[0m     +  0.0000  23.9557
      2      [36m0.8667[0m        [32m0.6263[0m       0.6502      0.6502        [94m1.0976[0m     +  0.0000  23.8283
      3      0.8500        [32m0.5488[0m       [35m0.6747[0m      [31m0.6747[0m        [94m1.0492[0m     +  0.0000  23.8578
      4      [36m0.9000[0m        [32m0.4453[0m       [35m0.6790[0m      [31m0.6790[0m        [94m1.0295[0m     +  0.0000  24.4376
      5      [36m0.9250[0m        [32m0.3640[0m       0.6788      0.6788        [94m1.0277[0m     +  0.0000  23.6945
      6      [36m0.9500[0m        [32m0.3369[0m       0.6720      0.6720        [94m1.0227[0m     +  0.0000  23.8805
      7      0.9333        [32m0.3312[0m       [35m0.6832[0m      [31m0.6832[0m        [94m0.9941[0m     +  0.0000  24.1352
      8      0.9500        [32m0.2948[0m       [35m0.6840[0m      [31m0.6840[0m        1.0057        0.0000  23.5355
      9      [36m0.9667[0m        [32m0.2796[0m       0.6811      0.6811        1.0116        0.0000  26.0186
     10      0.9583        [32m0.2371[0m       0.6825      0.6825        1.0084        0.0000  24.6141
     11      0.9500        0.2373       0.6835      0.6835        1.0022        0.0000  23.4530
     12      [36m0.9833[0m        [32m0.2327[0m       [35m0.6878[0m      [31m0.6878[0m        [94m0.9926[0m     +  0.0000  23.9232
     13      0.9750        [32m0.2059[0m       0.6878      0.6878        0.9948        0.0000  23.9284
     14      [36m0.9917[0m        [32m0.1800[0m       0.6868      0.6868        0.9962        0.0000  24.0843
     15      0.9917        [32m0.1730[0m       0.6861      0.6861        0.9998        0.0000  23.6323
     16      0.9750        0.2019       0.6873      0.6873        0.9984        0.0000  23.8025
     17      [36m1.0000[0m        [32m0.1480[0m       [35m0.6910[0m      [31m0.6910[0m        [94m0.9909[0m     +  0.0000  23.8471
     18      1.0000        0.1565       0.6910      0.6910        [94m0.9886[0m     +  0.0000  23.6021
     19      0.9833        0.1776       [35m0.6965[0m      [31m0.6965[0m        [94m0.9812[0m     +  0.0000  24.1622
     20      0.9833        0.1634       0.6913      0.6913        0.9977        0.0000  23.7877
     21      0.9917        0.1620       0.6924      0.6924        0.9938        0.0000  23.8302
     22      1.0000        0.1579       0.6939      0.6939        0.9864        0.0000  23.6931
     23      0.9583        0.1857       0.6939      0.6939        [94m0.9775[0m     +  0.0000  23.5669
     24      0.9833        [32m0.1395[0m       0.6937      0.6937        0.9808        0.0000  23.8026
     25      0.9833        0.1746       0.6948      0.6948        0.9824        0.0000  23.8488
     26      0.9917        0.1589       0.6906      0.6906        0.9878        0.0000  23.8620
     27      1.0000        0.1515       0.6929      0.6929        0.9799        0.0000  23.8302
     28      0.9833        0.1565       0.6927      0.6927        0.9951        0.0000  23.8157
     29      0.9750        0.1604       0.6915      0.6915        0.9998        0.0000  23.5815
     30      0.9833        0.1515       0.6911      0.6911        1.0018        0.0000  23.9879
     31      1.0000        [32m0.1356[0m       0.6913      0.6913        0.9963        0.0000  23.7063
     32      1.0000        [32m0.1254[0m       0.6932      0.6932        0.9946        0.0000  23.7551
     33      1.0000        [32m0.1249[0m       0.6925      0.6925        0.9904        0.0000  23.7693
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 120]
F1 Micro Score after query 3: 0.6987847222222222
F1 Macro Score after query 3: 0.3403772504439199
Number of samples used for retraining: 120
Number of samples in pool after training and deleting samples: 26760
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 216 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6991[0m        [32m0.9154[0m       [35m0.6960[0m      [31m0.6960[0m        [94m0.9019[0m     +  0.0000  26.6588
      2      [36m0.8472[0m        [32m0.4977[0m       [35m0.7113[0m      [31m0.7113[0m        [94m0.8596[0m     +  0.0000  26.8042
      3      [36m0.9074[0m        [32m0.4498[0m       [35m0.7217[0m      [31m0.7217[0m        [94m0.8316[0m     +  0.0000  26.7252
      4      0.8981        [32m0.3890[0m       0.7174      0.7174        0.8500        0.0000  26.7431
      5      [36m0.9306[0m        [32m0.3401[0m       0.7149      0.7149        0.8539        0.0000  26.8330
      6      [36m0.9398[0m        [32m0.2780[0m       0.7214      0.7214        0.8548        0.0000  26.3168
      7      [36m0.9537[0m        0.2785       0.7189      0.7189        0.8495        0.0000  26.6617
      8      0.9444        [32m0.2494[0m       [35m0.7253[0m      [31m0.7253[0m        0.8596        0.0000  26.6132
      9      [36m0.9676[0m        [32m0.2061[0m       0.7224      0.7224        0.8596        0.0000  26.7884
     10      [36m0.9861[0m        [32m0.1784[0m       0.7238      0.7238        0.8634        0.0000  26.9273
     11      0.9815        [32m0.1771[0m       [35m0.7255[0m      [31m0.7255[0m        0.8614        0.0000  26.6935
     12      0.9815        [32m0.1522[0m       0.7222      0.7222        0.8713        0.0000  26.6145
     13      0.9630        0.1701       0.7231      0.7231        0.8692        0.0000  26.7708
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 120, 216]
F1 Micro Score after query 4: 0.7180555555555556
F1 Macro Score after query 4: 0.370020538774542
Number of samples used for retraining: 216
Number of samples in pool after training and deleting samples: 26664
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 392 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7985[0m        [32m0.6612[0m       [35m0.7352[0m      [31m0.7352[0m        [94m0.8029[0m     +  0.0000  32.4322
      2      [36m0.8673[0m        [32m0.4669[0m       [35m0.7477[0m      [31m0.7477[0m        [94m0.8023[0m     +  0.0000  32.1038
      3      [36m0.9184[0m        [32m0.3464[0m       [35m0.7587[0m      [31m0.7587[0m        [94m0.7687[0m     +  0.0000  32.4167
      4      [36m0.9439[0m        [32m0.2773[0m       0.7530      0.7530        0.7929        0.0000  32.1869
      5      [36m0.9464[0m        [32m0.2536[0m       0.7533      0.7533        0.8030        0.0000  32.9198
      6      0.9388        0.2622       0.7530      0.7530        0.7894        0.0000  33.4058
      7      [36m0.9541[0m        [32m0.2124[0m       0.7498      0.7498        0.8315        0.0000  32.2777
      8      [36m0.9668[0m        [32m0.1843[0m       0.7516      0.7516        0.8309        0.0000  32.3852
      9      0.9643        [32m0.1731[0m       0.7543      0.7543        0.8408        0.0000  32.4617
     10      [36m0.9770[0m        [32m0.1484[0m       0.7536      0.7536        0.8514        0.0000  32.1965
     11      0.9745        0.1501       0.7530      0.7530        0.8601        0.0000  32.0836
     12      0.9694        [32m0.1413[0m       0.7564      0.7564        0.8449        0.0000  32.3031
     13      [36m0.9796[0m        [32m0.1178[0m       0.7549      0.7549        0.8573        0.0000  32.3109
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 120, 216, 392]
F1 Micro Score after query 5: 0.7864583333333334
F1 Macro Score after query 5: 0.44174935995928655
Number of samples used for retraining: 392
Number of samples in pool after training and deleting samples: 26488
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 712 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7472[0m        [32m0.7341[0m       [35m0.7411[0m      [31m0.7411[0m        [94m0.8175[0m     +  0.0000  42.1534
      2      [36m0.8553[0m        [32m0.4863[0m       0.7316      0.7316        [94m0.7880[0m     +  0.0000  42.3489
      3      [36m0.9101[0m        [32m0.3851[0m       0.7219      0.7219        0.8104        0.0000  42.1756
      4      [36m0.9115[0m        [32m0.3387[0m       0.7227      0.7227        0.7925        0.0000  42.1868
      5      [36m0.9284[0m        [32m0.2841[0m       0.6951      0.6951        0.8506        0.0000  42.2702
      6      [36m0.9452[0m        [32m0.2355[0m       0.7351      0.7351        [94m0.7770[0m     +  0.0000  42.0323
      7      [36m0.9635[0m        [32m0.2117[0m       0.7104      0.7104        0.8557        0.0000  44.3444
      8      0.9635        [32m0.1816[0m       0.7052      0.7052        0.8353        0.0000  41.9099
      9      0.9607        [32m0.1706[0m       0.7278      0.7278        0.8102        0.0000  42.1198
     10      [36m0.9733[0m        [32m0.1520[0m       0.7302      0.7302        0.8103        0.0000  42.1251
     11      [36m0.9761[0m        [32m0.1372[0m       0.7347      0.7347        0.7989        0.0000  42.2049
     12      [36m0.9846[0m        [32m0.1165[0m       0.7403      0.7403        0.8052        0.0000  42.1272
     13      [36m0.9860[0m        [32m0.1150[0m       0.7384      0.7384        0.8203        0.0000  42.1092
     14      0.9860        [32m0.1010[0m       0.7247      0.7247        0.8597        0.0000  42.4522
     15      [36m0.9874[0m        [32m0.0986[0m       0.7281      0.7281        0.8589        0.0000  42.0809
     16      0.9831        0.1012       0.7340      0.7340        0.8459        0.0000  41.8430
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 120, 216, 392, 712]
F1 Micro Score after query 6: 0.790625
F1 Macro Score after query 6: 0.48341763592147236
Number of samples used for retraining: 712
Number of samples in pool after training and deleting samples: 26168
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1272 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7987[0m        [32m0.6019[0m       [35m0.7887[0m      [31m0.7887[0m        [94m0.6157[0m     +  0.0000  59.5278
      2      [36m0.8860[0m        [32m0.3838[0m       0.7870      0.7870        0.6241        0.0000  59.5481
      3      [36m0.9253[0m        [32m0.2909[0m       [35m0.8010[0m      [31m0.8010[0m        [94m0.6037[0m     +  0.0000  60.2498
      4      [36m0.9332[0m        [32m0.2396[0m       0.7969      0.7969        0.6200        0.0000  59.3312
      5      [36m0.9536[0m        [32m0.1960[0m       0.7986      0.7986        0.6196        0.0000  59.3901
      6      [36m0.9591[0m        [32m0.1810[0m       [35m0.8030[0m      [31m0.8030[0m        0.6112        0.0000  59.4180
      7      [36m0.9686[0m        [32m0.1536[0m       0.7740      0.7740        0.7292        0.0000  59.1157
      8      [36m0.9717[0m        [32m0.1344[0m       0.7951      0.7951        0.6481        0.0000  59.6636
      9      [36m0.9788[0m        [32m0.1079[0m       0.7892      0.7892        0.6874        0.0000  59.3096
     10      0.9733        0.1144       0.7811      0.7811        0.7163        0.0000  59.4335
     11      [36m0.9882[0m        [32m0.0820[0m       0.7866      0.7866        0.7158        0.0000  59.3600
     12      [36m0.9906[0m        [32m0.0728[0m       0.7868      0.7868        0.7301        0.0000  59.4618
     13      0.9811        0.0848       0.7941      0.7941        0.6964        0.0000  59.6991
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272]
F1 Micro Score after query 7: 0.8253472222222222
F1 Macro Score after query 7: 0.5583391931297899
Number of samples used for retraining: 1272
Number of samples in pool after training and deleting samples: 25608
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 992 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8361[0m        [32m0.5033[0m       [35m0.8010[0m      [31m0.8010[0m        [94m0.5583[0m     +  0.0000  90.2098
      2      [36m0.8918[0m        [32m0.3454[0m       [35m0.8151[0m      [31m0.8151[0m        [94m0.5276[0m     +  0.0000  90.0772
      3      [36m0.9152[0m        [32m0.2737[0m       0.8137      0.8137        0.5331        0.0000  90.0787
      4      [36m0.9342[0m        [32m0.2279[0m       0.7931      0.7931        0.6569        0.0000  90.1464
      5      [36m0.9510[0m        [32m0.1828[0m       [35m0.8224[0m      [31m0.8224[0m        0.5633        0.0000  90.1466
      6      [36m0.9611[0m        [32m0.1567[0m       0.8069      0.8069        0.6369        0.0000  89.9719
      7      [36m0.9655[0m        [32m0.1342[0m       0.8082      0.8082        0.6663        0.0000  92.6745
      8      [36m0.9695[0m        [32m0.1177[0m       0.8075      0.8075        0.6503        0.0000  90.1479
      9      [36m0.9731[0m        [32m0.1044[0m       0.8024      0.8024        0.6830        0.0000  90.2236
     10      [36m0.9801[0m        [32m0.0813[0m       0.7972      0.7972        0.7370        0.0000  90.1138
     11      [36m0.9819[0m        [32m0.0792[0m       0.8057      0.8057        0.6986        0.0000  90.1296
     12      [36m0.9850[0m        [32m0.0630[0m       0.8017      0.8017        0.6815        0.0000  89.9630
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272, 2264]
F1 Micro Score after query 8: 0.8352430555555554
F1 Macro Score after query 8: 0.5435787793352644
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.8366[0m        [32m0.4595[0m       [35m0.7837[0m      [31m0.7837[0m        [94m0.5843[0m     +  0.0000  145.8753
      2      [36m0.8822[0m        [32m0.3342[0m       [35m0.7974[0m      [31m0.7974[0m        [94m0.5609[0m     +  0.0000  145.3685
      3      [36m0.9097[0m        [32m0.2671[0m       [35m0.8106[0m      [31m0.8106[0m        [94m0.5341[0m     +  0.0000  144.7645
      4      [36m0.9223[0m        [32m0.2283[0m       0.8095      0.8095        0.5722        0.0000  145.5070
      5      [36m0.9391[0m        [32m0.1863[0m       [35m0.8111[0m      [31m0.8111[0m        0.5660        0.0000  145.1256
      6      [36m0.9480[0m        [32m0.1669[0m       [35m0.8186[0m      [31m0.8186[0m        0.5679        0.0000  145.1212
      7      [36m0.9527[0m        [32m0.1462[0m       0.8186      0.8186        0.5897        0.0000  145.3005
      8      [36m0.9606[0m        [32m0.1236[0m       0.8132      0.8132        0.6172        0.0000  145.1600
      9      [36m0.9641[0m        [32m0.1152[0m       0.8132      0.8132        0.6867        0.0000  145.3822
     10      [36m0.9708[0m        [32m0.0993[0m       0.7939      0.7939        0.7263        0.0000  145.2330
     11      [36m0.9772[0m        [32m0.0829[0m       0.8116      0.8116        0.6775        0.0000  145.4970
     12      [36m0.9829[0m        [32m0.0674[0m       [35m0.8203[0m      [31m0.8203[0m        0.6207        0.0000  146.9248
     13      [36m0.9837[0m        [32m0.0630[0m       [35m0.8205[0m      [31m0.8205[0m        0.6469        0.0000  145.1354
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272, 2264, 4040]
F1 Micro Score after query 9: 0.8180555555555555
F1 Macro Score after query 9: 0.5335977927957218
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3168 informative samples: 

Training started with 7208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.8916[0m        [32m0.3269[0m       [35m0.8240[0m      [31m0.8240[0m        [94m0.5403[0m     +  0.0000  243.3141
      2      [36m0.9141[0m        [32m0.2603[0m       0.8028      0.8028        0.6238        0.0000  243.7174
      3      [36m0.9295[0m        [32m0.2109[0m       0.8033      0.8033        0.6639        0.0000  243.4572
      4      [36m0.9421[0m        [32m0.1803[0m       0.7997      0.7997        0.6813        0.0000  243.3169
      5      [36m0.9484[0m        [32m0.1523[0m       0.8151      0.8151        0.6614        0.0000  243.2062
      6      [36m0.9538[0m        [32m0.1364[0m       0.8040      0.8040        0.6894        0.0000  243.2607
      7      [36m0.9617[0m        [32m0.1134[0m       0.8059      0.8059        0.6917        0.0000  243.4543
      8      [36m0.9659[0m        [32m0.1024[0m       0.8087      0.8087        0.7030        0.0000  243.4513
      9      [36m0.9706[0m        [32m0.0891[0m       0.7965      0.7965        0.7673        0.0000  243.6193
     10      [36m0.9713[0m        [32m0.0865[0m       0.8017      0.8017        0.7175        0.0000  243.0275
     11      [36m0.9802[0m        [32m0.0624[0m       0.8127      0.8127        0.7506        0.0000  243.4618
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272, 2264, 4040, 7208]
F1 Micro Score after query 10: 0.8215277777777777
F1 Macro Score after query 10: 0.5536557344215226
Number of samples used for retraining: 7208
Number of samples in pool after training and deleting samples: 19672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5632 informative samples: 

Training started with 12840 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9229[0m        [32m0.2431[0m       [35m0.8231[0m      [31m0.8231[0m        [94m0.5475[0m     +  0.0000  417.3422
      2      [36m0.9417[0m        [32m0.1863[0m       [35m0.8236[0m      [31m0.8236[0m        0.5696        0.0000  417.9474
      3      [36m0.9484[0m        [32m0.1569[0m       [35m0.8337[0m      [31m0.8337[0m        0.5660        0.0000  417.7759
      4      [36m0.9552[0m        [32m0.1336[0m       [35m0.8339[0m      [31m0.8339[0m        0.5721        0.0000  418.0597
      5      [36m0.9600[0m        [32m0.1175[0m       0.8293      0.8293        0.5993        0.0000  417.7325
      6      [36m0.9697[0m        [32m0.0940[0m       0.8262      0.8262        0.6427        0.0000  418.1040
      7      [36m0.9717[0m        [32m0.0821[0m       [35m0.8514[0m      [31m0.8514[0m        [94m0.5022[0m     +  0.0000  418.0718
      8      [36m0.9762[0m        [32m0.0719[0m       0.8234      0.8234        0.7321        0.0000  418.3058
      9      [36m0.9795[0m        [32m0.0628[0m       0.8384      0.8384        0.6549        0.0000  417.9643
     10      [36m0.9802[0m        [32m0.0563[0m       0.8332      0.8332        0.6601        0.0000  417.9757
     11      [36m0.9864[0m        [32m0.0408[0m       0.8339      0.8339        0.6421        0.0000  418.0908
     12      [36m0.9884[0m        [32m0.0364[0m       0.8245      0.8245        0.6939        0.0000  416.0121
     13      [36m0.9896[0m        [32m0.0331[0m       0.8311      0.8311        0.6955        0.0000  413.3015
     14      [36m0.9913[0m        [32m0.0271[0m       0.8342      0.8342        0.6882        0.0000  414.0556
     15      0.9902        0.0291       0.8356      0.8356        0.6970        0.0000  413.1284
     16      [36m0.9923[0m        [32m0.0240[0m       0.8434      0.8434        0.6725        0.0000  413.5759
     17      [36m0.9937[0m        [32m0.0217[0m       0.8335      0.8335        0.7374        0.0000  413.5941
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272, 2264, 4040, 7208, 12840]
F1 Micro Score after query 11: 0.8362847222222223
F1 Macro Score after query 11: 0.6372945379336115
Number of samples used for retraining: 12840
Number of samples in pool after training and deleting samples: 14040
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22840 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9810[0m        [32m0.0619[0m       [35m0.8229[0m      [31m0.8229[0m        [94m0.7107[0m     +  0.0000  722.5528
      2      [36m0.9833[0m        [32m0.0514[0m       [35m0.8332[0m      [31m0.8332[0m        [94m0.5963[0m     +  0.0000  736.3852
      3      [36m0.9861[0m        [32m0.0422[0m       0.8283      0.8283        0.7153        0.0000  737.0471
      4      [36m0.9877[0m        [32m0.0382[0m       0.8267      0.8267        0.7003        0.0000  736.2650
      5      [36m0.9893[0m        [32m0.0329[0m       [35m0.8500[0m      [31m0.8500[0m        0.6352        0.0000  736.0984
      6      [36m0.9895[0m        [32m0.0293[0m       0.8434      0.8434        0.6411        0.0000  736.0156
      7      [36m0.9908[0m        [32m0.0274[0m       0.8491      0.8491        0.6253        0.0000  735.6876
      8      [36m0.9914[0m        [32m0.0254[0m       0.8406      0.8406        0.7435        0.0000  735.4531
      9      [36m0.9922[0m        [32m0.0229[0m       [35m0.8509[0m      [31m0.8509[0m        0.6987        0.0000  733.7305
     10      [36m0.9926[0m        [32m0.0211[0m       0.8507      0.8507        0.6885        0.0000  731.4904
     11      [36m0.9953[0m        [32m0.0150[0m       0.8441      0.8441        0.7707        0.0000  729.7839
     12      [36m0.9958[0m        [32m0.0121[0m       0.8431      0.8431        0.7814        0.0000  727.7760
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272, 2264, 4040, 7208, 12840, 22840]
F1 Micro Score after query 12: 0.845138888888889
F1 Macro Score after query 12: 0.6000304482918648
Number of samples used for retraining: 22840
Number of samples in pool after training and deleting samples: 4040
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4040 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9873[0m        [32m0.0396[0m       [35m0.8224[0m      [31m0.8224[0m        [94m0.7444[0m     +  0.0000  850.7064
      2      [36m0.9879[0m        [32m0.0350[0m       [35m0.8247[0m      [31m0.8247[0m        [94m0.6907[0m     +  0.0000  853.1365
      3      [36m0.9895[0m        [32m0.0311[0m       0.8075      0.8075        0.8541        0.0000  850.9930
      4      [36m0.9907[0m        [32m0.0275[0m       [35m0.8250[0m      [31m0.8250[0m        0.8032        0.0000  851.5845
      5      [36m0.9920[0m        [32m0.0252[0m       0.8208      0.8208        0.8432        0.0000  851.3534
      6      [36m0.9933[0m        [32m0.0222[0m       0.8220      0.8220        0.9185        0.0000  853.1567
      7      0.9929        [32m0.0208[0m       0.7984      0.7984        1.1028        0.0000  851.0981
      8      [36m0.9942[0m        [32m0.0176[0m       0.8116      0.8116        0.9962        0.0000  851.3508
      9      0.9939        0.0177       0.8231      0.8231        0.9255        0.0000  850.4467
     10      0.9941        [32m0.0174[0m       0.7920      0.7920        1.2604        0.0000  851.3988
     11      [36m0.9959[0m        [32m0.0119[0m       [35m0.8363[0m      [31m0.8363[0m        0.8848        0.0000  850.7878
     12      [36m0.9969[0m        [32m0.0098[0m       0.8306      0.8306        0.9618        0.0000  852.1868
Stopping since valid_loss has not improved in the last 11 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272, 2264, 4040, 7208, 12840, 22840, 26880]
F1 Micro Score after query 13: 0.8225694444444444
F1 Macro Score after query 13: 0.6076430302541014
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/uncertainty_sampling_seed42_param2\AL_margin_sampling_results_for_multiclass_classification_s42.pickle
