(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.1250[0m        [32m2.1278[0m       [35m0.1677[0m      [31m0.1677[0m        [94m2.0542[0m     +  0.0000  22.6356
      2      [36m0.5000[0m        [32m1.6515[0m       [35m0.2377[0m      [31m0.2377[0m        [94m2.0213[0m     +  0.0000  23.9996
      3      [36m0.6250[0m        [32m1.4650[0m       0.2300      0.2300        [94m1.9865[0m     +  0.0000  20.6530
      4      0.6250        [32m1.4459[0m       0.1792      0.1792        [94m1.9784[0m     +  0.0000  20.9703
      5      [36m1.0000[0m        [32m0.8297[0m       0.1229      0.1229        1.9934        0.0000  21.2663
      6      0.8750        1.0085       0.1104      0.1104        2.0018        0.0000  24.0748
      7      1.0000        [32m0.7459[0m       0.0962      0.0962        2.0168        0.0000  21.2048
      8      1.0000        [32m0.7205[0m       0.0845      0.0845        2.0399        0.0000  21.0679
      9      1.0000        [32m0.4696[0m       0.0797      0.0797        2.0595        0.0000  21.2231
     10      0.8750        0.7379       0.0753      0.0753        2.0859        0.0000  23.8106
     11      0.8750        0.6935       0.0764      0.0764        2.1177        0.0000  21.3123
     12      1.0000        0.6246       0.0665      0.0665        2.1407        0.0000  20.7714
     13      1.0000        0.6990       0.0571      0.0571        2.1538        0.0000  20.8456
     14      1.0000        0.5506       0.0517      0.0517        2.1595        0.0000  22.2820
     15      1.0000        0.4924       0.0458      0.0458        2.1733        0.0000  22.9700
     16      1.0000        0.7199       0.0382      0.0382        2.1849        0.0000  21.0739
     17      1.0000        0.6501       0.0325      0.0325        2.2035        0.0000  20.6974
     18      1.0000        0.5544       0.0280      0.0280        2.2170        0.0000  20.9306
     19      1.0000        0.6782       0.0280      0.0280        2.2370        0.0000  23.4598
Stopping since valid_loss has not improved in the last 16 epochs.
Pre F1 micro score = 0.0490
Pre F1 macro score = 0.0450

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.4583[0m        [32m1.7444[0m       [35m0.2019[0m      [31m0.2019[0m        [94m2.0702[0m     +  0.0000  24.5197
      2      [36m0.7917[0m        [32m1.1393[0m       [35m0.3042[0m      [31m0.3042[0m        [94m1.9613[0m     +  0.0000  24.9567
      3      [36m0.8333[0m        [32m0.9701[0m       [35m0.3679[0m      [31m0.3679[0m        [94m1.8648[0m     +  0.0000  24.2635
      4      0.8333        [32m0.8280[0m       [35m0.4102[0m      [31m0.4102[0m        [94m1.8041[0m     +  0.0000  21.5645
      5      [36m0.9583[0m        [32m0.6974[0m       [35m0.4328[0m      [31m0.4328[0m        [94m1.7348[0m     +  0.0000  21.0933
      6      0.9583        [32m0.6161[0m       [35m0.4457[0m      [31m0.4457[0m        [94m1.6941[0m     +  0.0000  21.3613
      7      [36m1.0000[0m        0.6566       [35m0.4615[0m      [31m0.4615[0m        [94m1.6654[0m     +  0.0000  21.4179
      8      0.9167        0.6179       [35m0.4821[0m      [31m0.4821[0m        [94m1.6320[0m     +  0.0000  21.5509
      9      1.0000        [32m0.4988[0m       [35m0.4993[0m      [31m0.4993[0m        [94m1.6062[0m     +  0.0000  23.4584
     10      1.0000        [32m0.3983[0m       [35m0.5078[0m      [31m0.5078[0m        [94m1.5962[0m     +  0.0000  22.9290
     11      1.0000        0.4432       [35m0.5174[0m      [31m0.5174[0m        [94m1.5886[0m     +  0.0000  21.3778
     12      0.9583        0.4558       [35m0.5283[0m      [31m0.5283[0m        [94m1.5750[0m     +  0.0000  21.3960
     13      0.9583        0.5284       [35m0.5366[0m      [31m0.5366[0m        [94m1.5624[0m     +  0.0000  21.1574
     14      1.0000        0.4055       [35m0.5380[0m      [31m0.5380[0m        [94m1.5583[0m     +  0.0000  21.4086
     15      0.8333        0.5604       0.5380      0.5380        [94m1.5506[0m     +  0.0000  21.4063
     16      0.9583        0.4775       0.5358      0.5358        [94m1.5486[0m     +  0.0000  24.1840
     17      0.9583        0.4476       0.5356      0.5356        [94m1.5469[0m     +  0.0000  21.4832
     18      0.9583        0.4254       0.5347      0.5347        [94m1.5430[0m     +  0.0000  21.3594
     19      0.9167        0.5066       0.5361      0.5361        1.5464        0.0000  21.5467
     20      0.9167        0.5137       [35m0.5417[0m      [31m0.5417[0m        [94m1.5418[0m     +  0.0000  21.4113
     21      1.0000        0.4429       0.5401      0.5401        1.5440        0.0000  21.2966
     22      1.0000        0.4870       [35m0.5420[0m      [31m0.5420[0m        [94m1.5409[0m     +  0.0000  22.1624
     23      1.0000        0.3988       [35m0.5437[0m      [31m0.5437[0m        [94m1.5387[0m     +  0.0000  23.4389
     24      1.0000        [32m0.3867[0m       0.5434      0.5434        [94m1.5384[0m     +  0.0000  21.5030
     25      0.9583        0.4680       0.5411      0.5411        [94m1.5376[0m     +  0.0000  21.3761
     26      0.9583        0.4210       [35m0.5467[0m      [31m0.5467[0m        [94m1.5305[0m     +  0.0000  20.9724
     27      1.0000        0.3922       0.5462      0.5462        1.5321        0.0000  21.5513
     28      0.9583        0.4388       0.5464      0.5464        [94m1.5292[0m     +  0.0000  21.4685
     29      1.0000        [32m0.3683[0m       0.5462      0.5462        [94m1.5285[0m     +  0.0000  24.2968
     30      1.0000        [32m0.3598[0m       0.5417      0.5417        1.5325        0.0000  21.5621
     31      0.9583        [32m0.3555[0m       0.5415      0.5415        1.5330        0.0000  21.2030
     32      1.0000        0.3952       0.5413      0.5413        1.5328        0.0000  21.5959
     33      0.9583        0.4994       0.5450      0.5450        1.5297        0.0000  21.4431
     34      0.9583        0.3863       [35m0.5495[0m      [31m0.5495[0m        [94m1.5253[0m     +  0.0000  21.2107
     35      1.0000        0.3820       0.5476      0.5476        [94m1.5246[0m     +  0.0000  21.2835
     36      1.0000        0.3600       [35m0.5503[0m      [31m0.5503[0m        [94m1.5236[0m     +  0.0000  25.0224
     37      0.9583        0.4363       0.5476      0.5476        [94m1.5222[0m     +  0.0000  21.3151
     38      1.0000        [32m0.3318[0m       0.5491      0.5491        1.5250        0.0000  21.5985
     39      0.9583        0.5032       0.5450      0.5450        1.5254        0.0000  21.3021
     40      1.0000        0.4641       0.5448      0.5448        1.5243        0.0000  21.5044
     41      0.9583        0.4806       0.5437      0.5437        1.5279        0.0000  21.3393
     42      0.9583        0.4299       0.5490      0.5490        1.5252        0.0000  22.7132
     43      1.0000        0.3745       0.5453      0.5453        1.5250        0.0000  23.4401
     44      0.9583        0.5483       0.5451      0.5451        1.5240        0.0000  21.3465
     45      1.0000        0.3728       0.5469      0.5469        1.5243        0.0000  21.3148
     46      1.0000        0.3683       0.5422      0.5422        1.5306        0.0000  21.9243
     47      0.9583        0.4533       0.5424      0.5424        1.5311        0.0000  21.3337
     48      0.9583        0.3760       0.5462      0.5462        1.5273        0.0000  21.3160
     49      1.0000        0.3731       0.5436      0.5436        1.5314        0.0000  22.2371
     50      1.0000        [32m0.2956[0m       0.5469      0.5469        1.5298        0.0000  22.5478
     51      1.0000        0.3807       0.5462      0.5462        1.5347        0.0000  21.3174
     52      1.0000        0.3551       0.5457      0.5457        1.5390        0.0000  21.2089
Stopping since valid_loss has not improved in the last 16 epochs.
[8, 24]
F1 Micro Score after query 1: 0.6173611111111111
F1 Macro Score after query 1: 0.24706981879310647
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.5893[0m        [32m1.2873[0m       [35m0.5807[0m      [31m0.5807[0m        [94m1.3844[0m     +  0.0000  22.4715
      2      [36m0.6786[0m        [32m0.9384[0m       [35m0.5882[0m      [31m0.5882[0m        [94m1.3118[0m     +  0.0000  22.3505
      3      [36m0.7857[0m        [32m0.8077[0m       [35m0.5979[0m      [31m0.5979[0m        [94m1.3099[0m     +  0.0000  25.4135
      4      [36m0.8036[0m        [32m0.7521[0m       [35m0.6054[0m      [31m0.6054[0m        [94m1.2745[0m     +  0.0000  23.1021
      5      [36m0.9107[0m        [32m0.5934[0m       [35m0.6193[0m      [31m0.6193[0m        [94m1.2491[0m     +  0.0000  22.2708
      6      0.8929        [32m0.5868[0m       [35m0.6247[0m      [31m0.6247[0m        [94m1.2374[0m     +  0.0000  22.6295
      7      0.9107        [32m0.4647[0m       [35m0.6257[0m      [31m0.6257[0m        [94m1.2300[0m     +  0.0000  22.3634
      8      0.9107        0.4960       [35m0.6337[0m      [31m0.6337[0m        [94m1.2189[0m     +  0.0000  22.0273
      9      [36m0.9464[0m        [32m0.4280[0m       [35m0.6366[0m      [31m0.6366[0m        [94m1.2101[0m     +  0.0000  22.9117
     10      0.9286        0.4913       0.6292      0.6292        1.2170        0.0000  23.7830
     11      [36m0.9643[0m        0.4323       0.6299      0.6299        [94m1.2080[0m     +  0.0000  22.3968
     12      [36m0.9821[0m        [32m0.4049[0m       0.6339      0.6339        [94m1.2061[0m     +  0.0000  22.4249
     13      0.9643        [32m0.3783[0m       [35m0.6373[0m      [31m0.6373[0m        [94m1.2060[0m     +  0.0000  22.2669
     14      0.9643        [32m0.3753[0m       0.6351      0.6351        1.2083        0.0000  22.1920
     15      0.9821        [32m0.3580[0m       0.6321      0.6321        1.2086        0.0000  22.0690
     16      0.9821        0.3826       0.6312      0.6312        [94m1.2048[0m     +  0.0000  25.8058
     17      0.9464        0.4029       0.6352      0.6352        [94m1.1983[0m     +  0.0000  22.3621
     18      0.9643        0.4014       0.6340      0.6340        [94m1.1980[0m     +  0.0000  22.3349
     19      0.8929        0.4930       0.6358      0.6358        [94m1.1975[0m     +  0.0000  22.3484
     20      0.9286        0.4299       [35m0.6382[0m      [31m0.6382[0m        [94m1.1910[0m     +  0.0000  22.2380
     21      0.9821        0.3763       [35m0.6420[0m      [31m0.6420[0m        [94m1.1845[0m     +  0.0000  22.3657
     22      0.9821        [32m0.3476[0m       0.6370      0.6370        1.1871        0.0000  25.4747
     23      0.9821        0.3686       0.6380      0.6380        1.1910        0.0000  23.1770
     24      [36m1.0000[0m        [32m0.3053[0m       0.6340      0.6340        1.1950        0.0000  22.3325
     25      0.9821        0.3596       0.6352      0.6352        1.1996        0.0000  22.3005
     26      0.9821        0.3600       0.6352      0.6352        1.1937        0.0000  22.2709
     27      0.9821        0.3457       0.6349      0.6349        1.1959        0.0000  22.4424
     28      0.9643        0.3843       0.6326      0.6326        1.1929        0.0000  22.5201
     29      0.9643        0.3584       0.6347      0.6347        1.1969        0.0000  24.3000
     30      0.9821        0.3175       0.6358      0.6358        1.1896        0.0000  22.7658
     31      0.9643        0.3773       0.6373      0.6373        1.1928        0.0000  22.7366
     32      0.9821        0.3669       0.6349      0.6349        1.1938        0.0000  22.3824
     33      1.0000        0.3472       0.6307      0.6307        1.2037        0.0000  22.4573
     34      0.9643        0.3460       0.6351      0.6351        1.1919        0.0000  22.0402
     35      1.0000        0.3087       0.6340      0.6340        1.1941        0.0000  24.6773
     36      0.9464        0.4039       0.6312      0.6312        1.2003        0.0000  23.1145
Stopping since valid_loss has not improved in the last 16 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.6730902777777777
F1 Macro Score after query 2: 0.2637961530428862
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 64 informative samples: 

Training started with 120 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6750[0m        [32m0.9583[0m       [35m0.6719[0m      [31m0.6719[0m        [94m1.0355[0m     +  0.0000  24.2863
      2      [36m0.8500[0m        [32m0.6440[0m       [35m0.6748[0m      [31m0.6748[0m        [94m1.0077[0m     +  0.0000  24.0843
      3      [36m0.8833[0m        [32m0.5355[0m       [35m0.6786[0m      [31m0.6786[0m        [94m0.9751[0m     +  0.0000  23.8033
      4      [36m0.9083[0m        [32m0.5115[0m       [35m0.6828[0m      [31m0.6828[0m        [94m0.9509[0m     +  0.0000  25.4915
      5      [36m0.9500[0m        [32m0.3845[0m       [35m0.6865[0m      [31m0.6865[0m        [94m0.9358[0m     +  0.0000  26.1502
      6      [36m0.9750[0m        [32m0.3681[0m       [35m0.6894[0m      [31m0.6894[0m        [94m0.9257[0m     +  0.0000  24.4296
      7      0.9500        [32m0.3516[0m       [35m0.6913[0m      [31m0.6913[0m        [94m0.9239[0m     +  0.0000  24.0676
      8      0.9167        0.3551       0.6885      0.6885        0.9277        0.0000  24.3193
      9      0.9417        [32m0.3407[0m       0.6905      0.6905        [94m0.9176[0m     +  0.0000  24.2869
     10      0.9667        [32m0.2789[0m       0.6866      0.6866        [94m0.9093[0m     +  0.0000  26.1485
     11      [36m0.9833[0m        [32m0.2650[0m       0.6887      0.6887        0.9143        0.0000  24.7705
     12      0.9667        0.2798       0.6905      0.6905        0.9122        0.0000  24.5859
     13      0.9583        0.2738       [35m0.6936[0m      [31m0.6936[0m        [94m0.9011[0m     +  0.0000  24.4617
     14      0.9667        [32m0.2621[0m       0.6906      0.6906        0.9093        0.0000  24.0027
     15      0.9750        0.2634       0.6936      0.6936        [94m0.8994[0m     +  0.0000  24.2722
     16      0.9750        [32m0.2597[0m       0.6925      0.6925        [94m0.8982[0m     +  0.0000  26.3204
     17      0.9667        0.2853       [35m0.6941[0m      [31m0.6941[0m        [94m0.8939[0m     +  0.0000  28.3086
     18      0.9500        0.2647       0.6910      0.6910        0.8984        0.0000  27.4822
     19      [36m0.9917[0m        [32m0.2241[0m       0.6887      0.6887        0.9063        0.0000  24.2112
     20      0.9750        0.2403       0.6894      0.6894        0.9004        0.0000  24.2858
     21      0.9833        0.2719       0.6913      0.6913        0.8985        0.0000  24.3598
     22      0.9750        0.2298       0.6872      0.6872        0.9065        0.0000  24.3768
     23      0.9833        0.2341       0.6898      0.6898        0.9094        0.0000  24.2691
     24      0.9750        [32m0.2157[0m       0.6896      0.6896        0.9040        0.0000  24.2382
     25      0.9667        0.2483       0.6885      0.6885        0.9032        0.0000  24.3320
     26      [36m1.0000[0m        0.2331       0.6918      0.6918        0.9027        0.0000  24.0499
     27      0.9833        0.2238       0.6861      0.6861        0.9094        0.0000  24.3322
     28      0.9583        0.2461       0.6899      0.6899        0.8988        0.0000  28.5378
     29      0.9583        0.2483       0.6878      0.6878        0.9022        0.0000  24.1172
     30      0.9667        0.2796       0.6918      0.6918        0.8941        0.0000  24.1182
     31      0.9750        0.2465       0.6898      0.6898        0.8990        0.0000  25.0679
     32      0.9833        0.2359       0.6905      0.6905        0.8995        0.0000  24.6448
Stopping since valid_loss has not improved in the last 16 epochs.
[8, 24, 56, 120]
F1 Micro Score after query 3: 0.7364583333333333
F1 Macro Score after query 3: 0.312554900317614
Number of samples used for retraining: 120
Number of samples in pool after training and deleting samples: 26760
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 216 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7824[0m        [32m0.6836[0m       [35m0.7481[0m      [31m0.7481[0m        [94m0.7682[0m     +  0.0000  27.1474
      2      [36m0.9028[0m        [32m0.4505[0m       0.7351      0.7351        0.7861        0.0000  27.3707
      3      [36m0.9352[0m        [32m0.3458[0m       0.7358      0.7358        0.7891        0.0000  27.1979
      4      [36m0.9398[0m        [32m0.3139[0m       0.7247      0.7247        0.8188        0.0000  27.6662
      5      0.9398        [32m0.2741[0m       0.7220      0.7220        0.7983        0.0000  27.0869
      6      [36m0.9537[0m        [32m0.2591[0m       0.7307      0.7307        0.8017        0.0000  26.9452
      7      [36m0.9722[0m        [32m0.2144[0m       0.7292      0.7292        0.8072        0.0000  26.8682
      8      0.9722        [32m0.1889[0m       0.7429      0.7429        0.7866        0.0000  29.4633
      9      0.9583        0.2150       0.7333      0.7333        0.7927        0.0000  27.5124
     10      [36m0.9815[0m        [32m0.1743[0m       0.7318      0.7318        0.7925        0.0000  27.1206
     11      0.9815        [32m0.1609[0m       0.7314      0.7314        0.8041        0.0000  26.7125
     12      0.9630        0.1753       0.7260      0.7260        0.8150        0.0000  27.2290
     13      0.9815        [32m0.1605[0m       0.7351      0.7351        0.8056        0.0000  27.3823
     14      [36m0.9861[0m        [32m0.1361[0m       0.7347      0.7347        0.8000        0.0000  26.9772
     15      0.9769        0.1706       0.7264      0.7264        0.8212        0.0000  27.0224
     16      0.9815        [32m0.1360[0m       0.7300      0.7300        0.8127        0.0000  27.1794
Stopping since valid_loss has not improved in the last 16 epochs.
[8, 24, 56, 120, 216]
F1 Micro Score after query 4: 0.7484375
F1 Macro Score after query 4: 0.31228597788772194
Number of samples used for retraining: 216
Number of samples in pool after training and deleting samples: 26664
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 392 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7653[0m        [32m0.7625[0m       [35m0.7389[0m      [31m0.7389[0m        [94m0.7694[0m     +  0.0000  32.7431
      2      [36m0.8827[0m        [32m0.4773[0m       [35m0.7585[0m      [31m0.7585[0m        [94m0.7273[0m     +  0.0000  32.4549
      3      [36m0.8929[0m        [32m0.4094[0m       0.7538      0.7538        0.7384        0.0000  32.9041
      4      [36m0.9184[0m        [32m0.3367[0m       0.7564      0.7564        [94m0.7204[0m     +  0.0000  33.8455
      5      [36m0.9235[0m        [32m0.3076[0m       0.7432      0.7432        0.7749        0.0000  32.8734
      6      [36m0.9439[0m        [32m0.2705[0m       0.7542      0.7542        0.7328        0.0000  32.4042
      7      [36m0.9770[0m        [32m0.2156[0m       0.7575      0.7575        0.7296        0.0000  32.6174
      8      0.9515        0.2412       0.7533      0.7533        0.7217        0.0000  32.4198
      9      0.9745        [32m0.2024[0m       0.7543      0.7543        0.7331        0.0000  32.7297
     10      0.9617        0.2175       0.7517      0.7517        0.7542        0.0000  32.4163
     11      0.9745        [32m0.1692[0m       0.7472      0.7472        0.7603        0.0000  35.1054
     12      0.9566        0.2034       0.7425      0.7425        0.7683        0.0000  32.7345
     13      0.9745        0.1703       0.7446      0.7446        0.7755        0.0000  32.6371
     14      0.9668        0.1784       0.7431      0.7431        0.7918        0.0000  33.1197
     15      0.9694        0.1968       0.7469      0.7469        0.7781        0.0000  32.1373
     16      [36m0.9796[0m        [32m0.1550[0m       0.7455      0.7455        0.7772        0.0000  32.7155
     17      0.9668        0.1917       0.7460      0.7460        0.7891        0.0000  32.5742
     18      0.9694        0.1679       0.7424      0.7424        0.7975        0.0000  33.7779
     19      0.9770        0.1607       0.7441      0.7441        0.7873        0.0000  32.7335
Stopping since valid_loss has not improved in the last 16 epochs.
[8, 24, 56, 120, 216, 392]
F1 Micro Score after query 5: 0.7788194444444444
F1 Macro Score after query 5: 0.43801640571420214
Number of samples used for retraining: 392
Number of samples in pool after training and deleting samples: 26488
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 712 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7626[0m        [32m0.7114[0m       [35m0.7688[0m      [31m0.7688[0m        [94m0.7157[0m     +  0.0000  43.7073
      2      [36m0.8624[0m        [32m0.4740[0m       [35m0.7748[0m      [31m0.7748[0m        [94m0.7023[0m     +  0.0000  42.4424
      3      [36m0.8919[0m        [32m0.3666[0m       [35m0.7828[0m      [31m0.7828[0m        [94m0.6848[0m     +  0.0000  42.2228
      4      [36m0.9101[0m        [32m0.3332[0m       [35m0.7830[0m      [31m0.7830[0m        [94m0.6805[0m     +  0.0000  42.2714
      5      [36m0.9242[0m        [32m0.2836[0m       0.7823      0.7823        [94m0.6647[0m     +  0.0000  42.2267
      6      [36m0.9382[0m        [32m0.2575[0m       0.7781      0.7781        0.6978        0.0000  42.0840
      7      [36m0.9551[0m        [32m0.2143[0m       0.7809      0.7809        0.7063        0.0000  45.3587
      8      0.9480        [32m0.1986[0m       [35m0.7851[0m      [31m0.7851[0m        0.6831        0.0000  42.3581
      9      [36m0.9747[0m        [32m0.1760[0m       0.7750      0.7750        0.7229        0.0000  42.2799
     10      0.9691        [32m0.1657[0m       0.7811      0.7811        0.7259        0.0000  42.1579
     11      0.9705        [32m0.1558[0m       0.7766      0.7766        0.7415        0.0000  42.1016
     12      [36m0.9803[0m        [32m0.1401[0m       0.7769      0.7769        0.7481        0.0000  42.2363
     13      0.9747        [32m0.1381[0m       0.7812      0.7812        0.7347        0.0000  44.3822
     14      0.9705        0.1448       0.7826      0.7826        0.7271        0.0000  42.1923
     15      [36m0.9874[0m        [32m0.1223[0m       0.7837      0.7837        0.7315        0.0000  42.0636
     16      0.9817        0.1265       0.7799      0.7799        0.7592        0.0000  42.3148
     17      0.9860        [32m0.1122[0m       0.7823      0.7823        0.7556        0.0000  42.5145
     18      0.9803        0.1179       0.7835      0.7835        0.7608        0.0000  42.3339
     19      0.9817        [32m0.1089[0m       [35m0.7866[0m      [31m0.7866[0m        0.7369        0.0000  42.5214
     20      0.9817        0.1268       0.7816      0.7816        0.7518        0.0000  42.2557
Stopping since valid_loss has not improved in the last 16 epochs.
[8, 24, 56, 120, 216, 392, 712]
F1 Micro Score after query 6: 0.8086805555555555
F1 Macro Score after query 6: 0.4778216709740194
Number of samples used for retraining: 712
Number of samples in pool after training and deleting samples: 26168
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1272 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8192[0m        [32m0.5319[0m       [35m0.7736[0m      [31m0.7736[0m        [94m0.6530[0m     +  0.0000  59.3089
      2      [36m0.8947[0m        [32m0.3679[0m       0.7665      0.7665        0.6993        0.0000  59.7095
      3      [36m0.9064[0m        [32m0.3061[0m       [35m0.7884[0m      [31m0.7884[0m        0.6918        0.0000  59.6281
      4      [36m0.9292[0m        [32m0.2526[0m       [35m0.7885[0m      [31m0.7885[0m        0.6923        0.0000  62.1565
      5      [36m0.9410[0m        [32m0.2198[0m       0.7859      0.7859        0.7098        0.0000  59.6563
      6      [36m0.9591[0m        [32m0.1798[0m       0.7863      0.7863        0.7573        0.0000  59.4496
      7      0.9575        [32m0.1630[0m       [35m0.7970[0m      [31m0.7970[0m        0.6893        0.0000  59.5648
      8      [36m0.9725[0m        [32m0.1342[0m       0.7875      0.7875        0.7424        0.0000  62.0158
      9      0.9662        0.1435       0.7911      0.7911        0.7396        0.0000  59.5139
     10      0.9717        [32m0.1269[0m       0.7924      0.7924        0.7454        0.0000  59.6812
     11      [36m0.9835[0m        [32m0.1008[0m       0.7936      0.7936        0.7285        0.0000  59.7038
     12      0.9803        [32m0.0979[0m       0.7948      0.7948        0.7394        0.0000  61.0108
     13      [36m0.9851[0m        [32m0.0928[0m       0.7957      0.7957        0.7368        0.0000  59.6094
     14      0.9803        0.0945       0.7918      0.7918        0.7573        0.0000  59.8310
     15      0.9811        0.0965       0.7920      0.7920        0.7760        0.0000  59.6210
     16      0.9827        [32m0.0919[0m       [35m0.7976[0m      [31m0.7976[0m        0.7557        0.0000  59.5326
Stopping since valid_loss has not improved in the last 16 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272]
F1 Micro Score after query 7: 0.8430555555555556
F1 Macro Score after query 7: 0.5529840988001823
Number of samples used for retraining: 1272
Number of samples in pool after training and deleting samples: 25608
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 992 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8229[0m        [32m0.5361[0m       [35m0.7844[0m      [31m0.7844[0m        [94m0.7202[0m     +  0.0000  90.0257
      2      [36m0.8843[0m        [32m0.3602[0m       0.7819      0.7819        [94m0.6849[0m     +  0.0000  89.8592
      3      [36m0.9139[0m        [32m0.2917[0m       [35m0.7986[0m      [31m0.7986[0m        [94m0.6554[0m     +  0.0000  89.7544
      4      [36m0.9240[0m        [32m0.2408[0m       0.7979      0.7979        0.7000        0.0000  89.8431
      5      [36m0.9355[0m        [32m0.2059[0m       0.7873      0.7873        0.7458        0.0000  89.7239
      6      [36m0.9479[0m        [32m0.1771[0m       0.7986      0.7986        0.7056        0.0000  91.3533
      7      [36m0.9620[0m        [32m0.1437[0m       0.7981      0.7981        0.7027        0.0000  89.9788
      8      [36m0.9651[0m        [32m0.1338[0m       0.7960      0.7960        0.7438        0.0000  90.0311
      9      [36m0.9686[0m        [32m0.1169[0m       [35m0.8031[0m      [31m0.8031[0m        0.7223        0.0000  89.8985
     10      [36m0.9717[0m        [32m0.1074[0m       0.7958      0.7958        0.7643        0.0000  89.7333
     11      [36m0.9788[0m        [32m0.0949[0m       0.7967      0.7967        0.7841        0.0000  90.3425
     12      [36m0.9792[0m        [32m0.0919[0m       0.7970      0.7970        0.7866        0.0000  89.7831
     13      [36m0.9863[0m        [32m0.0787[0m       0.7941      0.7941        0.8076        0.0000  89.8067
     14      0.9806        0.0822       0.7970      0.7970        0.7954        0.0000  89.7973
     15      0.9832        [32m0.0748[0m       0.7976      0.7976        0.7966        0.0000  90.0385
     16      0.9823        0.0761       0.7984      0.7984        0.7928        0.0000  92.1973
     17      0.9845        [32m0.0675[0m       0.7993      0.7993        0.8083        0.0000  89.7871
     18      0.9823        0.0720       0.8007      0.8007        0.7855        0.0000  90.2574
Stopping since valid_loss has not improved in the last 16 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272, 2264]
F1 Micro Score after query 8: 0.8282986111111111
F1 Macro Score after query 8: 0.5308056736816785
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.8205[0m        [32m0.5020[0m       [35m0.7877[0m      [31m0.7877[0m        [94m0.7080[0m     +  0.0000  144.8168
      2      [36m0.8663[0m        [32m0.3880[0m       [35m0.7899[0m      [31m0.7899[0m        [94m0.6713[0m     +  0.0000  144.8624
      3      [36m0.8965[0m        [32m0.3113[0m       [35m0.7981[0m      [31m0.7981[0m        0.6824        0.0000  146.0070
      4      [36m0.9077[0m        [32m0.2767[0m       0.7908      0.7908        0.6838        0.0000  145.0128
      5      [36m0.9228[0m        [32m0.2327[0m       [35m0.7993[0m      [31m0.7993[0m        0.6972        0.0000  144.7120
      6      [36m0.9342[0m        [32m0.1970[0m       [35m0.8014[0m      [31m0.8014[0m        0.6715        0.0000  144.6366
      7      [36m0.9485[0m        [32m0.1676[0m       [35m0.8069[0m      [31m0.8069[0m        [94m0.6683[0m     +  0.0000  144.7942
      8      [36m0.9507[0m        [32m0.1600[0m       0.8026      0.8026        0.7201        0.0000  144.4582
      9      [36m0.9542[0m        [32m0.1445[0m       0.8031      0.8031        0.6973        0.0000  144.9342
     10      [36m0.9584[0m        [32m0.1360[0m       0.7990      0.7990        0.7476        0.0000  144.6887
     11      [36m0.9713[0m        [32m0.1083[0m       0.8052      0.8052        0.7314        0.0000  144.6086
     12      0.9668        0.1105       0.8063      0.8062        0.7268        0.0000  144.3166
     13      [36m0.9730[0m        [32m0.1005[0m       0.8061      0.8061        0.7347        0.0000  144.7305
     14      [36m0.9755[0m        [32m0.0992[0m       0.8038      0.8038        0.7747        0.0000  145.2288
     15      [36m0.9762[0m        [32m0.0891[0m       0.8038      0.8038        0.7681        0.0000  144.6440
     16      [36m0.9814[0m        [32m0.0791[0m       0.8038      0.8038        0.7709        0.0000  144.8702
     17      [36m0.9824[0m        [32m0.0749[0m       0.8038      0.8038        0.7702        0.0000  144.7800
     18      [36m0.9837[0m        0.0750       0.8064      0.8064        0.7722        0.0000  144.8155
     19      [36m0.9844[0m        [32m0.0701[0m       [35m0.8113[0m      [31m0.8113[0m        0.7637        0.0000  144.7636
     20      0.9797        0.0778       0.8090      0.8090        0.7597        0.0000  144.9982
     21      0.9832        [32m0.0689[0m       0.8071      0.8071        0.7836        0.0000  144.7084
     22      0.9842        [32m0.0629[0m       0.8066      0.8066        0.7832        0.0000  145.0628
Stopping since valid_loss has not improved in the last 16 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272, 2264, 4040]
F1 Micro Score after query 9: 0.8487847222222222
F1 Macro Score after query 9: 0.5447746898771934
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3168 informative samples: 

Training started with 7208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.8976[0m        [32m0.3144[0m       [35m0.7979[0m      [31m0.7979[0m        [94m0.7822[0m     +  0.0000  242.4505
      2      [36m0.9227[0m        [32m0.2390[0m       [35m0.8016[0m      [31m0.8016[0m        [94m0.7374[0m     +  0.0000  242.1439
      3      [36m0.9342[0m        [32m0.2025[0m       [35m0.8040[0m      [31m0.8040[0m        0.7924        0.0000  242.6651
      4      [36m0.9445[0m        [32m0.1737[0m       [35m0.8080[0m      [31m0.8080[0m        0.7567        0.0000  241.2670
      5      [36m0.9481[0m        [32m0.1546[0m       [35m0.8082[0m      [31m0.8082[0m        0.7586        0.0000  241.5827
      6      [36m0.9620[0m        [32m0.1189[0m       [35m0.8123[0m      [31m0.8123[0m        0.7558        0.0000  241.5313
      7      [36m0.9678[0m        [32m0.1043[0m       0.8115      0.8115        0.7871        0.0000  241.2723
      8      [36m0.9696[0m        [32m0.0972[0m       0.8007      0.8007        0.8179        0.0000  241.0698
      9      [36m0.9717[0m        [32m0.0866[0m       0.8083      0.8083        0.8087        0.0000  241.5205
     10      [36m0.9782[0m        [32m0.0748[0m       0.8076      0.8076        0.8062        0.0000  245.3778
     11      [36m0.9806[0m        [32m0.0659[0m       0.8099      0.8099        0.7755        0.0000  242.6848
     12      [36m0.9861[0m        [32m0.0573[0m       [35m0.8125[0m      [31m0.8125[0m        0.7750        0.0000  241.8956
     13      0.9847        0.0580       0.8102      0.8102        0.7983        0.0000  243.6898
     14      0.9860        [32m0.0525[0m       0.8064      0.8064        0.8185        0.0000  241.5442
     15      [36m0.9870[0m        [32m0.0483[0m       0.8102      0.8102        0.8298        0.0000  241.8117
     16      [36m0.9879[0m        [32m0.0456[0m       0.8089      0.8089        0.8572        0.0000  243.5549
     17      0.9872        [32m0.0452[0m       0.8057      0.8057        0.8826        0.0000  241.7242
Stopping since valid_loss has not improved in the last 16 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272, 2264, 4040, 7208]
F1 Micro Score after query 10: 0.8440972222222223
F1 Macro Score after query 10: 0.550812400764511
Number of samples used for retraining: 7208
Number of samples in pool after training and deleting samples: 19672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5632 informative samples: 

Training started with 12840 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9379[0m        [32m0.1957[0m       [35m0.8069[0m      [31m0.8069[0m        [94m0.7611[0m     +  0.0000  414.5389
      2      [36m0.9503[0m        [32m0.1559[0m       [35m0.8102[0m      [31m0.8102[0m        [94m0.7608[0m     +  0.0000  415.2630
      3      [36m0.9574[0m        [32m0.1302[0m       [35m0.8135[0m      [31m0.8135[0m        [94m0.7203[0m     +  0.0000  414.5625
      4      [36m0.9663[0m        [32m0.1055[0m       0.8083      0.8083        0.7466        0.0000  414.7389
      5      [36m0.9681[0m        [32m0.0958[0m       0.8116      0.8116        0.7847        0.0000  414.4069
      6      [36m0.9762[0m        [32m0.0722[0m       [35m0.8241[0m      [31m0.8241[0m        0.7540        0.0000  414.2481
      7      [36m0.9802[0m        [32m0.0641[0m       0.8184      0.8184        0.7912        0.0000  414.7758
      8      [36m0.9834[0m        [32m0.0521[0m       [35m0.8283[0m      [31m0.8283[0m        0.7704        0.0000  414.9027
      9      [36m0.9859[0m        [32m0.0467[0m       [35m0.8321[0m      [31m0.8321[0m        0.7558        0.0000  414.2447
     10      [36m0.9867[0m        [32m0.0424[0m       0.8262      0.8262        0.7995        0.0000  414.7195
     11      [36m0.9911[0m        [32m0.0326[0m       0.8302      0.8302        0.7736        0.0000  414.8291
     12      [36m0.9913[0m        [32m0.0303[0m       0.8281      0.8281        0.7999        0.0000  414.4879
     13      0.9908        [32m0.0302[0m       0.8271      0.8271        0.7762        0.0000  415.2885
     14      0.9913        0.0302       0.8269      0.8269        0.7974        0.0000  414.9712
     15      [36m0.9922[0m        [32m0.0263[0m       0.8259      0.8259        0.8053        0.0000  414.3414
     16      [36m0.9934[0m        [32m0.0247[0m       0.8259      0.8259        0.8090        0.0000  414.4525
     17      [36m0.9946[0m        [32m0.0219[0m       0.8314      0.8314        0.7869        0.0000  414.7954
     18      0.9937        0.0232       0.8299      0.8299        0.7739        0.0000  414.9940
Stopping since valid_loss has not improved in the last 16 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272, 2264, 4040, 7208, 12840]
F1 Micro Score after query 11: 0.8430555555555556
F1 Macro Score after query 11: 0.5522858878243802
Number of samples used for retraining: 12840
Number of samples in pool after training and deleting samples: 14040
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22840 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9729[0m        [32m0.0878[0m       [35m0.7839[0m      [31m0.7839[0m        [94m0.8354[0m     +  0.0000  719.8480
      2      [36m0.9767[0m        [32m0.0715[0m       [35m0.7877[0m      [31m0.7877[0m        [94m0.8174[0m     +  0.0000  721.0671
      3      [36m0.9806[0m        [32m0.0605[0m       0.7800      0.7800        0.8332        0.0000  721.7333
      4      [36m0.9828[0m        [32m0.0508[0m       [35m0.7911[0m      [31m0.7911[0m        [94m0.7889[0m     +  0.0000  721.0820
      5      [36m0.9856[0m        [32m0.0440[0m       0.7870      0.7870        0.8891        0.0000  721.4102
      6      [36m0.9888[0m        [32m0.0346[0m       0.7778      0.7778        0.9678        0.0000  720.9757
      7      [36m0.9906[0m        [32m0.0274[0m       [35m0.8205[0m      [31m0.8205[0m        [94m0.7854[0m     +  0.0000  721.4354
      8      [36m0.9923[0m        [32m0.0243[0m       [35m0.8273[0m      [31m0.8273[0m        [94m0.7658[0m     +  0.0000  721.4839
      9      [36m0.9936[0m        [32m0.0218[0m       0.8222      0.8222        0.8240        0.0000  721.8269
     10      [36m0.9937[0m        [32m0.0184[0m       0.8224      0.8224        0.8384        0.0000  721.8180
     11      [36m0.9949[0m        [32m0.0164[0m       0.8148      0.8148        0.8828        0.0000  720.9605
     12      [36m0.9965[0m        [32m0.0123[0m       0.8200      0.8200        0.9240        0.0000  721.4722
     13      [36m0.9969[0m        [32m0.0110[0m       0.8226      0.8226        0.8719        0.0000  721.2074
     14      [36m0.9973[0m        [32m0.0096[0m       [35m0.8300[0m      [31m0.8300[0m        0.8948        0.0000  720.8302
     15      0.9972        0.0099       [35m0.8410[0m      [31m0.8410[0m        0.8034        0.0000  720.6259
     16      0.9962        0.0114       0.8389      0.8389        0.8616        0.0000  721.0749
     17      [36m0.9976[0m        [32m0.0078[0m       0.8325      0.8325        0.8776        0.0000  720.9282
     18      0.9974        0.0093       0.8316      0.8316        0.8682        0.0000  721.2263
     19      [36m0.9978[0m        [32m0.0074[0m       0.8292      0.8292        0.9267        0.0000  721.5670
     20      0.9977        0.0078       0.8378      0.8378        0.8912        0.0000  720.9170
     21      0.9978        [32m0.0069[0m       0.8398      0.8398        0.8801        0.0000  720.7637
     22      [36m0.9983[0m        [32m0.0063[0m       [35m0.8411[0m      [31m0.8411[0m        0.8572        0.0000  720.9295
     23      0.9981        0.0064       0.8368      0.8368        0.9097        0.0000  723.2391
Stopping since valid_loss has not improved in the last 16 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272, 2264, 4040, 7208, 12840, 22840]
F1 Micro Score after query 12: 0.8213541666666667
F1 Macro Score after query 12: 0.5074012842236822
Number of samples used for retraining: 22840
Number of samples in pool after training and deleting samples: 4040
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4040 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9901[0m        [32m0.0321[0m       [35m0.7932[0m      [31m0.7932[0m        [94m1.0544[0m     +  0.0000  845.1230
      2      [36m0.9917[0m        [32m0.0255[0m       0.7726      0.7726        1.1623        0.0000  846.4939
      3      [36m0.9927[0m        [32m0.0215[0m       0.7552      0.7552        1.2163        0.0000  838.4015
      4      0.9925        0.0235       0.7800      0.7800        1.1850        0.0000  835.7724
      5      [36m0.9928[0m        [32m0.0208[0m       0.7771      0.7771        1.1442        0.0000  836.4064
      6      [36m0.9948[0m        [32m0.0147[0m       [35m0.8026[0m      [31m0.8026[0m        [94m1.0270[0m     +  0.0000  835.9489
      7      [36m0.9962[0m        [32m0.0111[0m       [35m0.8047[0m      [31m0.8047[0m        1.0916        0.0000  836.9221
      8      [36m0.9969[0m        [32m0.0097[0m       0.7899      0.7899        1.1982        0.0000  837.1337
      9      [36m0.9971[0m        [32m0.0094[0m       0.7833      0.7833        1.2736        0.0000  836.2922
     10      [36m0.9975[0m        [32m0.0076[0m       0.7877      0.7877        1.2888        0.0000  842.2669
     11      [36m0.9978[0m        [32m0.0070[0m       0.7958      0.7958        1.1734        0.0000  844.9386
     12      [36m0.9981[0m        [32m0.0060[0m       0.7977      0.7977        1.2203        0.0000  855.4537
     13      [36m0.9984[0m        [32m0.0053[0m       0.7915      0.7915        1.2656        0.0000  853.1643
     14      0.9983        0.0059       0.8033      0.8033        1.1951        0.0000  853.0456
     15      [36m0.9987[0m        0.0054       [35m0.8089[0m      [31m0.8089[0m        1.1579        0.0000  851.4221
     16      0.9984        [32m0.0050[0m       [35m0.8109[0m      [31m0.8109[0m        1.1678        0.0000  854.4212
     17      0.9983        [32m0.0047[0m       [35m0.8148[0m      [31m0.8148[0m        1.1484        0.0000  853.1681
     18      [36m0.9990[0m        [32m0.0039[0m       0.8120      0.8120        1.1727        0.0000  852.8590
     19      0.9988        [32m0.0035[0m       0.8146      0.8146        1.1590        0.0000  850.9522
     20      0.9986        0.0044       0.8128      0.8128        1.1957        0.0000  848.2446
     21      [36m0.9991[0m        [32m0.0032[0m       0.8134      0.8134        1.1972        0.0000  848.2665
Stopping since valid_loss has not improved in the last 16 epochs.
[8, 24, 56, 120, 216, 392, 712, 1272, 2264, 4040, 7208, 12840, 22840, 26880]
F1 Micro Score after query 13: 0.8269097222222223
F1 Macro Score after query 13: 0.5022815732513678
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/EfficientNet/margin_sampling_seed43_param3\AL_margin_sampling_results_for_multiclass_classification_s43.pickle
