### Starting TaskPrologue of job 895288 on tg096 at Wed 25 Sep 2024 03:38:42 AM CEST
Running on cores 96-127 with governor ondemand
Wed Sep 25 03:38:42 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:C1:00.0 Off |                    0 |
| N/A   34C    P0             55W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

/home/hpc/iwfa/iwfa044h/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).
  from pandas.core.computation.check import NUMEXPR_INSTALLED
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
/home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
/home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
/home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
Epoch 1/30, Training Loss: 0.3447, Training F1-score: 0.9035, Validation Loss: 0.5111, Validation F1-score: 0.8429
Epoch 2/30, Training Loss: 0.1817, Training F1-score: 0.9481, Validation Loss: 0.5507, Validation F1-score: 0.8259
Epoch 3/30, Training Loss: 0.1522, Training F1-score: 0.9523, Validation Loss: 0.5017, Validation F1-score: 0.8453
Epoch 4/30, Training Loss: 0.1290, Training F1-score: 0.9567, Validation Loss: 0.5651, Validation F1-score: 0.8337
Epoch 5/30, Training Loss: 0.1222, Training F1-score: 0.9583, Validation Loss: 0.5007, Validation F1-score: 0.8352
Epoch 6/30, Training Loss: 0.1136, Training F1-score: 0.9613, Validation Loss: 0.4428, Validation F1-score: 0.8302
Epoch 7/30, Training Loss: 0.1067, Training F1-score: 0.9634, Validation Loss: 0.5483, Validation F1-score: 0.8214
Epoch 8/30, Training Loss: 0.0960, Training F1-score: 0.9666, Validation Loss: 0.6318, Validation F1-score: 0.8189
Early stopping triggered after 8 epochs.
Test F1-score: 0.8615
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3303, Training F1-score: 0.9084, Validation Loss: 0.5144, Validation F1-score: 0.8226
Epoch 2/30, Training Loss: 0.1732, Training F1-score: 0.9490, Validation Loss: 0.5643, Validation F1-score: 0.8085
Epoch 3/30, Training Loss: 0.1477, Training F1-score: 0.9542, Validation Loss: 0.5981, Validation F1-score: 0.8220
Epoch 4/30, Training Loss: 0.1258, Training F1-score: 0.9585, Validation Loss: 0.4392, Validation F1-score: 0.8398
Epoch 5/30, Training Loss: 0.1220, Training F1-score: 0.9595, Validation Loss: 0.7097, Validation F1-score: 0.8097
Epoch 6/30, Training Loss: 0.1071, Training F1-score: 0.9625, Validation Loss: 0.6822, Validation F1-score: 0.8002
Epoch 7/30, Training Loss: 0.1054, Training F1-score: 0.9626, Validation Loss: 0.5607, Validation F1-score: 0.8304
Epoch 8/30, Training Loss: 0.0939, Training F1-score: 0.9668, Validation Loss: 0.5427, Validation F1-score: 0.8384
Epoch 9/30, Training Loss: 0.0939, Training F1-score: 0.9672, Validation Loss: 0.6050, Validation F1-score: 0.8262
Early stopping triggered after 9 epochs.
Test F1-score: 0.8512
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3220, Training F1-score: 0.9060, Validation Loss: 0.4141, Validation F1-score: 0.8538
Epoch 2/30, Training Loss: 0.1728, Training F1-score: 0.9499, Validation Loss: 0.4583, Validation F1-score: 0.8389
Epoch 3/30, Training Loss: 0.1478, Training F1-score: 0.9531, Validation Loss: 0.3987, Validation F1-score: 0.8641
Epoch 4/30, Training Loss: 0.1282, Training F1-score: 0.9575, Validation Loss: 0.5945, Validation F1-score: 0.8229
Epoch 5/30, Training Loss: 0.1190, Training F1-score: 0.9586, Validation Loss: 0.5997, Validation F1-score: 0.8059
Epoch 6/30, Training Loss: 0.1101, Training F1-score: 0.9625, Validation Loss: 0.5299, Validation F1-score: 0.8418
Epoch 7/30, Training Loss: 0.1058, Training F1-score: 0.9634, Validation Loss: 0.6463, Validation F1-score: 0.8108
Epoch 8/30, Training Loss: 0.0928, Training F1-score: 0.9670, Validation Loss: 0.6336, Validation F1-score: 0.8155
Early stopping triggered after 8 epochs.
Test F1-score: 0.8392
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3242, Training F1-score: 0.9133, Validation Loss: 0.4898, Validation F1-score: 0.8345
Epoch 2/30, Training Loss: 0.1755, Training F1-score: 0.9484, Validation Loss: 0.5418, Validation F1-score: 0.8189
Epoch 3/30, Training Loss: 0.1509, Training F1-score: 0.9528, Validation Loss: 0.4372, Validation F1-score: 0.8370
Epoch 4/30, Training Loss: 0.1292, Training F1-score: 0.9558, Validation Loss: 0.5681, Validation F1-score: 0.8153
Epoch 5/30, Training Loss: 0.1187, Training F1-score: 0.9587, Validation Loss: 0.4988, Validation F1-score: 0.8417
Epoch 6/30, Training Loss: 0.1092, Training F1-score: 0.9625, Validation Loss: 0.5193, Validation F1-score: 0.8288
Epoch 7/30, Training Loss: 0.1027, Training F1-score: 0.9640, Validation Loss: 0.5165, Validation F1-score: 0.8399
Epoch 8/30, Training Loss: 0.0953, Training F1-score: 0.9654, Validation Loss: 0.6149, Validation F1-score: 0.8292
Epoch 9/30, Training Loss: 0.0920, Training F1-score: 0.9681, Validation Loss: 0.5650, Validation F1-score: 0.8361
Epoch 10/30, Training Loss: 0.0863, Training F1-score: 0.9693, Validation Loss: 0.7250, Validation F1-score: 0.8134
Early stopping triggered after 10 epochs.
Test F1-score: 0.8224
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3507, Training F1-score: 0.9088, Validation Loss: 0.5254, Validation F1-score: 0.8168
Epoch 2/30, Training Loss: 0.1850, Training F1-score: 0.9477, Validation Loss: 0.4952, Validation F1-score: 0.8163
Epoch 3/30, Training Loss: 0.1538, Training F1-score: 0.9515, Validation Loss: 0.6895, Validation F1-score: 0.8106
Epoch 4/30, Training Loss: 0.1287, Training F1-score: 0.9608, Validation Loss: 0.5462, Validation F1-score: 0.8187
Epoch 5/30, Training Loss: 0.1224, Training F1-score: 0.9593, Validation Loss: 0.4587, Validation F1-score: 0.8417
Epoch 6/30, Training Loss: 0.1151, Training F1-score: 0.9618, Validation Loss: 0.6440, Validation F1-score: 0.8094
Epoch 7/30, Training Loss: 0.1066, Training F1-score: 0.9629, Validation Loss: 0.4889, Validation F1-score: 0.8335
Epoch 8/30, Training Loss: 0.0983, Training F1-score: 0.9659, Validation Loss: 0.5209, Validation F1-score: 0.8387
Epoch 9/30, Training Loss: 0.0940, Training F1-score: 0.9666, Validation Loss: 0.5955, Validation F1-score: 0.8092
Epoch 10/30, Training Loss: 0.0877, Training F1-score: 0.9682, Validation Loss: 0.5524, Validation F1-score: 0.8359
Early stopping triggered after 10 epochs.
Test F1-score: 0.8380
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3329, Training F1-score: 0.9092, Validation Loss: 0.4530, Validation F1-score: 0.8573
Epoch 2/30, Training Loss: 0.1821, Training F1-score: 0.9464, Validation Loss: 0.4577, Validation F1-score: 0.8443
Epoch 3/30, Training Loss: 0.1526, Training F1-score: 0.9538, Validation Loss: 0.4971, Validation F1-score: 0.8250
Epoch 4/30, Training Loss: 0.1343, Training F1-score: 0.9566, Validation Loss: 0.4992, Validation F1-score: 0.8274
Epoch 5/30, Training Loss: 0.1205, Training F1-score: 0.9585, Validation Loss: 0.3606, Validation F1-score: 0.8720
Epoch 6/30, Training Loss: 0.1136, Training F1-score: 0.9602, Validation Loss: 0.4740, Validation F1-score: 0.8372
Epoch 7/30, Training Loss: 0.1054, Training F1-score: 0.9638, Validation Loss: 0.4992, Validation F1-score: 0.8349
Epoch 8/30, Training Loss: 0.0996, Training F1-score: 0.9643, Validation Loss: 0.5192, Validation F1-score: 0.8451
Epoch 9/30, Training Loss: 0.0940, Training F1-score: 0.9667, Validation Loss: 0.5140, Validation F1-score: 0.8451
Epoch 10/30, Training Loss: 0.0903, Training F1-score: 0.9689, Validation Loss: 0.5577, Validation F1-score: 0.8488
Early stopping triggered after 10 epochs.
Test F1-score: 0.8979
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3444, Training F1-score: 0.9080, Validation Loss: 0.5019, Validation F1-score: 0.8436
Epoch 2/30, Training Loss: 0.1813, Training F1-score: 0.9490, Validation Loss: 0.5663, Validation F1-score: 0.8127
Epoch 3/30, Training Loss: 0.1491, Training F1-score: 0.9547, Validation Loss: 0.5493, Validation F1-score: 0.8358
Epoch 4/30, Training Loss: 0.1359, Training F1-score: 0.9556, Validation Loss: 0.6746, Validation F1-score: 0.7972
Epoch 5/30, Training Loss: 0.1205, Training F1-score: 0.9599, Validation Loss: 0.5996, Validation F1-score: 0.8460
Epoch 6/30, Training Loss: 0.1138, Training F1-score: 0.9592, Validation Loss: 0.4963, Validation F1-score: 0.8455
Epoch 7/30, Training Loss: 0.1080, Training F1-score: 0.9634, Validation Loss: 0.6957, Validation F1-score: 0.7920
Epoch 8/30, Training Loss: 0.0990, Training F1-score: 0.9650, Validation Loss: 0.6143, Validation F1-score: 0.8005
Epoch 9/30, Training Loss: 0.0950, Training F1-score: 0.9662, Validation Loss: 0.6980, Validation F1-score: 0.8227
Epoch 10/30, Training Loss: 0.0899, Training F1-score: 0.9677, Validation Loss: 0.5273, Validation F1-score: 0.8378
Early stopping triggered after 10 epochs.
Test F1-score: 0.8599
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3569, Training F1-score: 0.9066, Validation Loss: 0.5303, Validation F1-score: 0.8286
Epoch 2/30, Training Loss: 0.1819, Training F1-score: 0.9478, Validation Loss: 0.4934, Validation F1-score: 0.8339
Epoch 3/30, Training Loss: 0.1563, Training F1-score: 0.9515, Validation Loss: 0.4358, Validation F1-score: 0.8507
Epoch 4/30, Training Loss: 0.1389, Training F1-score: 0.9556, Validation Loss: 0.4639, Validation F1-score: 0.8422
Epoch 5/30, Training Loss: 0.1252, Training F1-score: 0.9589, Validation Loss: 0.5107, Validation F1-score: 0.8431
Epoch 6/30, Training Loss: 0.1167, Training F1-score: 0.9597, Validation Loss: 0.4550, Validation F1-score: 0.8380
Epoch 7/30, Training Loss: 0.1090, Training F1-score: 0.9625, Validation Loss: 0.4358, Validation F1-score: 0.8250
Epoch 8/30, Training Loss: 0.1015, Training F1-score: 0.9651, Validation Loss: 0.4033, Validation F1-score: 0.8597
Epoch 9/30, Training Loss: 0.0967, Training F1-score: 0.9658, Validation Loss: 0.6073, Validation F1-score: 0.7797
Epoch 10/30, Training Loss: 0.0865, Training F1-score: 0.9687, Validation Loss: 0.5041, Validation F1-score: 0.8167
Epoch 11/30, Training Loss: 0.0892, Training F1-score: 0.9682, Validation Loss: 0.5688, Validation F1-score: 0.8085
Epoch 12/30, Training Loss: 0.0820, Training F1-score: 0.9708, Validation Loss: 0.6213, Validation F1-score: 0.8295
Epoch 13/30, Training Loss: 0.0754, Training F1-score: 0.9719, Validation Loss: 0.5882, Validation F1-score: 0.8309
Early stopping triggered after 13 epochs.
Test F1-score: 0.8783
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3382, Training F1-score: 0.9086, Validation Loss: 0.6417, Validation F1-score: 0.7740
Epoch 2/30, Training Loss: 0.1731, Training F1-score: 0.9501, Validation Loss: 0.4971, Validation F1-score: 0.8585
Epoch 3/30, Training Loss: 0.1453, Training F1-score: 0.9539, Validation Loss: 0.4572, Validation F1-score: 0.8424
Epoch 4/30, Training Loss: 0.1268, Training F1-score: 0.9587, Validation Loss: 0.4783, Validation F1-score: 0.8408
Epoch 5/30, Training Loss: 0.1177, Training F1-score: 0.9613, Validation Loss: 0.4401, Validation F1-score: 0.8502
Epoch 6/30, Training Loss: 0.1095, Training F1-score: 0.9622, Validation Loss: 0.4753, Validation F1-score: 0.8352
Epoch 7/30, Training Loss: 0.0997, Training F1-score: 0.9647, Validation Loss: 0.4940, Validation F1-score: 0.8389
Early stopping triggered after 7 epochs.
Test F1-score: 0.8561
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
Epoch 1/30, Training Loss: 0.3272, Training F1-score: 0.9077, Validation Loss: 0.5202, Validation F1-score: 0.8153
slurmstepd: error: *** JOB 895288 ON tg096 CANCELLED AT 2024-09-26T03:38:52 DUE TO TIME LIMIT ***
=== JOB_STATISTICS ===
=== current date     : Thu 26 Sep 2024 03:38:54 AM CEST
= Job-ID             : 895288 on tinygpu
= Job-Name           : MinicondaName
= Job-Command        : /home/woody/iwfa/iwfa044h/runner3.sh
= Initial workdir    : /home/woody/iwfa/iwfa044h
= Queue/Partition    : a100
= Slurm account      : iwfa with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 1-00:00:13
= Total RAM usage    : 3.3 GiB of requested  GiB (%)   
= Node list          : tg096
= Subm/Elig/Start/End: 2024-09-24T23:00:05 / 2024-09-24T23:00:05 / 2024-09-25T03:38:39 / 2024-09-26T03:38:52
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           56.8G   104.9G   209.7G        N/A     142K     500K   1,000K        N/A    
    /home/vault          0.0K  1048.6G  2097.2G        N/A       1      200K     400K        N/A    
    /home/woody        823.0G  1000.0G  1500.0G        N/A   1,811K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:C1:00.0, 129507, 98 %, 23 %, 14176 MiB, 86384138 ms
