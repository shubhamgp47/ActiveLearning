  File "C:\Users\localuserSG\anaconda3\envs\shubham_gupta_AL01\lib\site-packages\modAL\models\base.py", line 140, in predict
PS C:\Users\localuserSG\ActiveLearning\Multiclass01\DinoSmall\ES> python .\entropy_sampling_paramsfrommultilabl.py
(26880, 5)
(5760, 5)
(5760, 5)
100%|███████████████████████████████████████████████████████████████████████████████████████████| 26880/26880 [00:00<00:00, 128771.46it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5760/5760 [00:00<00:00, 130400.61it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5760/5760 [00:00<00:00, 124260.33it/s]
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
Using cache found in C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main
C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.1250        2.0928       0.2361      0.2361        1.9911     +  7.4341
      2      0.2500        2.0706       0.2620      0.2620        1.9895     +  6.9497
      3      1.0000        2.0717       0.2283      0.2283        1.9990        7.0027
      4      0.1250        2.0845       0.2521      0.2521        1.9934        7.0614
      5      0.2500        2.0278       0.2745      0.2745        1.9899        7.0701
      6      1.0000        2.0422       0.3123      0.3123        1.9822     +  7.1029
      7      0.3750        1.9888       0.2964      0.2964        1.9850        7.1189
      8      0.2500        1.9742       0.3168      0.3168        1.9792     +  7.1223
      9      0.2500        2.0159       0.3019      0.3019        1.9859        7.1521
     10      0.3750        1.9491       0.3344      0.3344        1.9742     +  7.1709
     11      0.2500        2.0156       0.3312      0.3312        1.9756        7.1702
     12      0.3750        1.9943       0.3556      0.3556        1.9723     +  7.1725
     13      0.3750        1.8890       0.3373      0.3373        1.9759        7.1935
     14      0.6250        1.8492       0.3372      0.3372        1.9782        7.2276
     15      0.3750        1.8994       0.2958      0.2958        1.9896        7.2276
     16      0.5000        1.9590       0.2710      0.2710        1.9932        7.2248
     17      0.6250        1.8665       0.2819      0.2819        1.9931        7.2154
     18      0.1250        1.9353       0.2799      0.2799        1.9931        7.2143
     19      0.3750        1.9199       0.2615      0.2615        2.0003        7.1955
     20      0.3750        1.9193       0.2552      0.2552        2.0018        7.2276
     21      0.5000        1.8704       0.2429      0.2429        2.0039        7.2268
     22      0.5000        1.8322       0.2316      0.2316        2.0095        7.2631
     23      0.7500        1.8150       0.2292      0.2292        2.0132        7.2601
     24      0.5000        1.8086       0.2311      0.2311        2.0084        7.2794
     25      0.5000        1.7820       0.2351      0.2351        2.0125        7.2469
     26      0.6250        1.7628       0.2188      0.2188        2.0289        7.2609
Stopping since valid_loss has not improved in the last 15 epochs.
Pre F1 score = 0.287

Iteration:  1
Selecting 16 informative samples:

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.2083        2.0387       0.4259      0.4259        1.9527     +  7.2980
      2      0.5833        1.8441       0.4806      0.4806        1.8880     +  7.3092
      3      0.9167        1.6735       0.4575      0.4575        1.8466     +  7.2682
      4      0.7917        1.5964       0.4479      0.4479        1.8150     +  7.3046
      5      0.7500        1.4802       0.4479      0.4479        1.7947     +  7.3066
      6      0.7917        1.3970       0.4479      0.4479        1.7806     +  7.2900
      7      0.7500        1.4262       0.4479      0.4479        1.7703     +  7.3026
      8      0.7500        1.3765       0.4479      0.4479        1.7602     +  7.3152
      9      0.7500        1.3534       0.4479      0.4479        1.7549     +  7.3047
     10      0.7083        1.3168       0.4479      0.4479        1.7476     +  7.2865
     11      0.7083        1.2973       0.4479      0.4479        1.7413     +  7.2911
     12      0.7500        1.2541       0.4479      0.4479        1.7354     +  7.3070
     13      0.7083        1.2562       0.4479      0.4479        1.7333     +  7.2953
     14      0.7083        1.2422       0.4479      0.4479        1.7321     +  7.2975
     15      0.7500        1.1986       0.4479      0.4479        1.7326        7.3176
     16      0.7083        1.2052       0.4479      0.4479        1.7291     +  7.2577
     17      0.7083        1.2161       0.4479      0.4479        1.7249     +  7.2591
     18      0.7083        1.2043       0.4479      0.4479        1.7228     +  7.2675
     19      0.7083        1.1987       0.4479      0.4479        1.7207     +  7.2632
     20      0.7083        1.1598       0.4479      0.4479        1.7169     +  7.2934
     21      0.7083        1.1499       0.4479      0.4479        1.7145     +  7.2930
     22      0.7083        1.1351       0.4479      0.4479        1.7121     +  7.3087
     23      0.7500        1.1134       0.4479      0.4479        1.7109     +  7.2898
     24      0.7083        1.1034       0.4479      0.4479        1.7096     +  7.3810
     25      0.7083        1.1132       0.4479      0.4479        1.7094     +  7.3427
    0.4540      0.4540        1.6819        7.3012
     48      0.7917        0.9510       0.4550      0.4550        1.6782     +  7.4658
     49      0.8333        0.9316       0.4566      0.4566        1.6755     +  7.4341
     50      0.8333        0.9372       0.4556      0.4556        1.6705     +  7.2803
     51      0.8333        0.9294       0.4594      0.4594        1.6678     +  7.3022
     52      0.8333        0.8985       0.4609      0.4609        1.6675     +  7.3800
     53      0.8333        0.9035       0.4625      0.4625        1.6697        7.3879
     54      0.8333        0.8991       0.4675      0.4675        1.6690        7.3039
     55      0.8750        0.9048       0.4729      0.4729        1.6725        7.3010
     56      0.8333        0.9167       0.4795      0.4795        1.6766        7.2900
     57      0.8750        0.8746       0.4762      0.4762        1.6759        7.2907
     58      0.8750        0.8975       0.4740      0.4740        1.6726        7.3162
     59      0.8750        0.8972       0.4804      0.4804        1.6772        7.2930
     60      0.8750        0.8726       0.4851      0.4851        1.6807        7.2845
     61      0.8750        0.8595       0.4837      0.4837        1.6785        7.3053
     62      0.8750        0.8672       0.4839      0.4839        1.6761        7.3128
     63      0.9167        0.8559       0.4783      0.4783        1.6698        7.3019
     64      0.9167        0.8573       0.4788      0.4788        1.6701        7.3078
     65      0.8333        0.8611       0.4811      0.4811        1.6708        7.2979
     66      0.9167        0.8434       0.4833      0.4833        1.6689        7.2776
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 1: 0.5090277777777777
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples:

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.5000        1.5184       0.5106      0.5106        1.6717     +  7.4035
      2      0.5357        1.4676       0.5080      0.5080        1.6721        7.3634
      3      0.5714        1.4144       0.4783      0.4783        1.6656     +  7.4054
      4      0.6786        1.4197       0.4726      0.4726        1.6540     +  7.3700
      5      0.7679        1.3946       0.4689      0.4689        1.6474     +  7.3775
      6      0.7500        1.3577       0.4686      0.4686        1.6411     +  7.3805
      7      0.7500        1.3507       0.4576      0.4576        1.6442        7.3697
      8      0.7500        1.3440       0.4470      0.4470        1.6456        7.3646
      9      0.7321        1.3012       0.4396      0.4396        1.6467        7.3692
     10      0.7321        1.2903       0.4352      0.4352        1.6449        7.3767
     11      0.7500        1.2759       0.4300      0.4300        1.6465        7.3920
     12      0.7500        1.2687       0.4297      0.4297        1.6414        7.3834
     13      0.7500        1.2478       0.4321      0.4321        1.6369     +  7.3995
     14      0.7500        1.2297       0.4281      0.4281        1.6360     +  7.3891
     15      0.7500        1.2010       0.4170      0.4170        1.6393        7.3746
     16      0.7321        1.2191       0.4212      0.4212        1.6396        7.4035
     17      0.7500        1.1893       0.4175      0.4175        1.6351     +  7.3951
     18      0.7500        1.1688       0.4033      0.4033        1.6420        7.3690
     19      0.7500        1.1625       0.4118      0.4118        1.6386        7.3817
     20      0.7500        1.1628       0.4106      0.4106        1.6338     +  7.3935
     21      0.7500        1.1665       0.4108      0.4108        1.6372        7.3810
     22      0.7500        1.1345       0.4017      0.4017        1.6411        7.3824
     23      0.7500        1.1404       0.3991      0.3991        1.6405        7.3508
     24      0.7679        1.1284       0.3934      0.3934        1.6429        7.3548
     25      0.7500        1.1166       0.3918      0.3918        1.6444        7.3793
     26      0.7500        1.1255       0.3917      0.3917        1.6455        7.3485
     27      0.7500        1.1384       0.3960      0.3960        1.6409        7.3691
     28      0.7500        1.0878       0.3932      0.3932        1.6447        7.3684
     29      0.7500        1.1083       0.3920      0.3920        1.6470        7.3878
     30      0.7500        1.0903       0.3877      0.3877        1.6518        7.3843
     31      0.7500        1.0885       0.3873      0.3873        1.6532        7.3838
     32      0.7500        1.0707       0.3927      0.3927        1.6474        7.3402
     33      0.7500        1.0691       0.3922      0.3922        1.6456        7.3418
     34      0.7500        1.0683       0.3972      0.3972        1.6457        7.3814
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 2: 0.45225694444444436
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples:

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.3839        1.6745       0.3812      0.3812        1.6305     +  7.5050
      2      0.3929        1.5457       0.3700      0.3700        1.6227     +  7.5216
      3      0.4821        1.4795       0.3927      0.3927        1.6173     +  7.5305
      4      0.6071        1.4456       0.4111      0.4111        1.6118     +  7.5346
      5      0.7500        1.3826       0.4085      0.4085        1.6097     +  7.5427
      6      0.7768        1.3391       0.4054      0.4054        1.6108        7.5252
      7      0.7946        1.3133       0.3972      0.3972        1.6107        7.5201
      8      0.7946        1.2889       0.3990      0.3990        1.6041     +  7.5211
      9      0.7946        1.2759       0.3995      0.3995        1.5997     +  7.5283
     10      0.7857        1.2428       0.3894      0.3894        1.6136        7.5469
     11      0.7857        1.2193       0.3833      0.3833        1.6153        7.5365
     12      0.8036        1.2004       0.3812      0.3812        1.6158        7.5199
     13      0.7946        1.1825       0.3672      0.3672        1.6202        7.5101
     14      0.7946        1.1769       0.3691      0.3691        1.6151        7.5098
     15      0.7857        1.1582       0.3545      0.3545        1.6191        7.4934
     16      0.7946        1.1322       0.3260      0.3260        1.6332        7.5200
     17      0.7946        1.1480       0.3370      0.3370        1.6261        7.5302
     18      0.8036        1.1259       0.3314      0.3314        1.6294        7.5275
     19      0.7946        1.1180       0.3288      0.3288        1.6298        7.5199
     20      0.8036        1.1038       0.3278      0.3278        1.6344        7.5295
     21      0.7946        1.0874       0.3229      0.3229        1.6422        7.5425
     22      0.7946        1.0881       0.3302      0.3302        1.6357        7.5303
     23      0.7857        1.0884       0.3262      0.3262        1.6365        7.5350
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 3: 0.33697916666666666
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples:

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.5865        1.3830       0.3609      0.3609        1.5643     +  7.7702
      2      0.6106        1.3137       0.3424      0.3424        1.5761        7.7724
      3      0.6442        1.2957       0.3873      0.3873        1.5413     +  7.8015
      4      0.6538        1.2516       0.3505      0.3505        1.5615        7.7851
      5      0.6587        1.2364       0.3523      0.3523        1.5593        7.7803
      6      0.6538        1.2219       0.3556      0.3556        1.5475        7.7892
      7      0.6875        1.2013       0.3530      0.3530        1.5507        7.7861
      8      0.6827        1.2042       0.3839      0.3839        1.5367     +  7.7869
      9      0.7067        1.1652       0.3861      0.3861        1.5220     +  7.7863
     10      0.7163        1.1662       0.3707      0.3707        1.5228        7.7664
     11      0.7115        1.1397       0.3661      0.3661        1.5254        7.8011
     12      0.7067        1.1388       0.3595      0.3595        1.5301        7.7646
     13      0.7212        1.1276       0.4003      0.4003        1.4971     +  7.7738
     14      0.7356        1.1106       0.3920      0.3920        1.5033        7.7467
     15      0.7404        1.1035       0.3658      0.3658        1.5185        7.7624
     16      0.7548        1.0941       0.4083      0.4083        1.4849     +  7.7532
     17      0.7356        1.0820       0.3762      0.3762        1.5070        7.7919
     18      0.7500        1.0707       0.3495      0.3495        1.5400        7.7788
     19      0.7500        1.0664       0.4681      0.4681        1.4419     +  7.8014
     20      0.7548        1.0907       0.3545      0.3545        1.5252        7.8125
     21      0.7644        1.0668       0.3455      0.3455        1.5539        7.7870
     22      0.7356        1.0581       0.4851      0.4851        1.4243     +  7.7830
     23      0.7788        1.0743       0.3354      0.3354        1.5496        7.7744
     24      0.7885        1.0536       0.3719      0.3719        1.5192        7.8012
     25      0.7837        1.0213       0.4783      0.4783        1.4146     +  7.7793
     26      0.8125        1.0284       0.3646      0.3646        1.5234        7.7965
     27      0.7837        1.0201       0.3917      0.3917        1.5126        7.7958
     28      0.8077        0.9960       0.4788      0.4788        1.4099     +  7.7989
     29      0.8173        1.0018       0.4483      0.4483        1.4326        7.7693
     30      0.8077        0.9760       0.3583      0.3583        1.5619        7.7472
     31      0.8173        1.0038       0.4503      0.4503        1.4618        7.7728
     32      0.8365        0.9587       0.4877      0.4877        1.3989     +  7.7767
     33      0.8221        0.9688       0.4618      0.4618        1.4261        7.8128
     34      0.8365        0.9405       0.4049      0.4049        1.4995        7.8010
     35      0.8269        0.9547       0.4484      0.4484        1.4517        7.8060
     36      0.8365        0.9313       0.5082      0.5082        1.3825     +  7.8084
     37      0.8269        0.9448       0.4788      0.4788        1.4047        7.7938
     38      0.8269        0.9501       0.3891      0.3891        1.5711        7.7990
     39      0.8317        0.9776       0.4493      0.4493        1.4689        7.7788
     40      0.8365        0.9092       0.5314      0.5314        1.3705     +  7.7921
     41      0.8317        0.9383       0.4354      0.4354        1.4709        7.7966
     42      0.8558        0.9099       0.4083      0.4083        1.5244        7.7944
     43      0.8510        0.8990       0.5155      0.5155        1.3758        7.7797
     44      0.8510        0.8807       0.5299      0.5299        1.3632     +  7.7832
     45      0.8510        0.8846       0.4427      0.4427        1.4553        7.7960
     46      0.8558        0.8898       0.4356      0.4356        1.4772        7.7866
     47      0.8606        0.8666       0.5207      0.5207        1.3863        7.8008
     48      0.8558        0.8471       0.5523      0.5523        1.3434     +  7.7841
     49      0.8606        0.8673       0.4719      0.4719        1.4086        7.7766
     50      0.8798        0.8483       0.4773      0.4773        1.4146        7.7679
     51      0.8750        0.8351       0.5189      0.5189        1.3642        7.7794
     52      0.8654        0.8234       0.5422      0.5422        1.3411     +  7.7704
     53      0.8750        0.8204       0.4941      0.4941        1.3920        7.7650
     54      0.8894        0.8177       0.5094      0.5094        1.3882        7.7630
     55      0.8846        0.8045       0.5170      0.5170        1.3521        7.7826
     56      0.8846        0.8066       0.5580      0.5580        1.3252     +  7.7892
     57      0.8606        0.8122       0.5262      0.5262        1.3451        7.7704
     58      0.8846        0.7922       0.5042      0.5042        1.3922        7.7826
     59      0.8798        0.8099       0.4068      0.4068        1.5735        7.7789
     60      0.8510        0.8549       0.5771      0.5771        1.3763        7.7347
     61      0.8606        0.8965       0.4792      0.4792        1.4183        7.7510
     62      0.8990        0.7867       0.4974      0.4974        1.3843        7.7595
     63      0.8894        0.7783       0.5483      0.5483        1.3349        7.7633
     64      0.9087        0.7721       0.5186      0.5186        1.3460        7.7978
     65      0.8894        0.7591       0.5405      0.5405        1.3435        7.7764
     66      0.8990        0.7531       0.5339      0.5339        1.3391        7.7650
     67      0.9135        0.7526       0.5542      0.5542        1.3335        7.7792
     68      0.9087        0.7439       0.5451      0.5451        1.3278        7.7731
     69      0.9038        0.7439       0.5517      0.5517        1.3183     +  7.7622
     70      0.8990        0.7445       0.5547      0.5547        1.3090     +  7.7652
     71      0.9183        0.7358       0.5370      0.5370        1.3399        7.7902
     72      0.9038        0.7322       0.5602      0.5602        1.3145        7.7823
     73      0.9135        0.7310       0.5781      0.5781        1.2986     +  7.7899
     74      0.8942        0.7352       0.5441      0.5441        1.3185        7.7810
     75      0.9135        0.7141       0.5321      0.5321        1.3254        7.7593
     76      0.9087        0.7186       0.5582      0.5582        1.2979     +  7.7648
     77      0.9135        0.7291       0.5667      0.5667        1.2956     +  7.7762
     78      0.9087        0.7159       0.5203      0.5203        1.3286        7.7686
     79      0.9087        0.7118       0.5769      0.5769        1.2943     +  7.8048
     80      0.9135        0.7111       0.5743      0.5743        1.2926     +  7.7999
     81      0.9183        0.7030       0.5602      0.5602        1.2928        7.7906
     82      0.9183        0.6989       0.5569      0.5569        1.2935        7.7917
     83      0.9183        0.6958       0.5712      0.5712        1.2852     +  7.8107
     84      0.9087        0.6843       0.5655      0.5655        1.2886        7.7815
     85      0.9087        0.6803       0.5806      0.5806        1.2829     +  7.7943
     86      0.9135        0.6769       0.5868      0.5868        1.2699     +  7.7846
     87      0.9135        0.6884       0.5637      0.5637        1.2835        7.7844
     88      0.9183        0.6704       0.5352      0.5352        1.3167        7.7672
     89      0.9135        0.6842       0.5443      0.5443        1.2963        7.7882
     90      0.9135        0.6756       0.5903      0.5903        1.2610     +  7.7669
     91      0.9183        0.6683       0.5736      0.5736        1.2763        7.7535
     92      0.9327        0.6638       0.5509      0.5509        1.3032        7.7566
     93      0.9183        0.6755       0.4821      0.4821        1.3923        7.7510
     94      0.9038        0.6982       0.5656      0.5656        1.2663        7.7687
     95      0.9183        0.6664       0.5955      0.5955        1.2868        7.7817
     96      0.9135        0.6768       0.5811      0.5811        1.2634        7.7955
     97      0.9279        0.6548       0.4580      0.4580        1.5249        7.7993
     98      0.9038        0.7432       0.6030      0.6030        1.2513     +  7.7732
     99      0.9183        0.6649       0.5852      0.5852        1.2801        7.7955
    100      0.9135        0.6622       0.5582      0.5582        1.2879        7.7777
F1 Score after query 4: 0.5347222222222222
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples:

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.7318        1.0460       0.4038      0.4038        1.6043     +  8.2033
      2      0.7630        1.0271       0.4477      0.4477        1.5524     +  8.2215
      3      0.7995        0.9475       0.5175      0.5175        1.3632     +  8.2751
      4      0.8333        0.9006       0.5186      0.5186        1.3451     +  8.2462
      5      0.8307        0.8654       0.5273      0.5273        1.3207     +  8.2585
      6      0.8411        0.8403       0.5259      0.5259        1.3299        8.2407
      7      0.8385        0.8101       0.5167      0.5167        1.3380        8.2491
      8      0.8438        0.8010       0.5116      0.5116        1.3275        8.2649
      9      0.8516        0.7767       0.5177      0.5177        1.3452        8.2421
     10      0.8724        0.7555       0.5278      0.5278        1.3047     +  8.2535
     11      0.8646        0.7541       0.5222      0.5222        1.3357        8.2472
     12      0.8984        0.7363       0.5161      0.5161        1.3305        8.2685
     13      0.9141        0.7279       0.5290      0.5290        1.3553        8.2657
     14      0.9141        0.7172       0.5464      0.5464        1.2900     +  8.2614
     15      0.9245        0.7238       0.4790      0.4790        1.4606        8.2496
     16      0.9141        0.7178       0.5684      0.5684        1.2519     +  8.2373
     17      0.9219        0.7079       0.5469      0.5469        1.2760        8.2434
     18      0.9089        0.6862       0.5220      0.5220        1.3245        8.2767
     19      0.9245        0.6693       0.5799      0.5799        1.2592        8.2587
     20      0.9323        0.6481       0.5710      0.5710        1.2726        8.2573
     21      0.9297        0.6445       0.5675      0.5675        1.2675        8.2556
     22      0.9297        0.6440       0.5557      0.5557        1.2914        8.2664
     23      0.9401        0.6256       0.5833      0.5833        1.2533        8.2600
     24      0.9427        0.6223       0.5618      0.5618        1.2832        8.2482
     25      0.9427        0.6209       0.5538      0.5538        1.2933        8.2448
     26      0.9427        0.6041       0.5929      0.5929        1.2347     +  8.2440
     27      0.9401        0.6087       0.5460      0.5460        1.3035        8.2396
     28      0.9401        0.6042       0.5927      0.5927        1.2366        8.2366
     29      0.9427        0.6141       0.4870      0.4870        1.4679        8.2206
     30      0.9245        0.6524       0.5849      0.5849        1.2374        8.2234
     31      0.9089        0.6480       0.5670      0.5670        1.2728        8.2437
     32      0.9453        0.5844       0.5719      0.5719        1.2605        8.2477
     33      0.9453        0.5764       0.5660      0.5660        1.2810        8.2650
     34      0.9479        0.5693       0.5628      0.5628        1.2807        8.2537
     35      0.9505        0.5611       0.5799      0.5799        1.2500        8.2600
     36      0.9479        0.5541       0.5773      0.5773        1.2614        8.2321
     37      0.9479        0.5425       0.5839      0.5839        1.2462        8.2448
     38      0.9453        0.5411       0.5819      0.5819        1.2529        8.2291
     39      0.9479        0.5429       0.5797      0.5797        1.2569        8.2601
     40      0.9453        0.5355       0.5802      0.5802        1.2550        8.2361
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 5: 0.56875
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples:

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.7898        0.9268       0.4479      0.4479        1.7408     +  9.0677
      2      0.4119        1.6255       0.5514      0.5514        1.3023     +  9.0975
      3      0.7159        1.0730       0.6595      0.6595        1.0756     +  9.0871
      4      0.8523        0.8558       0.6708      0.6708        1.0067     +  9.0779
      5      0.8736        0.7727       0.7031      0.7031        0.9541     +  9.1237
      6      0.8991        0.7074       0.6911      0.6911        0.9768        9.1196
      7      0.9062        0.6809       0.7017      0.7017        0.9476     +  9.1075
      8      0.9205        0.6438       0.7316      0.7316        0.8998     +  9.1168
      9      0.9190        0.6222       0.7356      0.7356        0.8955     +  9.0805
     10      0.9176        0.6135       0.7304      0.7304        0.8976        9.0938
     11      0.9190        0.6002       0.7330      0.7330        0.8873     +  9.0894
     12      0.9176        0.5900       0.7377      0.7377        0.8918        9.1084
     13      0.9162        0.5812       0.7236      0.7236        0.8988        9.1248
     14      0.9247        0.5730       0.7255      0.7255        0.9013        9.1121
     15      0.9233        0.5694       0.6967      0.6967        0.9338        9.1471
     16      0.9261        0.5572       0.7276      0.7276        0.8992        9.1322
     17      0.9190        0.5550       0.6944      0.6944        0.9428        9.1429
     18      0.9304        0.5389       0.7257      0.7257        0.8955        9.1125
     19      0.9247        0.5308       0.7198      0.7198        0.8978        9.1145
     20      0.9347        0.5195       0.7113      0.7113        0.9172        9.0959
     21      0.9332        0.5075       0.7085      0.7085        0.9257        9.0990
     22      0.9347        0.5022       0.7208      0.7208        0.8999        9.0850
     23      0.9403        0.4902       0.7321      0.7321        0.8875        9.0928
     24      0.9403        0.4947       0.5705      0.5705        1.4217        9.0940
     25      0.8608        0.6904       0.5260      0.5260        1.5443        9.1116
     26      0.8523        0.7069       0.7326      0.7326        0.8528     +  9.0857
     27      0.9304        0.5337       0.7465      0.7465        0.8546        9.0960
     28      0.9432        0.4861       0.7316      0.7316        0.8771        9.1240
     29      0.9432        0.4808       0.7479      0.7479        0.8454     +  9.0982
     30      0.9474        0.4677       0.7477      0.7477        0.8498        9.0703
     31      0.9517        0.4588       0.7620      0.7620        0.8224     +  9.1250
     32      0.9531        0.4409       0.7405      0.7405        0.8700        9.1044
     33      0.9588        0.4401       0.7510      0.7510        0.8505        9.1059
     34      0.9616        0.4328       0.7344      0.7344        0.8758        9.0959
     35      0.9631        0.4270       0.7462      0.7462        0.8663        9.0733
     36      0.9616        0.4248       0.7488      0.7488        0.8408        9.0886
     37      0.9616        0.4213       0.7245      0.7245        0.8984        9.0707
     38      0.9616        0.4180       0.7550      0.7550        0.8375        9.0812
     39      0.9631        0.4080       0.7043      0.7043        0.9293        9.0968
     40      0.9631        0.4139       0.7493      0.7493        0.8682        9.1042
     41      0.9531        0.4242       0.7526      0.7526        0.8211     +  9.1065
     42      0.9631        0.4011       0.7082      0.7082        0.9357        9.1047
     43      0.9574        0.4051       0.7391      0.7391        0.8453        9.1062
     44      0.9659        0.3891       0.7314      0.7314        0.8899        9.0993
     45      0.9631        0.3951       0.7406      0.7406        0.8501        9.1187
     46      0.9688        0.3835       0.7300      0.7300        0.8931        9.1189
     47      0.9659        0.3813       0.7260      0.7260        0.8813        9.1053
     48      0.9659        0.3789       0.7378      0.7378        0.8772        9.0989
     49      0.9673        0.3716       0.7229      0.7229        0.8850        9.0914
     50      0.9688        0.3698       0.7365      0.7365        0.8764        9.0944
     51      0.9716        0.3632       0.7333      0.7333        0.8697        9.0843
     52      0.9716        0.3595       0.7326      0.7326        0.8953        9.1169
     53      0.9702        0.3577       0.7302      0.7302        0.8653        9.1199
     54      0.9716        0.3571       0.7262      0.7262        0.8915        9.1118
     55      0.9716        0.3490       0.7297      0.7297        0.8765        9.1094
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 6: 0.7611111111111111
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples:

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.6812        1.0057       0.5535      0.5535        1.3157     +  10.5544
      2      0.7136        0.9943       0.6333      0.6333        1.2142     +  10.5651
      3      0.6748        1.0500       0.3498      0.3498        2.0242        10.5895
      4      0.6044        1.2845       0.5337      0.5337        1.3344        10.5937
      5      0.7785        0.8652       0.6097      0.6097        1.0335     +  10.5880
      6      0.8236        0.7658       0.6569      0.6569        1.0886        10.5961
      7      0.8774        0.6885       0.7389      0.7389        0.8662     +  10.5932
      8      0.8908        0.6395       0.7410      0.7410        0.8629     +  10.5961
      9      0.8995        0.6205       0.7408      0.7408        0.8633        10.5921
     10      0.9130        0.6038       0.7464      0.7464        0.8231     +  10.6195
     11      0.9233        0.5926       0.7356      0.7356        0.8602        10.5855
     12      0.9288        0.5830       0.7431      0.7431        0.8611        10.5633
     13      0.9264        0.5796       0.7085      0.7085        0.9386        10.5856
     14      0.9335        0.5754       0.7170      0.7170        0.9190        10.6015
     15      0.9359        0.5512       0.6833      0.6833        0.8887        10.5893
     16      0.9335        0.5605       0.7288      0.7288        0.8372        10.5907
     17      0.9438        0.5308       0.7092      0.7092        0.8425        10.5982
     18      0.9383        0.5396       0.7069      0.7069        0.9612        10.6150
     19      0.9383        0.5270       0.7028      0.7028        0.8729        10.6055
     20      0.9415        0.5187       0.7250      0.7250        0.8376        10.6166
     21      0.9446        0.5047       0.7241      0.7241        0.8605        10.5947
     22      0.9430        0.5034       0.7191      0.7191        0.8970        10.5841
     23      0.9446        0.4974       0.7134      0.7134        0.8653        10.5642
     24      0.9486        0.4883       0.7168      0.7168        0.8371        10.5562
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 7: 0.7753472222222222
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples:

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.7120        0.9868       0.4767      0.4767        1.6077     +  13.2209
      2      0.7027        1.0560       0.6366      0.6366        1.0453     +  13.2171
      3      0.7951        0.8258       0.7509      0.7509        0.7806     +  13.2365
      4      0.8489        0.7238       0.7063      0.7063        0.8389        13.2420
      5      0.8441        0.7045       0.7783      0.7783        0.7107     +  13.2580
      6      0.8865        0.6374       0.7609      0.7609        0.7530        13.2462
      7      0.8432        0.6934       0.7644      0.7644        0.7483        13.2454
      8      0.8852        0.6132       0.7601      0.7601        0.7650        13.2386
      9      0.9002        0.5852       0.7543      0.7543        0.8407        13.2401
     10      0.9024        0.5699       0.7535      0.7535        0.7744        13.2519
     11      0.8812        0.6054       0.7694      0.7694        0.7524        13.2500
     12      0.9143        0.5380       0.7592      0.7592        0.7747        13.2314
     13      0.9099        0.5326       0.6441      0.6441        1.0782        13.2274
     14      0.8989        0.5694       0.7517      0.7517        0.7929        13.2023
     15      0.9139        0.5166       0.7568      0.7568        0.7686        13.2390
     16      0.9112        0.5289       0.7625      0.7625        0.7680        13.2818
     17      0.9201        0.4965       0.7583      0.7583        0.8365        13.2410
     18      0.9271        0.4853       0.7573      0.7573        0.7964        13.2324
     19      0.9117        0.5159       0.6441      0.6441        1.0514        13.2604
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 8: 0.7980902777777777
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples:

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.7849        0.7977       0.7111      0.7111        0.8540     +  18.8768
      2      0.8349        0.6671       0.6986      0.6986        0.9017        19.2509
      3      0.8775        0.5686       0.8066      0.8066        0.6236     +  19.3665
      4      0.8908        0.5374       0.6788      0.6788        1.0869        18.4424
      5      0.8901        0.5293       0.7944      0.7944        0.6728        17.9170
      6      0.8963        0.5033       0.7854      0.7854        0.6797        17.9205
      7      0.9156        0.4590       0.6939      0.6939        0.9189        18.0184
      8      0.9233        0.4385       0.8007      0.8007        0.6403        17.9559
      9      0.9342        0.4152       0.7964      0.7964        0.6647        17.9731
     10      0.9369        0.4008       0.7988      0.7988        0.6634        17.9703
     11      0.9374        0.3903       0.8023      0.8023        0.6600        17.9285
     12      0.9443        0.3757       0.8028      0.8028        0.6659        17.9021
     13      0.9455        0.3644       0.7960      0.7960        0.6860        17.9830
     14      0.9059        0.4750       0.8130      0.8130        0.6593        17.9688
     15      0.9354        0.3821       0.7941      0.7941        0.6674        17.9045
     16      0.9483        0.3492       0.7990      0.7990        0.6670        17.9327
     17      0.9480        0.3404       0.8049      0.8049        0.6474        17.9453
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 9: 0.8331597222222222
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples:

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.8582        0.5636       0.8101      0.8101        0.6114     +  26.3550
      2      0.8976        0.4635       0.8109      0.8109        0.6226        26.2850
      3      0.8983        0.4538       0.8127      0.8127        0.6264        26.2558
      4      0.9199        0.4003       0.8106      0.8106        0.6482        26.3065
      5      0.9189        0.3815       0.8165      0.8165        0.6297        26.3291
      6      0.9293        0.3600       0.8200      0.8200        0.6315        26.3119
      7      0.9333        0.3447       0.8219      0.8219        0.6379        26.3225
      8      0.9361        0.3319       0.8156      0.8156        0.6675        26.2326
      9      0.9378        0.3223       0.8148      0.8148        0.6640        26.3379
     10      0.9406        0.3119       0.8137      0.8137        0.6719        26.3634
     11      0.9425        0.3046       0.8210      0.8210        0.6518        26.3395
     12      0.9442        0.2970       0.8203      0.8203        0.6555        26.3114
     13      0.9487        0.2850       0.8229      0.8229        0.6559        26.3582
     14      0.9479        0.2805       0.8120      0.8120        0.6778        26.3400
     15      0.9508        0.2728       0.8128      0.8128        0.6787        26.3408
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 10: 0.8439236111111111
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples:

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.9409        0.2860       0.8283      0.8283        0.5729     +  41.2519
      2      0.9415        0.2813       0.8259      0.8259        0.5591     +  41.1602
      3      0.9518        0.2495       0.8319      0.8319        0.5603        41.1884
      4      0.9531        0.2413       0.8321      0.8321        0.5496     +  41.2659
      5      0.9566        0.2305       0.8184      0.8184        0.5730        41.2558
      6      0.9563        0.2235       0.8043      0.8043        0.6347        41.2563
      7      0.9598        0.2152       0.8307      0.8307        0.5780        41.2781
      8      0.9605        0.2106       0.8332      0.8332        0.5829        41.2161
      9      0.9529        0.2227       0.8280      0.8280        0.5843        41.2287
     10      0.9619        0.1992       0.8295      0.8295        0.5973        41.2382
     11      0.9656        0.1877       0.8293      0.8293        0.6137        41.1905
     12      0.9651        0.1848       0.8330      0.8330        0.6341        41.2299
     13      0.9687        0.1764       0.8285      0.8285        0.6362        41.2657
     14      0.9686        0.1704       0.8266      0.8266        0.6438        41.2313
     15      0.9694        0.1683       0.8226      0.8226        0.6729        41.2659
     16      0.9722        0.1605       0.8247      0.8247        0.6622        41.2882
     17      0.9713        0.1586       0.8189      0.8189        0.6710        41.2825
     18      0.9731        0.1534       0.8172      0.8172        0.6809        41.2673
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 11: 0.8335069444444444
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples:

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.9793        0.1237       0.8269      0.8269        0.6724     +  67.5354
      2      0.9826        0.1135       0.8224      0.8224        0.6856        67.7908
      3      0.9817        0.1135       0.8219      0.8219        0.6394     +  67.8596
      4      0.9829        0.1083       0.8113      0.8113        0.6984        67.6904
      5      0.9782        0.1212       0.8189      0.8189        0.6806        67.7365
      6      0.9820        0.1057       0.8059      0.8059        0.6862        68.0355
      7      0.9860        0.0934       0.8064      0.8064        0.7523        67.9465
      8      0.9864        0.0903       0.8382      0.8382        0.6406        67.8007
      9      0.9866        0.0881       0.8149      0.8149        0.7380        67.6443
     10      0.9877        0.0847       0.8224      0.8224        0.7032        67.7264
     11      0.9890        0.0796       0.8266      0.8266        0.7093        67.6646
     12      0.9887        0.0793       0.8201      0.8201        0.7220        67.7877
     13      0.9877        0.0812       0.8063      0.8062        0.7443        67.7506
     14      0.9867        0.0846       0.8122      0.8122        0.7405        67.7331
     15      0.9907        0.0714       0.8122      0.8122        0.7726        67.7649
     16      0.9915        0.0683       0.8238      0.8238        0.7499        67.7099
     17      0.9432        0.2502       0.7868      0.7868        0.8700        67.8201
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 12: 0.845138888888889
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples:

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.9917        0.0624       0.8241      0.8241        0.7489     +  78.3911
      2      0.9924        0.0591       0.8311      0.8311        0.7165     +  78.4419
      3      0.9946        0.0530       0.8262      0.8262        0.7593        78.3612
      4      0.9948        0.0510       0.8245      0.8245        0.7571        78.3600
      5      0.9946        0.0502       0.8161      0.8161        0.7885        78.5002
      6      0.9938        0.0512       0.8167      0.8167        0.7830        78.3529
      7      0.9949        0.0475       0.8073      0.8073        0.8236        78.3436
      8      0.9938        0.0506       0.8163      0.8163        0.8089        78.4997
      9      0.9953        0.0452       0.8163      0.8163        0.8280        78.3891
     10      0.9953        0.0444       0.8231      0.8231        0.8171        78.3671
     11      0.9949        0.0454       0.8220      0.8220        0.7876        78.2755
     12      0.9947        0.0446       0.8104      0.8104        0.8760        78.3921
     13      0.9878        0.0656       0.8094      0.8094        0.8453        78.4318
     14      0.9934        0.0480       0.8177      0.8177        0.8307        78.3455
     15      0.9916        0.0523       0.8118      0.8118        0.8415        78.3216
     16      0.9957        0.0401       0.8168      0.8168        0.8553        78.3419
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 13: 0.8420138888888888
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\model_checkpoint_iteration_12.pt
Performance results saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\entropy_sampling\performance_results.npy
PS C:\Users\localuserSG\ActiveLearning\Multiclass01\DinoSmall\ES>