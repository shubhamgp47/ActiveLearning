PS C:\Users\localuserSG\ActiveLearning\Multiclass01\DinoSmall\US>
PS C:\Users\localuserSG\ActiveLearning\Multiclass01\DinoSmall\US>



PS C:\Users\localuserSG\ActiveLearning\Multiclass01\DinoSmall\US>

PS C:\Users\localuserSG\ActiveLearning\Multiclass01\DinoSmall\US>

PS C:\Users\localuserSG\ActiveLearning\Multiclass01\DinoSmall\US> python .\uncertainty_sampling_paramsfrommultilabl.py
(26880, 5)
(5760, 5)
(5760, 5)
100%|█████████████████████████████████████████████████████████████| 26880/26880 [00:00<00:00, 121346.87it/s]
100%|███████████████████████████████████████████████████████████████| 5760/5760 [00:00<00:00, 129163.83it/s]
100%|███████████████████████████████████████████████████████████████| 5760/5760 [00:00<00:00, 125858.62it/s]
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
Using cache found in C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main
C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
C:\Users\localuserSG/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.2500        2.1759       0.0569      0.0569        2.1781     +  7.2508
      2      0.1250        2.0674       0.0536      0.0536        2.1770     +  6.9526
      3      0.3750        2.0319       0.0510      0.0510        2.1745     +  6.9587
      4      0.2500        1.9984       0.0630      0.0630        2.1718     +  6.9277
      5      0.1250        2.1071       0.0625      0.0625        2.1690     +  6.9767
      6      1.0000        2.1314       0.0672      0.0672        2.1601     +  7.0672
      7      0.1250        2.0926       0.0547      0.0547        2.1576     +  7.1311
      8      0.2500        2.0193       0.0545      0.0545        2.1487     +  7.0982
      9      0.2500        2.0050       0.0524      0.0524        2.1391     +  7.1042
     10      0.1250        2.0119       0.0583      0.0583        2.1319     +  7.1090
     11      0.1250        1.9949       0.0535      0.0535        2.1323        7.1057
     12      0.1250        1.9581       0.0556      0.0556        2.1286     +  7.1181
     13      0.3750        1.9434       0.0552      0.0552        2.1230     +  7.1162
     14      0.6250        1.9222       0.0533      0.0533        2.1218     +  7.1400
     15      0.3750        1.9386       0.0807      0.0807        2.1071     +  7.1888
     16      0.3750        1.9710       0.1002      0.1002        2.0999     +  7.1911
     17      0.3750        1.9084       0.1040      0.1040        2.0944     +  7.1907
     18      0.2500        1.9398       0.1113      0.1113        2.0878     +  7.2195
     19      0.3750        1.8968       0.1163      0.1163        2.0853     +  7.2409
     20      0.2500        1.9025       0.1181      0.1181        2.0790     +  7.2256
     21      0.5000        1.8680       0.1132      0.1132        2.0812        7.2239
     22      0.5000        1.8752       0.1193      0.1193        2.0712     +  7.2378
     23      0.3750        1.8403       0.1184      0.1184        2.0671     +  7.2142
     24      0.5000        1.8591       0.1215      0.1215        2.0654     +  7.2129
     25      0.3750        1.8239       0.1332      0.1332        2.0580     +  7.2232
     26      0.5000        1.8375       0.1259      0.1259        2.0632        7.2339
     27      0.6250        1.8082       0.1189      0.1189        2.0723        7.2348
     28      0.2500        1.8697       0.1293      0.1293        2.0600        7.2243
     29      0.6250        1.7325       0.1280      0.1280        2.0597        7.2337
     30      0.7500        1.7329       0.1267      0.1267        2.0582        7.2447
     31      0.7500        1.7486       0.1293      0.1293        2.0600        7.2333
     32      0.7500        1.7146       0.1427      0.1427        2.0542     +  7.2815
     33      0.8750        1.6805       0.1514      0.1514        2.0486     +  7.2499
     34      0.6250        1.7239       0.1528      0.1528        2.0463     +  7.2646
     35      0.5000        1.6923       0.1484      0.1484        2.0576        7.2620
     36      0.8750        1.5902       0.1550      0.1550        2.0546        7.2735
     37      1.0000        1.5727       0.1686      0.1686        2.0460     +  7.2479
     38      0.7500        1.5894       0.1804      0.1804        2.0446     +  7.2477
     39      0.8750        1.5887       0.1717      0.1717        2.0466        7.2636
     40      0.8750        1.5882       0.1543      0.1543        2.0638        7.2671
     41      0.8750        1.5834       0.1436      0.1436        2.0712        7.2715
     42      0.8750        1.5860       0.1587      0.1587        2.0694        7.2683
     43      0.6250        1.5087       0.1665      0.1665        2.0608        7.2651
     44      0.6250        1.5810       0.1658      0.1658        2.0620        7.2553
     45      0.8750        1.5468       0.1689      0.1689        2.0646        7.2286
     46      0.8750        1.4474       0.1606      0.1606        2.0667        7.2277
     47      0.8750        1.4575       0.1653      0.1653        2.0593        7.2311
     48      1.0000        1.4335       0.1764      0.1764        2.0544        7.2657
     49      1.0000        1.4042       0.1717      0.1717        2.0650        7.2592
     50      1.0000        1.3695       0.1722      0.1722        2.0659        7.2677
     51      0.8750        1.4897       0.1726      0.1726        2.0593        7.2942
     52      0.8750        1.4529       0.1832      0.1832        2.0422     +  7.2591
     53      1.0000        1.4710       0.1958      0.1958        2.0407     +  7.2500
     54      1.0000        1.3431       0.1894      0.1894        2.0442        7.2568
     55      0.8750        1.3448       0.1915      0.1915        2.0523        7.2813
     56      0.8750        1.3524       0.2017      0.2017        2.0432        7.2792
     57      0.7500        1.4284       0.2064      0.2064        2.0386     +  7.2735
     58      1.0000        1.3974       0.1997      0.1997        2.0317     +  7.2665
     59      1.0000        1.3551       0.2019      0.2019        2.0438        7.2671
     60      1.0000        1.3012       0.2036      0.2036        2.0386        7.2694
     61      1.0000        1.2744       0.2148      0.2148        2.0280     +  7.2457
     62      0.8750        1.3230       0.2078      0.2078        2.0517        7.2159
     63      1.0000        1.2412       0.2080      0.2080        2.0513        7.2357
     64      1.0000        1.3019       0.2075      0.2075        2.0522        7.2474
     65      1.0000        1.2641       0.2139      0.2139        2.0493        7.2702
     66      0.8750        1.3099       0.2127      0.2127        2.0462        7.2733
     67      0.8750        1.3039       0.2139      0.2139        2.0570        7.2733
     68      1.0000        1.2628       0.2141      0.2141        2.0555        7.2733
     69      1.0000        1.2194       0.2181      0.2181        2.0495        7.2647
     70      1.0000        1.2400       0.2184      0.2184        2.0452        7.2841
     71      1.0000        1.2003       0.2102      0.2102        2.0554        7.2839
     72      0.8750        1.2398       0.2123      0.2123        2.0682        7.2816
     73      1.0000        1.2198       0.2158      0.2158        2.0561        7.2656
     74      1.0000        1.1865       0.2168      0.2168        2.0445        7.2699
     75      1.0000        1.1925       0.2186      0.2186        2.0565        7.2541
Stopping since valid_loss has not improved in the last 15 epochs.
Pre F1 score = 0.238

Iteration:  1
Selecting 16 informative samples:

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.3333        1.8838       0.2941      0.2941        1.9255     +  7.3428
      2      0.7500        1.6143       0.3240      0.3240        1.8698     +  7.2842
      3      0.8750        1.4734       0.3608      0.3608        1.8501     +  7.2895
      4      0.9167        1.3772       0.3826      0.3826        1.8441     +  7.3163
      5      0.9167        1.3165       0.3851      0.3851        1.8337     +  7.3150
      6      0.9167        1.2844       0.3868      0.3868        1.8284     +  7.2927
      7      0.9167        1.2526       0.3967      0.3967        1.8228     +  7.3028
      8      0.8750        1.1936       0.3972      0.3972        1.8159     +  7.3043
      9      0.9167        1.1677       0.4068      0.4068        1.8084     +  7.2812
     10      0.8333        1.1596       0.3972      0.3972        1.8066     +  7.3019
     11      0.8333        1.1776       0.4010      0.4010        1.8027     +  7.2757
     12      0.8750        1.1067       0.3799      0.3799        1.8103        7.2740
     13      0.9167        1.0541       0.3892      0.3892        1.8060        7.2638
     14      0.9167        1.0179       0.3792      0.3792        1.8055        7.2963
     15      0.8750        1.0242       0.3750      0.3750        1.8116        7.2972
     16      0.9167        1.0040       0.3870      0.3870        1.8086        7.2971
     17      0.9167        1.0266       0.3700      0.3700        1.8081        7.3209
     18      0.9167        1.0110       0.3781      0.3781        1.8094        7.2959
     19      0.9167        0.9790       0.3566      0.3566        1.8111        7.3038
     20      0.9583        0.9684       0.3700      0.3700        1.8085        7.2963
     21      0.9583        0.9621       0.3550      0.3550        1.8074        7.3171
     22      0.9167        0.9656       0.3634      0.3634        1.8083        7.3194
     23      0.9583        0.9396       0.3411      0.3411        1.8129        7.3143
     24      0.9583        0.9163       0.3385      0.3385        1.8251        7.3215
     25      0.9583        0.9165       0.3394      0.3394        1.8201        7.3046
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 1: 0.33090277777777777
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples:

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.5893        1.4739       0.4741      0.4741        1.7384     +  7.4042
      2      0.9107        1.2317       0.4483      0.4483        1.7040     +  7.3780
      3      0.8571        1.1190       0.4479      0.4479        1.6955     +  7.3340
      4      0.8571        1.0332       0.4479      0.4479        1.6928     +  7.3683
      5      0.8571        0.9913       0.4479      0.4479        1.6917     +  7.3597
      6      0.8214        0.9616       0.4479      0.4479        1.6946        7.3284
      7      0.8214        0.9243       0.4479      0.4479        1.6958        7.3805
      8      0.8214        0.9011       0.4479      0.4479        1.6970        7.3842
      9      0.8571        0.8839       0.4479      0.4479        1.6966        7.3837
     10      0.8214        0.8626       0.4479      0.4479        1.6966        7.3556
     11      0.8393        0.8438       0.4479      0.4479        1.6967        7.3429
     12      0.8571        0.8445       0.4479      0.4479        1.6953        7.3285
     13      0.8571        0.8171       0.4479      0.4479        1.6924        7.3388
     14      0.8571        0.8177       0.4479      0.4479        1.6862     +  7.3503
     15      0.8571        0.8072       0.4479      0.4479        1.6830     +  7.3612
     16      0.8571        0.7804       0.4479      0.4479        1.6854        7.3670
     17      0.8571        0.7930       0.4479      0.4479        1.6851        7.3713
     18      0.8571        0.7862       0.4479      0.4479        1.6929        7.4066
     19      0.8571        0.7719       0.4479      0.4479        1.6835        7.3753
     20      0.8393        0.7721       0.4479      0.4479        1.6820     +  7.3773
     21      0.8750        0.7462       0.4479      0.4479        1.6773     +  7.3474
     22      0.8571        0.7545       0.4479      0.4479        1.6788        7.3753
     23      0.8393        0.7538       0.4479      0.4479        1.6838        7.3851
     24      0.8571        0.7354       0.4479      0.4479        1.6761     +  7.3944
     25      0.8571        0.7227       0.4479      0.4479        1.6767        7.3760
     26      0.8750        0.7306       0.4479      0.4479        1.6752     +  7.3552
     27      0.8929        0.7181       0.4479      0.4479        1.6701     +  7.3341
     28      0.8750        0.7165       0.4479      0.4479        1.6717        7.3512
     29      0.8750        0.7191       0.4479      0.4479        1.6819        7.3521
     30      0.8571        0.7064       0.4479      0.4479        1.6694     +  7.3681
     31      0.8750        0.6975       0.4479      0.4479        1.6760        7.3873
     32      0.8750        0.6905       0.4479      0.4479        1.6705        7.4048
     33      0.8750        0.6821       0.4479      0.4479        1.6719        7.3941
     34      0.8929        0.6831       0.4479      0.4479        1.6659     +  7.3869
     35      0.8750        0.6900       0.4479      0.4479        1.6663        7.3792
     36      0.9107        0.6835       0.4479      0.4479        1.6708        7.3937
     37      0.8929        0.6670       0.4479      0.4479        1.6664        7.3976
     38      0.9107        0.6623       0.4479      0.4479        1.6623     +  7.3917
     39      0.9107        0.6531       0.4479      0.4479        1.6538     +  7.4004
     40      0.8750        0.6569       0.4479      0.4479        1.6623        7.3752
     41      0.9286        0.6344       0.4479      0.4479        1.6635        7.3747
     42      0.8750        0.6532       0.4479      0.4479        1.6580        7.4066
     43      0.8750        0.6456       0.4479      0.4479        1.6655        7.3720
     44      0.9107        0.6299       0.4479      0.4479        1.6595        7.3693
     45      0.8929        0.6642       0.4479      0.4479        1.6635        7.3645
     46      0.9286        0.6264       0.4479      0.4479        1.6668        7.3743
     47      0.8929        0.6411       0.4479      0.4479        1.6643        7.4302
     48      0.8929        0.6319       0.4479      0.4479        1.6591        7.4424
     49      0.8929        0.6265       0.4479      0.4479        1.6590        7.3635
     50      0.9107        0.6108       0.4479      0.4479        1.6576        7.3912
     51      0.9286        0.6241       0.4479      0.4479        1.6556        7.3424
     52      0.9286        0.6219       0.4479      0.4479        1.6563        7.3450
     53      0.9286        0.6117       0.4479      0.4479        1.6554        7.3752
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 2: 0.47934027777777777
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples:

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.5179        1.4775       0.4490      0.4490        1.5720     +  7.4533
      2      0.5625        1.3790       0.4495      0.4495        1.5297     +  7.4917
      3      0.5982        1.3029       0.4497      0.4497        1.5140     +  7.4904
      4      0.6071        1.2667       0.4510      0.4510        1.4908     +  7.4929
      5      0.6607        1.2405       0.4495      0.4495        1.5045        7.5115
      6      0.6786        1.2281       0.4597      0.4597        1.4690     +  7.5021
      7      0.7589        1.2057       0.4564      0.4564        1.4737        7.4916
      8      0.7679        1.1860       0.4628      0.4628        1.4620     +  7.4784
      9      0.7679        1.1566       0.4694      0.4694        1.4567     +  7.5097
     10      0.8393        1.1480       0.4722      0.4722        1.4542     +  7.5110
     11      0.8125        1.1311       0.4856      0.4856        1.4394     +  7.4769
     12      0.8393        1.1191       0.4747      0.4747        1.4521        7.4894
     13      0.8393        1.1096       0.4833      0.4833        1.4410        7.4907
     14      0.8393        1.0925       0.4764      0.4764        1.4499        7.4657
     15      0.8304        1.0896       0.4762      0.4762        1.4495        7.4820
     16      0.8393        1.0799       0.4872      0.4872        1.4325     +  7.4529
     17      0.8214        1.0826       0.4865      0.4865        1.4324     +  7.4826
     18      0.8304        1.0536       0.4828      0.4828        1.4377        7.5116
     19      0.8393        1.0557       0.4939      0.4939        1.4218     +  7.4952
     20      0.8125        1.0479       0.4809      0.4809        1.4399        7.5203
     21      0.8304        1.0397       0.5026      0.5026        1.4148     +  7.4880
     22      0.8214        1.0409       0.4760      0.4760        1.4477        7.5002
     23      0.8214        1.0353       0.5109      0.5109        1.4086     +  7.5072
     24      0.7946        1.0187       0.4802      0.4802        1.4441        7.5063
     25      0.8482        1.0108       0.5122      0.5122        1.4072     +  7.5031
     26      0.8214        1.0012       0.4837      0.4837        1.4395        7.5124
     27      0.8304        1.0115       0.5132      0.5132        1.4039     +  7.4930
     28      0.8304        0.9953       0.4790      0.4790        1.4428        7.4948
     29      0.8304        1.0019       0.5219      0.5219        1.3890     +  7.4964
     30      0.8036        0.9896       0.4712      0.4712        1.4629        7.4584
     31      0.8304        0.9969       0.5330      0.5330        1.3812     +  7.4794
     32      0.7768        0.9979       0.4715      0.4715        1.4587        7.4689
     33      0.8393        0.9919       0.5283      0.5283        1.3876        7.4862
     34      0.8214        0.9799       0.4835      0.4835        1.4407        7.5026
     35      0.8304        0.9780       0.5281      0.5281        1.3859        7.5118
     36      0.7946        0.9693       0.4767      0.4767        1.4545        7.4875
     37      0.8482        0.9712       0.5375      0.5375        1.3802     +  7.5120
     38      0.7946        0.9605       0.4925      0.4925        1.4318        7.5084
     39      0.8482        0.9653       0.5201      0.5201        1.3978        7.5076
     40      0.8214        0.9568       0.4941      0.4941        1.4257        7.5069
     41      0.8304        0.9495       0.5132      0.5132        1.4003        7.5020
     42      0.8214        0.9321       0.4965      0.4965        1.4234        7.4871
     43      0.8393        0.9441       0.5259      0.5259        1.3843        7.4843
     44      0.8125        0.9388       0.4847      0.4847        1.4419        7.4872
     45      0.8482        0.9365       0.5411      0.5411        1.3660     +  7.4999
     46      0.8125        0.9443       0.4661      0.4661        1.4780        7.4703
     47      0.8571        0.9606       0.5595      0.5595        1.3594     +  7.4662
     48      0.7946        0.9431       0.4884      0.4884        1.4394        7.4522
     49      0.8393        0.9155       0.5255      0.5255        1.3911        7.4911
     50      0.8482        0.9102       0.4892      0.4892        1.4363        7.4891
     51      0.8393        0.9157       0.5328      0.5328        1.3786        7.4870
     52      0.8304        0.9158       0.4797      0.4797        1.4559        7.5085
     53      0.8482        0.9067       0.5498      0.5498        1.3633        7.5034
     54      0.8214        0.9216       0.4719      0.4719        1.4723        7.4862
     55      0.8482        0.9135       0.5530      0.5530        1.3688        7.4772
     56      0.8393        0.8982       0.5043      0.5043        1.4210        7.4843
     57      0.8482        0.8876       0.5155      0.5155        1.4037        7.4914
     58      0.8393        0.8915       0.4991      0.4991        1.4263        7.4928
     59      0.8571        0.8753       0.5155      0.5155        1.4022        7.5074
     60      0.8571        0.8807       0.5089      0.5089        1.4114        7.4803
     61      0.8482        0.8669       0.5080      0.5080        1.4085        7.4688
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 3: 0.5430555555555555
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples:

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.8029        1.0368       0.4479      0.4479        1.7608     +  7.8148
      2      0.6106        1.3272       0.4479      0.4479        1.6509     +  7.7773
      3      0.6154        1.2655       0.4503      0.4503        1.5724     +  7.7268
      4      0.6635        1.1742       0.4701      0.4701        1.4529     +  7.7350
      5      0.6683        1.1847       0.4479      0.4479        1.7521        7.7578
      6      0.6106        1.2723       0.4479      0.4479        1.6677        7.7809
      7      0.6346        1.2058       0.4497      0.4497        1.5817        7.7812
      8      0.6635        1.1581       0.4594      0.4594        1.5253        7.7622
      9      0.6683        1.1123       0.4833      0.4833        1.4427     +  7.7584
     10      0.6683        1.0613       0.5082      0.5082        1.3869     +  7.7426
     11      0.7212        0.9857       0.5391      0.5391        1.3217     +  7.7562
     12      0.8029        0.9281       0.5354      0.5354        1.3252        7.7773
     13      0.8077        0.9172       0.5340      0.5340        1.3218        7.7958
     14      0.8125        0.8928       0.5389      0.5389        1.3117     +  7.7977
     15      0.8317        0.8813       0.5312      0.5312        1.3251        7.7537
     16      0.8221        0.8670       0.5347      0.5347        1.3200        7.7772
     17      0.8173        0.8622       0.5273      0.5273        1.3311        7.7972
     18      0.8077        0.8637       0.5411      0.5411        1.3113     +  7.7870
     19      0.8173        0.8536       0.5241      0.5241        1.3362        7.7794
     20      0.8317        0.8439       0.5259      0.5259        1.3382        7.7613
     21      0.8269        0.8353       0.5556      0.5556        1.3002     +  7.7816
     22      0.8317        0.8202       0.5259      0.5259        1.3368        7.7657
     23      0.8269        0.8244       0.5174      0.5174        1.3484        7.7616
     24      0.8413        0.8248       0.5293      0.5293        1.3370        7.7581
     25      0.8365        0.8129       0.5517      0.5517        1.3059        7.7493
     26      0.8462        0.8094       0.5323      0.5323        1.3300        7.7689
     27      0.8462        0.8087       0.5448      0.5448        1.3135        7.7613
     28      0.8462        0.7977       0.5391      0.5391        1.3220        7.7655
     29      0.8365        0.7895       0.5321      0.5321        1.3350        7.7626
     30      0.8413        0.7895       0.5340      0.5340        1.3329        7.7604
     31      0.8413        0.7843       0.5396      0.5396        1.3224        7.7505
     32      0.8365        0.7938       0.5307      0.5307        1.3376        7.7668
     33      0.8462        0.7775       0.5594      0.5594        1.3036        7.7529
     34      0.8413        0.7759       0.5363      0.5363        1.3273        7.7733
     35      0.8365        0.7731       0.5495      0.5495        1.3180        7.7628
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 4: 0.6133680555555555
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples:

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.6667        1.1482       0.6212      0.6212        1.2365     +  8.2068
      2      0.6641        1.1335       0.6288      0.6288        1.2124     +  8.2142
      3      0.7083        1.0788       0.6309      0.6309        1.2070     +  8.2219
      4      0.7370        1.0572       0.6269      0.6269        1.2091        8.2408
      5      0.7396        1.0420       0.6285      0.6285        1.2125        8.2228
      6      0.7682        1.0146       0.6241      0.6241        1.2066     +  8.2363
      7      0.7448        1.0078       0.6205      0.6205        1.2146        8.2319
      8      0.7578        0.9855       0.6153      0.6153        1.2115        8.2388
      9      0.7734        0.9844       0.6188      0.6188        1.2078        8.2212
     10      0.7734        0.9678       0.6194      0.6194        1.2036     +  8.2206
     11      0.7630        0.9659       0.6194      0.6194        1.2061        8.1932
     12      0.7526        0.9489       0.6135      0.6135        1.2126        8.2196
     13      0.7760        0.9382       0.6111      0.6111        1.2148        8.2073
     14      0.7786        0.9225       0.6050      0.6050        1.2215        8.2165
     15      0.8021        0.9140       0.6155      0.6155        1.2114        8.2464
     16      0.7839        0.9124       0.6233      0.6233        1.1993     +  8.2590
     17      0.7839        0.9037       0.6181      0.6181        1.2069        8.2438
     18      0.7865        0.8910       0.6205      0.6205        1.2017        8.2365
     19      0.8125        0.8836       0.6207      0.6207        1.2055        8.2406
     20      0.7943        0.8811       0.6165      0.6165        1.2052        8.2188
     21      0.8125        0.8674       0.6167      0.6167        1.2078        8.2556
     22      0.8229        0.8634       0.6156      0.6156        1.2103        8.2191
     23      0.8229        0.8489       0.6122      0.6122        1.2099        8.2094
     24      0.8281        0.8415       0.6158      0.6158        1.2069        8.2278
     25      0.8438        0.8336       0.6122      0.6122        1.2171        8.2255
     26      0.8307        0.8308       0.6106      0.6106        1.2154        8.2034
     27      0.8516        0.8269       0.6186      0.6186        1.2113        8.2026
     28      0.8203        0.8159       0.6116      0.6116        1.2227        8.2041
     29      0.8490        0.8004       0.6123      0.6123        1.2145        8.2113
     30      0.8620        0.7980       0.6090      0.6090        1.2232        8.2416
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 5: 0.6486111111111111
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples:

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp     dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------
      1      0.6136        1.2074       0.6878      0.6878        1.1197     +  9.0191
      2      0.6108        1.2077       0.5451      0.5451        1.3801        9.0365
      3      0.6364        1.2665       0.6807      0.6807        1.0450     +  9.0542
      4      0.7060        1.0928       0.7118      0.7118        0.9970     +  9.0227
      5      0.7045        1.0721       0.7240      0.7240        0.9688     +  9.0114
      6      0.7557        1.0374       0.7033      0.7033        0.9856        9.0551
      7      0.8452        0.9750       0.6906      0.6906        0.9696        9.1045
      8      0.8480        0.9525       0.6363      0.6363        1.1378        9.0852
      9      0.8665        0.9607       0.5891      0.5891        1.1845        9.0910
     10      0.8722        0.9115       0.6884      0.6884        0.9746        9.1011
     11      0.8665        0.9028       0.6842      0.6842        1.0172        9.0966
     12      0.8949        0.8851       0.6670      0.6670        1.0055        9.0746
     13      0.8778        0.8695       0.5127      0.5127        1.3655        9.1287
     14      0.8608        0.9658       0.6741      0.6741        0.9964        9.1193
     15      0.9091        0.8227       0.7014      0.7014        0.9523     +  9.0967
     16      0.9091        0.8159       0.6111      0.6111        1.1398        9.0654
     17      0.9034        0.8090       0.6984      0.6984        0.9511     +  9.0696
     18      0.9148        0.7821       0.7028      0.7028        0.9492     +  9.0784
     19      0.8977        0.8138       0.5790      0.5790        1.2504        9.0938
     20      0.9062        0.7950       0.7125      0.7125        0.9470     +  9.1171
     21      0.9176        0.7647       0.6545      0.6545        1.0408        9.0938
     22      0.9247        0.7400       0.6734      0.6734        1.0100        9.1300
     23      0.9233        0.7324       0.6854      0.6854        1.0235        9.0644
     24      0.9062        0.7679       0.5826      0.5826        1.2531        9.0937
     25      0.9190        0.7310       0.7078      0.7078        0.9398     +  9.0865
     26      0.9304        0.7008       0.6970      0.6970        0.9529        9.0718
     27      0.9276        0.6902       0.6625      0.6625        1.0378        9.0936
     28      0.9318        0.6784       0.6700      0.6700        1.0198        9.0839
     29      0.9375        0.6769       0.7160      0.7160        0.9447        9.0727
     30      0.9176        0.7095       0.6729      0.6729        1.0011        9.0568
     31      0.9318        0.6643       0.6932      0.6932        0.9687        9.0792
     32      0.9389        0.6543       0.7010      0.7010        0.9442        9.0698
     33      0.9361        0.6426       0.6510      0.6510        1.0663        9.0941
     34      0.9446        0.6325       0.6778      0.6778        1.0034        9.0821
     35      0.9418        0.6291       0.6854      0.6854        0.9828        9.0912
     36      0.9403        0.6311       0.6797      0.6797        1.0060        9.0915
     37      0.9446        0.6169       0.6748      0.6748        1.0146        9.1014
     38      0.9474        0.6072       0.6804      0.6804        0.9980        9.0818
     39      0.9418        0.6088       0.6665      0.6665        1.0305        9.0800
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 6: 0.7288194444444445
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples:

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.7516        0.9952       0.7184      0.7184        0.8624     +  10.5242
      2      0.7429        1.0004       0.7486      0.7486        0.8307     +  10.5410
      3      0.7476        0.9980       0.7432      0.7432        0.9367        10.5630
      4      0.8030        0.9083       0.6729      0.6729        0.9506        10.5922
      5      0.7888        0.9047       0.7408      0.7408        0.8167     +  10.5635
      6      0.8085        0.8891       0.7566      0.7566        0.7777     +  10.5835
      7      0.8180        0.8649       0.7800      0.7800        0.7339     +  10.5455
      8      0.8489        0.8135       0.7986      0.7986        0.7323     +  10.5650
      9      0.8568        0.8068       0.6450      0.6450        1.0480        10.5528
     10      0.8418        0.8388       0.6898      0.6898        0.9299        10.5574
     11      0.8718        0.7695       0.7458      0.7458        0.8122        10.5738
     12      0.8805        0.7465       0.6845      0.6845        0.9240        10.5827
     13      0.8837        0.7392       0.7297      0.7297        0.8450        10.5776
     14      0.8845        0.7228       0.6970      0.6970        0.8921        10.5943
     15      0.8932        0.7034       0.7389      0.7389        0.8420        10.5551
     16      0.8924        0.6961       0.7936      0.7936        0.7076     +  11.6237
     17      0.8797        0.7312       0.6415      0.6415        1.0465        16.2907
     18      0.8797        0.7180       0.7703      0.7703        0.7616        16.1700
     19      0.9043        0.6602       0.7804      0.7804        0.7444        16.0684
     20      0.9003        0.6566       0.8016      0.8016        0.6934     +  16.1946
     21      0.9066        0.6451       0.7851      0.7851        0.7286        16.0769
     22      0.9074        0.6344       0.7731      0.7731        0.7514        16.2397
     23      0.9082        0.6240       0.7825      0.7825        0.7523        16.2509
     24      0.9098        0.6239       0.7790      0.7790        0.7489        16.1633
     25      0.9090        0.6083       0.7747      0.7747        0.7648        16.2408
     26      0.9146        0.5943       0.7818      0.7818        0.7454        16.1022
     27      0.9153        0.5910       0.7970      0.7970        0.7209        16.0105
     28      0.9153        0.5899       0.7941      0.7941        0.7125        16.0262
     29      0.9082        0.5869       0.8030      0.8030        0.7004        16.1943
     30      0.9185        0.5682       0.7670      0.7670        0.7747        16.2590
     31      0.9106        0.5926       0.7502      0.7502        0.8235        16.1045
     32      0.9003        0.6060       0.7828      0.7828        0.7344        16.2847
     33      0.9233        0.5461       0.7951      0.7951        0.7060        16.2451
     34      0.9233        0.5479       0.7910      0.7910        0.7301        16.2294
     35      0.9233        0.5341       0.8012      0.8012        0.6850     +  16.3255
     36      0.9225        0.5326       0.7818      0.7818        0.7378        16.4722
     37      0.9320        0.5182       0.7878      0.7878        0.7269        16.2928
     38      0.9312        0.5153       0.7918      0.7918        0.7173        16.3112
     39      0.9335        0.5076       0.7974      0.7974        0.7008        16.4107
     40      0.9264        0.5198       0.6267      0.6267        1.2058        16.4949
     41      0.8639        0.6705       0.7958      0.7958        0.6941        16.1063
     42      0.9304        0.5124       0.7931      0.7931        0.7055        16.3563
     43      0.9343        0.5002       0.7859      0.7859        0.7191        16.4207
     44      0.9264        0.4968       0.7870      0.7870        0.7161        16.3071
     45      0.9201        0.5239       0.7783      0.7783        0.7190        16.1670
     46      0.9343        0.4923       0.7792      0.7792        0.7136        16.3723
     47      0.9343        0.4830       0.7778      0.7778        0.7370        16.4672
     48      0.9415        0.4741       0.7858      0.7858        0.6987        16.2491
     49      0.9399        0.4647       0.7743      0.7743        0.7404        15.9541
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 7: 0.7727430555555556
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples:

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.7995        0.7553       0.7752      0.7752        0.7478     +  18.7928
      2      0.8149        0.7331       0.7873      0.7873        0.7067     +  19.2238
      3      0.8405        0.6745       0.7392      0.7392        0.7694        19.2954
      4      0.8516        0.6528       0.8061      0.8061        0.6519     +  19.5077
      5      0.8693        0.6018       0.8078      0.8078        0.6495     +  19.3586
      6      0.8520        0.6380       0.8036      0.8036        0.6573        19.4203
      7      0.8799        0.5790       0.8288      0.8288        0.6152     +  18.8706
      8      0.8732        0.5936       0.8181      0.8181        0.6129     +  19.0845
      9      0.8891        0.5536       0.7858      0.7858        0.6625        19.2755
     10      0.8847        0.5533       0.7248      0.7248        0.7803        19.2498
     11      0.8896        0.5442       0.8019      0.8019        0.6609        19.1998
     12      0.8953        0.5251       0.8182      0.8182        0.6277        19.1934
     13      0.8900        0.5482       0.8043      0.8043        0.6385        18.9190
     14      0.8966        0.5178       0.8311      0.8311        0.6017     +  18.7931
     15      0.8958        0.4998       0.7234      0.7234        0.8026        19.4777
     16      0.9037        0.4940       0.8233      0.8233        0.6041        19.3772
     17      0.9037        0.4824       0.8016      0.8016        0.6295        19.3032
     18      0.9134        0.4692       0.8253      0.8253        0.6088        19.5240
     19      0.9161        0.4673       0.8156      0.8156        0.6081        19.1757
     20      0.9201        0.4473       0.8240      0.8240        0.6075        19.0702
 18.9813
     27      0.9284        0.4146       0.7123      0.7123        0.9194        19.0620
     28      0.9289        0.4174       0.8078      0.8078        0.6352        19.1469
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 8: 0.8217013888888889
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples:

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.8260        0.6373       0.8007      0.8007        0.6114     +  17.8398
      2      0.8354        0.6152       0.8026      0.8026        0.6337        17.9170
      3      0.8663        0.5458       0.8167      0.8167        0.6144        17.9778
      4      0.8822        0.5055       0.7925      0.7925        0.6474        17.9556
      5      0.9047        0.4596       0.8115      0.8115        0.6119        18.0000
      6      0.9025        0.4525       0.8000      0.8000        0.6462        17.9836
      7      0.8567        0.5617       0.8130      0.8130        0.5855     +  17.9688
      8      0.9012        0.4612       0.8012      0.8012        0.6282        17.9384
      9      0.9030        0.4424       0.8052      0.8052        0.6142        17.9993
     10      0.9176        0.4095       0.8122      0.8122        0.6243        17.9696
     11      0.9126        0.4141       0.8054      0.8054        0.6451        18.0062
     12      0.9302        0.3779       0.7944      0.7944        0.6773        17.9635
     13      0.9366        0.3654       0.8007      0.8007        0.6576        17.9742
     14      0.9391        0.3583       0.7844      0.7844        0.7013        17.9138
     15      0.9381        0.3507       0.7891      0.7891        0.6924        17.9378
     16      0.9384        0.3518       0.7892      0.7892        0.6893        17.9598
     17      0.9426        0.3352       0.7835      0.7835        0.7050        17.9688
     18      0.9257        0.3706       0.7790      0.7790        0.7150        17.9505
     19      0.9460        0.3317       0.7750      0.7750        0.7371        17.9734
     20      0.9500        0.3144       0.7821      0.7821        0.7163        17.9279
     21      0.9542        0.3081       0.7682      0.7682        0.7609        17.9086
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 9: 0.8135416666666667
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples:

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.8738        0.4998       0.7476      0.7476        0.8234     +  26.3100
      2      0.8943        0.4294       0.8274      0.8274        0.5674     +  26.3255
      3      0.9110        0.3819       0.8285      0.8285        0.5705        26.3901
      4      0.9044        0.3991       0.8170      0.8170        0.5891        26.4273
      5      0.9231        0.3474       0.8224      0.8224        0.5838        26.3856
      6      0.9203        0.3481       0.8155      0.8155        0.6190        26.3754
      7      0.9153        0.3544       0.8049      0.8049        0.6324        26.3089
      8      0.9318        0.3201       0.8170      0.8170        0.6155        26.4057
      9      0.9364        0.3018       0.8111      0.8111        0.6289        26.3741
     10      0.9393        0.2970       0.8161      0.8161        0.6056        26.3747
     11      0.9449        0.2774       0.8087      0.8087        0.6531        26.3992
     12      0.9424        0.2815       0.8116      0.8116        0.6544        26.3114
     13      0.9486        0.2599       0.8035      0.8035        0.6755        26.2722
     14      0.9457        0.2689       0.8087      0.8087        0.6591        26.3050
     15      0.9511        0.2525       0.8142      0.8142        0.6648        26.2997
     16      0.9513        0.2453       0.8160      0.8160        0.6599        26.2380
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 10: 0.8296875
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples:

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.9443        0.2692       0.8170      0.8170        0.5918     +  41.1427
      2      0.9474        0.2538       0.8212      0.8212        0.5937        41.1935
      3      0.9591        0.2203       0.8226      0.8226        0.6038        41.1582
      4      0.9607        0.2112       0.8161      0.8161        0.6201        41.0925
      5      0.9652        0.1968       0.8186      0.8186        0.6312        41.1945
      6      0.9621        0.1984       0.8142      0.8142        0.6535        41.2342
      7      0.9648        0.1916       0.8238      0.8238        0.6150        41.1438
      8      0.9665        0.1820       0.8245      0.8245        0.6444        41.2007
      9      0.9707        0.1732       0.8255      0.8255        0.6312        41.1615
     10      0.9707        0.1678       0.8280      0.8280        0.6313        41.0890
     11      0.9683        0.1686       0.8252      0.8252        0.6460        41.1652
     12      0.9712        0.1649       0.8196      0.8196        0.6502        41.1828
     13      0.9215        0.3040       0.8297      0.8297        0.5994        41.1766
     14      0.9679        0.1733       0.8181      0.8181        0.6253        41.2154
     15      0.9738        0.1552       0.8257      0.8257        0.6189        41.2135
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 11: 0.8333333333333334
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples:

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.9776        0.1377       0.7155      0.7155        1.1405     +  67.5914
      2      0.9785        0.1258       0.8047      0.8047        0.7521     +  68.1529
      3      0.9842        0.1081       0.8106      0.8106        0.7325     +  67.6781
      4      0.9856        0.1017       0.8118      0.8118        0.7104     +  67.7285
      5      0.9860        0.0992       0.8063      0.8062        0.7425        67.7122
      6      0.9872        0.0918       0.8076      0.8076        0.7413        67.7187
      7      0.9870        0.0903       0.8187      0.8187        0.6951     +  67.6418
      8      0.9657        0.1494       0.8273      0.8273        0.6268     +  67.7453
      9      0.9861        0.0887       0.8227      0.8227        0.6764        67.7823
     10      0.9879        0.0825       0.8215      0.8215        0.6949        67.6893
     11      0.9867        0.0846       0.8269      0.8269        0.6637        67.7594
     12      0.9889        0.0782       0.8177      0.8177        0.7204        67.6227
     13      0.9885        0.0765       0.8210      0.8210        0.7000        67.7278
     14      0.9901        0.0728       0.8267      0.8267        0.6958        67.6816
     15      0.9919        0.0670       0.8259      0.8259        0.7096        67.7006
     16      0.9900        0.0701       0.8200      0.8200        0.7390        67.7602
     17      0.9911        0.0653       0.8222      0.8222        0.7130        67.6883
     18      0.9927        0.0605       0.8149      0.8149        0.7629        67.8506
     19      0.9936        0.0573       0.8146      0.8146        0.7708        67.7017
     20      0.9808        0.0935       0.7118      0.7118        1.3872        67.7267
     21      0.9698        0.1259       0.8142      0.8142        0.7408        67.6902
     22      0.9841        0.0820       0.8148      0.8148        0.7435        67.7182
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 12: 0.83125
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples:

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      0.9940        0.0507       0.8101      0.8101        0.7980     +  78.3504
      2      0.9949        0.0473       0.8132      0.8132        0.7908     +  78.4455
      3      0.9956        0.0448       0.8139      0.8139        0.7995        78.5079
      4      0.9958        0.0430       0.8104      0.8104        0.8283        78.3543
      5      0.9948        0.0459       0.8049      0.8049        0.8308        78.4039
      6      0.9958        0.0419       0.8066      0.8066        0.8410        78.3880
      7      0.9935        0.0465       0.7693      0.7693        1.0792        78.4776
      8      0.9960        0.0410       0.8134      0.8134        0.8322        78.4454
      9      0.9969        0.0369       0.8061      0.8061        0.8671        78.4757
     10      0.9964        0.0371       0.8167      0.8167        0.8257        78.3725
     11      0.9947        0.0401       0.8189      0.8189        0.8068        78.5748
     12      0.9922        0.0477       0.8066      0.8066        0.8384        78.5421
     13      0.9958        0.0376       0.8113      0.8113        0.8330        78.4168
     14      0.9948        0.0387       0.8071      0.8071        0.8332        78.4532
     15      0.9970        0.0332       0.8089      0.8089        0.8685        78.4034
     16      0.9972        0.0317       0.8153      0.8153        0.8369        78.3932
Stopping since valid_loss has not improved in the last 15 epochs.
F1 Score after query 13: 0.8411458333333333
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\model_checkpoint_iteration_12.pt
Performance results saved to D:\Shubham\results\Multiclass01\DinoSmall\ActiveLearning\ParamsFromMultilabel\uncertainty_sampling\Run2\performance_results.npy
PS C:\Users\localuserSG\ActiveLearning\Multiclass01\DinoSmall\US>