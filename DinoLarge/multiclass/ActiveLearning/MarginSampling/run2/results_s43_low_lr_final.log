(26880, 5)
(5760, 5)
(5760, 5)
3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.1250[0m        [32m2.2005[0m       [35m0.0071[0m      [31m0.0071[0m        [94m2.2178[0m     +  0.0000  74.0330
      2      [36m0.3750[0m        [32m2.0784[0m       [35m0.0075[0m      [31m0.0075[0m        [94m2.2135[0m     +  0.0000  75.6559
      3      0.2500        2.1329       [35m0.0141[0m      [31m0.0141[0m        [94m2.2065[0m     +  0.0000  76.3811
      4      0.3750        [32m1.9676[0m       [35m0.0155[0m      [31m0.0155[0m        [94m2.2012[0m     +  0.0000  76.5241
      5      0.3750        2.0148       0.0148      0.0148        [94m2.1968[0m     +  0.0000  76.4243
      6      0.2500        2.0428       0.0146      0.0146        [94m2.1898[0m     +  0.0000  76.3924
      7      0.1250        2.0039       0.0153      0.0153        [94m2.1832[0m     +  0.0000  76.4301
      8      0.2500        [32m1.9580[0m       [35m0.0160[0m      [31m0.0160[0m        [94m2.1774[0m     +  0.0000  76.4664
      9      0.3750        [32m1.8184[0m       [35m0.0193[0m      [31m0.0193[0m        [94m2.1734[0m     +  0.0000  76.5188
     10      0.2500        [32m1.8017[0m       [35m0.0219[0m      [31m0.0219[0m        [94m2.1708[0m     +  0.0000  76.4571
     11      [36m0.8750[0m        [32m1.7493[0m       [35m0.0236[0m      [31m0.0236[0m        [94m2.1671[0m     +  0.0000  76.5025
     12      0.5000        1.7750       [35m0.0252[0m      [31m0.0252[0m        [94m2.1628[0m     +  0.0000  76.5171
     13      0.2500        1.7545       [35m0.0253[0m      [31m0.0253[0m        [94m2.1611[0m     +  0.0000  76.5042
     14      0.2500        1.8311       [35m0.0257[0m      [31m0.0257[0m        [94m2.1593[0m     +  0.0000  76.5410
     15      0.7500        [32m1.6712[0m       [35m0.0260[0m      [31m0.0260[0m        [94m2.1574[0m     +  0.0000  76.5031
     16      0.5000        [32m1.6711[0m       [35m0.0267[0m      [31m0.0267[0m        [94m2.1558[0m     +  0.0000  76.5299
     17      0.3750        1.7848       [35m0.0274[0m      [31m0.0274[0m        [94m2.1545[0m     +  0.0000  76.5292
     18      0.5000        1.7201       [35m0.0278[0m      [31m0.0278[0m        [94m2.1539[0m     +  0.0000  76.4479
     19      0.6250        [32m1.6236[0m       [35m0.0283[0m      [31m0.0283[0m        [94m2.1531[0m     +  0.0000  76.4013
     20      0.5000        [32m1.5958[0m       [35m0.0293[0m      [31m0.0293[0m        [94m2.1524[0m     +  0.0000  76.2877
     21      0.6250        1.6969       [35m0.0302[0m      [31m0.0302[0m        [94m2.1512[0m     +  0.0000  76.3877
     22      0.6250        1.6320       [35m0.0312[0m      [31m0.0312[0m        [94m2.1494[0m     +  0.0000  76.3721
     23      0.3750        1.7019       [35m0.0323[0m      [31m0.0323[0m        [94m2.1479[0m     +  0.0000  76.4538
     24      0.3750        1.6757       [35m0.0339[0m      [31m0.0339[0m        [94m2.1461[0m     +  0.0000  76.4478
     25      0.5000        1.6048       [35m0.0344[0m      [31m0.0344[0m        [94m2.1454[0m     +  0.0000  76.4339
     26      0.6250        1.6561       [35m0.0349[0m      [31m0.0349[0m        [94m2.1450[0m     +  0.0000  76.4089
     27      0.8750        [32m1.5623[0m       [35m0.0354[0m      [31m0.0354[0m        [94m2.1445[0m     +  0.0000  76.3858
     28      [36m1.0000[0m        [32m1.4761[0m       [35m0.0358[0m      [31m0.0358[0m        [94m2.1440[0m     +  0.0000  76.3511
     29      0.8750        1.4994       [35m0.0363[0m      [31m0.0363[0m        [94m2.1436[0m     +  0.0000  76.3335
     30      0.5000        1.5748       [35m0.0368[0m      [31m0.0368[0m        [94m2.1431[0m     +  0.0000  76.3914
     31      0.7500        1.5652       [35m0.0387[0m      [31m0.0387[0m        [94m2.1426[0m     +  0.0000  76.3740
     32      0.8750        1.5636       [35m0.0411[0m      [31m0.0411[0m        [94m2.1422[0m     +  0.0000  76.3129
     33      1.0000        1.5261       [35m0.0432[0m      [31m0.0432[0m        [94m2.1416[0m     +  0.0000  76.3273
     34      0.6250        1.6599       [35m0.0451[0m      [31m0.0451[0m        [94m2.1409[0m     +  0.0000  76.3929
     35      0.5000        1.5988       [35m0.0476[0m      [31m0.0476[0m        [94m2.1402[0m     +  0.0000  76.3974
     36      0.8750        [32m1.4624[0m       [35m0.0507[0m      [31m0.0507[0m        [94m2.1394[0m     +  0.0000  76.3450
     37      0.7500        [32m1.4549[0m       [35m0.0523[0m      [31m0.0523[0m        [94m2.1390[0m     +  0.0000  76.3275
     38      0.7500        1.5713       [35m0.0531[0m      [31m0.0531[0m        [94m2.1386[0m     +  0.0000  76.2724
     39      0.6250        1.5797       [35m0.0540[0m      [31m0.0540[0m        [94m2.1382[0m     +  0.0000  76.3632
     40      0.7500        [32m1.3901[0m       [35m0.0549[0m      [31m0.0549[0m        [94m2.1377[0m     +  0.0000  76.3870
     41      0.6250        1.5437       [35m0.0563[0m      [31m0.0563[0m        [94m2.1373[0m     +  0.0000  76.3496
     42      0.7500        1.4676       [35m0.0571[0m      [31m0.0571[0m        [94m2.1370[0m     +  0.0000  76.4138
     43      0.8750        1.4696       [35m0.0578[0m      [31m0.0578[0m        [94m2.1366[0m     +  0.0000  76.4168
     44      0.8750        1.3929       [35m0.0582[0m      [31m0.0582[0m        [94m2.1363[0m     +  0.0000  76.3604
     45      0.7500        1.4972       [35m0.0585[0m      [31m0.0585[0m        [94m2.1360[0m     +  0.0000  76.4213
     46      0.7500        1.5532       [35m0.0590[0m      [31m0.0590[0m        [94m2.1358[0m     +  0.0000  76.4264
     47      1.0000        1.4178       [35m0.0595[0m      [31m0.0595[0m        [94m2.1357[0m     +  0.0000  76.4379
     48      0.7500        1.4210       [35m0.0602[0m      [31m0.0602[0m        [94m2.1355[0m     +  0.0000  76.4113
     49      0.8750        1.4464       [35m0.0604[0m      [31m0.0604[0m        [94m2.1354[0m     +  0.0000  76.3832
     50      0.7500        1.5057       [35m0.0608[0m      [31m0.0608[0m        [94m2.1354[0m     +  0.0000  76.4237
     51      0.7500        1.4663       [35m0.0615[0m      [31m0.0615[0m        [94m2.1353[0m     +  0.0000  76.4574
     52      0.8750        1.4545       0.0615      0.0615        [94m2.1352[0m     +  0.0000  76.3752
     53      0.8750        1.4446       [35m0.0618[0m      [31m0.0618[0m        [94m2.1352[0m     +  0.0000  76.4607
     54      1.0000        [32m1.3848[0m       [35m0.0622[0m      [31m0.0622[0m        [94m2.1352[0m     +  0.0000  76.4319
     55      0.6250        1.4656       0.0622      0.0622        [94m2.1352[0m     +  0.0000  76.3667
     56      0.7500        1.5173       [35m0.0625[0m      [31m0.0625[0m        [94m2.1351[0m     +  0.0000  76.3670
     57      0.7500        1.4736       [35m0.0628[0m      [31m0.0628[0m        [94m2.1351[0m     +  0.0000  76.3326
     58      0.6250        1.5408       [35m0.0635[0m      [31m0.0635[0m        [94m2.1350[0m     +  0.0000  76.3901
     59      0.6250        1.4658       [35m0.0637[0m      [31m0.0637[0m        [94m2.1349[0m     +  0.0000  76.4412
     60      0.8750        1.4166       [35m0.0648[0m      [31m0.0648[0m        [94m2.1347[0m     +  0.0000  76.1835
     61      0.7500        1.4398       [35m0.0649[0m      [31m0.0649[0m        [94m2.1347[0m     +  0.0000  76.3623
     62      0.7500        1.4659       [35m0.0651[0m      [31m0.0651[0m        [94m2.1346[0m     +  0.0000  76.4200
     63      0.7500        1.4724       0.0651      0.0651        [94m2.1346[0m     +  0.0000  76.3843
     64      0.5000        1.5696       0.0651      0.0651        [94m2.1346[0m     +  0.0000  76.4093
     65      0.8750        [32m1.3752[0m       [35m0.0655[0m      [31m0.0655[0m        [94m2.1345[0m     +  0.0000  76.3778
     66      0.7500        1.4239       [35m0.0656[0m      [31m0.0656[0m        [94m2.1345[0m     +  0.0000  76.3309
     67      0.7500        1.4496       [35m0.0658[0m      [31m0.0658[0m        [94m2.1344[0m     +  0.0000  76.3691
     68      0.8750        [32m1.3713[0m       0.0658      0.0658        [94m2.1344[0m     +  0.0000  76.4256
     69      0.7500        1.3735       [35m0.0661[0m      [31m0.0661[0m        [94m2.1343[0m     +  0.0000  76.4166
     70      0.7500        1.4365       [35m0.0663[0m      [31m0.0663[0m        [94m2.1343[0m     +  0.0000  76.4669
     71      0.7500        1.4818       0.0663      0.0663        [94m2.1343[0m     +  0.0000  76.4257
     72      0.6250        1.4553       [35m0.0668[0m      [31m0.0668[0m        [94m2.1342[0m     +  0.0000  76.3935
     73      0.8750        1.4473       0.0668      0.0668        [94m2.1342[0m     +  0.0000  76.4467
     74      0.6250        1.4714       [35m0.0670[0m      [31m0.0670[0m        [94m2.1342[0m     +  0.0000  76.4639
     75      0.7500        1.5473       [35m0.0672[0m      [31m0.0672[0m        2.1342        0.0000  76.4220
     76      0.6250        1.5171       0.0672      0.0672        2.1342        0.0000  76.4319
     77      0.7500        1.4447       [35m0.0674[0m      [31m0.0674[0m        2.1342        0.0000  76.3494
     78      0.7500        1.4360       0.0674      0.0674        2.1342        0.0000  76.2794
     79      1.0000        1.4536       0.0674      0.0674        2.1343        0.0000  76.2927
     80      1.0000        1.4049       0.0674      0.0674        2.1343        0.0000  76.2261
     81      1.0000        [32m1.3051[0m       0.0674      0.0674        2.1343        0.0000  76.3257
     82      0.7500        1.4752       [35m0.0675[0m      [31m0.0675[0m        2.1343        0.0000  76.2788
     83      0.6250        1.4787       [35m0.0677[0m      [31m0.0677[0m        2.1343        0.0000  76.2881
Stopping since valid_loss has not improved in the last 13 epochs.
Pre F1 micro score = 0.0566
Pre F1 macro score = 0.0498

Iteration:  1
Selecting 16 informative samples: 

Training started with 24 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.4167[0m        [32m1.9095[0m       [35m0.2109[0m      [31m0.2109[0m        [94m2.0511[0m     +  0.0000  76.8103
      2      0.3750        [32m1.7797[0m       [35m0.3760[0m      [31m0.3760[0m        [94m1.9542[0m     +  0.0000  76.7856
      3      [36m0.5000[0m        [32m1.7231[0m       [35m0.4401[0m      [31m0.4401[0m        [94m1.8800[0m     +  0.0000  76.8763
      4      [36m0.7083[0m        [32m1.5490[0m       [35m0.4465[0m      [31m0.4465[0m        [94m1.8243[0m     +  0.0000  76.9115
      5      0.5417        [32m1.5004[0m       [35m0.4476[0m      [31m0.4476[0m        [94m1.7871[0m     +  0.0000  76.9004
      6      0.6250        [32m1.4286[0m       0.4476      0.4476        [94m1.7549[0m     +  0.0000  76.8978
      7      0.5833        [32m1.4259[0m       [35m0.4477[0m      [31m0.4477[0m        [94m1.7280[0m     +  0.0000  77.0241
      8      0.5833        [32m1.3152[0m       [35m0.4495[0m      [31m0.4495[0m        [94m1.7076[0m     +  0.0000  76.9429
      9      0.6250        [32m1.3084[0m       [35m0.4557[0m      [31m0.4557[0m        [94m1.6942[0m     +  0.0000  76.9097
     10      0.5833        [32m1.2769[0m       [35m0.4651[0m      [31m0.4651[0m        [94m1.6824[0m     +  0.0000  76.9372
     11      0.6667        [32m1.2324[0m       [35m0.4813[0m      [31m0.4813[0m        [94m1.6708[0m     +  0.0000  76.9624
     12      [36m0.7500[0m        [32m1.1630[0m       [35m0.5033[0m      [31m0.5033[0m        [94m1.6577[0m     +  0.0000  76.8300
     13      [36m0.7917[0m        [32m1.0680[0m       [35m0.5116[0m      [31m0.5116[0m        [94m1.6530[0m     +  0.0000  76.9535
     14      0.7500        1.1218       [35m0.5224[0m      [31m0.5224[0m        [94m1.6513[0m     +  0.0000  76.9036
     15      0.7500        1.1036       [35m0.5380[0m      [31m0.5380[0m        [94m1.6507[0m     +  0.0000  76.8947
     16      0.7917        [32m1.0417[0m       [35m0.5417[0m      [31m0.5417[0m        [94m1.6485[0m     +  0.0000  76.8865
     17      [36m0.8333[0m        [32m1.0055[0m       [35m0.5446[0m      [31m0.5446[0m        [94m1.6433[0m     +  0.0000  76.8703
     18      [36m0.8750[0m        [32m0.9891[0m       [35m0.5486[0m      [31m0.5486[0m        [94m1.6375[0m     +  0.0000  76.8998
     19      0.8750        [32m0.9517[0m       [35m0.5524[0m      [31m0.5524[0m        [94m1.6335[0m     +  0.0000  76.7855
     20      0.7917        1.0230       0.5519      0.5519        [94m1.6309[0m     +  0.0000  76.7721
     21      [36m0.9583[0m        [32m0.8687[0m       0.5490      0.5490        [94m1.6274[0m     +  0.0000  76.7814
     22      [36m1.0000[0m        0.9235       0.5497      0.5497        [94m1.6234[0m     +  0.0000  76.8177
     23      0.9167        0.9232       0.5505      0.5505        [94m1.6181[0m     +  0.0000  76.7526
     24      0.9583        [32m0.8644[0m       0.5514      0.5514        [94m1.6153[0m     +  0.0000  76.7902
     25      0.9167        0.9112       0.5519      0.5519        [94m1.6143[0m     +  0.0000  76.7824
     26      0.9167        [32m0.8360[0m       0.5517      0.5517        [94m1.6131[0m     +  0.0000  76.7887
     27      0.9167        0.8556       [35m0.5530[0m      [31m0.5530[0m        [94m1.6121[0m     +  0.0000  76.8077
     28      0.9583        [32m0.8345[0m       [35m0.5531[0m      [31m0.5531[0m        [94m1.6103[0m     +  0.0000  76.8388
     29      0.9583        [32m0.8217[0m       [35m0.5540[0m      [31m0.5540[0m        [94m1.6074[0m     +  0.0000  76.8415
     30      0.9167        [32m0.8014[0m       [35m0.5550[0m      [31m0.5550[0m        [94m1.6043[0m     +  0.0000  76.8495
     31      0.8750        [32m0.8013[0m       0.5535      0.5535        [94m1.6017[0m     +  0.0000  76.9373
     32      0.9583        [32m0.7804[0m       0.5540      0.5540        [94m1.5997[0m     +  0.0000  76.9467
     33      1.0000        [32m0.7403[0m       0.5536      0.5536        [94m1.5977[0m     +  0.0000  76.9270
     34      0.9583        0.7902       0.5533      0.5533        [94m1.5963[0m     +  0.0000  76.8734
     35      1.0000        0.7428       0.5540      0.5540        [94m1.5950[0m     +  0.0000  76.9256
     36      0.8750        0.8205       [35m0.5554[0m      [31m0.5554[0m        [94m1.5936[0m     +  0.0000  76.9535
     37      0.9583        0.7864       0.5554      0.5554        [94m1.5928[0m     +  0.0000  76.9115
     38      1.0000        [32m0.7182[0m       0.5554      0.5554        [94m1.5920[0m     +  0.0000  76.9124
     39      1.0000        0.7690       0.5552      0.5552        [94m1.5910[0m     +  0.0000  76.8622
     40      1.0000        0.7255       0.5554      0.5554        [94m1.5905[0m     +  0.0000  76.9367
     41      1.0000        0.7675       0.5549      0.5549        [94m1.5903[0m     +  0.0000  76.9432
     42      1.0000        0.7191       0.5543      0.5543        [94m1.5902[0m     +  0.0000  76.8540
     43      1.0000        0.7253       0.5543      0.5543        1.5903        0.0000  76.9357
     44      1.0000        0.7339       0.5552      0.5552        [94m1.5902[0m     +  0.0000  76.8777
     45      1.0000        0.7419       0.5552      0.5552        [94m1.5900[0m     +  0.0000  76.8726
     46      0.9583        0.7238       [35m0.5557[0m      [31m0.5557[0m        [94m1.5899[0m     +  0.0000  76.9761
     47      0.9583        0.7684       [35m0.5561[0m      [31m0.5561[0m        [94m1.5899[0m     +  0.0000  76.9176
     48      1.0000        0.7191       [35m0.5563[0m      [31m0.5563[0m        [94m1.5895[0m     +  0.0000  76.9795
     49      0.9583        0.7470       [35m0.5568[0m      [31m0.5568[0m        [94m1.5893[0m     +  0.0000  76.9101
     50      1.0000        0.7355       0.5566      0.5566        [94m1.5891[0m     +  0.0000  76.8696
     51      1.0000        [32m0.6977[0m       0.5563      0.5563        [94m1.5887[0m     +  0.0000  76.8831
     52      1.0000        [32m0.6941[0m       0.5557      0.5557        [94m1.5884[0m     +  0.0000  76.8892
     53      1.0000        0.7344       0.5549      0.5549        [94m1.5881[0m     +  0.0000  76.8283
     54      0.9583        0.7070       0.5538      0.5538        [94m1.5878[0m     +  0.0000  76.9167
     55      1.0000        0.6955       0.5540      0.5540        [94m1.5874[0m     +  0.0000  76.8976
     56      0.9583        0.7204       0.5543      0.5543        [94m1.5870[0m     +  0.0000  76.9473
     57      1.0000        0.7263       0.5536      0.5536        [94m1.5866[0m     +  0.0000  76.9534
     58      1.0000        [32m0.6930[0m       0.5540      0.5540        [94m1.5862[0m     +  0.0000  76.9366
     59      1.0000        [32m0.6541[0m       0.5540      0.5540        [94m1.5860[0m     +  0.0000  76.9619
     60      1.0000        0.6918       0.5543      0.5543        [94m1.5857[0m     +  0.0000  76.9040
     61      1.0000        0.6957       0.5545      0.5545        [94m1.5856[0m     +  0.0000  76.8676
     62      0.9583        0.7285       0.5545      0.5545        [94m1.5854[0m     +  0.0000  76.8954
     63      1.0000        0.7061       0.5547      0.5547        [94m1.5853[0m     +  0.0000  76.9930
     64      0.9583        0.6714       0.5552      0.5552        [94m1.5852[0m     +  0.0000  76.9475
     65      1.0000        0.6841       0.5559      0.5559        [94m1.5852[0m     +  0.0000  76.9670
     66      1.0000        0.6589       0.5559      0.5559        [94m1.5852[0m     +  0.0000  76.9180
     67      1.0000        0.6944       0.5561      0.5561        [94m1.5852[0m     +  0.0000  76.9362
     68      0.9583        0.6969       0.5559      0.5559        [94m1.5852[0m     +  0.0000  76.8800
     69      0.9583        0.7128       0.5557      0.5557        [94m1.5851[0m     +  0.0000  76.9813
     70      1.0000        [32m0.6432[0m       0.5554      0.5554        [94m1.5851[0m     +  0.0000  76.9173
     71      1.0000        0.6863       0.5556      0.5556        [94m1.5850[0m     +  0.0000  76.8365
     72      1.0000        0.6489       0.5556      0.5556        [94m1.5848[0m     +  0.0000  76.8941
     73      0.9583        0.7046       0.5556      0.5556        [94m1.5848[0m     +  0.0000  76.8754
     74      0.9583        0.7254       0.5557      0.5557        [94m1.5847[0m     +  0.0000  76.9142
     75      1.0000        0.6886       0.5557      0.5557        [94m1.5847[0m     +  0.0000  76.9977
     76      1.0000        0.7248       0.5557      0.5557        [94m1.5847[0m     +  0.0000  76.9024
     77      1.0000        0.6625       0.5557      0.5557        [94m1.5846[0m     +  0.0000  76.9339
     78      0.9583        0.7269       0.5561      0.5561        [94m1.5846[0m     +  0.0000  76.8450
     79      0.9583        0.6690       0.5563      0.5563        [94m1.5845[0m     +  0.0000  76.8741
     80      1.0000        0.6857       0.5563      0.5563        [94m1.5845[0m     +  0.0000  76.9155
     81      1.0000        0.7024       0.5564      0.5564        [94m1.5844[0m     +  0.0000  76.9235
     82      1.0000        0.6822       0.5564      0.5564        [94m1.5843[0m     +  0.0000  76.8685
     83      0.9583        0.6962       0.5566      0.5566        [94m1.5842[0m     +  0.0000  76.8561
     84      1.0000        0.6440       0.5564      0.5564        [94m1.5842[0m     +  0.0000  76.9520
     85      0.9583        0.7004       0.5564      0.5564        [94m1.5842[0m     +  0.0000  76.8538
     86      1.0000        0.6635       0.5563      0.5563        [94m1.5841[0m     +  0.0000  76.9200
     87      1.0000        0.7227       0.5563      0.5563        [94m1.5841[0m     +  0.0000  76.9096
     88      1.0000        0.6737       0.5564      0.5564        [94m1.5841[0m     +  0.0000  76.7739
     89      0.9583        0.6860       0.5563      0.5563        [94m1.5841[0m     +  0.0000  76.7860
     90      0.9583        0.7186       0.5563      0.5563        [94m1.5841[0m     +  0.0000  76.8175
     91      0.9167        0.6549       0.5563      0.5563        1.5841        0.0000  76.9221
     92      1.0000        0.6588       0.5563      0.5563        1.5841        0.0000  76.8735
     93      1.0000        0.6891       0.5563      0.5563        [94m1.5841[0m     +  0.0000  76.8861
     94      1.0000        0.6949       0.5563      0.5563        [94m1.5841[0m     +  0.0000  76.8287
     95      1.0000        0.7312       0.5563      0.5563        [94m1.5841[0m     +  0.0000  76.9396
     96      0.9583        0.7216       0.5563      0.5563        [94m1.5840[0m     +  0.0000  76.9475
     97      1.0000        0.7037       0.5563      0.5563        [94m1.5840[0m     +  0.0000  76.9683
     98      1.0000        0.6712       0.5563      0.5563        [94m1.5840[0m     +  0.0000  76.9398
     99      0.9583        0.6752       0.5563      0.5563        [94m1.5840[0m     +  0.0000  76.9034
    100      1.0000        0.7226       0.5563      0.5563        [94m1.5840[0m     +  0.0000  76.9408
[8, 24]
F1 Micro Score after query 1: 0.584375
F1 Macro Score after query 1: 0.22026656649262666
Number of samples used for retraining: 24
Number of samples in pool after training and deleting samples: 26856
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\model_checkpoint_iteration_0.pt

Iteration:  2
Selecting 32 informative samples: 

Training started with 56 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6250[0m        [32m1.3670[0m       [35m0.5832[0m      [31m0.5832[0m        [94m1.5445[0m     +  0.0000  77.8736
      2      [36m0.8036[0m        [32m1.1204[0m       [35m0.6205[0m      [31m0.6205[0m        [94m1.4003[0m     +  0.0000  77.8211
      3      0.7857        [32m1.0295[0m       0.6120      0.6120        [94m1.3345[0m     +  0.0000  77.9124
      4      [36m0.8571[0m        [32m0.9171[0m       0.6127      0.6127        [94m1.3019[0m     +  0.0000  77.8070
      5      [36m0.8929[0m        [32m0.8448[0m       0.6149      0.6149        [94m1.2698[0m     +  0.0000  77.9785
      6      0.8393        [32m0.7603[0m       0.6203      0.6203        [94m1.2293[0m     +  0.0000  77.9111
      7      0.8929        [32m0.7019[0m       0.6184      0.6184        [94m1.2184[0m     +  0.0000  77.9872
      8      0.8750        [32m0.5986[0m       [35m0.6215[0m      [31m0.6215[0m        [94m1.2098[0m     +  0.0000  77.9733
      9      [36m0.9107[0m        [32m0.5754[0m       0.6191      0.6191        [94m1.1913[0m     +  0.0000  77.9345
     10      [36m0.9821[0m        [32m0.5184[0m       0.6212      0.6212        [94m1.1809[0m     +  0.0000  77.9869
     11      0.9821        [32m0.4892[0m       [35m0.6247[0m      [31m0.6247[0m        [94m1.1791[0m     +  0.0000  77.8999
     12      [36m1.0000[0m        [32m0.4189[0m       0.6231      0.6231        [94m1.1640[0m     +  0.0000  77.9992
     13      0.9821        [32m0.4169[0m       [35m0.6264[0m      [31m0.6264[0m        [94m1.1609[0m     +  0.0000  77.9547
     14      1.0000        [32m0.3902[0m       [35m0.6299[0m      [31m0.6299[0m        [94m1.1573[0m     +  0.0000  77.9980
     15      1.0000        0.4068       0.6273      0.6273        1.1575        0.0000  78.0211
     16      0.9821        [32m0.3690[0m       0.6267      0.6267        [94m1.1538[0m     +  0.0000  77.9690
     17      1.0000        [32m0.3435[0m       0.6299      0.6299        [94m1.1507[0m     +  0.0000  77.8376
     18      1.0000        0.3739       0.6280      0.6280        [94m1.1487[0m     +  0.0000  77.9762
     19      1.0000        0.3509       0.6271      0.6271        [94m1.1462[0m     +  0.0000  77.9262
     20      1.0000        [32m0.3143[0m       0.6273      0.6273        [94m1.1429[0m     +  0.0000  77.9434
     21      1.0000        0.3192       0.6266      0.6266        1.1465        0.0000  77.9328
     22      1.0000        [32m0.2914[0m       0.6269      0.6269        1.1477        0.0000  77.9085
     23      1.0000        0.3236       0.6266      0.6266        1.1464        0.0000  77.9606
     24      1.0000        [32m0.2854[0m       0.6278      0.6278        1.1461        0.0000  77.8979
     25      1.0000        0.3074       0.6280      0.6280        1.1454        0.0000  77.8790
     26      1.0000        [32m0.2770[0m       0.6252      0.6252        1.1440        0.0000  77.9145
     27      1.0000        [32m0.2631[0m       0.6252      0.6252        [94m1.1413[0m     +  0.0000  77.8767
     28      1.0000        0.2939       0.6255      0.6255        1.1438        0.0000  77.8891
     29      1.0000        [32m0.2505[0m       0.6255      0.6255        1.1439        0.0000  77.9686
     30      1.0000        0.2617       0.6259      0.6259        [94m1.1411[0m     +  0.0000  77.9555
     31      1.0000        0.2616       0.6253      0.6253        [94m1.1386[0m     +  0.0000  77.9042
     32      1.0000        0.2596       0.6241      0.6241        1.1405        0.0000  77.9305
     33      1.0000        0.2714       0.6247      0.6247        1.1421        0.0000  78.0227
     34      1.0000        [32m0.2476[0m       0.6259      0.6259        [94m1.1383[0m     +  0.0000  77.9853
     35      1.0000        0.2801       0.6241      0.6241        1.1388        0.0000  77.9463
     36      1.0000        0.2799       0.6262      0.6262        [94m1.1382[0m     +  0.0000  77.9673
     37      1.0000        0.2668       0.6247      0.6247        1.1393        0.0000  78.0037
     38      1.0000        0.2772       0.6252      0.6252        1.1400        0.0000  77.9167
     39      1.0000        [32m0.2375[0m       0.6252      0.6252        1.1389        0.0000  77.9073
     40      1.0000        0.2440       0.6260      0.6260        [94m1.1381[0m     +  0.0000  77.9701
     41      1.0000        0.2602       0.6248      0.6248        1.1389        0.0000  77.8480
     42      1.0000        0.2381       0.6250      0.6250        1.1394        0.0000  77.9723
     43      1.0000        0.2664       0.6250      0.6250        1.1387        0.0000  77.9537
     44      1.0000        [32m0.2284[0m       0.6248      0.6248        1.1383        0.0000  77.9600
     45      1.0000        0.2537       0.6252      0.6252        1.1385        0.0000  77.9549
     46      1.0000        0.2530       0.6252      0.6252        1.1382        0.0000  77.9117
     47      1.0000        0.2522       0.6250      0.6250        [94m1.1380[0m     +  0.0000  77.9165
     48      1.0000        0.2390       0.6245      0.6245        1.1383        0.0000  77.9021
     49      1.0000        0.2475       0.6247      0.6247        1.1380        0.0000  77.9369
     50      1.0000        0.2441       0.6250      0.6250        [94m1.1380[0m     +  0.0000  78.0138
     51      1.0000        [32m0.2211[0m       0.6252      0.6252        [94m1.1380[0m     +  0.0000  77.8970
     52      1.0000        0.2427       0.6255      0.6255        [94m1.1378[0m     +  0.0000  77.9738
     53      1.0000        0.2604       0.6255      0.6255        1.1379        0.0000  77.9604
     54      1.0000        0.2466       0.6257      0.6257        [94m1.1377[0m     +  0.0000  78.0410
     55      1.0000        0.2486       0.6255      0.6255        1.1378        0.0000  77.9077
     56      1.0000        0.2500       0.6257      0.6257        1.1378        0.0000  77.8642
     57      1.0000        0.2514       0.6259      0.6259        1.1378        0.0000  77.8729
     58      1.0000        0.2391       0.6257      0.6257        1.1380        0.0000  77.8945
     59      1.0000        0.2463       0.6255      0.6255        1.1382        0.0000  77.8920
     60      1.0000        0.2355       0.6253      0.6253        1.1383        0.0000  77.8886
     61      1.0000        0.2557       0.6253      0.6253        1.1381        0.0000  77.8839
     62      1.0000        0.2407       0.6252      0.6252        1.1379        0.0000  77.9344
     63      1.0000        0.2307       0.6257      0.6257        1.1378        0.0000  77.9371
     64      1.0000        0.2308       0.6257      0.6257        1.1378        0.0000  77.8825
Stopping since valid_loss has not improved in the last 13 epochs.
[8, 24, 56]
F1 Micro Score after query 2: 0.659375
F1 Macro Score after query 2: 0.2278543187472216
Number of samples used for retraining: 56
Number of samples in pool after training and deleting samples: 26824
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\model_checkpoint_iteration_1.pt

Iteration:  3
Selecting 56 informative samples: 

Training started with 112 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7054[0m        [32m0.9649[0m       [35m0.6118[0m      [31m0.6118[0m        [94m1.1485[0m     +  0.0000  79.5606
      2      [36m0.8125[0m        [32m0.7941[0m       [35m0.6825[0m      [31m0.6825[0m        [94m0.9912[0m     +  0.0000  79.6583
      3      [36m0.9107[0m        [32m0.5911[0m       [35m0.6974[0m      [31m0.6974[0m        [94m0.9647[0m     +  0.0000  79.7284
      4      [36m0.9196[0m        [32m0.4979[0m       0.6823      0.6823        [94m0.9496[0m     +  0.0000  79.7660
      5      [36m0.9643[0m        [32m0.4215[0m       0.6856      0.6856        [94m0.9450[0m     +  0.0000  79.7244
      6      [36m0.9821[0m        [32m0.3808[0m       0.6937      0.6937        [94m0.9293[0m     +  0.0000  79.7557
      7      0.9821        [32m0.3338[0m       [35m0.7063[0m      [31m0.7063[0m        [94m0.9265[0m     +  0.0000  79.7168
      8      0.9821        [32m0.3296[0m       0.6917      0.6917        [94m0.9258[0m     +  0.0000  79.7615
      9      [36m0.9911[0m        [32m0.2722[0m       0.6832      0.6832        0.9262        0.0000  79.7261
     10      0.9911        [32m0.2398[0m       0.6892      0.6892        0.9331        0.0000  79.6574
     11      [36m1.0000[0m        [32m0.2352[0m       0.6920      0.6920        0.9306        0.0000  79.7068
     12      1.0000        [32m0.2179[0m       0.7017      0.7017        0.9263        0.0000  79.7045
     13      1.0000        0.2214       0.6861      0.6861        0.9407        0.0000  79.6323
     14      1.0000        [32m0.2093[0m       0.6939      0.6939        0.9334        0.0000  79.4736
     15      1.0000        [32m0.1985[0m       0.6941      0.6941        0.9321        0.0000  79.6060
     16      1.0000        0.2010       0.6984      0.6984        0.9266        0.0000  79.5013
     17      1.0000        [32m0.1904[0m       0.6993      0.6993        0.9291        0.0000  79.5524
     18      1.0000        [32m0.1713[0m       0.6905      0.6905        0.9331        0.0000  79.6173
     19      1.0000        0.1803       0.6993      0.6993        0.9298        0.0000  79.5915
     20      1.0000        0.1735       0.6970      0.6970        0.9316        0.0000  79.5886
Stopping since valid_loss has not improved in the last 13 epochs.
[8, 24, 56, 112]
F1 Micro Score after query 3: 0.7227430555555555
F1 Macro Score after query 3: 0.2793878012447303
Number of samples used for retraining: 112
Number of samples in pool after training and deleting samples: 26768
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\model_checkpoint_iteration_2.pt

Iteration:  4
Selecting 96 informative samples: 

Training started with 208 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7452[0m        [32m0.7917[0m       [35m0.6948[0m      [31m0.6948[0m        [94m0.9351[0m     +  0.0000  82.5755
      2      [36m0.8846[0m        [32m0.5674[0m       [35m0.7023[0m      [31m0.7023[0m        [94m0.9012[0m     +  0.0000  82.7089
      3      [36m0.9471[0m        [32m0.4469[0m       [35m0.7092[0m      [31m0.7092[0m        [94m0.8861[0m     +  0.0000  82.7123
      4      [36m0.9615[0m        [32m0.3920[0m       [35m0.7266[0m      [31m0.7266[0m        [94m0.8557[0m     +  0.0000  82.7616
      5      [36m0.9712[0m        [32m0.3390[0m       [35m0.7372[0m      [31m0.7372[0m        [94m0.8514[0m     +  0.0000  82.6705
      6      [36m0.9760[0m        [32m0.3245[0m       0.7026      0.7026        0.8900        0.0000  82.7885
      7      [36m0.9808[0m        [32m0.3224[0m       0.6314      0.6314        1.0308        0.0000  82.7504
      8      0.9663        0.3347       0.6585      0.6585        0.9578        0.0000  82.7120
      9      [36m0.9856[0m        [32m0.3042[0m       0.7290      0.7290        [94m0.8272[0m     +  0.0000  82.7147
     10      [36m0.9904[0m        [32m0.2411[0m       0.7063      0.7063        0.9536        0.0000  82.6328
     11      [36m0.9952[0m        [32m0.2157[0m       0.7040      0.7040        0.9434        0.0000  82.7092
     12      0.9904        [32m0.1824[0m       0.7186      0.7186        0.8875        0.0000  82.6382
     13      0.9952        0.1829       0.7361      0.7361        0.8532        0.0000  82.6806
     14      0.9952        [32m0.1568[0m       0.7306      0.7306        0.8579        0.0000  82.6617
     15      0.9952        0.1589       0.7295      0.7295        0.8628        0.0000  82.7033
     16      [36m1.0000[0m        [32m0.1463[0m       0.7318      0.7318        0.8597        0.0000  82.6437
     17      1.0000        0.1479       0.7325      0.7325        0.8587        0.0000  82.7411
     18      1.0000        [32m0.1345[0m       0.7309      0.7309        0.8620        0.0000  82.6726
     19      1.0000        0.1363       0.7299      0.7299        0.8626        0.0000  82.6941
     20      1.0000        [32m0.1267[0m       0.7323      0.7323        0.8591        0.0000  82.6564
     21      1.0000        0.1280       0.7283      0.7283        0.8735        0.0000  82.6446
Stopping since valid_loss has not improved in the last 13 epochs.
[8, 24, 56, 112, 208]
F1 Micro Score after query 4: 0.7718749999999999
F1 Macro Score after query 4: 0.3820749807013719
Number of samples used for retraining: 208
Number of samples in pool after training and deleting samples: 26672
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\model_checkpoint_iteration_3.pt

Iteration:  5
Selecting 176 informative samples: 

Training started with 384 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7786[0m        [32m0.6777[0m       [35m0.7549[0m      [31m0.7549[0m        [94m0.7517[0m     +  0.0000  88.0072
      2      [36m0.8594[0m        [32m0.5736[0m       0.7007      0.7007        0.8393        0.0000  88.0749
      3      [36m0.9245[0m        [32m0.4585[0m       0.7274      0.7274        0.7981        0.0000  88.0876
      4      [36m0.9375[0m        [32m0.3570[0m       0.6521      0.6521        0.9905        0.0000  88.0622
      5      [36m0.9740[0m        [32m0.2706[0m       0.7104      0.7104        0.8871        0.0000  88.0001
      6      0.9557        0.2933       [35m0.7632[0m      [31m0.7632[0m        0.7741        0.0000  88.1236
      7      0.9740        [32m0.2540[0m       [35m0.7812[0m      [31m0.7812[0m        0.7571        0.0000  88.1046
      8      [36m0.9844[0m        [32m0.1919[0m       0.7811      0.7811        [94m0.7413[0m     +  0.0000  88.1122
      9      [36m0.9870[0m        [32m0.1705[0m       0.7569      0.7569        0.7859        0.0000  88.1036
     10      [36m0.9922[0m        [32m0.1527[0m       [35m0.7908[0m      [31m0.7908[0m        [94m0.7159[0m     +  0.0000  88.1839
     11      [36m0.9948[0m        [32m0.1436[0m       [35m0.7917[0m      [31m0.7917[0m        [94m0.7144[0m     +  0.0000  88.1150
     12      0.9948        [32m0.1310[0m       [35m0.7934[0m      [31m0.7934[0m        0.7174        0.0000  88.0733
     13      0.9896        [32m0.1308[0m       0.7833      0.7833        0.7921        0.0000  88.1320
     14      0.9896        [32m0.1274[0m       0.7760      0.7760        0.8033        0.0000  88.0295
     15      [36m0.9974[0m        [32m0.1177[0m       0.7753      0.7753        0.7787        0.0000  88.0560
     16      0.9974        [32m0.1046[0m       0.7762      0.7762        0.8027        0.0000  88.2119
     17      0.9974        0.1068       0.7807      0.7807        0.7691        0.0000  88.1644
     18      0.9974        [32m0.1027[0m       0.7788      0.7788        0.7873        0.0000  88.1552
     19      0.9974        [32m0.0975[0m       0.7762      0.7762        0.7725        0.0000  88.1421
     20      0.9974        [32m0.0969[0m       0.7792      0.7792        0.7972        0.0000  88.0106
     21      0.9974        0.0993       0.7778      0.7778        0.7766        0.0000  88.1491
     22      [36m1.0000[0m        [32m0.0873[0m       0.7814      0.7814        0.7832        0.0000  88.0772
     23      1.0000        0.0893       0.7795      0.7795        0.8019        0.0000  88.1089
Stopping since valid_loss has not improved in the last 13 epochs.
[8, 24, 56, 112, 208, 384]
F1 Micro Score after query 5: 0.8119791666666667
F1 Macro Score after query 5: 0.4796945107944294
Number of samples used for retraining: 384
Number of samples in pool after training and deleting samples: 26496
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\model_checkpoint_iteration_4.pt

Iteration:  6
Selecting 320 informative samples: 

Training started with 704 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7926[0m        [32m0.6216[0m       [35m0.7599[0m      [31m0.7599[0m        [94m0.7235[0m     +  0.0000  97.7426
      2      [36m0.8935[0m        [32m0.4283[0m       [35m0.7929[0m      [31m0.7929[0m        [94m0.6859[0m     +  0.0000  97.9169
      3      [36m0.9361[0m        [32m0.2986[0m       0.7748      0.7748        0.7307        0.0000  98.0689
      4      [36m0.9531[0m        [32m0.2502[0m       [35m0.7965[0m      [31m0.7965[0m        0.6912        0.0000  98.1048
      5      0.9503        [32m0.2391[0m       [35m0.8160[0m      [31m0.8160[0m        [94m0.6188[0m     +  0.0000  98.0859
      6      [36m0.9616[0m        [32m0.2012[0m       0.8080      0.8080        0.6482        0.0000  98.0822
      7      0.9588        [32m0.1843[0m       0.7764      0.7764        0.7350        0.0000  98.1189
      8      [36m0.9830[0m        [32m0.1468[0m       0.7899      0.7899        0.7434        0.0000  98.0824
      9      [36m0.9901[0m        [32m0.1182[0m       0.7979      0.7979        0.7423        0.0000  98.0708
     10      [36m0.9915[0m        [32m0.1097[0m       0.7972      0.7972        0.7404        0.0000  97.9202
     11      [36m0.9943[0m        [32m0.0999[0m       0.8003      0.8003        0.7130        0.0000  97.9179
     12      [36m0.9972[0m        [32m0.0839[0m       0.7991      0.7991        0.7952        0.0000  97.9102
     13      0.9972        [32m0.0758[0m       0.8052      0.8052        0.7268        0.0000  97.9533
     14      [36m0.9986[0m        [32m0.0705[0m       0.8002      0.8002        0.7322        0.0000  97.9611
     15      0.9972        [32m0.0704[0m       0.7993      0.7993        0.7289        0.0000  97.9583
     16      0.9986        [32m0.0661[0m       0.8052      0.8052        0.7327        0.0000  98.0124
     17      0.9986        [32m0.0628[0m       0.7986      0.7986        0.7384        0.0000  97.9571
Stopping since valid_loss has not improved in the last 13 epochs.
[8, 24, 56, 112, 208, 384, 704]
F1 Micro Score after query 6: 0.8387152777777778
F1 Macro Score after query 6: 0.5475161260582092
Number of samples used for retraining: 704
Number of samples in pool after training and deleting samples: 26176
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\model_checkpoint_iteration_5.pt

Iteration:  7
Selecting 560 informative samples: 

Training started with 1264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.8038[0m        [32m0.5970[0m       [35m0.7936[0m      [31m0.7936[0m        [94m0.5778[0m     +  0.0000  115.4235
      2      [36m0.8623[0m        [32m0.4453[0m       [35m0.8009[0m      [31m0.8009[0m        0.5998        0.0000  115.5304
      3      [36m0.9098[0m        [32m0.3196[0m       [35m0.8026[0m      [31m0.8026[0m        0.6210        0.0000  115.5820
      4      [36m0.9343[0m        [32m0.2724[0m       0.7925      0.7925        0.6980        0.0000  115.5235
      5      [36m0.9470[0m        [32m0.2438[0m       0.7611      0.7611        0.7526        0.0000  115.5517
      6      [36m0.9502[0m        [32m0.2226[0m       0.7842      0.7842        0.6835        0.0000  115.5338
      7      [36m0.9620[0m        [32m0.1877[0m       0.7609      0.7609        0.8277        0.0000  115.5330
      8      [36m0.9644[0m        [32m0.1677[0m       0.7481      0.7481        0.8384        0.0000  115.4178
      9      [36m0.9771[0m        [32m0.1487[0m       0.7351      0.7351        0.9042        0.0000  115.4289
     10      [36m0.9858[0m        [32m0.1200[0m       0.7252      0.7252        1.0145        0.0000  115.4614
     11      0.9858        [32m0.1156[0m       0.7184      0.7184        1.0661        0.0000  115.3405
     12      0.9850        [32m0.1055[0m       0.7562      0.7562        0.8262        0.0000  115.3683
     13      [36m0.9897[0m        [32m0.0839[0m       [35m0.8186[0m      [31m0.8186[0m        0.6755        0.0000  115.4236
Stopping since valid_loss has not improved in the last 13 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264]
F1 Micro Score after query 7: 0.8510416666666667
F1 Macro Score after query 7: 0.5995432883234888
Number of samples used for retraining: 1264
Number of samples in pool after training and deleting samples: 25616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\model_checkpoint_iteration_6.pt

Iteration:  8
Selecting 1000 informative samples: 

Training started with 2264 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.8291[0m        [32m0.5122[0m       [35m0.8141[0m      [31m0.8141[0m        [94m0.6049[0m     +  0.0000  146.4937
      2      [36m0.8852[0m        [32m0.3791[0m       0.8101      0.8101        0.6051        0.0000  146.7516
      3      [36m0.9050[0m        [32m0.3262[0m       0.7986      0.7986        0.6293        0.0000  146.6894
      4      [36m0.9178[0m        [32m0.2924[0m       0.8127      0.8127        0.6117        0.0000  146.5008
      5      [36m0.9262[0m        [32m0.2618[0m       [35m0.8158[0m      [31m0.8158[0m        [94m0.5707[0m     +  0.0000  146.4418
      6      [36m0.9399[0m        [32m0.2207[0m       0.8038      0.8038        0.6619        0.0000  146.7235
      7      [36m0.9532[0m        [32m0.1852[0m       0.7811      0.7811        0.7273        0.0000  146.6751
      8      [36m0.9669[0m        [32m0.1450[0m       0.7922      0.7922        0.6867        0.0000  146.6972
      9      0.9625        0.1516       0.8108      0.8108        0.6417        0.0000  146.6077
     10      [36m0.9678[0m        [32m0.1408[0m       0.8083      0.8083        0.6526        0.0000  146.5433
     11      [36m0.9726[0m        [32m0.1269[0m       0.7972      0.7972        0.7027        0.0000  146.5874
     12      0.9726        [32m0.1130[0m       0.7896      0.7896        0.7383        0.0000  146.5880
     13      [36m0.9867[0m        [32m0.0820[0m       0.8135      0.8135        0.6694        0.0000  146.6816
     14      [36m0.9934[0m        [32m0.0624[0m       [35m0.8231[0m      [31m0.8231[0m        0.6463        0.0000  146.7095
     15      [36m0.9951[0m        [32m0.0516[0m       [35m0.8266[0m      [31m0.8266[0m        0.6456        0.0000  146.7714
     16      [36m0.9987[0m        [32m0.0423[0m       0.8229      0.8229        0.6744        0.0000  146.5306
     17      0.9987        [32m0.0378[0m       0.8208      0.8208        0.6991        0.0000  146.6159
Stopping since valid_loss has not improved in the last 13 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264]
F1 Micro Score after query 8: 0.8581597222222223
F1 Macro Score after query 8: 0.5732083875184562
Number of samples used for retraining: 2264
Number of samples in pool after training and deleting samples: 24616
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\model_checkpoint_iteration_7.pt

Iteration:  9
Selecting 1776 informative samples: 

Training started with 4040 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.8693[0m        [32m0.4092[0m       [35m0.8238[0m      [31m0.8238[0m        [94m0.4773[0m     +  0.0000  201.8343
      2      [36m0.8970[0m        [32m0.3366[0m       [35m0.8411[0m      [31m0.8411[0m        [94m0.4398[0m     +  0.0000  202.1126
      3      [36m0.9161[0m        [32m0.2799[0m       0.8351      0.8351        0.4826        0.0000  202.1276
      4      [36m0.9339[0m        [32m0.2302[0m       0.8276      0.8276        0.4897        0.0000  201.9052
      5      [36m0.9426[0m        [32m0.2042[0m       0.8182      0.8182        0.5451        0.0000  201.8746
      6      [36m0.9450[0m        [32m0.1847[0m       0.8292      0.8292        0.5285        0.0000  201.9451
      7      [36m0.9572[0m        [32m0.1570[0m       0.8236      0.8236        0.5913        0.0000  201.8215
      8      [36m0.9624[0m        [32m0.1396[0m       0.8302      0.8302        0.5806        0.0000  201.8992
      9      [36m0.9683[0m        [32m0.1222[0m       0.8325      0.8325        0.5968        0.0000  201.9402
     10      0.9611        0.1296       0.8250      0.8250        0.5928        0.0000  201.9601
     11      0.9656        [32m0.1155[0m       0.8392      0.8392        0.5343        0.0000  202.0014
     12      [36m0.9738[0m        [32m0.1022[0m       [35m0.8448[0m      [31m0.8448[0m        0.5543        0.0000  202.0048
     13      [36m0.9894[0m        [32m0.0582[0m       [35m0.8536[0m      [31m0.8536[0m        0.5570        0.0000  202.0035
     14      [36m0.9968[0m        [32m0.0350[0m       0.8500      0.8500        0.6030        0.0000  202.0056
Stopping since valid_loss has not improved in the last 13 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040]
F1 Micro Score after query 9: 0.8579861111111111
F1 Macro Score after query 9: 0.5980184125143281
Number of samples used for retraining: 4040
Number of samples in pool after training and deleting samples: 22840
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\model_checkpoint_iteration_8.pt

Iteration:  10
Selecting 3160 informative samples: 

Training started with 7200 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9076[0m        [32m0.3083[0m       [35m0.8260[0m      [31m0.8260[0m        [94m0.5246[0m     +  0.0000  299.8941
      2      [36m0.9274[0m        [32m0.2524[0m       [35m0.8345[0m      [31m0.8345[0m        [94m0.5043[0m     +  0.0000  300.3973
      3      [36m0.9382[0m        [32m0.2150[0m       [35m0.8467[0m      [31m0.8467[0m        [94m0.4809[0m     +  0.0000  300.5376
      4      [36m0.9457[0m        [32m0.1843[0m       0.8422      0.8422        0.5362        0.0000  300.5458
      5      [36m0.9515[0m        [32m0.1609[0m       0.8335      0.8335        0.5877        0.0000  300.2886
      6      [36m0.9601[0m        [32m0.1312[0m       0.8391      0.8391        0.5661        0.0000  300.3469
      7      [36m0.9604[0m        [32m0.1258[0m       0.8177      0.8177        0.6829        0.0000  300.1242
      8      [36m0.9663[0m        [32m0.1138[0m       0.8007      0.8007        0.8246        0.0000  300.2807
      9      0.9663        [32m0.1042[0m       0.7894      0.7894        0.8379        0.0000  300.1803
     10      [36m0.9679[0m        0.1114       0.8182      0.8182        0.6584        0.0000  300.3106
     11      [36m0.9769[0m        [32m0.0807[0m       0.7931      0.7931        0.8255        0.0000  300.1196
     12      0.9765        0.0823       0.8306      0.8306        0.6709        0.0000  300.2445
     13      [36m0.9904[0m        [32m0.0449[0m       0.8276      0.8276        0.7597        0.0000  300.2785
     14      [36m0.9951[0m        [32m0.0278[0m       0.8231      0.8231        0.8122        0.0000  300.3090
     15      [36m0.9967[0m        [32m0.0236[0m       0.8224      0.8224        0.8182        0.0000  300.3571
Stopping since valid_loss has not improved in the last 13 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200]
F1 Micro Score after query 10: 0.85
F1 Macro Score after query 10: 0.5954953297802666
Number of samples used for retraining: 7200
Number of samples in pool after training and deleting samples: 19680
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\model_checkpoint_iteration_9.pt

Iteration:  11
Selecting 5624 informative samples: 

Training started with 12824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9502[0m        [32m0.1801[0m       [35m0.8488[0m      [31m0.8488[0m        [94m0.5254[0m     +  0.0000  474.8803
      2      0.9491        [32m0.1651[0m       0.8413      0.8413        0.5825        0.0000  475.4349
      3      [36m0.9566[0m        [32m0.1412[0m       [35m0.8493[0m      [31m0.8493[0m        [94m0.5129[0m     +  0.0000  475.4084
      4      [36m0.9588[0m        [32m0.1270[0m       0.8450      0.8450        0.5253        0.0000  475.5616
      5      [36m0.9662[0m        [32m0.1081[0m       [35m0.8547[0m      [31m0.8547[0m        0.5598        0.0000  475.2898
      6      [36m0.9683[0m        [32m0.0988[0m       0.8543      0.8543        [94m0.5003[0m     +  0.0000  475.2813
      7      [36m0.9746[0m        [32m0.0799[0m       [35m0.8627[0m      [31m0.8627[0m        0.5730        0.0000  475.5583
      8      [36m0.9769[0m        [32m0.0761[0m       0.8536      0.8536        0.6473        0.0000  475.4625
      9      [36m0.9790[0m        [32m0.0707[0m       0.8464      0.8464        0.6325        0.0000  475.5220
     10      [36m0.9835[0m        [32m0.0566[0m       0.8568      0.8568        0.5900        0.0000  475.2808
     11      [36m0.9850[0m        [32m0.0536[0m       0.8538      0.8538        0.6622        0.0000  475.6157
     12      [36m0.9877[0m        [32m0.0428[0m       0.8470      0.8470        0.8034        0.0000  475.6195
     13      [36m0.9922[0m        [32m0.0280[0m       0.8417      0.8417        0.7220        0.0000  475.6251
     14      [36m0.9975[0m        [32m0.0142[0m       0.8457      0.8457        0.7614        0.0000  475.4632
     15      [36m0.9981[0m        [32m0.0124[0m       0.8503      0.8503        0.8163        0.0000  475.4494
     16      0.9972        0.0137       0.8516      0.8516        0.7994        0.0000  475.6229
     17      0.9975        0.0132       0.8582      0.8582        0.7696        0.0000  475.6103
     18      0.9980        [32m0.0094[0m       0.8562      0.8562        0.8220        0.0000  475.6103
Stopping since valid_loss has not improved in the last 13 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824]
F1 Micro Score after query 11: 0.859375
F1 Macro Score after query 11: 0.6401646934652085
Number of samples used for retraining: 12824
Number of samples in pool after training and deleting samples: 14056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\model_checkpoint_iteration_10.pt

Iteration:  12
Selecting 10000 informative samples: 

Training started with 22824 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9852[0m        [32m0.0532[0m       [35m0.8592[0m      [31m0.8592[0m        [94m0.5695[0m     +  0.0000  786.1074
      2      0.9829        0.0595       0.8474      0.8474        0.6628        0.0000  787.4823
      3      0.9846        [32m0.0528[0m       0.8462      0.8462        0.6192        0.0000  787.5479
      4      [36m0.9886[0m        [32m0.0419[0m       0.8564      0.8564        0.6393        0.0000  787.4155
      5      0.9878        [32m0.0409[0m       0.8464      0.8464        0.7398        0.0000  787.2184
      6      [36m0.9887[0m        [32m0.0379[0m       0.8111      0.8111        0.7904        0.0000  787.7736
      7      [36m0.9900[0m        [32m0.0351[0m       [35m0.8595[0m      [31m0.8595[0m        0.6710        0.0000  787.6906
      8      [36m0.9914[0m        [32m0.0272[0m       [35m0.8665[0m      [31m0.8665[0m        0.6147        0.0000  788.0643
      9      0.9905        0.0309       0.8590      0.8590        0.7124        0.0000  787.5652
     10      [36m0.9924[0m        [32m0.0267[0m       0.8474      0.8474        0.7796        0.0000  788.1943
     11      [36m0.9940[0m        [32m0.0221[0m       0.8500      0.8500        0.8173        0.0000  788.1663
     12      0.9930        0.0252       0.8613      0.8613        0.6551        0.0000  787.7083
     13      [36m0.9975[0m        [32m0.0105[0m       0.8486      0.8486        0.7805        0.0000  787.3590
Stopping since valid_loss has not improved in the last 13 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824]
F1 Micro Score after query 12: 0.8576388888888888
F1 Macro Score after query 12: 0.6282676004546219
Number of samples used for retraining: 22824
Number of samples in pool after training and deleting samples: 4056
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\model_checkpoint_iteration_11.pt

Iteration:  13
Selecting 4056 informative samples: 

Training started with 26880 samples:

Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9887[0m        [32m0.0406[0m       [35m0.8392[0m      [31m0.8392[0m        [94m0.7274[0m     +  0.0000  912.5072
      2      0.9857        0.0488       [35m0.8573[0m      [31m0.8573[0m        [94m0.6777[0m     +  0.0000  914.4235
      3      0.9865        0.0453       [35m0.8661[0m      [31m0.8661[0m        [94m0.5178[0m     +  0.0000  913.9072
      4      [36m0.9891[0m        [32m0.0375[0m       0.8594      0.8594        0.6857        0.0000  914.6719
      5      0.9881        [32m0.0371[0m       0.8620      0.8620        0.6097        0.0000  914.1447
      6      [36m0.9910[0m        [32m0.0315[0m       0.7932      0.7932        1.0715        0.0000  914.8226
      7      [36m0.9912[0m        [32m0.0288[0m       0.8576      0.8576        0.6532        0.0000  915.0367
      8      [36m0.9917[0m        [32m0.0272[0m       0.8569      0.8569        0.7398        0.0000  914.7524
      9      [36m0.9930[0m        [32m0.0241[0m       0.8561      0.8561        0.7921        0.0000  914.6776
     10      [36m0.9937[0m        [32m0.0216[0m       0.8528      0.8528        0.7106        0.0000  915.0566
     11      [36m0.9943[0m        [32m0.0198[0m       0.8457      0.8457        0.8305        0.0000  914.7649
     12      0.9942        0.0203       0.8595      0.8595        0.7637        0.0000  915.0176
     13      [36m0.9975[0m        [32m0.0104[0m       0.8597      0.8597        0.7684        0.0000  914.5759
     14      [36m0.9989[0m        [32m0.0058[0m       0.8623      0.8623        0.8175        0.0000  914.3212
     15      0.9986        0.0066       0.8403      0.8403        0.8636        0.0000  914.2987
Stopping since valid_loss has not improved in the last 13 epochs.
[8, 24, 56, 112, 208, 384, 704, 1264, 2264, 4040, 7200, 12824, 22824, 26880]
F1 Micro Score after query 13: 0.8696180555555556
F1 Macro Score after query 13: 0.6499989693591065
Number of samples used for retraining: 26880
Number of samples in pool after training and deleting samples: 0
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\model_checkpoint_iteration_12.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\ActiveLearning/Multiclass/DinoL/margin_sampling_seed43_low_lr\AL_margin_sampling_results_for_multiclass_classification_s43.pickle
