3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8

Iteration 1: Using initial samples.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.1250[0m        [32m2.2005[0m       [35m0.0071[0m      [31m0.0071[0m        [94m2.2178[0m     +  0.0000  74.9824
      2      [36m0.3750[0m        [32m2.0784[0m       [35m0.0075[0m      [31m0.0075[0m        [94m2.2135[0m     +  0.0000  76.2751
      3      0.2500        2.1329       [35m0.0141[0m      [31m0.0141[0m        [94m2.2065[0m     +  0.0000  76.5180
      4      0.3750        [32m1.9676[0m       [35m0.0155[0m      [31m0.0155[0m        [94m2.2012[0m     +  0.0000  76.4704
      5      0.3750        2.0148       0.0148      0.0148        [94m2.1968[0m     +  0.0000  76.3495
      6      0.2500        2.0428       0.0146      0.0146        [94m2.1898[0m     +  0.0000  76.5170
      7      0.1250        2.0039       0.0153      0.0153        [94m2.1832[0m     +  0.0000  76.4276
      8      0.2500        [32m1.9580[0m       [35m0.0160[0m      [31m0.0160[0m        [94m2.1774[0m     +  0.0000  76.4074
      9      0.3750        [32m1.8184[0m       [35m0.0193[0m      [31m0.0193[0m        [94m2.1734[0m     +  0.0000  76.1542
     10      0.2500        [32m1.8017[0m       [35m0.0219[0m      [31m0.0219[0m        [94m2.1708[0m     +  0.0000  76.4326
     11      [36m0.8750[0m        [32m1.7493[0m       [35m0.0236[0m      [31m0.0236[0m        [94m2.1671[0m     +  0.0000  77.2033
     12      0.5000        1.7750       [35m0.0252[0m      [31m0.0252[0m        [94m2.1628[0m     +  0.0000  77.2078
     13      0.2500        1.7545       [35m0.0253[0m      [31m0.0253[0m        [94m2.1611[0m     +  0.0000  76.3752
     14      0.2500        1.8311       [35m0.0257[0m      [31m0.0257[0m        [94m2.1593[0m     +  0.0000  76.3539
     15      0.7500        [32m1.6712[0m       [35m0.0260[0m      [31m0.0260[0m        [94m2.1574[0m     +  0.0000  76.4622
     16      0.5000        [32m1.6711[0m       [35m0.0267[0m      [31m0.0267[0m        [94m2.1558[0m     +  0.0000  76.2819
     17      0.3750        1.7848       [35m0.0274[0m      [31m0.0274[0m        [94m2.1545[0m     +  0.0000  76.3206
     18      0.5000        1.7201       [35m0.0278[0m      [31m0.0278[0m        [94m2.1539[0m     +  0.0000  76.4203
     19      0.6250        [32m1.6236[0m       [35m0.0283[0m      [31m0.0283[0m        [94m2.1531[0m     +  0.0000  76.4585
     20      0.5000        [32m1.5958[0m       [35m0.0293[0m      [31m0.0293[0m        [94m2.1524[0m     +  0.0000  76.2789
     21      0.6250        1.6969       [35m0.0302[0m      [31m0.0302[0m        [94m2.1512[0m     +  0.0000  76.4510
     22      0.6250        1.6320       [35m0.0312[0m      [31m0.0312[0m        [94m2.1494[0m     +  0.0000  76.4850
     23      0.3750        1.7019       [35m0.0323[0m      [31m0.0323[0m        [94m2.1479[0m     +  0.0000  76.3277
     24      0.3750        1.6757       [35m0.0339[0m      [31m0.0339[0m        [94m2.1461[0m     +  0.0000  76.3365
     25      0.5000        1.6048       [35m0.0344[0m      [31m0.0344[0m        [94m2.1454[0m     +  0.0000  76.4411
     26      0.6250        1.6561       [35m0.0349[0m      [31m0.0349[0m        [94m2.1450[0m     +  0.0000  76.3447
     27      0.8750        [32m1.5623[0m       [35m0.0354[0m      [31m0.0354[0m        [94m2.1445[0m     +  0.0000  76.1778
     28      [36m1.0000[0m        [32m1.4761[0m       [35m0.0358[0m      [31m0.0358[0m        [94m2.1440[0m     +  0.0000  76.3805
     29      0.8750        1.4994       [35m0.0363[0m      [31m0.0363[0m        [94m2.1436[0m     +  0.0000  76.4204
     30      0.5000        1.5748       [35m0.0368[0m      [31m0.0368[0m        [94m2.1431[0m     +  0.0000  76.8605
     31      0.7500        1.5652       [35m0.0387[0m      [31m0.0387[0m        [94m2.1426[0m     +  0.0000  76.7099
     32      0.8750        1.5636       [35m0.0411[0m      [31m0.0411[0m        [94m2.1422[0m     +  0.0000  76.3626
     33      1.0000        1.5261       [35m0.0432[0m      [31m0.0432[0m        [94m2.1416[0m     +  0.0000  76.3608
     34      0.6250        1.6599       [35m0.0451[0m      [31m0.0451[0m        [94m2.1409[0m     +  0.0000  76.2047
     35      0.5000        1.5988       [35m0.0476[0m      [31m0.0476[0m        [94m2.1402[0m     +  0.0000  76.2328
     36      0.8750        [32m1.4624[0m       [35m0.0507[0m      [31m0.0507[0m        [94m2.1394[0m     +  0.0000  76.3584
     37      0.7500        [32m1.4549[0m       [35m0.0523[0m      [31m0.0523[0m        [94m2.1390[0m     +  0.0000  76.2930
     38      0.7500        1.5713       [35m0.0531[0m      [31m0.0531[0m        [94m2.1386[0m     +  0.0000  76.3292
     39      0.6250        1.5797       [35m0.0540[0m      [31m0.0540[0m        [94m2.1382[0m     +  0.0000  76.3203
     40      0.7500        [32m1.3901[0m       [35m0.0549[0m      [31m0.0549[0m        [94m2.1377[0m     +  0.0000  76.2441
     41      0.6250        1.5437       [35m0.0563[0m      [31m0.0563[0m        [94m2.1373[0m     +  0.0000  76.3155
     42      0.7500        1.4676       [35m0.0571[0m      [31m0.0571[0m        [94m2.1370[0m     +  0.0000  76.3015
     43      0.8750        1.4696       [35m0.0578[0m      [31m0.0578[0m        [94m2.1366[0m     +  0.0000  76.3399
     44      0.8750        1.3929       [35m0.0582[0m      [31m0.0582[0m        [94m2.1363[0m     +  0.0000  76.3119
     45      0.7500        1.4972       [35m0.0585[0m      [31m0.0585[0m        [94m2.1360[0m     +  0.0000  76.3411
     46      0.7500        1.5532       [35m0.0590[0m      [31m0.0590[0m        [94m2.1358[0m     +  0.0000  76.3424
     47      1.0000        1.4178       [35m0.0595[0m      [31m0.0595[0m        [94m2.1357[0m     +  0.0000  76.2961
     48      0.7500        1.4210       [35m0.0602[0m      [31m0.0602[0m        [94m2.1355[0m     +  0.0000  76.3711
     49      0.8750        1.4464       [35m0.0604[0m      [31m0.0604[0m        [94m2.1354[0m     +  0.0000  76.3727
     50      0.7500        1.5057       [35m0.0608[0m      [31m0.0608[0m        [94m2.1354[0m     +  0.0000  76.4222
     51      0.7500        1.4663       [35m0.0615[0m      [31m0.0615[0m        [94m2.1353[0m     +  0.0000  76.3225
     52      0.8750        1.4545       0.0615      0.0615        [94m2.1352[0m     +  0.0000  76.3257
     53      0.8750        1.4446       [35m0.0618[0m      [31m0.0618[0m        [94m2.1352[0m     +  0.0000  76.1227
     54      1.0000        [32m1.3848[0m       [35m0.0622[0m      [31m0.0622[0m        [94m2.1352[0m     +  0.0000  76.2010
     55      0.6250        1.4656       0.0622      0.0622        [94m2.1352[0m     +  0.0000  76.2168
     56      0.7500        1.5173       [35m0.0625[0m      [31m0.0625[0m        [94m2.1351[0m     +  0.0000  76.3714
     57      0.7500        1.4736       [35m0.0628[0m      [31m0.0628[0m        [94m2.1351[0m     +  0.0000  76.3097
     58      0.6250        1.5408       [35m0.0635[0m      [31m0.0635[0m        [94m2.1350[0m     +  0.0000  76.2012
     59      0.6250        1.4658       [35m0.0637[0m      [31m0.0637[0m        [94m2.1349[0m     +  0.0000  76.1362
     60      0.8750        1.4166       [35m0.0648[0m      [31m0.0648[0m        [94m2.1347[0m     +  0.0000  76.3622
     61      0.7500        1.4398       [35m0.0649[0m      [31m0.0649[0m        [94m2.1347[0m     +  0.0000  76.3774
     62      0.7500        1.4659       [35m0.0651[0m      [31m0.0651[0m        [94m2.1346[0m     +  0.0000  76.1758
     63      0.7500        1.4724       0.0651      0.0651        [94m2.1346[0m     +  0.0000  76.1894
     64      0.5000        1.5696       0.0651      0.0651        [94m2.1346[0m     +  0.0000  76.2317
     65      0.8750        [32m1.3752[0m       [35m0.0655[0m      [31m0.0655[0m        [94m2.1345[0m     +  0.0000  76.3413
     66      0.7500        1.4239       [35m0.0656[0m      [31m0.0656[0m        [94m2.1345[0m     +  0.0000  76.3239
     67      0.7500        1.4496       [35m0.0658[0m      [31m0.0658[0m        [94m2.1344[0m     +  0.0000  76.1878
     68      0.8750        [32m1.3713[0m       0.0658      0.0658        [94m2.1344[0m     +  0.0000  76.2025
     69      0.7500        1.3735       [35m0.0661[0m      [31m0.0661[0m        [94m2.1343[0m     +  0.0000  76.2961
     70      0.7500        1.4365       [35m0.0663[0m      [31m0.0663[0m        [94m2.1343[0m     +  0.0000  76.3989
     71      0.7500        1.4818       0.0663      0.0663        [94m2.1343[0m     +  0.0000  76.3100
     72      0.6250        1.4553       [35m0.0668[0m      [31m0.0668[0m        [94m2.1342[0m     +  0.0000  76.1262
     73      0.8750        1.4473       0.0668      0.0668        [94m2.1342[0m     +  0.0000  76.1287
     74      0.6250        1.4714       [35m0.0670[0m      [31m0.0670[0m        [94m2.1342[0m     +  0.0000  76.2351
     75      0.7500        1.5473       [35m0.0672[0m      [31m0.0672[0m        2.1342        0.0000  76.3757
     76      0.6250        1.5171       0.0672      0.0672        2.1342        0.0000  76.2117
     77      0.7500        1.4447       [35m0.0674[0m      [31m0.0674[0m        2.1342        0.0000  76.0923
     78      0.7500        1.4360       0.0674      0.0674        2.1342        0.0000  76.0636
     79      1.0000        1.4536       0.0674      0.0674        2.1343        0.0000  76.2178
     80      1.0000        1.4049       0.0674      0.0674        2.1343        0.0000  76.2400
     81      1.0000        [32m1.3051[0m       0.0674      0.0674        2.1343        0.0000  76.0543
     82      0.7500        1.4752       [35m0.0675[0m      [31m0.0675[0m        2.1343        0.0000  76.0060
     83      0.6250        1.4787       [35m0.0677[0m      [31m0.0677[0m        2.1343        0.0000  76.1174
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 1: Test F1 Micro Score: 0.05659722222222222
Iteration 1: Test F1 Macro Score: 0.04979886453932133
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_0.pt

Iteration 2: Requesting 16 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.3750[0m        [32m1.8739[0m       [35m0.2536[0m      [31m0.2536[0m        [94m2.0462[0m     +  0.0000  76.5377
      2      [36m0.6667[0m        [32m1.6610[0m       [35m0.3344[0m      [31m0.3344[0m        [94m1.9514[0m     +  0.0000  76.7201
      3      0.5000        [32m1.6140[0m       [35m0.3757[0m      [31m0.3757[0m        [94m1.8731[0m     +  0.0000  76.8292
      4      0.6667        [32m1.4858[0m       [35m0.4226[0m      [31m0.4226[0m        [94m1.8117[0m     +  0.0000  76.7896
      5      0.6250        [32m1.4833[0m       [35m0.4609[0m      [31m0.4609[0m        [94m1.7708[0m     +  0.0000  76.9017
      6      0.6667        [32m1.4040[0m       [35m0.4899[0m      [31m0.4899[0m        [94m1.7376[0m     +  0.0000  76.7722
      7      [36m0.7917[0m        [32m1.3132[0m       [35m0.5207[0m      [31m0.5207[0m        [94m1.7032[0m     +  0.0000  76.8172
      8      0.6667        [32m1.2717[0m       [35m0.5483[0m      [31m0.5483[0m        [94m1.6704[0m     +  0.0000  76.8113
      9      0.7917        [32m1.2017[0m       [35m0.5628[0m      [31m0.5628[0m        [94m1.6455[0m     +  0.0000  76.5938
     10      0.7917        [32m1.1965[0m       [35m0.5661[0m      [31m0.5661[0m        [94m1.6263[0m     +  0.0000  76.6440
     11      [36m0.8333[0m        [32m1.1337[0m       [35m0.5781[0m      [31m0.5781[0m        [94m1.6051[0m     +  0.0000  76.7870
     12      0.7083        [32m1.1045[0m       [35m0.5984[0m      [31m0.5984[0m        [94m1.5802[0m     +  0.0000  76.8190
     13      0.8333        [32m1.0077[0m       [35m0.6009[0m      [31m0.6009[0m        [94m1.5726[0m     +  0.0000  76.7266
     14      0.8333        1.0540       0.5943      0.5943        [94m1.5693[0m     +  0.0000  76.6015
     15      [36m0.8750[0m        1.0218       0.5858      0.5858        [94m1.5672[0m     +  0.0000  76.6371
     16      0.8750        [32m0.9525[0m       0.5790      0.5790        [94m1.5636[0m     +  0.0000  76.8028
     17      0.7917        1.0121       0.5776      0.5776        [94m1.5582[0m     +  0.0000  76.8649
     18      [36m0.9167[0m        [32m0.9083[0m       0.5842      0.5842        [94m1.5505[0m     +  0.0000  76.6974
     19      0.8333        0.9475       0.5858      0.5858        [94m1.5453[0m     +  0.0000  76.6048
     20      0.8750        0.9312       0.5896      0.5896        [94m1.5380[0m     +  0.0000  76.7086
     21      [36m0.9583[0m        [32m0.8489[0m       0.5972      0.5972        [94m1.5299[0m     +  0.0000  76.8339
     22      0.9167        0.8511       [35m0.6016[0m      [31m0.6016[0m        [94m1.5204[0m     +  0.0000  76.8228
     23      0.8750        [32m0.8401[0m       [35m0.6080[0m      [31m0.6080[0m        [94m1.5100[0m     +  0.0000  76.6171
     24      0.9167        [32m0.8296[0m       [35m0.6095[0m      [31m0.6095[0m        [94m1.5047[0m     +  0.0000  76.6285
     25      0.8750        0.8420       0.6073      0.6073        [94m1.5040[0m     +  0.0000  76.8217
     26      0.9167        [32m0.7807[0m       0.6068      0.6068        [94m1.5027[0m     +  0.0000  76.8517
     27      0.8750        [32m0.7771[0m       0.6057      0.6057        [94m1.5018[0m     +  0.0000  76.7673
     28      0.9167        0.7791       0.6087      0.6087        [94m1.4995[0m     +  0.0000  76.6663
     29      0.9167        [32m0.7465[0m       [35m0.6102[0m      [31m0.6102[0m        [94m1.4971[0m     +  0.0000  76.6427
     30      0.9583        [32m0.7278[0m       0.6092      0.6092        [94m1.4959[0m     +  0.0000  76.8447
     31      0.9167        0.7390       0.6075      0.6075        [94m1.4950[0m     +  0.0000  76.9039
     32      0.9167        0.7327       0.6069      0.6069        [94m1.4936[0m     +  0.0000  76.6668
     33      0.9167        0.7413       0.6073      0.6073        [94m1.4910[0m     +  0.0000  76.5896
     34      0.8750        0.7456       0.6089      0.6089        [94m1.4879[0m     +  0.0000  76.7338
     35      0.9583        0.7368       0.6080      0.6080        [94m1.4868[0m     +  0.0000  76.8124
     36      0.9167        0.7737       0.6073      0.6073        [94m1.4866[0m     +  0.0000  76.8831
     37      0.9583        [32m0.7261[0m       0.6076      0.6076        [94m1.4860[0m     +  0.0000  76.8889
     38      0.9583        [32m0.6597[0m       0.6078      0.6078        [94m1.4851[0m     +  0.0000  76.8286
     39      0.9583        0.7325       0.6075      0.6075        [94m1.4847[0m     +  0.0000  76.9049
     40      0.9583        0.6605       0.6075      0.6075        [94m1.4840[0m     +  0.0000  76.8479
     41      0.9167        0.6773       0.6075      0.6075        [94m1.4832[0m     +  0.0000  76.8610
     42      0.9583        0.6805       0.6075      0.6075        [94m1.4823[0m     +  0.0000  76.8510
     43      0.9583        [32m0.6536[0m       0.6075      0.6075        [94m1.4817[0m     +  0.0000  76.8647
     44      0.9167        0.6719       0.6075      0.6075        [94m1.4808[0m     +  0.0000  76.8819
     45      0.9167        0.6826       0.6076      0.6076        [94m1.4795[0m     +  0.0000  76.8175
     46      0.9167        [32m0.6380[0m       0.6075      0.6075        [94m1.4785[0m     +  0.0000  76.8820
     47      0.9167        0.7100       0.6075      0.6075        [94m1.4781[0m     +  0.0000  76.9917
     48      0.9583        0.6805       0.6076      0.6076        [94m1.4772[0m     +  0.0000  76.9596
     49      0.9583        0.6451       0.6076      0.6076        [94m1.4769[0m     +  0.0000  76.8801
     50      0.9583        0.6566       0.6078      0.6078        [94m1.4765[0m     +  0.0000  76.8319
     51      0.9583        0.6592       0.6080      0.6080        [94m1.4762[0m     +  0.0000  76.7200
     52      0.9167        0.6531       0.6080      0.6080        [94m1.4758[0m     +  0.0000  76.6023
     53      0.9583        0.7223       0.6082      0.6082        [94m1.4755[0m     +  0.0000  76.5949
     54      0.9583        0.6633       0.6082      0.6082        [94m1.4752[0m     +  0.0000  76.6377
     55      0.9167        0.6895       0.6080      0.6080        [94m1.4751[0m     +  0.0000  76.7248
     56      0.9167        0.6857       0.6076      0.6076        [94m1.4751[0m     +  0.0000  76.8496
     57      0.9583        0.6670       0.6071      0.6071        [94m1.4750[0m     +  0.0000  76.8354
     58      0.9583        [32m0.6343[0m       0.6071      0.6071        [94m1.4748[0m     +  0.0000  76.6964
     59      0.9583        [32m0.6195[0m       0.6071      0.6071        [94m1.4744[0m     +  0.0000  76.6918
     60      0.9583        0.6379       0.6073      0.6073        [94m1.4743[0m     +  0.0000  76.6464
     61      0.9583        0.6595       0.6075      0.6075        [94m1.4742[0m     +  0.0000  76.6480
     62      0.9583        0.6488       0.6076      0.6076        [94m1.4741[0m     +  0.0000  76.8254
     63      0.9583        0.6256       0.6073      0.6073        [94m1.4741[0m     +  0.0000  76.8947
     64      0.9583        0.6235       0.6069      0.6069        [94m1.4740[0m     +  0.0000  76.6226
     65      0.9583        0.6669       0.6069      0.6069        [94m1.4739[0m     +  0.0000  76.6222
     66      0.9583        0.6658       0.6069      0.6069        [94m1.4738[0m     +  0.0000  76.6083
     67      0.9583        0.6551       0.6069      0.6069        [94m1.4737[0m     +  0.0000  76.5746
     68      0.9583        0.6366       0.6068      0.6068        [94m1.4737[0m     +  0.0000  76.8217
     69      0.9583        0.6759       0.6069      0.6069        [94m1.4736[0m     +  0.0000  76.9003
     70      0.9583        0.6228       0.6068      0.6068        [94m1.4734[0m     +  0.0000  76.7891
     71      0.9583        0.6437       0.6069      0.6069        [94m1.4732[0m     +  0.0000  76.6227
     72      0.9583        0.6769       0.6069      0.6069        [94m1.4731[0m     +  0.0000  76.6343
     73      0.9583        0.6786       0.6069      0.6069        [94m1.4730[0m     +  0.0000  76.5774
     74      0.9583        0.6594       0.6069      0.6069        [94m1.4730[0m     +  0.0000  76.6646
     75      0.9583        [32m0.6189[0m       0.6069      0.6069        [94m1.4730[0m     +  0.0000  76.8092
     76      0.9583        0.6918       0.6069      0.6069        [94m1.4729[0m     +  0.0000  76.7552
     77      0.9167        0.6674       0.6069      0.6069        [94m1.4729[0m     +  0.0000  76.6532
     78      0.9167        0.6793       0.6069      0.6069        [94m1.4728[0m     +  0.0000  76.5997
     79      0.8750        0.6501       0.6069      0.6069        [94m1.4728[0m     +  0.0000  76.6067
     80      [36m1.0000[0m        0.6526       0.6069      0.6069        [94m1.4727[0m     +  0.0000  76.6190
     81      0.9583        0.6349       0.6069      0.6069        [94m1.4726[0m     +  0.0000  76.7491
     82      0.9583        0.6439       0.6069      0.6069        [94m1.4726[0m     +  0.0000  76.8076
     83      0.9583        0.6581       0.6069      0.6069        [94m1.4725[0m     +  0.0000  76.7193
     84      0.9583        [32m0.5895[0m       0.6069      0.6069        [94m1.4724[0m     +  0.0000  76.6262
     85      0.9167        0.6426       0.6071      0.6071        [94m1.4724[0m     +  0.0000  76.6225
     86      0.9583        0.6018       0.6071      0.6071        [94m1.4724[0m     +  0.0000  76.6730
     87      0.9167        0.6204       0.6071      0.6071        [94m1.4724[0m     +  0.0000  76.7898
     88      0.9583        0.6851       0.6073      0.6073        [94m1.4724[0m     +  0.0000  76.8358
     89      0.9583        0.6323       0.6073      0.6073        [94m1.4724[0m     +  0.0000  76.8001
     90      0.9583        0.6259       0.6073      0.6073        [94m1.4723[0m     +  0.0000  77.4252
     91      0.9167        0.6688       0.6073      0.6073        [94m1.4723[0m     +  0.0000  76.9702
     92      0.9583        0.6463       0.6073      0.6073        1.4723        0.0000  76.6944
     93      0.9583        0.6461       0.6073      0.6073        1.4723        0.0000  76.8281
     94      0.9583        0.6496       0.6073      0.6073        1.4723        0.0000  76.8123
     95      0.9583        0.6670       0.6073      0.6073        1.4723        0.0000  76.7526
     96      0.9583        0.6862       0.6071      0.6071        1.4723        0.0000  76.5921
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 2: Test F1 Micro Score: 0.6074652777777778
Iteration 2: Test F1 Macro Score: 0.19934189431448823
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_1.pt

Iteration 3: Requesting 32 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.7857[0m        [32m1.0626[0m       [35m0.5632[0m      [31m0.5632[0m        [94m1.4572[0m     +  0.0000  77.8281
      2      [36m0.8393[0m        [32m0.9208[0m       [35m0.6220[0m      [31m0.6220[0m        [94m1.3555[0m     +  0.0000  77.9035
      3      [36m0.8929[0m        [32m0.7924[0m       [35m0.6240[0m      [31m0.6240[0m        [94m1.3351[0m     +  0.0000  77.8281
      4      0.8750        [32m0.7165[0m       0.6170      0.6170        [94m1.3151[0m     +  0.0000  77.7692
      5      0.8929        [32m0.6362[0m       [35m0.6259[0m      [31m0.6259[0m        [94m1.2731[0m     +  0.0000  77.7523
      6      [36m0.9286[0m        [32m0.5844[0m       [35m0.6311[0m      [31m0.6311[0m        [94m1.2496[0m     +  0.0000  77.7186
      7      0.9107        [32m0.5441[0m       [35m0.6339[0m      [31m0.6339[0m        [94m1.2277[0m     +  0.0000  77.8295
      8      [36m0.9464[0m        [32m0.4924[0m       0.6300      0.6300        [94m1.2176[0m     +  0.0000  77.9230
      9      [36m0.9643[0m        [32m0.4667[0m       0.6319      0.6319        [94m1.2065[0m     +  0.0000  77.8912
     10      [36m0.9821[0m        [32m0.4426[0m       [35m0.6368[0m      [31m0.6368[0m        [94m1.1807[0m     +  0.0000  77.7707
     11      0.9821        [32m0.3789[0m       0.6295      0.6295        1.1832        0.0000  77.8007
     12      0.9821        [32m0.3655[0m       0.6352      0.6352        [94m1.1729[0m     +  0.0000  77.6740
     13      0.9643        [32m0.3557[0m       0.6300      0.6300        1.1757        0.0000  77.7965
     14      0.9821        [32m0.3187[0m       0.6290      0.6290        1.1754        0.0000  77.8461
     15      [36m1.0000[0m        0.3198       0.6311      0.6311        [94m1.1666[0m     +  0.0000  77.8773
     16      0.9821        [32m0.3130[0m       0.6316      0.6316        [94m1.1635[0m     +  0.0000  77.7057
     17      1.0000        0.3172       0.6319      0.6319        [94m1.1628[0m     +  0.0000  77.7193
     18      1.0000        [32m0.2837[0m       0.6321      0.6321        [94m1.1591[0m     +  0.0000  77.6678
     19      1.0000        0.2871       0.6316      0.6316        [94m1.1551[0m     +  0.0000  77.6526
     20      1.0000        0.2842       0.6314      0.6314        1.1589        0.0000  77.8599
     21      1.0000        [32m0.2658[0m       0.6339      0.6339        1.1564        0.0000  77.7415
     22      1.0000        [32m0.2564[0m       0.6328      0.6328        1.1581        0.0000  77.5860
     23      1.0000        [32m0.2395[0m       0.6311      0.6311        1.1595        0.0000  77.9187
     24      0.9821        0.2501       0.6365      0.6365        [94m1.1514[0m     +  0.0000  77.5935
     25      1.0000        0.2584       0.6352      0.6352        [94m1.1500[0m     +  0.0000  77.6294
     26      1.0000        0.2452       0.6354      0.6354        1.1504        0.0000  78.4367
     27      1.0000        [32m0.2350[0m       0.6352      0.6352        [94m1.1486[0m     +  0.0000  78.7203
     28      1.0000        [32m0.2299[0m       0.6345      0.6345        1.1489        0.0000  78.0089
     29      1.0000        [32m0.2282[0m       0.6323      0.6323        1.1518        0.0000  77.7112
     30      1.0000        [32m0.2179[0m       0.6311      0.6311        1.1537        0.0000  77.9973
     31      1.0000        0.2408       0.6319      0.6319        1.1529        0.0000  77.5855
     32      1.0000        0.2311       0.6319      0.6319        1.1502        0.0000  77.5504
     33      1.0000        [32m0.2173[0m       0.6321      0.6321        1.1490        0.0000  77.8705
     34      1.0000        0.2364       0.6328      0.6328        1.1497        0.0000  77.7920
     35      1.0000        0.2442       0.6330      0.6330        1.1514        0.0000  77.5038
     36      1.0000        0.2335       0.6318      0.6318        1.1506        0.0000  77.5440
     37      1.0000        [32m0.2122[0m       0.6321      0.6321        1.1505        0.0000  77.4792
     38      1.0000        0.2167       0.6321      0.6321        1.1514        0.0000  77.5147
     39      1.0000        0.2368       0.6319      0.6319        1.1514        0.0000  77.6708
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 3: Test F1 Micro Score: 0.6748263888888889
Iteration 3: Test F1 Macro Score: 0.3013692098460842
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_2.pt

Iteration 4: Requesting 56 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8750[0m        [32m0.5956[0m       [35m0.6057[0m      [31m0.6057[0m        [94m1.2498[0m     +  0.0000  79.2903
      2      [36m0.9196[0m        [32m0.5076[0m       0.5464      0.5464        1.3013        0.0000  79.2907
      3      0.9196        [32m0.4299[0m       [35m0.6674[0m      [31m0.6674[0m        [94m1.0764[0m     +  0.0000  79.3529
      4      [36m0.9554[0m        [32m0.3392[0m       0.6457      0.6457        [94m1.0638[0m     +  0.0000  79.5676
      5      0.9554        [32m0.3030[0m       0.6391      0.6391        1.1091        0.0000  79.5860
      6      [36m0.9732[0m        [32m0.2592[0m       0.6472      0.6472        1.0659        0.0000  79.2733
      7      [36m0.9911[0m        [32m0.2282[0m       0.6604      0.6604        [94m1.0514[0m     +  0.0000  79.2724
      8      0.9911        [32m0.2193[0m       0.6368      0.6368        1.1249        0.0000  79.1927
      9      0.9821        [32m0.2109[0m       0.6486      0.6486        1.0707        0.0000  79.3880
     10      0.9911        [32m0.1784[0m       0.6632      0.6632        1.0544        0.0000  79.4984
     11      [36m1.0000[0m        [32m0.1667[0m       0.6458      0.6458        1.1243        0.0000  79.4902
     12      1.0000        [32m0.1543[0m       0.6465      0.6465        1.1085        0.0000  79.2920
     13      1.0000        [32m0.1473[0m       0.6519      0.6519        1.0948        0.0000  79.2585
     14      1.0000        [32m0.1415[0m       0.6557      0.6557        1.0879        0.0000  79.2338
     15      1.0000        [32m0.1373[0m       0.6495      0.6495        1.1006        0.0000  79.2357
     16      1.0000        [32m0.1305[0m       0.6559      0.6559        1.0838        0.0000  79.4226
     17      1.0000        0.1374       0.6514      0.6514        1.0974        0.0000  79.4489
     18      1.0000        [32m0.1246[0m       0.6564      0.6564        1.0916        0.0000  79.4019
     19      1.0000        0.1252       0.6517      0.6517        1.1045        0.0000  79.2642
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 4: Test F1 Micro Score: 0.6935763888888888
Iteration 4: Test F1 Macro Score: 0.27761438447146325
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_3.pt

Iteration 5: Requesting 96 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8606[0m        [32m0.5131[0m       [35m0.6398[0m      [31m0.6398[0m        [94m0.9131[0m     +  0.0000  82.4291
      2      [36m0.8990[0m        [32m0.4351[0m       [35m0.6500[0m      [31m0.6500[0m        [94m0.8832[0m     +  0.0000  82.4759
      3      [36m0.9231[0m        [32m0.3873[0m       [35m0.6505[0m      [31m0.6505[0m        [94m0.8763[0m     +  0.0000  82.4995
      4      [36m0.9567[0m        [32m0.3197[0m       [35m0.6655[0m      [31m0.6655[0m        [94m0.8738[0m     +  0.0000  82.5750
      5      [36m0.9760[0m        [32m0.2773[0m       [35m0.6809[0m      [31m0.6809[0m        [94m0.8636[0m     +  0.0000  82.5641
      6      0.9760        [32m0.2390[0m       [35m0.7090[0m      [31m0.7090[0m        [94m0.7860[0m     +  0.0000  82.5939
      7      [36m0.9808[0m        [32m0.2294[0m       [35m0.7372[0m      [31m0.7372[0m        [94m0.7599[0m     +  0.0000  82.5169
      8      [36m0.9904[0m        [32m0.1982[0m       [35m0.7479[0m      [31m0.7479[0m        0.7626        0.0000  82.5190
      9      [36m0.9952[0m        [32m0.1699[0m       0.7220      0.7220        0.7789        0.0000  82.4089
     10      0.9808        0.1843       0.6986      0.6986        0.8025        0.0000  82.4981
     11      0.9856        [32m0.1635[0m       0.6939      0.6939        0.8375        0.0000  82.6227
     12      0.9904        [32m0.1611[0m       0.6750      0.6750        0.8691        0.0000  82.5648
     13      0.9904        [32m0.1574[0m       0.6571      0.6571        1.0156        0.0000  82.3747
     14      0.9952        [32m0.1360[0m       0.6970      0.6970        0.8374        0.0000  82.4218
     15      [36m1.0000[0m        [32m0.1129[0m       0.6780      0.6780        0.8954        0.0000  82.4381
     16      1.0000        [32m0.1032[0m       0.6833      0.6833        0.8817        0.0000  82.3874
     17      1.0000        [32m0.0979[0m       0.6825      0.6825        0.8860        0.0000  82.3524
     18      1.0000        0.1055       0.6825      0.6825        0.8840        0.0000  82.4020
     19      1.0000        [32m0.0975[0m       0.6858      0.6858        0.8789        0.0000  82.3636
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 5: Test F1 Micro Score: 0.7251736111111111
Iteration 5: Test F1 Macro Score: 0.34659948349337266
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_4.pt

Iteration 6: Requesting 176 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8828[0m        [32m0.4722[0m       [35m0.6950[0m      [31m0.6950[0m        [94m0.7941[0m     +  0.0000  87.8076
      2      [36m0.9193[0m        [32m0.3445[0m       [35m0.7156[0m      [31m0.7156[0m        [94m0.7180[0m     +  0.0000  87.8700
      3      [36m0.9635[0m        [32m0.2573[0m       0.7076      0.7076        0.7609        0.0000  87.9653
      4      [36m0.9766[0m        [32m0.2069[0m       0.6500      0.6500        0.9604        0.0000  87.8943
      5      [36m0.9948[0m        [32m0.1731[0m       0.6389      0.6389        1.0579        0.0000  87.8944
      6      0.9870        [32m0.1604[0m       0.6472      0.6472        1.0402        0.0000  87.8395
      7      [36m0.9974[0m        [32m0.1258[0m       0.7118      0.7118        0.7747        0.0000  87.8524
      8      0.9974        [32m0.1086[0m       [35m0.7352[0m      [31m0.7352[0m        [94m0.7137[0m     +  0.0000  87.8426
      9      0.9974        [32m0.0974[0m       0.7311      0.7311        0.7326        0.0000  87.8669
     10      [36m1.0000[0m        [32m0.0887[0m       [35m0.7462[0m      [31m0.7462[0m        [94m0.7038[0m     +  0.0000  87.8690
     11      1.0000        [32m0.0808[0m       0.7351      0.7351        0.7319        0.0000  87.8905
     12      1.0000        [32m0.0766[0m       [35m0.7505[0m      [31m0.7505[0m        0.7116        0.0000  87.8333
     13      1.0000        [32m0.0722[0m       [35m0.7601[0m      [31m0.7601[0m        0.7288        0.0000  87.8203
     14      1.0000        [32m0.0711[0m       0.7523      0.7523        0.7376        0.0000  87.8484
     15      1.0000        [32m0.0674[0m       0.7589      0.7589        0.7368        0.0000  87.8392
     16      1.0000        [32m0.0666[0m       0.7547      0.7547        0.7377        0.0000  87.7897
     17      1.0000        0.0666       0.7549      0.7549        0.7423        0.0000  87.8350
     18      1.0000        [32m0.0624[0m       0.7495      0.7495        0.7528        0.0000  87.8338
     19      1.0000        [32m0.0604[0m       0.7493      0.7493        0.7538        0.0000  87.8322
     20      1.0000        [32m0.0552[0m       0.7517      0.7517        0.7571        0.0000  87.8108
     21      1.0000        0.0553       0.7505      0.7505        0.7605        0.0000  87.8302
     22      1.0000        0.0572       0.7526      0.7526        0.7588        0.0000  87.7931
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 6: Test F1 Micro Score: 0.7809027777777777
Iteration 6: Test F1 Macro Score: 0.3931667547294549
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_5.pt

Iteration 7: Requesting 320 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9077[0m        [32m0.3149[0m       [35m0.7536[0m      [31m0.7536[0m        [94m0.6204[0m     +  0.0000  97.8212
      2      [36m0.9233[0m        [32m0.2995[0m       0.7328      0.7328        0.7079        0.0000  97.9245
      3      [36m0.9560[0m        [32m0.2083[0m       [35m0.7901[0m      [31m0.7901[0m        [94m0.5739[0m     +  0.0000  97.8079
      4      [36m0.9744[0m        [32m0.1516[0m       0.7540      0.7540        0.6624        0.0000  97.8015
      5      [36m0.9787[0m        [32m0.1292[0m       0.7750      0.7750        0.6228        0.0000  97.8375
      6      [36m0.9929[0m        [32m0.0843[0m       0.7882      0.7882        0.5976        0.0000  97.8071
      7      [36m0.9986[0m        [32m0.0713[0m       0.7622      0.7622        0.7083        0.0000  97.8090
      8      [36m1.0000[0m        [32m0.0595[0m       0.7627      0.7627        0.7257        0.0000  97.8530
      9      1.0000        [32m0.0544[0m       0.7464      0.7464        0.7952        0.0000  97.8370
     10      1.0000        [32m0.0493[0m       0.7326      0.7326        0.8666        0.0000  97.8105
     11      1.0000        [32m0.0467[0m       0.7351      0.7351        0.8735        0.0000  97.7748
     12      1.0000        [32m0.0428[0m       0.7293      0.7293        0.9227        0.0000  97.8516
     13      0.9986        0.0457       0.7033      0.7033        1.0522        0.0000  97.8370
     14      0.9986        0.0453       0.7625      0.7625        0.7624        0.0000  97.7726
     15      0.9872        0.0645       0.7514      0.7514        0.7899        0.0000  97.8101
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 7: Test F1 Micro Score: 0.7555555555555555
Iteration 7: Test F1 Macro Score: 0.42789493012668767
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_6.pt

Iteration 8: Requesting 560 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9225[0m        [32m0.2920[0m       [35m0.7835[0m      [31m0.7835[0m        [94m0.5915[0m     +  0.0000  115.0480
      2      [36m0.9636[0m        [32m0.1886[0m       [35m0.8207[0m      [31m0.8207[0m        [94m0.5375[0m     +  0.0000  115.1738
      3      [36m0.9786[0m        [32m0.1308[0m       0.7429      0.7429        0.7428        0.0000  115.2767
      4      [36m0.9802[0m        [32m0.1161[0m       0.7085      0.7085        0.9720        0.0000  115.2083
      5      0.9771        [32m0.1145[0m       0.7839      0.7839        0.7188        0.0000  115.1576
      6      [36m0.9881[0m        [32m0.0809[0m       0.7981      0.7981        0.7097        0.0000  115.1371
      7      0.9834        0.0921       0.7974      0.7974        0.7281        0.0000  115.0674
      8      [36m0.9897[0m        [32m0.0681[0m       0.8059      0.8059        0.6829        0.0000  115.1332
      9      [36m0.9945[0m        [32m0.0564[0m       0.7755      0.7755        0.8360        0.0000  115.1859
     10      0.9905        0.0641       0.8054      0.8054        0.6608        0.0000  115.1656
     11      0.9937        [32m0.0508[0m       0.8144      0.8144        0.7133        0.0000  115.1814
     12      0.9929        [32m0.0501[0m       0.7960      0.7960        0.6931        0.0000  115.1164
     13      [36m0.9976[0m        [32m0.0377[0m       0.8172      0.8172        0.6517        0.0000  115.1863
     14      [36m0.9992[0m        [32m0.0319[0m       0.8141      0.8141        0.6438        0.0000  115.2377
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 8: Test F1 Micro Score: 0.8503472222222224
Iteration 8: Test F1 Macro Score: 0.5012479995996165
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_7.pt

Iteration 9: Requesting 1000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9373[0m        [32m0.2449[0m       [35m0.7486[0m      [31m0.7486[0m        [94m0.6924[0m     +  0.0000  146.1060
      2      [36m0.9625[0m        [32m0.1713[0m       [35m0.7726[0m      [31m0.7726[0m        [94m0.6363[0m     +  0.0000  146.3119
      3      [36m0.9722[0m        [32m0.1369[0m       [35m0.8042[0m      [31m0.8042[0m        [94m0.5972[0m     +  0.0000  146.2474
      4      [36m0.9779[0m        [32m0.1130[0m       0.8016      0.8016        0.6249        0.0000  146.3258
      5      [36m0.9797[0m        [32m0.1033[0m       0.7903      0.7903        0.6682        0.0000  146.2186
      6      0.9735        0.1080       0.7773      0.7773        0.7885        0.0000  146.1323
      7      0.9735        0.1040       [35m0.8168[0m      [31m0.8168[0m        [94m0.5790[0m     +  0.0000  146.1746
      8      [36m0.9837[0m        [32m0.0773[0m       [35m0.8189[0m      [31m0.8189[0m        0.6147        0.0000  146.2975
      9      [36m0.9876[0m        [32m0.0593[0m       0.8017      0.8017        0.6506        0.0000  146.1875
     10      [36m0.9907[0m        [32m0.0508[0m       0.8156      0.8156        0.6354        0.0000  146.2020
     11      [36m0.9973[0m        [32m0.0332[0m       [35m0.8260[0m      [31m0.8260[0m        0.6481        0.0000  146.1910
     12      0.9920        0.0472       0.8085      0.8085        0.6764        0.0000  146.2356
     13      0.9973        [32m0.0286[0m       0.8092      0.8092        0.7075        0.0000  146.1968
     14      [36m0.9996[0m        [32m0.0217[0m       0.8148      0.8148        0.6989        0.0000  146.1748
     15      [36m1.0000[0m        [32m0.0194[0m       0.8142      0.8142        0.7108        0.0000  146.1877
     16      1.0000        [32m0.0190[0m       0.8141      0.8141        0.7084        0.0000  146.1745
     17      1.0000        [32m0.0181[0m       0.8130      0.8130        0.7256        0.0000  146.1777
     18      1.0000        [32m0.0166[0m       0.8139      0.8139        0.7267        0.0000  146.1562
     19      1.0000        [32m0.0153[0m       0.8141      0.8141        0.7408        0.0000  146.1668
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 9: Test F1 Micro Score: 0.8491319444444444
Iteration 9: Test F1 Macro Score: 0.5640731708946596
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_8.pt

Iteration 10: Requesting 1776 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9562[0m        [32m0.1675[0m       [35m0.7991[0m      [31m0.7991[0m        [94m0.5921[0m     +  0.0000  201.0329
      2      [36m0.9681[0m        [32m0.1238[0m       [35m0.8304[0m      [31m0.8304[0m        [94m0.5212[0m     +  0.0000  201.4974
      3      [36m0.9752[0m        [32m0.0977[0m       [35m0.8352[0m      [31m0.8352[0m        [94m0.4580[0m     +  0.0000  201.5999
      4      [36m0.9782[0m        [32m0.0874[0m       [35m0.8389[0m      [31m0.8389[0m        0.5220        0.0000  201.4590
      5      [36m0.9819[0m        [32m0.0769[0m       0.8252      0.8252        0.5527        0.0000  201.4364
      6      [36m0.9876[0m        [32m0.0621[0m       0.8085      0.8085        0.6293        0.0000  201.3064
      7      [36m0.9903[0m        [32m0.0491[0m       0.8313      0.8313        0.6421        0.0000  201.4017
      8      [36m0.9931[0m        [32m0.0384[0m       0.8243      0.8243        0.6653        0.0000  201.2378
      9      0.9839        0.0623       0.8252      0.8252        0.6060        0.0000  201.3048
     10      0.9901        0.0445       0.8280      0.8280        0.6190        0.0000  201.3533
     11      [36m0.9953[0m        [32m0.0294[0m       0.8144      0.8144        0.7110        0.0000  201.4353
     12      0.9950        [32m0.0266[0m       0.7745      0.7745        0.9467        0.0000  201.4162
     13      [36m0.9985[0m        [32m0.0164[0m       0.8073      0.8073        0.7813        0.0000  201.3838
     14      [36m0.9995[0m        [32m0.0115[0m       0.8017      0.8017        0.8246        0.0000  201.2787
     15      [36m1.0000[0m        [32m0.0099[0m       0.8073      0.8073        0.8174        0.0000  201.4243
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 10: Test F1 Micro Score: 0.8536458333333333
Iteration 10: Test F1 Macro Score: 0.6050792532821634
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_9.pt

Iteration 11: Requesting 3160 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9624[0m        [32m0.1374[0m       [35m0.8243[0m      [31m0.8243[0m        [94m0.5509[0m     +  0.0000  298.9134
      2      [36m0.9696[0m        [32m0.1099[0m       [35m0.8273[0m      [31m0.8273[0m        [94m0.4991[0m     +  0.0000  299.6214
      3      [36m0.9743[0m        [32m0.0934[0m       0.8099      0.8099        0.5750        0.0000  299.7427
      4      [36m0.9754[0m        [32m0.0828[0m       [35m0.8405[0m      [31m0.8405[0m        [94m0.4887[0m     +  0.0000  299.5038
      5      [36m0.9824[0m        [32m0.0647[0m       0.8064      0.8064        0.5989        0.0000  299.7253
      6      0.9819        0.0648       0.7950      0.7950        0.6477        0.0000  299.4176
      7      [36m0.9839[0m        [32m0.0587[0m       [35m0.8455[0m      [31m0.8455[0m        0.5024        0.0000  300.6324
      8      [36m0.9882[0m        [32m0.0482[0m       [35m0.8592[0m      [31m0.8592[0m        0.5366        0.0000  302.6562
      9      0.9871        [32m0.0449[0m       0.8300      0.8300        0.6302        0.0000  301.8021
     10      [36m0.9908[0m        [32m0.0382[0m       0.8465      0.8465        0.5846        0.0000  304.3235
     11      0.9908        [32m0.0356[0m       0.7997      0.7997        0.7501        0.0000  308.4729
     12      [36m0.9917[0m        [32m0.0306[0m       0.8571      0.8571        0.5957        0.0000  306.4010
     13      [36m0.9956[0m        [32m0.0216[0m       0.8378      0.8378        0.6783        0.0000  306.5635
     14      [36m0.9990[0m        [32m0.0110[0m       0.8398      0.8398        0.6859        0.0000  307.0368
     15      0.9979        0.0126       0.8370      0.8370        0.6874        0.0000  306.0007
     16      0.9990        [32m0.0092[0m       0.8344      0.8344        0.7315        0.0000  307.9976
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 11: Test F1 Micro Score: 0.8630208333333335
Iteration 11: Test F1 Macro Score: 0.5989480591532969
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_10.pt

Iteration 12: Requesting 5624 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9660[0m        [32m0.1165[0m       [35m0.8646[0m      [31m0.8646[0m        [94m0.4084[0m     +  0.0000  474.6109
      2      [36m0.9708[0m        [32m0.0969[0m       0.8413      0.8413        0.4841        0.0000  475.0508
      3      [36m0.9759[0m        [32m0.0811[0m       0.8167      0.8167        0.5770        0.0000  475.2978
      4      [36m0.9800[0m        [32m0.0686[0m       0.8321      0.8321        0.5860        0.0000  474.9686
      5      [36m0.9816[0m        [32m0.0610[0m       0.8069      0.8069        0.6161        0.0000  474.5980
      6      [36m0.9849[0m        [32m0.0509[0m       0.8432      0.8432        0.6117        0.0000  476.0542
      7      [36m0.9871[0m        [32m0.0458[0m       0.8269      0.8269        0.6314        0.0000  477.1707
      8      [36m0.9892[0m        [32m0.0351[0m       0.8227      0.8227        0.7955        0.0000  476.9834
      9      [36m0.9904[0m        [32m0.0332[0m       0.8625      0.8625        0.5933        0.0000  477.1110
     10      0.9903        0.0339       0.8509      0.8509        0.6197        0.0000  475.7750
     11      [36m0.9917[0m        [32m0.0292[0m       0.8634      0.8634        0.5721        0.0000  474.2650
     12      [36m0.9920[0m        [32m0.0282[0m       0.8429      0.8429        0.5892        0.0000  473.9658
     13      [36m0.9955[0m        [32m0.0181[0m       0.8156      0.8156        0.8133        0.0000  473.9699
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 12: Test F1 Micro Score: 0.8543402777777777
Iteration 12: Test F1 Macro Score: 0.6203184197021367
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_11.pt

Iteration 13: Requesting 10000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9648[0m        [32m0.1174[0m       [35m0.8302[0m      [31m0.8302[0m        [94m0.4960[0m     +  0.0000  784.2556
      2      [36m0.9699[0m        [32m0.0963[0m       [35m0.8611[0m      [31m0.8611[0m        [94m0.4594[0m     +  0.0000  785.5551
      3      [36m0.9746[0m        [32m0.0796[0m       [35m0.8679[0m      [31m0.8679[0m        0.4848        0.0000  785.6826
      4      [36m0.9785[0m        [32m0.0661[0m       0.8549      0.8549        0.5033        0.0000  784.9677
      5      [36m0.9813[0m        [32m0.0590[0m       0.8472      0.8472        0.5467        0.0000  785.2430
      6      [36m0.9845[0m        [32m0.0491[0m       0.8399      0.8399        0.6097        0.0000  785.1691
      7      [36m0.9876[0m        [32m0.0411[0m       0.8580      0.8580        0.5372        0.0000  785.1572
      8      0.9874        [32m0.0397[0m       0.8248      0.8248        0.7127        0.0000  785.2425
      9      [36m0.9899[0m        [32m0.0352[0m       0.8625      0.8625        0.5395        0.0000  785.4595
     10      [36m0.9915[0m        [32m0.0304[0m       0.8377      0.8377        0.6979        0.0000  785.2254
     11      0.9908        [32m0.0294[0m       0.8552      0.8552        0.6502        0.0000  785.2857
     12      [36m0.9923[0m        [32m0.0261[0m       0.8135      0.8135        0.8655        0.0000  785.1383
     13      [36m0.9959[0m        [32m0.0149[0m       0.8288      0.8288        0.8508        0.0000  785.0356
     14      [36m0.9979[0m        [32m0.0089[0m       0.8406      0.8406        0.8001        0.0000  785.2784
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 13: Test F1 Micro Score: 0.8722222222222223
Iteration 13: Test F1 Macro Score: 0.6501270234231666
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_12.pt

Iteration 14: Requesting all remaining samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9722[0m        [32m0.0887[0m       [35m0.8502[0m      [31m0.8502[0m        [94m0.5000[0m     +  0.0000  910.1486
      2      [36m0.9762[0m        [32m0.0729[0m       0.8234      0.8234        0.5977        0.0000  911.4740
      3      [36m0.9798[0m        [32m0.0630[0m       [35m0.8528[0m      [31m0.8528[0m        0.5418        0.0000  910.9075
      4      [36m0.9830[0m        [32m0.0526[0m       0.8252      0.8252        0.6972        0.0000  905.5021
      5      [36m0.9846[0m        [32m0.0480[0m       0.8444      0.8444        0.6340        0.0000  905.4845
      6      [36m0.9866[0m        [32m0.0426[0m       0.8491      0.8491        0.6512        0.0000  909.0781
      7      [36m0.9887[0m        [32m0.0342[0m       0.8396      0.8396        0.7022        0.0000  920.4680
      8      [36m0.9888[0m        [32m0.0336[0m       0.8267      0.8267        0.8290        0.0000  913.2190
      9      [36m0.9901[0m        [32m0.0294[0m       0.8286      0.8286        0.8079        0.0000  916.9273
     10      [36m0.9921[0m        [32m0.0248[0m       0.8273      0.8273        0.8323        0.0000  913.2717
     11      0.9919        0.0271       0.8240      0.8240        0.8807        0.0000  912.6529
     12      [36m0.9931[0m        [32m0.0217[0m       0.8226      0.8226        0.9805        0.0000  913.0757
     13      [36m0.9964[0m        [32m0.0133[0m       0.8401      0.8401        0.8643        0.0000  913.1331
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 14: Test F1 Micro Score: 0.8510416666666667
Iteration 14: Test F1 Macro Score: 0.6180725046158411
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr/model_checkpoint_iteration_13.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_43_low_lr\random_sampling_results_for_multilabel_classification_s43.pickle
