3
multiclass_train_df shape: (26880, 2)
multiclass_test_df shape: (5760, 2)
multiclass_val_df shape: (5760, 2)
Calculated train_size: 8

Iteration 1: Using initial samples.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.1250[0m        [32m2.0531[0m       [35m0.3391[0m      [31m0.3391[0m        [94m1.9715[0m     +  0.0000  74.0317
      2      [36m0.3750[0m        [32m2.0163[0m       [35m0.3510[0m      [31m0.3510[0m        1.9719        0.0000  75.6718
      3      0.2500        2.1357       0.3408      0.3408        1.9730        0.0000  75.7831
      4      0.2500        [32m1.9632[0m       0.3453      0.3453        1.9733        0.0000  75.7968
      5      0.2500        [32m1.9491[0m       [35m0.3526[0m      [31m0.3526[0m        1.9743        0.0000  75.7228
      6      0.1250        1.9898       [35m0.3547[0m      [31m0.3547[0m        1.9760        0.0000  75.7339
      7      0.3750        [32m1.8697[0m       [35m0.3571[0m      [31m0.3571[0m        1.9796        0.0000  75.7338
      8      0.3750        [32m1.8625[0m       0.3563      0.3563        1.9830        0.0000  75.7659
      9      [36m0.5000[0m        [32m1.8228[0m       0.3458      0.3458        1.9884        0.0000  75.7813
     10      0.3750        1.8804       0.3425      0.3425        1.9913        0.0000  75.7462
     11      [36m0.6250[0m        [32m1.7658[0m       0.3425      0.3425        1.9920        0.0000  75.7660
     12      [36m0.8750[0m        [32m1.6856[0m       0.3424      0.3424        1.9915        0.0000  75.7517
     13      0.7500        1.6971       0.3446      0.3446        1.9908        0.0000  75.7243
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 1: Test F1 Micro Score: 0.33645833333333336
Iteration 1: Test F1 Macro Score: 0.1407840473482933
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_0.pt

Iteration 2: Requesting 16 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.2500[0m        [32m1.9687[0m       [35m0.4403[0m      [31m0.4403[0m        [94m1.9228[0m     +  0.0000  76.1878
      2      [36m0.4583[0m        [32m1.8820[0m       [35m0.4491[0m      [31m0.4491[0m        [94m1.8478[0m     +  0.0000  76.2970
      3      0.4583        [32m1.7994[0m       0.4481      0.4481        [94m1.7843[0m     +  0.0000  76.0547
      4      0.4583        [32m1.7162[0m       0.4479      0.4479        [94m1.7292[0m     +  0.0000  75.8866
      5      0.4167        [32m1.6277[0m       0.4483      0.4483        [94m1.6885[0m     +  0.0000  75.9153
      6      0.4583        [32m1.5569[0m       [35m0.4524[0m      [31m0.4524[0m        [94m1.6594[0m     +  0.0000  75.8431
      7      [36m0.5417[0m        1.5578       [35m0.4628[0m      [31m0.4628[0m        [94m1.6439[0m     +  0.0000  75.7254
      8      0.5000        [32m1.4620[0m       [35m0.4813[0m      [31m0.4813[0m        [94m1.6231[0m     +  0.0000  75.8568
      9      [36m0.5833[0m        [32m1.4455[0m       [35m0.5019[0m      [31m0.5019[0m        [94m1.5955[0m     +  0.0000  75.7470
     10      0.5833        [32m1.4039[0m       [35m0.5151[0m      [31m0.5151[0m        [94m1.5737[0m     +  0.0000  75.7619
     11      0.5833        [32m1.3695[0m       0.5144      0.5144        [94m1.5685[0m     +  0.0000  75.7587
     12      [36m0.6250[0m        [32m1.2952[0m       0.5125      0.5125        1.5691        0.0000  75.8245
     13      [36m0.6667[0m        [32m1.2267[0m       0.5122      0.5122        [94m1.5682[0m     +  0.0000  75.7739
     14      0.6250        1.2687       0.5109      0.5109        [94m1.5640[0m     +  0.0000  75.7155
     15      0.6667        [32m1.2043[0m       0.5106      0.5106        [94m1.5604[0m     +  0.0000  75.8186
     16      0.6667        1.2221       0.5062      0.5062        [94m1.5534[0m     +  0.0000  75.9018
     17      [36m0.7083[0m        [32m1.1729[0m       0.5059      0.5059        [94m1.5472[0m     +  0.0000  75.8528
     18      0.6667        1.1809       0.5036      0.5036        [94m1.5427[0m     +  0.0000  76.4075
     19      0.6667        [32m1.1499[0m       0.5033      0.5033        [94m1.5396[0m     +  0.0000  76.5777
     20      0.7083        [32m1.0887[0m       0.5033      0.5033        [94m1.5364[0m     +  0.0000  76.7807
     21      [36m0.7500[0m        1.0986       0.5038      0.5038        [94m1.5326[0m     +  0.0000  77.0052
     22      0.7500        [32m1.0334[0m       0.5040      0.5040        [94m1.5277[0m     +  0.0000  75.8181
     23      0.7500        [32m1.0250[0m       0.5038      0.5038        [94m1.5209[0m     +  0.0000  75.8763
     24      0.7083        1.0986       0.5040      0.5040        [94m1.5167[0m     +  0.0000  75.8874
     25      0.7500        [32m0.9723[0m       0.5040      0.5040        [94m1.5153[0m     +  0.0000  75.8522
     26      0.7500        0.9823       0.5042      0.5042        [94m1.5146[0m     +  0.0000  75.8296
     27      0.7083        1.0204       0.5042      0.5042        [94m1.5143[0m     +  0.0000  75.8325
     28      0.7083        0.9864       0.5047      0.5047        1.5145        0.0000  75.8228
     29      0.7500        0.9784       0.5047      0.5047        [94m1.5135[0m     +  0.0000  75.8400
     30      0.7500        [32m0.9533[0m       0.5047      0.5047        1.5136        0.0000  75.8081
     31      0.7500        0.9565       0.5042      0.5042        [94m1.5117[0m     +  0.0000  75.7584
     32      0.7500        [32m0.9388[0m       0.5035      0.5035        [94m1.5086[0m     +  0.0000  75.8529
     33      0.7500        [32m0.9313[0m       0.5028      0.5028        [94m1.5066[0m     +  0.0000  75.8224
     34      0.7500        0.9498       0.5023      0.5023        [94m1.5062[0m     +  0.0000  75.7723
     35      0.7500        [32m0.9094[0m       0.5021      0.5021        1.5071        0.0000  75.7895
     36      0.7500        0.9141       0.5021      0.5021        1.5084        0.0000  75.7383
     37      [36m0.7917[0m        [32m0.8907[0m       0.5021      0.5021        1.5084        0.0000  75.7986
     38      0.7500        [32m0.8788[0m       0.5021      0.5021        1.5075        0.0000  75.6352
     39      0.7500        [32m0.8580[0m       0.5021      0.5021        1.5065        0.0000  75.6817
     40      0.7500        0.9075       0.5028      0.5028        [94m1.5057[0m     +  0.0000  75.7097
     41      0.7500        [32m0.8554[0m       0.5033      0.5033        [94m1.5048[0m     +  0.0000  75.7974
     42      0.7500        [32m0.8494[0m       0.5038      0.5038        [94m1.5036[0m     +  0.0000  75.8238
     43      0.7917        0.8787       0.5038      0.5038        [94m1.5022[0m     +  0.0000  75.7895
     44      0.7500        0.8520       0.5036      0.5036        [94m1.5005[0m     +  0.0000  75.8037
     45      0.7500        0.9088       0.5035      0.5035        [94m1.4989[0m     +  0.0000  75.8197
     46      0.7917        [32m0.8219[0m       0.5036      0.5036        [94m1.4980[0m     +  0.0000  75.8757
     47      0.7917        0.8477       0.5038      0.5038        [94m1.4976[0m     +  0.0000  75.8236
     48      0.7917        0.8759       0.5040      0.5040        [94m1.4975[0m     +  0.0000  75.8799
     49      0.7500        0.8743       0.5042      0.5042        1.4977        0.0000  75.8072
     50      [36m0.8333[0m        0.8584       0.5047      0.5047        1.4980        0.0000  75.7393
     51      0.7917        0.8701       0.5047      0.5047        1.4983        0.0000  75.7505
     52      0.7917        0.8993       0.5049      0.5049        1.4983        0.0000  75.6922
     53      0.7917        0.8618       0.5052      0.5052        1.4982        0.0000  75.7132
     54      0.7917        0.9175       0.5052      0.5052        1.4983        0.0000  75.6204
     55      0.7917        0.8891       0.5052      0.5052        1.4982        0.0000  75.6525
     56      0.7500        0.8323       0.5052      0.5052        1.4980        0.0000  75.7005
     57      0.7500        0.8497       0.5050      0.5050        1.4978        0.0000  75.7043
     58      0.7500        0.9090       0.5052      0.5052        1.4977        0.0000  75.6325
     59      0.7917        [32m0.8191[0m       0.5052      0.5052        [94m1.4975[0m     +  0.0000  75.7189
     60      0.7917        0.8657       0.5052      0.5052        [94m1.4972[0m     +  0.0000  75.7708
     61      0.7500        0.8992       0.5052      0.5052        1.4972        0.0000  75.7939
     62      0.7500        0.8355       0.5052      0.5052        1.4973        0.0000  75.6620
     63      0.7500        0.8322       0.5052      0.5052        1.4973        0.0000  75.6334
     64      0.7500        0.8592       0.5052      0.5052        1.4973        0.0000  75.6469
     65      0.7500        0.8248       0.5052      0.5052        1.4973        0.0000  75.6536
     66      0.7917        0.8834       0.5052      0.5052        [94m1.4972[0m     +  0.0000  75.6976
     67      0.7917        0.8301       0.5052      0.5052        [94m1.4971[0m     +  0.0000  75.8085
     68      0.7917        [32m0.8120[0m       0.5052      0.5052        [94m1.4970[0m     +  0.0000  75.7768
     69      0.7917        0.8757       0.5052      0.5052        [94m1.4970[0m     +  0.0000  75.8287
     70      0.8333        [32m0.8010[0m       0.5052      0.5052        [94m1.4969[0m     +  0.0000  75.8684
     71      0.7500        0.8524       0.5052      0.5052        [94m1.4968[0m     +  0.0000  75.7772
     72      0.7917        0.8596       0.5052      0.5052        [94m1.4967[0m     +  0.0000  75.7366
     73      0.7917        0.8468       0.5052      0.5052        [94m1.4966[0m     +  0.0000  75.8106
     74      0.7917        0.8242       0.5052      0.5052        [94m1.4966[0m     +  0.0000  75.9169
     75      0.7500        0.8104       0.5052      0.5052        [94m1.4966[0m     +  0.0000  75.8220
     76      0.8333        0.8067       0.5054      0.5054        [94m1.4966[0m     +  0.0000  75.7573
     77      0.7917        0.8702       0.5054      0.5054        [94m1.4966[0m     +  0.0000  75.7917
     78      0.7917        0.8092       0.5056      0.5056        [94m1.4966[0m     +  0.0000  75.8090
     79      0.8333        0.8992       0.5056      0.5056        [94m1.4965[0m     +  0.0000  75.8211
     80      0.7917        0.8823       0.5056      0.5056        [94m1.4965[0m     +  0.0000  75.8049
     81      0.7917        0.8217       0.5056      0.5056        1.4965        0.0000  75.8706
     82      0.7917        0.8156       0.5056      0.5056        1.4965        0.0000  75.7188
     83      0.8333        0.8911       0.5056      0.5056        1.4965        0.0000  75.7256
     84      0.8333        0.8476       0.5056      0.5056        1.4965        0.0000  75.7394
     85      0.7917        0.8603       0.5056      0.5056        1.4965        0.0000  75.6942
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 2: Test F1 Micro Score: 0.5628472222222223
Iteration 2: Test F1 Macro Score: 0.1518863830622273
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_1.pt

Iteration 3: Requesting 32 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.6250[0m        [32m1.1528[0m       [35m0.5203[0m      [31m0.5203[0m        [94m1.4498[0m     +  0.0000  76.6756
      2      [36m0.6964[0m        [32m1.0176[0m       [35m0.5469[0m      [31m0.5469[0m        [94m1.4065[0m     +  0.0000  76.7451
      3      [36m0.7500[0m        [32m0.9161[0m       [35m0.5727[0m      [31m0.5727[0m        [94m1.3771[0m     +  0.0000  76.7983
      4      0.7500        [32m0.8779[0m       [35m0.6003[0m      [31m0.6003[0m        [94m1.3422[0m     +  0.0000  76.8529
      5      [36m0.8036[0m        [32m0.7997[0m       0.5915      0.5915        [94m1.3243[0m     +  0.0000  76.7796
      6      0.8036        [32m0.7173[0m       0.6000      0.6000        [94m1.3132[0m     +  0.0000  76.8982
      7      [36m0.8214[0m        [32m0.6709[0m       0.5854      0.5854        [94m1.3103[0m     +  0.0000  76.7896
      8      [36m0.8393[0m        [32m0.6294[0m       [35m0.6092[0m      [31m0.6092[0m        [94m1.2794[0m     +  0.0000  76.8244
      9      0.8393        [32m0.5897[0m       [35m0.6134[0m      [31m0.6134[0m        [94m1.2757[0m     +  0.0000  76.8855
     10      [36m0.8750[0m        [32m0.5395[0m       0.6007      0.6007        1.2900        0.0000  76.8535
     11      0.8750        [32m0.5225[0m       0.6028      0.6028        1.2879        0.0000  76.7841
     12      [36m0.9643[0m        [32m0.4597[0m       [35m0.6189[0m      [31m0.6189[0m        [94m1.2672[0m     +  0.0000  76.7227
     13      0.9464        [32m0.4029[0m       [35m0.6252[0m      [31m0.6252[0m        [94m1.2551[0m     +  0.0000  76.8194
     14      0.9286        0.4293       0.6109      0.6109        1.2642        0.0000  76.8032
     15      0.9286        0.4141       0.6128      0.6128        1.2603        0.0000  76.7097
     16      [36m0.9821[0m        [32m0.3822[0m       0.6240      0.6240        [94m1.2482[0m     +  0.0000  76.7724
     17      0.9821        0.4028       0.6179      0.6179        1.2569        0.0000  76.8264
     18      0.9821        [32m0.3506[0m       0.6200      0.6200        1.2520        0.0000  76.6314
     19      0.9821        [32m0.3467[0m       0.6210      0.6210        [94m1.2467[0m     +  0.0000  76.7616
     20      [36m1.0000[0m        [32m0.3318[0m       0.6160      0.6160        1.2591        0.0000  76.8042
     21      0.9821        [32m0.3210[0m       0.6122      0.6122        1.2648        0.0000  76.6967
     22      1.0000        0.3346       0.6139      0.6139        1.2532        0.0000  76.7772
     23      0.9821        [32m0.3024[0m       0.6144      0.6144        1.2539        0.0000  76.7567
     24      0.9821        0.3041       0.6177      0.6177        1.2485        0.0000  76.7127
     25      1.0000        [32m0.2979[0m       0.6184      0.6184        1.2477        0.0000  76.6464
     26      0.9821        [32m0.2765[0m       0.6189      0.6189        1.2475        0.0000  76.7213
     27      0.9821        0.2896       0.6191      0.6191        1.2493        0.0000  76.7400
     28      1.0000        [32m0.2655[0m       0.6153      0.6153        1.2558        0.0000  76.8227
     29      0.9821        0.2948       0.6161      0.6161        1.2555        0.0000  76.8490
     30      1.0000        0.2931       0.6215      0.6215        1.2484        0.0000  76.6557
     31      1.0000        0.2971       0.6200      0.6200        1.2512        0.0000  76.7012
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 3: Test F1 Micro Score: 0.6678819444444445
Iteration 3: Test F1 Macro Score: 0.22299008254692138
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_2.pt

Iteration 4: Requesting 56 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8661[0m        [32m0.7276[0m       [35m0.6755[0m      [31m0.6755[0m        [94m1.1010[0m     +  0.0000  78.4795
      2      [36m0.8839[0m        [32m0.5920[0m       [35m0.6766[0m      [31m0.6766[0m        [94m1.0215[0m     +  0.0000  78.4034
      3      [36m0.8929[0m        [32m0.5221[0m       0.6524      0.6524        1.0296        0.0000  78.4293
      4      [36m0.9196[0m        [32m0.4761[0m       0.6556      0.6556        [94m1.0118[0m     +  0.0000  78.4877
      5      [36m0.9286[0m        [32m0.3983[0m       0.6333      0.6333        1.0626        0.0000  78.4036
      6      [36m0.9643[0m        [32m0.3410[0m       0.6361      0.6361        1.0570        0.0000  78.4163
      7      [36m0.9821[0m        [32m0.3177[0m       0.6392      0.6392        1.0492        0.0000  78.4733
      8      [36m0.9911[0m        [32m0.3042[0m       [35m0.6807[0m      [31m0.6807[0m        [94m0.9587[0m     +  0.0000  78.3568
      9      0.9911        [32m0.2921[0m       [35m0.7128[0m      [31m0.7128[0m        [94m0.9064[0m     +  0.0000  78.4390
     10      0.9643        0.3114       [35m0.7219[0m      [31m0.7219[0m        0.9356        0.0000  78.4953
     11      [36m1.0000[0m        0.2960       0.6201      0.6201        1.1440        0.0000  78.4548
     12      1.0000        [32m0.2474[0m       0.6651      0.6651        1.0055        0.0000  78.4789
     13      1.0000        [32m0.2082[0m       0.6689      0.6689        0.9787        0.0000  78.5200
     14      1.0000        [32m0.1825[0m       0.6687      0.6687        0.9719        0.0000  78.5112
     15      1.0000        [32m0.1776[0m       0.6611      0.6611        1.0141        0.0000  78.4113
     16      1.0000        [32m0.1743[0m       0.6632      0.6632        0.9976        0.0000  78.4619
     17      1.0000        0.1773       0.6672      0.6672        0.9852        0.0000  78.3236
     18      1.0000        [32m0.1660[0m       0.6630      0.6630        1.0054        0.0000  78.3932
     19      1.0000        [32m0.1586[0m       0.6625      0.6625        1.0042        0.0000  78.4959
     20      1.0000        0.1672       0.6656      0.6656        0.9890        0.0000  78.5132
     21      1.0000        0.1626       0.6632      0.6632        1.0078        0.0000  78.3889
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 4: Test F1 Micro Score: 0.6958333333333333
Iteration 4: Test F1 Macro Score: 0.25121261057766553
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_3.pt

Iteration 5: Requesting 96 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.8942[0m        [32m0.5134[0m       [35m0.6793[0m      [31m0.6793[0m        [94m0.9702[0m     +  0.0000  81.3513
      2      [36m0.9183[0m        [32m0.4762[0m       [35m0.7007[0m      [31m0.7007[0m        [94m0.8487[0m     +  0.0000  81.4428
      3      [36m0.9519[0m        [32m0.3586[0m       [35m0.7259[0m      [31m0.7259[0m        [94m0.8214[0m     +  0.0000  81.3103
      4      0.9519        [32m0.3022[0m       0.7253      0.7253        0.8332        0.0000  81.4236
      5      [36m0.9760[0m        [32m0.2618[0m       0.7255      0.7255        0.8244        0.0000  81.4127
      6      [36m0.9808[0m        [32m0.2312[0m       [35m0.7425[0m      [31m0.7425[0m        [94m0.7916[0m     +  0.0000  81.3224
      7      0.9663        0.2565       0.7375      0.7375        0.7992        0.0000  81.4372
      8      [36m0.9952[0m        [32m0.1902[0m       [35m0.7486[0m      [31m0.7486[0m        [94m0.7708[0m     +  0.0000  81.4641
      9      0.9904        [32m0.1853[0m       [35m0.7491[0m      [31m0.7491[0m        0.7866        0.0000  81.5192
     10      0.9952        [32m0.1609[0m       [35m0.7497[0m      [31m0.7497[0m        0.8322        0.0000  81.3684
     11      0.9952        [32m0.1587[0m       0.7405      0.7405        0.8719        0.0000  81.3213
     12      [36m1.0000[0m        [32m0.1369[0m       0.7307      0.7307        0.9331        0.0000  81.2929
     13      1.0000        [32m0.1301[0m       0.7191      0.7191        0.8510        0.0000  81.3240
     14      1.0000        [32m0.1123[0m       0.7344      0.7344        0.8222        0.0000  81.3107
     15      1.0000        [32m0.1038[0m       0.7321      0.7321        0.8308        0.0000  81.3100
     16      1.0000        0.1045       0.7378      0.7378        0.8268        0.0000  81.3915
     17      1.0000        0.1047       0.7351      0.7351        0.8294        0.0000  81.3385
     18      1.0000        [32m0.0998[0m       0.7398      0.7398        0.8273        0.0000  81.3431
     19      1.0000        [32m0.0980[0m       0.7424      0.7424        0.8219        0.0000  81.3393
     20      1.0000        [32m0.0931[0m       0.7415      0.7415        0.8242        0.0000  81.3215
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 5: Test F1 Micro Score: 0.7465277777777777
Iteration 5: Test F1 Macro Score: 0.2930127163950224
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_4.pt

Iteration 6: Requesting 176 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9271[0m        [32m0.3522[0m       [35m0.7918[0m      [31m0.7918[0m        [94m0.7239[0m     +  0.0000  86.7190
      2      0.9036        0.3544       0.7753      0.7753        0.7248        0.0000  86.8640
      3      [36m0.9557[0m        [32m0.2551[0m       [35m0.8045[0m      [31m0.8045[0m        [94m0.6721[0m     +  0.0000  86.9701
      4      [36m0.9661[0m        [32m0.2231[0m       0.7648      0.7648        0.7770        0.0000  86.9034
      5      [36m0.9792[0m        [32m0.1744[0m       0.7962      0.7962        0.6899        0.0000  86.9552
      6      [36m0.9922[0m        [32m0.1331[0m       0.7898      0.7898        0.7379        0.0000  87.3998
      7      [36m0.9948[0m        [32m0.1139[0m       0.7984      0.7984        0.6872        0.0000  87.2539
      8      0.9948        [32m0.0948[0m       [35m0.8049[0m      [31m0.8049[0m        [94m0.6602[0m     +  0.0000  87.0424
      9      0.9948        [32m0.0903[0m       0.7993      0.7993        0.6741        0.0000  87.0680
     10      0.9948        [32m0.0854[0m       0.7995      0.7995        0.6827        0.0000  86.9840
     11      0.9948        [32m0.0776[0m       0.7990      0.7990        0.6950        0.0000  87.6282
     12      0.9948        [32m0.0729[0m       0.8047      0.8047        0.6808        0.0000  87.3737
     13      [36m1.0000[0m        [32m0.0674[0m       0.8019      0.8019        0.6997        0.0000  87.5381
     14      1.0000        [32m0.0656[0m       0.8035      0.8035        0.6956        0.0000  86.9574
     15      0.9974        [32m0.0647[0m       0.7991      0.7991        0.7083        0.0000  86.9993
     16      0.9974        0.0648       [35m0.8059[0m      [31m0.8059[0m        0.6946        0.0000  87.0492
     17      1.0000        [32m0.0610[0m       0.8033      0.8033        0.6981        0.0000  86.9359
     18      1.0000        0.0613       0.8038      0.8038        0.7066        0.0000  86.9971
     19      1.0000        [32m0.0558[0m       0.8054      0.8054        0.6965        0.0000  86.9853
     20      1.0000        [32m0.0531[0m       0.8036      0.8036        0.7157        0.0000  86.9876
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 6: Test F1 Micro Score: 0.7850694444444445
Iteration 6: Test F1 Macro Score: 0.3202235353483067
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_5.pt

Iteration 7: Requesting 320 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  -------
      1      [36m0.9190[0m        [32m0.3306[0m       [35m0.8106[0m      [31m0.8106[0m        [94m0.5920[0m     +  0.0000  96.9847
      2      [36m0.9304[0m        [32m0.2711[0m       0.7733      0.7733        0.8061        0.0000  97.0561
      3      [36m0.9503[0m        [32m0.2159[0m       0.8010      0.8010        0.6973        0.0000  96.9897
      4      [36m0.9631[0m        [32m0.1675[0m       0.7990      0.7990        0.6691        0.0000  96.9740
      5      [36m0.9645[0m        [32m0.1492[0m       0.8092      0.8092        0.6345        0.0000  96.9460
      6      [36m0.9787[0m        [32m0.1204[0m       0.8026      0.8026        0.6362        0.0000  96.9397
      7      [36m0.9830[0m        [32m0.1089[0m       0.8068      0.8068        0.6151        0.0000  97.0728
      8      [36m0.9858[0m        [32m0.0920[0m       0.8021      0.8021        0.6360        0.0000  97.3098
      9      [36m0.9915[0m        [32m0.0835[0m       0.7816      0.7816        0.7708        0.0000  97.8373
     10      [36m0.9972[0m        [32m0.0689[0m       0.8090      0.8090        0.6641        0.0000  98.2334
     11      0.9972        [32m0.0595[0m       [35m0.8137[0m      [31m0.8137[0m        0.6553        0.0000  99.2346
     12      [36m0.9986[0m        [32m0.0554[0m       0.8123      0.8123        0.6594        0.0000  98.7209
     13      0.9986        [32m0.0521[0m       0.8095      0.8095        0.6966        0.0000  98.6069
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 7: Test F1 Micro Score: 0.8097222222222222
Iteration 7: Test F1 Macro Score: 0.381734125945857
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_6.pt

Iteration 8: Requesting 560 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9051[0m        [32m0.3434[0m       [35m0.8153[0m      [31m0.8153[0m        [94m0.5587[0m     +  0.0000  115.2604
      2      [36m0.9367[0m        [32m0.2439[0m       0.7858      0.7858        0.6691        0.0000  115.4581
      3      [36m0.9573[0m        [32m0.1865[0m       0.8123      0.8123        0.5632        0.0000  115.3209
      4      [36m0.9612[0m        [32m0.1637[0m       0.7703      0.7703        0.6812        0.0000  115.3020
      5      [36m0.9739[0m        [32m0.1398[0m       [35m0.8215[0m      [31m0.8215[0m        [94m0.5539[0m     +  0.0000  115.0974
      6      [36m0.9778[0m        [32m0.1229[0m       [35m0.8280[0m      [31m0.8280[0m        0.5706        0.0000  115.2677
      7      [36m0.9802[0m        [32m0.1134[0m       0.7995      0.7995        0.7066        0.0000  115.1714
      8      [36m0.9842[0m        [32m0.0963[0m       0.8253      0.8253        0.6386        0.0000  115.0940
      9      [36m0.9873[0m        [32m0.0911[0m       0.7955      0.7955        0.7302        0.0000  115.0733
     10      0.9873        [32m0.0859[0m       0.8128      0.8128        0.7751        0.0000  115.1047
     11      0.9858        [32m0.0837[0m       0.8217      0.8217        0.7512        0.0000  115.0657
     12      [36m0.9905[0m        [32m0.0776[0m       0.8273      0.8273        0.5868        0.0000  115.1207
     13      [36m0.9960[0m        [32m0.0525[0m       [35m0.8358[0m      [31m0.8358[0m        0.6373        0.0000  115.0462
     14      [36m0.9968[0m        [32m0.0442[0m       0.8328      0.8328        0.6411        0.0000  115.0669
     15      [36m0.9976[0m        [32m0.0419[0m       0.8302      0.8302        0.6482        0.0000  114.9001
     16      [36m0.9984[0m        [32m0.0403[0m       [35m0.8394[0m      [31m0.8394[0m        0.6199        0.0000  114.9818
     17      0.9968        [32m0.0377[0m       [35m0.8432[0m      [31m0.8432[0m        0.6108        0.0000  114.9398
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 8: Test F1 Micro Score: 0.8229166666666666
Iteration 8: Test F1 Macro Score: 0.4007781553939146
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_7.pt

Iteration 9: Requesting 1000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9457[0m        [32m0.2166[0m       [35m0.8217[0m      [31m0.8217[0m        [94m0.5873[0m     +  0.0000  145.9588
      2      [36m0.9598[0m        [32m0.1613[0m       0.8151      0.8151        [94m0.5694[0m     +  0.0000  146.1285
      3      [36m0.9744[0m        [32m0.1255[0m       [35m0.8297[0m      [31m0.8297[0m        [94m0.5111[0m     +  0.0000  146.1756
      4      [36m0.9810[0m        [32m0.0990[0m       0.8156      0.8156        0.5524        0.0000  146.3003
      5      [36m0.9837[0m        [32m0.0887[0m       0.8290      0.8290        0.5584        0.0000  145.9742
      6      0.9828        [32m0.0804[0m       [35m0.8418[0m      [31m0.8418[0m        0.5763        0.0000  145.9258
      7      [36m0.9850[0m        [32m0.0739[0m       0.8122      0.8122        0.7264        0.0000  145.9286
      8      0.9814        0.0860       0.8394      0.8394        0.5742        0.0000  145.9880
      9      [36m0.9890[0m        [32m0.0645[0m       0.8141      0.8141        0.6505        0.0000  146.1282
     10      0.9872        0.0656       0.8415      0.8415        0.6263        0.0000  145.9369
     11      [36m0.9912[0m        [32m0.0527[0m       [35m0.8439[0m      [31m0.8439[0m        0.6698        0.0000  145.9428
     12      [36m0.9965[0m        [32m0.0378[0m       0.8380      0.8380        0.6788        0.0000  145.9324
     13      [36m0.9973[0m        [32m0.0336[0m       [35m0.8495[0m      [31m0.8495[0m        0.6469        0.0000  145.9200
     14      [36m0.9982[0m        [32m0.0283[0m       0.8490      0.8490        0.6342        0.0000  146.0381
     15      0.9978        [32m0.0269[0m       0.8488      0.8488        0.6442        0.0000  146.0484
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 9: Test F1 Micro Score: 0.8548611111111111
Iteration 9: Test F1 Macro Score: 0.5203520787978998
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_8.pt

Iteration 10: Requesting 1776 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9562[0m        [32m0.1689[0m       [35m0.8266[0m      [31m0.8266[0m        [94m0.5312[0m     +  0.0000  200.9638
      2      [36m0.9681[0m        [32m0.1301[0m       [35m0.8300[0m      [31m0.8300[0m        0.5757        0.0000  201.2761
      3      [36m0.9745[0m        [32m0.1144[0m       0.8127      0.8127        0.6841        0.0000  201.2907
      4      [36m0.9777[0m        [32m0.0983[0m       [35m0.8382[0m      [31m0.8382[0m        0.5550        0.0000  201.1448
      5      [36m0.9804[0m        [32m0.0840[0m       [35m0.8410[0m      [31m0.8410[0m        0.5401        0.0000  201.1137
      6      [36m0.9829[0m        [32m0.0706[0m       [35m0.8556[0m      [31m0.8556[0m        [94m0.5139[0m     +  0.0000  201.0984
      7      [36m0.9839[0m        [32m0.0694[0m       [35m0.8618[0m      [31m0.8618[0m        [94m0.4999[0m     +  0.0000  201.1960
      8      0.9804        0.0778       0.7932      0.7932        0.8242        0.0000  201.2721
      9      [36m0.9847[0m        [32m0.0631[0m       0.8057      0.8057        0.7326        0.0000  201.1241
     10      [36m0.9896[0m        [32m0.0506[0m       0.8446      0.8446        0.5321        0.0000  201.0803
     11      [36m0.9923[0m        [32m0.0402[0m       0.8457      0.8457        0.5905        0.0000  201.1646
     12      0.9923        [32m0.0369[0m       0.8512      0.8512        0.5950        0.0000  201.0894
     13      [36m0.9941[0m        [32m0.0343[0m       0.8401      0.8401        0.5951        0.0000  201.2526
     14      [36m0.9978[0m        [32m0.0220[0m       0.8410      0.8410        0.6273        0.0000  201.1329
     15      0.9965        [32m0.0206[0m       0.8470      0.8470        0.6263        0.0000  201.4512
     16      [36m0.9983[0m        [32m0.0163[0m       0.8339      0.8339        0.6531        0.0000  201.0650
     17      0.9978        0.0185       0.8207      0.8207        0.7490        0.0000  201.2010
     18      0.9975        0.0183       0.8245      0.8245        0.7464        0.0000  201.0409
     19      [36m0.9993[0m        [32m0.0121[0m       0.8493      0.8493        0.6704        0.0000  201.1926
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 10: Test F1 Micro Score: 0.845486111111111
Iteration 10: Test F1 Macro Score: 0.5636644387331149
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_9.pt

Iteration 11: Requesting 3160 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9686[0m        [32m0.1250[0m       [35m0.8516[0m      [31m0.8516[0m        [94m0.4467[0m     +  0.0000  299.2683
      2      [36m0.9743[0m        [32m0.1009[0m       [35m0.8627[0m      [31m0.8627[0m        [94m0.4197[0m     +  0.0000  299.5830
      3      [36m0.9803[0m        [32m0.0794[0m       0.8438      0.8438        0.5012        0.0000  299.5273
      4      [36m0.9842[0m        [32m0.0627[0m       0.8366      0.8366        0.5910        0.0000  299.2665
      5      [36m0.9878[0m        [32m0.0528[0m       0.7832      0.7832        0.8433        0.0000  299.3004
      6      0.9851        0.0550       0.8465      0.8465        0.5478        0.0000  299.4223
      7      [36m0.9883[0m        [32m0.0475[0m       0.8293      0.8293        0.6499        0.0000  299.1886
      8      [36m0.9924[0m        [32m0.0383[0m       0.8179      0.8179        0.7374        0.0000  299.2982
      9      0.9879        0.0480       0.8387      0.8387        0.6808        0.0000  299.2368
     10      0.9912        [32m0.0336[0m       0.8410      0.8410        0.6935        0.0000  299.4821
     11      0.9918        [32m0.0316[0m       0.8592      0.8592        0.5144        0.0000  299.3674
     12      [36m0.9925[0m        0.0336       0.8446      0.8446        0.6956        0.0000  299.2947
     13      [36m0.9962[0m        [32m0.0191[0m       0.8595      0.8595        0.5751        0.0000  299.2015
     14      [36m0.9982[0m        [32m0.0124[0m       0.8582      0.8582        0.6206        0.0000  299.2763
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 11: Test F1 Micro Score: 0.8619791666666666
Iteration 11: Test F1 Macro Score: 0.5764240818590424
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_10.pt

Iteration 12: Requesting 5624 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9630[0m        [32m0.1260[0m       [35m0.8536[0m      [31m0.8536[0m        [94m0.5135[0m     +  0.0000  474.0901
      2      [36m0.9733[0m        [32m0.0960[0m       [35m0.8655[0m      [31m0.8655[0m        [94m0.4561[0m     +  0.0000  473.9045
      3      [36m0.9746[0m        [32m0.0876[0m       0.8625      0.8625        [94m0.4149[0m     +  0.0000  473.7493
      4      [36m0.9786[0m        [32m0.0731[0m       0.8434      0.8434        0.4959        0.0000  474.2462
      5      [36m0.9832[0m        [32m0.0582[0m       0.8420      0.8420        0.5558        0.0000  473.8678
      6      [36m0.9840[0m        [32m0.0560[0m       0.8264      0.8264        0.6722        0.0000  473.8803
      7      [36m0.9849[0m        [32m0.0495[0m       0.8212      0.8212        0.6719        0.0000  473.7940
      8      [36m0.9884[0m        [32m0.0389[0m       0.8290      0.8290        0.6219        0.0000  473.7543
      9      [36m0.9904[0m        [32m0.0373[0m       0.8283      0.8283        0.7328        0.0000  473.7081
     10      0.9899        [32m0.0338[0m       0.8243      0.8243        0.6020        0.0000  474.0035
     11      0.9903        [32m0.0305[0m       0.8113      0.8113        0.7382        0.0000  474.1071
     12      [36m0.9925[0m        [32m0.0292[0m       0.8325      0.8325        0.6415        0.0000  473.9358
     13      [36m0.9956[0m        [32m0.0180[0m       0.8398      0.8398        0.6793        0.0000  473.9408
     14      [36m0.9983[0m        [32m0.0109[0m       0.8280      0.8280        0.8663        0.0000  473.9159
     15      0.9979        [32m0.0104[0m       0.8187      0.8187        0.8196        0.0000  473.9624
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 12: Test F1 Micro Score: 0.8494791666666667
Iteration 12: Test F1 Macro Score: 0.583566132642521
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_11.pt

Iteration 13: Requesting 10000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9676[0m        [32m0.1072[0m       [35m0.8740[0m      [31m0.8740[0m        [94m0.4078[0m     +  0.0000  783.6914
      2      [36m0.9732[0m        [32m0.0855[0m       0.8595      0.8595        0.4819        0.0000  785.1611
      3      [36m0.9759[0m        [32m0.0729[0m       0.8632      0.8632        0.5442        0.0000  784.9185
      4      [36m0.9789[0m        [32m0.0641[0m       [35m0.8804[0m      [31m0.8804[0m        0.5148        0.0000  784.7727
      5      [36m0.9822[0m        [32m0.0553[0m       0.8793      0.8793        0.5177        0.0000  784.7158
      6      [36m0.9844[0m        [32m0.0485[0m       0.8693      0.8693        0.5657        0.0000  789.2512
      7      [36m0.9866[0m        [32m0.0407[0m       0.8497      0.8497        0.6400        0.0000  788.0453
      8      [36m0.9883[0m        [32m0.0368[0m       0.8688      0.8688        0.5920        0.0000  785.9707
      9      [36m0.9904[0m        [32m0.0307[0m       0.8632      0.8632        0.6210        0.0000  786.0207
     10      [36m0.9923[0m        [32m0.0262[0m       0.8630      0.8630        0.6752        0.0000  786.2503
     11      [36m0.9927[0m        [32m0.0246[0m       0.8385      0.8385        0.7818        0.0000  785.7486
     12      0.9926        [32m0.0240[0m       0.8481      0.8481        0.7832        0.0000  785.2505
     13      [36m0.9967[0m        [32m0.0136[0m       0.8568      0.8568        0.7219        0.0000  784.9283
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 13: Test F1 Micro Score: 0.8598958333333333
Iteration 13: Test F1 Macro Score: 0.5968373535013483
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_12.pt

Iteration 14: Requesting all remaining samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  ------  --------
      1      [36m0.9692[0m        [32m0.0967[0m       [35m0.8448[0m      [31m0.8448[0m        [94m0.4847[0m     +  0.0000  908.9218
      2      [36m0.9747[0m        [32m0.0793[0m       0.8311      0.8311        0.5777        0.0000  910.9812
      3      [36m0.9784[0m        [32m0.0666[0m       [35m0.8649[0m      [31m0.8649[0m        [94m0.4378[0m     +  0.0000  910.6578
      4      [36m0.9815[0m        [32m0.0565[0m       0.8453      0.8453        0.5230        0.0000  910.8145
      5      [36m0.9833[0m        [32m0.0505[0m       0.8451      0.8451        0.5410        0.0000  910.4923
      6      [36m0.9863[0m        [32m0.0398[0m       0.8460      0.8460        0.6256        0.0000  912.4106
      7      [36m0.9876[0m        [32m0.0374[0m       0.8330      0.8330        0.6812        0.0000  912.3443
      8      [36m0.9896[0m        [32m0.0317[0m       0.8257      0.8257        0.7638        0.0000  911.9907
      9      [36m0.9909[0m        [32m0.0286[0m       0.8372      0.8372        0.7764        0.0000  908.2298
     10      [36m0.9932[0m        [32m0.0244[0m       0.8410      0.8410        0.7041        0.0000  906.5661
     11      0.9927        [32m0.0238[0m       0.8418      0.8418        0.7552        0.0000  910.9179
     12      [36m0.9936[0m        [32m0.0212[0m       0.8300      0.8300        0.8038        0.0000  912.2948
     13      [36m0.9968[0m        [32m0.0112[0m       0.8358      0.8358        0.9092        0.0000  911.1338
     14      [36m0.9981[0m        [32m0.0082[0m       0.8325      0.8325        0.9177        0.0000  911.5755
     15      [36m0.9987[0m        [32m0.0065[0m       0.8328      0.8328        0.9496        0.0000  910.4749
Stopping since valid_loss has not improved in the last 13 epochs.
Iteration 14: Test F1 Micro Score: 0.8564236111111111
Iteration 14: Test F1 Macro Score: 0.6070215163821165
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr/model_checkpoint_iteration_13.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\RandomSampling/Multiclass/DinoL/seed_42_low_lr\random_sampling_results_for_multilabel_classification_s42.pickle
