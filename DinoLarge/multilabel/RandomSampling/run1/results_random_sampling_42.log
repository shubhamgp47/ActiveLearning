Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)

Iteration 1: Using initial samples.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.7374[0m        [32m0.7129[0m       [35m0.1227[0m      [31m0.4134[0m        [94m0.7027[0m     +  74.8900
      2      0.5778        [32m0.6839[0m       [35m0.1615[0m      [31m0.5167[0m        [94m0.7008[0m     +  76.0133
      3      0.5599        [32m0.6747[0m       [35m0.1842[0m      [31m0.5803[0m        [94m0.7003[0m     +  76.8622
      4      0.7374        0.7233       0.1731      [31m0.5815[0m        [94m0.6994[0m     +  76.8068
      5      [36m0.8500[0m        [32m0.6678[0m       0.1769      [31m0.5864[0m        [94m0.6984[0m     +  76.7346
      6      0.6985        [32m0.6630[0m       0.1679      0.5812        [94m0.6975[0m     +  76.7104
      7      0.7389        [32m0.6438[0m       0.1538      0.5632        [94m0.6965[0m     +  76.7345
      8      0.4563        0.6506       0.1651      0.5503        [94m0.6951[0m     +  76.6884
      9      0.5889        0.6506       [35m0.1910[0m      0.5477        [94m0.6936[0m     +  76.7027
     10      0.8426        [32m0.6197[0m       [35m0.2071[0m      0.5474        [94m0.6917[0m     +  76.6903
     11      0.7963        [32m0.6028[0m       [35m0.2108[0m      0.5387        [94m0.6899[0m     +  76.7385
     12      0.8500        [32m0.5811[0m       [35m0.2118[0m      0.5305        [94m0.6886[0m     +  76.7676
     13      0.7831        0.6123       0.2104      0.5216        [94m0.6872[0m     +  76.7715
     14      [36m0.8796[0m        0.5836       0.2102      0.5137        [94m0.6860[0m     +  76.7044
     15      0.7963        [32m0.5787[0m       0.2083      0.5082        [94m0.6854[0m     +  76.7371
     16      [36m0.8963[0m        [32m0.5655[0m       0.2102      0.5082        0.6856        76.7386
     17      0.8593        [32m0.5378[0m       0.2062      0.5079        0.6859        76.6858
     18      [36m0.9259[0m        [32m0.5290[0m       0.2033      0.5095        0.6867        76.6877
     19      0.8426        0.5480       0.2017      0.5115        0.6873        76.6077
     20      0.8426        0.5492       0.2024      0.5149        0.6878        76.6056
     21      0.8889        [32m0.4998[0m       0.2052      0.5175        0.6881        76.5968
     22      0.8426        0.5206       0.2064      0.5192        0.6881        76.6321
     23      0.8783        [32m0.4940[0m       0.2062      0.5211        0.6878        76.5412
     24      0.9259        0.4962       0.2059      0.5224        0.6868        76.4896
     25      [36m0.9630[0m        [32m0.4526[0m       0.2057      0.5233        0.6859        76.4731
     26      0.9259        0.4611       0.2071      0.5248        [94m0.6850[0m     +  76.4824
     27      0.9259        [32m0.4416[0m       0.2118      0.5284        [94m0.6844[0m     +  76.5173
     28      0.9630        0.4612       [35m0.2220[0m      0.5335        [94m0.6843[0m     +  76.5553
     29      0.9630        [32m0.4090[0m       [35m0.2304[0m      0.5382        0.6845        76.5724
     30      0.9259        0.4365       [35m0.2342[0m      0.5396        0.6852        76.5441
     31      0.9630        0.4153       0.2314      0.5378        0.6861        76.5226
     32      0.9630        [32m0.4075[0m       0.2280      0.5363        0.6869        76.5119
     33      [36m1.0000[0m        [32m0.3851[0m       0.2260      0.5364        0.6876        76.5201
     34      1.0000        0.3881       0.2257      0.5363        0.6877        76.5211
     35      1.0000        [32m0.3717[0m       0.2271      0.5386        0.6880        76.5208
     36      0.9630        [32m0.3667[0m       0.2286      0.5386        0.6879        76.5060
     37      0.9630        [32m0.3452[0m       0.2316      0.5385        0.6875        76.4279
     38      0.9630        0.3690       0.2309      0.5364        0.6868        76.4452
     39      1.0000        [32m0.3433[0m       0.2332      0.5358        0.6861        76.5052
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 1: Test F1 Micro Score: 0.56437795678302
Iteration 1: Test F1 Macro Score: 0.5559964057346997
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_0.pt

Iteration 2: Requesting 16 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.7242[0m        [32m0.5795[0m       [35m0.2132[0m      [31m0.5041[0m        [94m0.6692[0m     +  76.9848
      2      [36m0.7299[0m        [32m0.5474[0m       [35m0.2295[0m      0.4874        [94m0.6474[0m     +  76.9648
      3      [36m0.7685[0m        [32m0.5092[0m       [35m0.2658[0m      0.4893        [94m0.6289[0m     +  77.0007
      4      0.6989        [32m0.4970[0m       [35m0.2826[0m      0.4926        [94m0.6149[0m     +  77.0876
      5      0.7333        [32m0.4791[0m       [35m0.2938[0m      0.5012        [94m0.6032[0m     +  77.1033
      6      [36m0.7762[0m        [32m0.4538[0m       [35m0.3153[0m      [31m0.5269[0m        [94m0.5932[0m     +  77.0919
      7      0.7569        [32m0.4339[0m       [35m0.3595[0m      [31m0.5634[0m        [94m0.5834[0m     +  77.0677
      8      [36m0.8590[0m        [32m0.4044[0m       [35m0.4009[0m      [31m0.6085[0m        [94m0.5727[0m     +  77.1158
      9      [36m0.8713[0m        [32m0.3944[0m       [35m0.4259[0m      [31m0.6405[0m        [94m0.5605[0m     +  77.0871
     10      0.8590        [32m0.3821[0m       [35m0.4363[0m      [31m0.6529[0m        [94m0.5489[0m     +  77.1139
     11      [36m0.9538[0m        [32m0.3622[0m       [35m0.4470[0m      [31m0.6605[0m        [94m0.5398[0m     +  77.1018
     12      0.9538        [32m0.3558[0m       [35m0.4568[0m      [31m0.6665[0m        [94m0.5317[0m     +  77.0970
     13      0.9030        [32m0.3257[0m       [35m0.4686[0m      [31m0.6791[0m        [94m0.5230[0m     +  77.1198
     14      0.9333        [32m0.3149[0m       [35m0.4849[0m      [31m0.6981[0m        [94m0.5151[0m     +  77.0740
     15      0.9333        [32m0.3075[0m       [35m0.5062[0m      [31m0.7176[0m        [94m0.5075[0m     +  77.0424
     16      [36m1.0000[0m        [32m0.2854[0m       [35m0.5335[0m      [31m0.7336[0m        [94m0.5001[0m     +  77.0504
     17      0.9697        [32m0.2801[0m       [35m0.5462[0m      [31m0.7411[0m        [94m0.4922[0m     +  77.0929
     18      1.0000        [32m0.2498[0m       [35m0.5469[0m      [31m0.7446[0m        [94m0.4851[0m     +  77.1073
     19      1.0000        0.2564       [35m0.5484[0m      [31m0.7507[0m        [94m0.4791[0m     +  77.0805
     20      1.0000        [32m0.2434[0m       [35m0.5512[0m      [31m0.7557[0m        [94m0.4762[0m     +  77.0567
     21      1.0000        [32m0.2370[0m       [35m0.5573[0m      [31m0.7569[0m        [94m0.4740[0m     +  77.0244
     22      1.0000        [32m0.2304[0m       0.5571      0.7542        [94m0.4720[0m     +  77.0440
     23      1.0000        0.2306       [35m0.5637[0m      [31m0.7587[0m        [94m0.4680[0m     +  77.0410
     24      1.0000        [32m0.2162[0m       [35m0.5651[0m      [31m0.7610[0m        [94m0.4635[0m     +  77.0379
     25      1.0000        [32m0.2030[0m       [35m0.5717[0m      [31m0.7642[0m        [94m0.4591[0m     +  77.0687
     26      1.0000        [32m0.1897[0m       [35m0.5741[0m      [31m0.7652[0m        [94m0.4544[0m     +  77.0849
     27      1.0000        0.1916       [35m0.5778[0m      [31m0.7673[0m        [94m0.4516[0m     +  77.0798
     28      1.0000        [32m0.1733[0m       0.5767      0.7671        [94m0.4493[0m     +  77.0386
     29      1.0000        0.1818       [35m0.5806[0m      [31m0.7691[0m        [94m0.4464[0m     +  77.1204
     30      1.0000        0.1843       [35m0.5816[0m      0.7682        [94m0.4455[0m     +  77.1188
     31      1.0000        [32m0.1716[0m       0.5780      0.7635        [94m0.4445[0m     +  77.0881
     32      1.0000        [32m0.1687[0m       0.5738      0.7598        [94m0.4440[0m     +  77.1198
     33      1.0000        0.1714       0.5771      0.7602        [94m0.4414[0m     +  77.0557
     34      1.0000        [32m0.1594[0m       [35m0.5852[0m      0.7671        [94m0.4355[0m     +  77.0769
     35      1.0000        0.1722       [35m0.5868[0m      0.7689        [94m0.4320[0m     +  77.0701
     36      1.0000        [32m0.1424[0m       0.5760      0.7645        0.4334        77.0528
     37      1.0000        0.1494       0.5736      0.7634        0.4341        77.0753
     38      1.0000        0.1482       0.5852      0.7631        0.4328        76.9846
     39      1.0000        0.1463       0.5847      0.7624        0.4328        76.9700
     40      1.0000        [32m0.1389[0m       0.5762      0.7611        0.4330        77.0076
     41      1.0000        [32m0.1277[0m       0.5797      0.7626        0.4322        76.9898
     42      1.0000        0.1457       0.5847      0.7606        [94m0.4311[0m     +  76.9568
     43      1.0000        0.1358       0.5786      0.7597        [94m0.4291[0m     +  76.9591
     44      1.0000        0.1324       0.5753      0.7591        [94m0.4287[0m     +  77.0604
     45      1.0000        [32m0.1255[0m       0.5729      0.7576        0.4298        77.0977
     46      1.0000        [32m0.1244[0m       0.5740      0.7589        0.4290        77.0406
     47      1.0000        [32m0.1207[0m       0.5806      0.7604        [94m0.4278[0m     +  77.0074
     48      1.0000        [32m0.1118[0m       0.5771      0.7601        [94m0.4261[0m     +  77.0598
     49      1.0000        0.1248       0.5774      0.7624        [94m0.4249[0m     +  77.0627
     50      1.0000        [32m0.1096[0m       0.5830      0.7629        [94m0.4247[0m     +  77.0253
     51      1.0000        0.1140       0.5740      0.7619        0.4251        77.1125
     52      1.0000        0.1147       0.5684      0.7599        0.4255        77.1020
     53      1.0000        0.1104       0.5786      0.7600        0.4253        77.0233
     54      1.0000        0.1099       0.5743      0.7587        [94m0.4244[0m     +  77.0749
     55      1.0000        0.1165       0.5757      0.7609        [94m0.4227[0m     +  77.0646
     56      1.0000        [32m0.1094[0m       0.5858      0.7654        [94m0.4187[0m     +  77.0786
     57      1.0000        [32m0.1073[0m       0.5852      [31m0.7694[0m        [94m0.4157[0m     +  77.0766
     58      1.0000        0.1104       0.5837      [31m0.7695[0m        0.4162        77.1261
     59      1.0000        [32m0.1043[0m       0.5865      0.7653        0.4185        77.0738
     60      1.0000        [32m0.0964[0m       0.5840      0.7671        0.4181        77.0236
     61      1.0000        0.1043       0.5804      0.7674        0.4175        76.9675
     62      1.0000        0.1008       0.5859      0.7688        0.4162        76.9885
     63      1.0000        0.1099       0.5844      0.7654        0.4165        76.9712
     64      1.0000        [32m0.0920[0m       0.5766      0.7615        0.4184        77.0703
     65      1.0000        0.0977       0.5793      0.7620        0.4175        76.9921
     66      1.0000        0.0961       0.5845      0.7638        0.4168        77.0488
     67      1.0000        [32m0.0875[0m       0.5776      0.7656        0.4159        77.0201
     68      1.0000        0.0890       0.5788      0.7660        0.4168        76.9739
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 2: Test F1 Micro Score: 0.7675328741390107
Iteration 2: Test F1 Macro Score: 0.760427546058454
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_1.pt

Iteration 3: Requesting 32 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.8644[0m        [32m0.2937[0m       [35m0.5920[0m      [31m0.7674[0m        [94m0.4038[0m     +  77.9910
      2      [36m0.9042[0m        [32m0.2281[0m       [35m0.6483[0m      [31m0.8128[0m        [94m0.3530[0m     +  77.9824
      3      [36m0.9524[0m        [32m0.2021[0m       [35m0.6738[0m      [31m0.8250[0m        [94m0.3302[0m     +  78.0528
      4      0.9429        [32m0.1900[0m       [35m0.6889[0m      [31m0.8510[0m        [94m0.3178[0m     +  78.0702
      5      [36m0.9742[0m        [32m0.1694[0m       [35m0.7030[0m      0.8472        [94m0.3115[0m     +  78.0741
      6      0.9576        [32m0.1667[0m       0.6948      0.8456        [94m0.3081[0m     +  78.0380
      7      0.9742        [32m0.1525[0m       [35m0.7109[0m      [31m0.8517[0m        [94m0.3057[0m     +  78.0220
      8      [36m0.9843[0m        [32m0.1420[0m       0.7003      0.8485        [94m0.3007[0m     +  78.0672
      9      [36m0.9892[0m        [32m0.1349[0m       0.7073      0.8516        [94m0.3000[0m     +  77.9773
     10      [36m0.9950[0m        [32m0.1328[0m       0.7049      [31m0.8545[0m        [94m0.2963[0m     +  78.0120
     11      [36m1.0000[0m        [32m0.1246[0m       0.7057      [31m0.8557[0m        [94m0.2923[0m     +  77.9607
     12      1.0000        [32m0.1210[0m       0.7042      0.8496        [94m0.2912[0m     +  78.0727
     13      0.9892        [32m0.1162[0m       0.7059      0.8544        [94m0.2891[0m     +  78.0425
     14      1.0000        [32m0.1133[0m       [35m0.7132[0m      [31m0.8570[0m        [94m0.2869[0m     +  78.0724
     15      1.0000        [32m0.1115[0m       0.7130      [31m0.8595[0m        [94m0.2841[0m     +  78.0976
     16      1.0000        [32m0.1086[0m       [35m0.7186[0m      [31m0.8638[0m        [94m0.2818[0m     +  78.0716
     17      1.0000        [32m0.1024[0m       0.7144      0.8613        0.2830        78.0863
     18      1.0000        [32m0.0988[0m       [35m0.7220[0m      [31m0.8656[0m        [94m0.2807[0m     +  78.0627
     19      1.0000        0.1004       [35m0.7231[0m      [31m0.8696[0m        [94m0.2772[0m     +  78.0656
     20      1.0000        [32m0.0968[0m       0.7198      0.8621        0.2775        78.0876
     21      1.0000        [32m0.0956[0m       0.7167      0.8617        [94m0.2768[0m     +  78.0368
     22      1.0000        0.0957       0.7212      0.8668        0.2769        77.9790
     23      1.0000        [32m0.0897[0m       [35m0.7250[0m      [31m0.8696[0m        [94m0.2748[0m     +  78.0049
     24      1.0000        [32m0.0826[0m       0.7234      0.8665        [94m0.2736[0m     +  78.0705
     25      1.0000        0.0881       0.7227      0.8661        [94m0.2736[0m     +  78.0913
     26      1.0000        0.0851       0.7224      0.8669        [94m0.2724[0m     +  78.0557
     27      1.0000        0.0880       [35m0.7264[0m      [31m0.8699[0m        [94m0.2707[0m     +  78.0965
     28      1.0000        [32m0.0814[0m       0.7196      0.8624        0.2711        78.1191
     29      1.0000        0.0823       0.7250      0.8677        0.2710        78.1036
     30      1.0000        [32m0.0805[0m       0.7241      0.8695        [94m0.2692[0m     +  78.1208
     31      1.0000        [32m0.0801[0m       0.7135      0.8500        0.2759        77.9835
     32      1.0000        [32m0.0774[0m       [35m0.7285[0m      [31m0.8718[0m        [94m0.2686[0m     +  78.0275
     33      1.0000        0.0789       0.7194      0.8644        0.2686        78.0699
     34      1.0000        0.0826       0.7205      0.8612        0.2724        78.0516
     35      1.0000        [32m0.0768[0m       0.7250      0.8693        [94m0.2661[0m     +  78.0784
     36      1.0000        0.0784       0.7245      0.8667        [94m0.2649[0m     +  78.0298
     37      1.0000        0.0780       0.7220      0.8646        0.2720        78.0102
     38      1.0000        [32m0.0715[0m       0.7177      0.8611        0.2682        78.1096
     39      1.0000        0.0724       0.7271      0.8690        [94m0.2641[0m     +  78.0843
     40      1.0000        0.0777       0.7193      0.8591        0.2668        78.0871
     41      1.0000        0.0720       [35m0.7299[0m      [31m0.8738[0m        [94m0.2614[0m     +  78.0572
     42      1.0000        [32m0.0712[0m       0.7132      0.8517        0.2688        78.0151
     43      1.0000        0.0750       0.7222      0.8672        0.2640        78.0207
     44      1.0000        [32m0.0688[0m       0.7205      0.8615        0.2634        78.0438
     45      1.0000        0.0692       0.7222      0.8633        [94m0.2608[0m     +  78.0207
     46      1.0000        0.0699       0.7214      0.8660        0.2632        78.0597
     47      1.0000        [32m0.0660[0m       0.7168      0.8578        0.2638        78.1339
     48      1.0000        0.0671       [35m0.7302[0m      0.8735        0.2613        78.0979
     49      1.0000        [32m0.0653[0m       0.7193      0.8568        0.2627        78.0707
     50      1.0000        0.0722       0.7264      0.8717        [94m0.2607[0m     +  78.0899
     51      1.0000        0.0677       0.7163      0.8514        0.2658        78.1883
     52      1.0000        0.0691       0.7271      0.8706        [94m0.2581[0m     +  78.0886
     53      1.0000        0.0705       0.7210      0.8608        0.2616        78.0926
     54      1.0000        0.0711       [35m0.7306[0m      0.8715        [94m0.2568[0m     +  78.1141
     55      1.0000        [32m0.0635[0m       0.7215      0.8595        0.2599        78.0710
     56      1.0000        0.0659       0.7194      0.8629        0.2608        78.0407
     57      1.0000        0.0646       0.7214      0.8641        [94m0.2567[0m     +  78.0517
     58      1.0000        [32m0.0625[0m       0.7234      0.8640        0.2571        78.0399
     59      1.0000        [32m0.0602[0m       0.7238      0.8665        0.2595        78.0167
     60      1.0000        0.0603       0.7227      0.8641        [94m0.2562[0m     +  77.9990
     61      1.0000        0.0624       0.7220      0.8605        0.2566        78.0406
     62      1.0000        [32m0.0570[0m       0.7219      0.8622        0.2603        79.2506
     63      1.0000        0.0606       0.7259      0.8670        [94m0.2533[0m     +  78.8910
     64      1.0000        0.0629       0.7207      0.8619        0.2564        78.8798
     65      1.0000        0.0612       0.7201      0.8622        0.2581        78.9555
     66      1.0000        0.0619       0.7233      0.8642        0.2562        79.3889
     67      1.0000        0.0592       0.7212      0.8648        0.2574        78.6532
     68      1.0000        0.0598       0.7208      0.8653        0.2571        78.1404
     69      1.0000        0.0574       0.7262      0.8659        0.2547        78.1625
     70      1.0000        0.0586       0.7184      0.8614        0.2594        78.1950
     71      1.0000        0.0575       0.7111      0.8579        0.2634        78.0820
     72      1.0000        [32m0.0570[0m       0.7226      0.8644        0.2547        78.1489
     73      1.0000        0.0589       0.7264      0.8673        0.2541        78.0972
     74      1.0000        0.0577       0.7219      0.8657        0.2607        78.1507
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 3: Test F1 Micro Score: 0.8612748565589876
Iteration 3: Test F1 Macro Score: 0.8480714711303657
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_2.pt

Iteration 4: Requesting 56 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.9397[0m        [32m0.1674[0m       [35m0.6729[0m      [31m0.8252[0m        [94m0.3539[0m     +  79.9628
      2      0.9160        0.1755       [35m0.7408[0m      [31m0.8713[0m        [94m0.2446[0m     +  79.9844
      3      [36m0.9484[0m        [32m0.1360[0m       [35m0.7799[0m      [31m0.8926[0m        [94m0.2150[0m     +  80.0093
      4      [36m0.9682[0m        [32m0.1144[0m       0.7679      0.8872        0.2207        80.0104
      5      [36m0.9910[0m        [32m0.0959[0m       0.7705      0.8848        0.2187        79.9788
      6      [36m0.9954[0m        [32m0.0871[0m       0.7667      0.8859        0.2192        79.9109
      7      0.9954        [32m0.0802[0m       0.7646      0.8810        0.2192        79.8437
      8      0.9954        [32m0.0735[0m       0.7743      0.8886        [94m0.2128[0m     +  79.8168
      9      0.9954        [32m0.0701[0m       0.7670      0.8841        0.2149        79.9376
     10      0.9954        0.0704       0.7689      0.8813        [94m0.2125[0m     +  79.9062
     11      [36m1.0000[0m        [32m0.0666[0m       0.7623      0.8832        0.2163        79.9491
     12      0.9966        [32m0.0652[0m       0.7547      0.8815        0.2270        79.9219
     13      1.0000        0.0663       0.7686      0.8811        0.2127        79.9617
     14      1.0000        [32m0.0624[0m       0.7720      0.8820        [94m0.2068[0m     +  79.8209
     15      1.0000        [32m0.0615[0m       0.7595      0.8831        0.2236        79.8668
     16      1.0000        0.0631       0.7595      0.8819        0.2179        79.8962
     17      1.0000        0.0618       0.7608      0.8749        0.2193        79.8378
     18      1.0000        0.0621       0.7681      0.8841        0.2120        79.7801
     19      1.0000        [32m0.0595[0m       0.7655      0.8836        0.2176        79.8036
     20      1.0000        [32m0.0568[0m       0.7670      0.8810        0.2078        79.7844
     21      1.0000        0.0589       0.7698      0.8837        0.2079        79.8520
     22      1.0000        [32m0.0565[0m       0.7615      0.8827        0.2182        79.7717
     23      1.0000        [32m0.0540[0m       0.7642      0.8824        0.2123        79.7732
     24      1.0000        0.0544       0.7740      0.8863        [94m0.2067[0m     +  79.7599
     25      1.0000        [32m0.0528[0m       0.7707      0.8851        [94m0.2065[0m     +  79.7895
     26      1.0000        [32m0.0501[0m       0.7646      0.8824        0.2110        79.7737
     27      1.0000        0.0537       0.7670      0.8839        0.2107        79.8267
     28      1.0000        0.0536       0.7655      0.8828        0.2124        79.8485
     29      1.0000        0.0503       0.7792      0.8876        [94m0.2016[0m     +  79.7740
     30      1.0000        0.0515       0.7738      0.8862        0.2054        79.8015
     31      1.0000        [32m0.0490[0m       0.7682      0.8831        0.2055        79.8158
     32      1.0000        0.0514       0.7642      0.8831        0.2146        79.8315
     33      1.0000        0.0522       0.7533      0.8797        0.2245        79.8164
     34      1.0000        0.0491       0.7668      0.8833        0.2106        79.7982
     35      1.0000        [32m0.0487[0m       [35m0.7837[0m      0.8823        [94m0.1974[0m     +  79.7749
     36      1.0000        0.0502       0.7594      0.8807        0.2225        79.8241
     37      1.0000        0.0513       0.7576      0.8798        0.2211        79.8492
     38      1.0000        0.0512       0.7825      0.8819        0.2005        79.8723
     39      1.0000        0.0501       0.7510      0.8749        0.2292        79.8407
     40      1.0000        0.0519       0.7497      0.8773        0.2368        79.8593
     41      1.0000        0.0500       0.7785      0.8877        0.2044        79.8237
     42      1.0000        [32m0.0476[0m       0.7745      0.8716        0.2011        79.8221
     43      1.0000        [32m0.0464[0m       0.7797      0.8876        0.2042        79.8461
     44      1.0000        [32m0.0445[0m       0.7689      0.8837        0.2068        79.8099
     45      1.0000        0.0451       0.7634      0.8819        0.2110        79.8166
     46      1.0000        [32m0.0422[0m       0.7750      0.8866        0.2022        79.8051
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 4: Test F1 Micro Score: 0.8927809929942127
Iteration 4: Test F1 Macro Score: 0.879882757585885
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_3.pt

Iteration 5: Requesting 96 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.9492[0m        [32m0.1442[0m       [35m0.7384[0m      [31m0.8594[0m        [94m0.2223[0m     +  82.6850
      2      [36m0.9580[0m        [32m0.1136[0m       [35m0.7703[0m      [31m0.8770[0m        [94m0.1988[0m     +  82.7177
      3      [36m0.9802[0m        [32m0.0853[0m       0.7458      0.8008        0.2396        82.7044
      4      [36m0.9896[0m        [32m0.0749[0m       0.7035      0.7353        0.2806        82.8411
      5      [36m0.9915[0m        [32m0.0711[0m       0.6967      0.6848        0.2918        82.7580
      6      0.9904        0.0748       0.7556      0.7912        0.2426        82.7323
      7      0.9813        0.0850       0.7545      0.8611        0.2175        82.6986
      8      0.9826        0.0811       0.7215      0.8619        0.2682        82.7269
      9      0.9876        0.0789       0.7200      0.8658        0.2531        82.7520
     10      0.9915        0.0723       [35m0.8016[0m      [31m0.8780[0m        [94m0.1881[0m     +  82.7725
     11      [36m1.0000[0m        [32m0.0514[0m       0.7903      [31m0.8868[0m        0.1945        82.7506
     12      1.0000        [32m0.0478[0m       0.7899      [31m0.8896[0m        0.1981        82.8379
     13      1.0000        [32m0.0471[0m       0.7743      0.8852        0.2095        82.8133
     14      1.0000        [32m0.0442[0m       0.7781      0.8868        0.2034        82.7625
     15      1.0000        0.0464       0.7943      [31m0.8916[0m        0.1930        82.7893
     16      1.0000        [32m0.0427[0m       0.7979      0.8914        [94m0.1869[0m     +  82.7931
     17      1.0000        [32m0.0415[0m       0.7990      [31m0.8918[0m        [94m0.1858[0m     +  82.8118
     18      1.0000        [32m0.0414[0m       0.7972      0.8908        0.1865        82.8412
     19      1.0000        [32m0.0401[0m       0.7967      [31m0.8927[0m        0.1894        82.8397
     20      1.0000        [32m0.0388[0m       0.7964      0.8910        [94m0.1857[0m     +  82.8058
     21      1.0000        0.0403       0.7995      0.8916        0.1861        82.8090
     22      1.0000        0.0389       0.7946      0.8904        0.1870        82.7876
     23      1.0000        [32m0.0376[0m       0.7920      0.8900        0.1903        82.8071
     24      1.0000        0.0384       0.7944      0.8908        0.1893        82.7472
     25      1.0000        [32m0.0359[0m       0.7948      0.8910        0.1864        82.7776
     26      1.0000        0.0370       0.7997      0.8921        [94m0.1832[0m     +  82.7719
     27      1.0000        [32m0.0355[0m       0.7972      0.8910        0.1852        82.6433
     28      1.0000        0.0358       0.7943      0.8909        0.1878        83.0126
     29      1.0000        [32m0.0351[0m       0.7934      0.8905        0.1885        82.8257
     30      1.0000        0.0365       0.7967      0.8916        0.1861        82.7296
     31      1.0000        [32m0.0341[0m       0.7880      0.8890        0.1912        82.7593
     32      1.0000        0.0341       0.7910      0.8893        0.1903        82.7301
     33      1.0000        [32m0.0330[0m       0.7873      0.8888        0.1940        82.7628
     34      1.0000        [32m0.0330[0m       0.7877      0.8884        0.1910        82.7887
     35      1.0000        [32m0.0328[0m       0.7866      0.8879        0.1961        82.8214
     36      1.0000        0.0330       0.7833      0.8870        0.1957        82.7997
     37      1.0000        [32m0.0323[0m       0.7925      0.8900        0.1866        82.8380
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 5: Test F1 Micro Score: 0.8986668721584342
Iteration 5: Test F1 Macro Score: 0.8891475583242444
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_4.pt

Iteration 6: Requesting 176 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.9492[0m        [32m0.1250[0m       [35m0.7675[0m      [31m0.8796[0m        [94m0.2366[0m     +  88.1969
      2      [36m0.9720[0m        [32m0.0873[0m       [35m0.7821[0m      [31m0.8809[0m        [94m0.2098[0m     +  88.1988
      3      [36m0.9813[0m        [32m0.0706[0m       [35m0.8097[0m      [31m0.8859[0m        [94m0.1776[0m     +  88.2543
      4      [36m0.9950[0m        [32m0.0526[0m       [35m0.8234[0m      [31m0.8967[0m        [94m0.1755[0m     +  88.3024
      5      [36m0.9960[0m        [32m0.0482[0m       0.8050      0.8918        0.1905        88.2348
      6      [36m0.9975[0m        0.0486       0.8089      0.8567        0.1984        88.1976
      7      0.9975        [32m0.0431[0m       0.8036      0.8559        0.1994        88.1682
      8      0.9950        0.0446       0.7858      0.8271        0.2243        88.1987
      9      0.9927        0.0456       0.7839      0.8592        0.2017        88.1848
     10      0.9945        0.0431       0.8132      0.8902        0.1799        88.1957
     11      [36m0.9985[0m        [32m0.0375[0m       0.8132      0.8962        0.1843        88.1997
     12      0.9985        [32m0.0357[0m       0.8036      0.8764        0.1890        88.1588
     13      [36m1.0000[0m        [32m0.0343[0m       0.7979      0.8529        0.2043        88.8743
     14      1.0000        [32m0.0311[0m       0.7979      0.8712        0.1890        88.4998
     15      1.0000        [32m0.0301[0m       0.8019      0.8720        0.1887        88.4757
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 6: Test F1 Micro Score: 0.9137596899224806
Iteration 6: Test F1 Macro Score: 0.8893792097200608
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_5.pt

Iteration 7: Requesting 320 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.9570[0m        [32m0.1055[0m       [35m0.7656[0m      [31m0.8662[0m        [94m0.2212[0m     +  98.2871
      2      [36m0.9740[0m        [32m0.0805[0m       0.7595      [31m0.8694[0m        [94m0.2203[0m     +  98.3859
      3      [36m0.9872[0m        [32m0.0609[0m       [35m0.8306[0m      [31m0.9068[0m        [94m0.1692[0m     +  98.4484
      4      [36m0.9923[0m        [32m0.0503[0m       [35m0.8340[0m      0.9015        [94m0.1629[0m     +  98.3595
      5      0.9914        [32m0.0495[0m       0.8219      0.8763        0.1803        98.3429
      6      [36m0.9954[0m        [32m0.0442[0m       0.8059      0.8803        0.1956        98.2888
      7      0.9926        [32m0.0436[0m       0.7849      0.8693        0.1981        98.2069
      8      [36m0.9979[0m        [32m0.0360[0m       0.8030      0.8795        0.1873        98.2259
      9      [36m0.9983[0m        [32m0.0350[0m       0.8120      0.8802        0.1802        98.2550
     10      0.9946        0.0384       0.8141      0.8825        0.1697        98.2370
     11      0.9967        [32m0.0339[0m       0.8160      0.8914        0.1793        98.2897
     12      0.9981        [32m0.0321[0m       0.7990      0.8895        0.1922        98.2279
     13      [36m0.9988[0m        [32m0.0280[0m       0.8017      0.8920        0.1934        98.2070
     14      0.9983        [32m0.0277[0m       0.7948      0.8918        0.2014        98.2264
     15      [36m1.0000[0m        [32m0.0241[0m       0.7943      0.8894        0.1932        98.2427
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 7: Test F1 Micro Score: 0.9213449187759727
Iteration 7: Test F1 Macro Score: 0.9093207934088227
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_6.pt

Iteration 8: Requesting 560 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9706[0m        [32m0.0791[0m       [35m0.8104[0m      [31m0.8671[0m        [94m0.1831[0m     +  115.6877
      2      [36m0.9814[0m        [32m0.0603[0m       0.7715      0.8067        0.2191        115.8395
      3      [36m0.9849[0m        [32m0.0531[0m       0.7561      0.7601        0.2430        115.8143
      4      0.9843        [32m0.0493[0m       0.7740      0.7975        0.2215        115.7213
      5      [36m0.9865[0m        [32m0.0447[0m       [35m0.8316[0m      [31m0.8792[0m        [94m0.1696[0m     +  115.7431
      6      0.9857        [32m0.0426[0m       0.8262      [31m0.8960[0m        [94m0.1680[0m     +  115.6819
      7      [36m0.9930[0m        [32m0.0339[0m       0.8104      0.8883        0.1859        115.7707
      8      [36m0.9966[0m        [32m0.0297[0m       0.8181      0.8846        0.1800        115.6760
      9      [36m0.9990[0m        [32m0.0257[0m       0.8214      [31m0.8976[0m        0.1869        115.7058
     10      0.9975        0.0264       0.8191      0.8968        0.1962        115.6333
     11      0.9985        [32m0.0224[0m       0.8306      0.8880        0.1712        115.7070
     12      0.9964        0.0248       0.8271      [31m0.8995[0m        0.1803        115.6566
     13      0.9985        [32m0.0208[0m       0.8313      [31m0.9017[0m        0.1894        115.7201
     14      0.9939        0.0245       0.8233      0.8969        0.1923        115.6467
     15      0.9970        0.0227       [35m0.8373[0m      [31m0.9050[0m        0.1842        115.6763
     16      [36m1.0000[0m        [32m0.0166[0m       0.8167      0.8969        0.1928        115.7132
     17      1.0000        [32m0.0158[0m       0.8083      0.8868        0.1994        115.7197
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 8: Test F1 Micro Score: 0.9295644826791613
Iteration 8: Test F1 Macro Score: 0.9172941581345612
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_7.pt

Iteration 9: Requesting 1000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9701[0m        [32m0.0669[0m       [35m0.8432[0m      [31m0.8900[0m        [94m0.1535[0m     +  146.6568
      2      [36m0.9836[0m        [32m0.0501[0m       0.8057      0.8289        0.1995        146.9050
      3      0.9834        [32m0.0455[0m       [35m0.8550[0m      [31m0.9090[0m        [94m0.1474[0m     +  146.9129
      4      [36m0.9877[0m        [32m0.0385[0m       0.8413      [31m0.9095[0m        0.1831        147.0274
      5      [36m0.9897[0m        [32m0.0342[0m       0.8526      0.9063        0.1568        146.9698
      6      [36m0.9917[0m        [32m0.0300[0m       0.8549      0.9028        0.1630        146.9509
      7      [36m0.9941[0m        [32m0.0265[0m       0.8231      0.8992        0.2034        146.8327
      8      [36m0.9953[0m        [32m0.0232[0m       0.8472      0.8993        0.1835        146.9188
      9      0.9942        0.0253       0.8490      0.8995        0.1829        146.8723
     10      [36m0.9975[0m        [32m0.0194[0m       0.8375      0.9062        0.2015        146.8896
     11      [36m0.9991[0m        [32m0.0156[0m       [35m0.8665[0m      0.9094        0.1660        146.8814
     12      0.9985        [32m0.0149[0m       0.8552      0.9045        0.1706        146.9324
     13      0.9978        0.0157       0.8637      0.9048        0.1697        146.8542
     14      [36m1.0000[0m        [32m0.0109[0m       0.8571      0.9043        0.1854        146.8741
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 9: Test F1 Micro Score: 0.9345559996864958
Iteration 9: Test F1 Macro Score: 0.9227513522629825
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_8.pt

Iteration 10: Requesting 1776 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9738[0m        [32m0.0610[0m       [35m0.8438[0m      [31m0.8999[0m        [94m0.1520[0m     +  202.1308
      2      [36m0.9835[0m        [32m0.0448[0m       [35m0.8616[0m      [31m0.9092[0m        [94m0.1419[0m     +  202.3508
      3      [36m0.9856[0m        [32m0.0398[0m       0.8311      0.8607        0.1810        202.4583
      4      [36m0.9875[0m        [32m0.0339[0m       0.8443      0.8748        0.1808        202.3035
      5      [36m0.9903[0m        [32m0.0291[0m       0.8500      0.8976        0.1616        202.3298
      6      [36m0.9906[0m        [32m0.0280[0m       0.8392      0.8988        0.1746        202.3303
      7      [36m0.9941[0m        [32m0.0238[0m       [35m0.8651[0m      0.9072        0.1622        202.2755
      8      0.9940        [32m0.0206[0m       0.8512      [31m0.9092[0m        0.1741        202.2902
      9      [36m0.9961[0m        [32m0.0169[0m       [35m0.8696[0m      [31m0.9102[0m        0.1673        202.2187
     10      0.9954        0.0173       0.8519      0.9028        0.1785        202.2148
     11      0.9931        0.0213       0.8453      0.9000        0.1868        202.2355
     12      [36m0.9967[0m        [32m0.0143[0m       0.8517      0.9034        0.1811        202.2282
     13      [36m0.9981[0m        [32m0.0112[0m       0.8637      [31m0.9150[0m        0.1815        202.2967
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 10: Test F1 Micro Score: 0.9246851983844143
Iteration 10: Test F1 Macro Score: 0.9021660722941637
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_9.pt

Iteration 11: Requesting 3160 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9770[0m        [32m0.0539[0m       [35m0.8667[0m      [31m0.9174[0m        [94m0.1324[0m     +  300.6076
      2      [36m0.9825[0m        [32m0.0424[0m       0.8490      0.9137        0.1607        301.2760
      3      [36m0.9845[0m        [32m0.0367[0m       0.8561      0.9124        0.1669        301.1938
      4      [36m0.9874[0m        [32m0.0307[0m       0.8363      0.8999        0.1755        301.1521
      5      [36m0.9890[0m        [32m0.0272[0m       0.8408      0.9073        0.1842        301.0849
      6      [36m0.9898[0m        [32m0.0249[0m       0.8420      0.9080        0.1910        301.0463
      7      [36m0.9900[0m        0.0251       0.8194      0.8928        0.2096        301.0516
      8      [36m0.9925[0m        [32m0.0204[0m       0.8418      0.9050        0.1848        301.1485
      9      [36m0.9926[0m        [32m0.0180[0m       0.8556      0.9056        0.1832        301.2893
     10      [36m0.9953[0m        [32m0.0137[0m       0.8417      0.9088        0.2021        301.3934
     11      0.9951        [32m0.0135[0m       0.8585      0.9128        0.1937        301.3054
     12      0.9940        0.0160       0.8479      0.9050        0.2072        301.1571
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 11: Test F1 Micro Score: 0.9321930360415394
Iteration 11: Test F1 Macro Score: 0.9210886607559289
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_10.pt

Iteration 12: Requesting 5624 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9760[0m        [32m0.0492[0m       [35m0.8630[0m      [31m0.9128[0m        [94m0.1333[0m     +  476.5837
      2      [36m0.9803[0m        [32m0.0407[0m       0.8370      0.9039        0.1539        477.0499
      3      [36m0.9833[0m        [32m0.0349[0m       0.8434      0.9005        0.1478        476.9975
      4      [36m0.9849[0m        [32m0.0315[0m       0.8490      0.9087        0.1427        476.8991
      5      [36m0.9873[0m        [32m0.0265[0m       [35m0.8700[0m      [31m0.9145[0m        0.1405        476.8112
      6      [36m0.9900[0m        [32m0.0222[0m       0.8464      0.9026        0.1804        476.9599
      7      [36m0.9901[0m        [32m0.0204[0m       0.8549      0.8991        0.1859        476.9510
      8      [36m0.9912[0m        [32m0.0185[0m       0.8521      0.9085        0.1813        477.2012
      9      [36m0.9932[0m        [32m0.0150[0m       0.8441      0.9080        0.2089        477.1458
     10      0.9932        0.0153       0.8439      0.9085        0.2227        477.0960
     11      0.9928        0.0150       0.8443      0.9077        0.2120        477.0984
     12      [36m0.9950[0m        [32m0.0109[0m       0.8351      0.9053        0.2302        477.1686
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 12: Test F1 Micro Score: 0.9397089397089397
Iteration 12: Test F1 Macro Score: 0.927045238873065
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_11.pt

Iteration 13: Requesting 10000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9763[0m        [32m0.0470[0m       [35m0.8476[0m      [31m0.9039[0m        [94m0.1467[0m     +  788.8021
      2      [36m0.9800[0m        [32m0.0390[0m       0.8415      0.9016        0.1506        790.3013
      3      [36m0.9825[0m        [32m0.0330[0m       0.8059      0.8905        0.2269        790.1343
      4      [36m0.9839[0m        [32m0.0295[0m       [35m0.8490[0m      [31m0.9059[0m        0.1641        789.9892
      5      [36m0.9871[0m        [32m0.0245[0m       0.8455      0.9017        0.1718        789.7940
      6      [36m0.9879[0m        [32m0.0224[0m       0.8483      0.8959        0.1774        790.3315
      7      [36m0.9899[0m        [32m0.0192[0m       0.8194      0.8976        0.2087        792.8808
      8      [36m0.9906[0m        [32m0.0174[0m       [35m0.8564[0m      [31m0.9131[0m        0.1833        791.9504
      9      [36m0.9927[0m        [32m0.0145[0m       0.8401      0.8922        0.2010        791.2586
     10      [36m0.9928[0m        [32m0.0135[0m       0.8266      0.8980        0.2259        792.1919
     11      [36m0.9938[0m        [32m0.0121[0m       0.8111      0.8929        0.2630        793.0387
     12      [36m0.9945[0m        [32m0.0108[0m       0.8332      0.8960        0.2322        793.1461
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 13: Test F1 Micro Score: 0.9277666306528786
Iteration 13: Test F1 Macro Score: 0.9164070652929297
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_12.pt

Iteration 14: Requesting all remaining samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9785[0m        [32m0.0404[0m       [35m0.8540[0m      [31m0.9119[0m        [94m0.1340[0m     +  915.4397
      2      [36m0.9818[0m        [32m0.0341[0m       [35m0.8578[0m      0.9024        0.1455        924.1129
      3      [36m0.9840[0m        [32m0.0301[0m       [35m0.8622[0m      0.9102        0.1509        928.0459
      4      [36m0.9862[0m        [32m0.0254[0m       0.8622      [31m0.9161[0m        0.1546        927.9351
      5      [36m0.9875[0m        [32m0.0230[0m       0.8510      0.9051        0.1689        942.1701
      6      [36m0.9898[0m        [32m0.0197[0m       0.8335      0.9053        0.2059        934.8543
      7      [36m0.9906[0m        [32m0.0181[0m       0.8538      0.9072        0.1881        926.0491
      8      [36m0.9913[0m        [32m0.0163[0m       0.8479      0.9036        0.1932        923.6558
      9      [36m0.9926[0m        [32m0.0137[0m       0.8608      0.9029        0.2089        921.2339
     10      [36m0.9936[0m        [32m0.0124[0m       0.8438      0.8977        0.2225        921.9070
     11      [36m0.9943[0m        [32m0.0109[0m       0.8424      0.9034        0.2272        922.0884
     12      [36m0.9949[0m        [32m0.0101[0m       0.8613      0.9115        0.2025        922.1576
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 14: Test F1 Micro Score: 0.9440251572327044
Iteration 14: Test F1 Macro Score: 0.9305708527031463
Model checkpoint saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42/model_checkpoint_iteration_13.pt
Pickle file saved to C:\Users\localuserSKSG\Desktop\Shubham\Results\RandomSampling/Multilabel/DinoL/seed_42\random_sampling_results_for_multiClass_classification.pickle
