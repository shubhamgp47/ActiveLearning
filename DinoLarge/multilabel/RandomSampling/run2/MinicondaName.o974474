### Starting TaskPrologue of job 974474 on tg091 at Thu 16 Jan 2025 05:27:55 PM CET
Running on cores 0-31 with governor ondemand
Thu Jan 16 17:27:55 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:01:00.0 Off |                    0 |
| N/A   36C    P0             53W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

[07;1;31;43m WARNING: You are over quota on at least one filesystem![0m
    Path              Used     SoftQ    HardQ    Gracetime  Filecount  FileQuota  FileHardQ  FileGrace    
[07;1;31;43m!!! /home/woody       1035.3G  1000.0G  1500.0G      6days   1,813K   5,000K   7,500K        N/A !!![0m
Adjusted shapes after loading:
X_initial_np: (8, 224, 224, 3), y_initial_np: (8, 3)
X_pool_np: (26872, 224, 224, 3), y_pool_np: (26872, 3)
X_test_np: (5760, 224, 224, 3), y_test_np: (5760, 3)
X_val_np: (5760, 224, 224, 3), y_val_np: (5760, 3)

Iteration 1: Using initial samples.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.3889[0m        [32m0.7043[0m       [35m0.2675[0m      [31m0.3634[0m        [94m0.6507[0m     +  75.5359
      2      [36m0.4571[0m        [32m0.6808[0m       [35m0.3056[0m      0.3536        [94m0.6502[0m     +  73.1813
      3      0.3016        0.6975       [35m0.3184[0m      [31m0.6914[0m        0.6513        73.0187
      4      [36m0.5524[0m        [32m0.6546[0m       [35m0.3224[0m      [31m0.6945[0m        0.6531        72.8279
      5      0.4722        0.6593       0.3177      [31m0.6964[0m        0.6556        72.7199
      6      [36m0.6190[0m        [32m0.6248[0m       0.3042      0.6920        0.6579        72.7062
      7      0.5820        [32m0.6221[0m       0.2837      0.6855        0.6606        72.8101
      8      [36m0.6519[0m        [32m0.6100[0m       0.2767      0.3580        0.6631        72.7780
      9      [36m0.6690[0m        [32m0.6045[0m       0.2703      0.4074        0.6642        72.9375
     10      [36m0.8320[0m        [32m0.5796[0m       0.2490      0.4304        0.6656        72.9973
     11      0.7619        [32m0.5767[0m       0.2417      0.4465        0.6669        72.7889
     12      0.7778        [32m0.5555[0m       0.2410      0.4655        0.6674        72.8083
     13      [36m0.8796[0m        0.5576       0.2450      0.4791        0.6675        72.8018
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 1: Test F1 Micro Score: 0.5453113815318539
Iteration 1: Test F1 Macro Score: 0.5164328343604964
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_0.pt

Iteration 2: Requesting 16 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.6604[0m        [32m0.6512[0m       [35m0.3524[0m      [31m0.3331[0m        [94m0.6433[0m     +  73.2443
      2      [36m0.8120[0m        [32m0.6176[0m       0.3366      0.2322        [94m0.6324[0m     +  73.2279
      3      0.3915        [32m0.5923[0m       0.3420      0.2157        [94m0.6238[0m     +  73.3578
      4      0.4101        [32m0.5627[0m       0.3406      0.2140        [94m0.6188[0m     +  73.4561
      5      0.3556        [32m0.5606[0m       0.3411      0.2167        [94m0.6152[0m     +  73.4371
      6      0.4940        [32m0.5357[0m       0.3403      0.2204        [94m0.6126[0m     +  73.4100
      7      0.3011        [32m0.5255[0m       0.3351      0.2212        [94m0.6104[0m     +  73.3481
      8      0.3556        [32m0.5136[0m       0.3323      0.2226        [94m0.6069[0m     +  73.3157
      9      0.3617        [32m0.4920[0m       0.3312      0.2250        [94m0.6032[0m     +  73.3071
     10      0.4122        [32m0.4841[0m       0.3352      0.2302        [94m0.5995[0m     +  73.3459
     11      0.5062        [32m0.4487[0m       0.3418      0.2379        [94m0.5950[0m     +  73.5381
     12      0.5392        [32m0.4409[0m       [35m0.3530[0m      0.2519        [94m0.5892[0m     +  73.4118
     13      0.6185        [32m0.4248[0m       [35m0.3587[0m      0.2676        [94m0.5821[0m     +  73.2145
     14      0.5885        [32m0.4011[0m       [35m0.3635[0m      0.2908        [94m0.5735[0m     +  73.2945
     15      0.7941        [32m0.3879[0m       [35m0.3644[0m      0.3221        [94m0.5651[0m     +  73.3426
     16      [36m0.8250[0m        [32m0.3840[0m       [35m0.3686[0m      [31m0.3555[0m        [94m0.5563[0m     +  73.2372
     17      0.8218        [32m0.3656[0m       [35m0.3818[0m      [31m0.3657[0m        [94m0.5495[0m     +  73.2513
     18      [36m0.8578[0m        [32m0.3383[0m       [35m0.4068[0m      [31m0.3657[0m        [94m0.5451[0m     +  73.2444
     19      [36m0.9218[0m        [32m0.3195[0m       [35m0.4120[0m      [31m0.7074[0m        [94m0.5409[0m     +  73.3509
     20      [36m0.9333[0m        [32m0.3082[0m       0.4038      [31m0.7228[0m        [94m0.5362[0m     +  73.3576
     21      0.9333        [32m0.2902[0m       0.3986      0.4107        [94m0.5316[0m     +  73.3985
     22      0.8889        0.2923       0.4038      0.4272        [94m0.5274[0m     +  73.4607
     23      [36m0.9697[0m        [32m0.2665[0m       0.4078      0.3998        [94m0.5265[0m     +  73.4403
     24      0.9697        [32m0.2523[0m       [35m0.4144[0m      0.4195        [94m0.5258[0m     +  73.4835
     25      0.9697        0.2537       0.4130      0.4402        [94m0.5245[0m     +  73.4955
     26      0.9697        [32m0.2405[0m       0.4017      0.4691        [94m0.5234[0m     +  73.3306
     27      0.9333        [32m0.2346[0m       0.4016      0.4790        [94m0.5227[0m     +  73.2544
     28      [36m1.0000[0m        [32m0.2241[0m       [35m0.4198[0m      0.4578        0.5237        73.4526
     29      0.9697        [32m0.2009[0m       [35m0.4214[0m      0.4544        0.5278        73.2739
     30      1.0000        0.2118       0.4141      0.4786        0.5271        73.2331
     31      1.0000        0.2031       0.3943      0.4925        0.5261        73.3367
     32      1.0000        [32m0.1898[0m       0.3901      0.4781        0.5273        73.2604
     33      1.0000        [32m0.1891[0m       0.4040      0.4975        0.5264        73.3207
     34      1.0000        [32m0.1821[0m       0.4193      0.4882        0.5281        73.3936
     35      1.0000        [32m0.1651[0m       0.4158      0.4878        0.5273        73.3793
     36      1.0000        [32m0.1597[0m       0.4148      0.5000        0.5274        73.3599
     37      1.0000        [32m0.1557[0m       0.4135      0.5209        0.5269        73.3111
     38      1.0000        0.1613       0.4078      0.4694        0.5316        73.4272
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 2: Test F1 Micro Score: 0.6543911752227409
Iteration 2: Test F1 Macro Score: 0.6112197458427341
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_1.pt

Iteration 3: Requesting 32 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.7699[0m        [32m0.3986[0m       [35m0.4705[0m      [31m0.5528[0m        [94m0.4960[0m     +  74.3120
      2      [36m0.8739[0m        [32m0.3359[0m       [35m0.5318[0m      [31m0.5801[0m        [94m0.4356[0m     +  74.1937
      3      [36m0.9111[0m        [32m0.2874[0m       [35m0.5868[0m      [31m0.6562[0m        [94m0.4043[0m     +  74.2697
      4      0.9032        [32m0.2743[0m       [35m0.5962[0m      [31m0.6764[0m        [94m0.3881[0m     +  74.2351
      5      [36m0.9243[0m        [32m0.2545[0m       0.5951      0.6409        [94m0.3806[0m     +  74.2359
      6      [36m0.9544[0m        [32m0.2419[0m       [35m0.6003[0m      0.6706        [94m0.3698[0m     +  74.3113
      7      [36m0.9559[0m        [32m0.2202[0m       [35m0.6061[0m      0.6516        [94m0.3636[0m     +  74.1986
      8      [36m1.0000[0m        [32m0.2100[0m       [35m0.6167[0m      0.6745        [94m0.3544[0m     +  74.3606
      9      0.9762        [32m0.2024[0m       0.6099      0.6558        [94m0.3517[0m     +  74.3188
     10      0.9877        [32m0.1905[0m       0.6139      0.6579        [94m0.3466[0m     +  74.5059
     11      1.0000        [32m0.1757[0m       [35m0.6200[0m      0.6697        [94m0.3418[0m     +  74.3730
     12      1.0000        [32m0.1734[0m       0.6120      0.6482        0.3421        74.4169
     13      0.9867        [32m0.1665[0m       [35m0.6217[0m      [31m0.6851[0m        [94m0.3350[0m     +  74.5082
     14      1.0000        [32m0.1548[0m       0.6113      0.6503        0.3392        74.2216
     15      1.0000        0.1578       0.6212      0.6734        [94m0.3334[0m     +  74.2541
     16      1.0000        [32m0.1472[0m       0.6205      0.6683        [94m0.3312[0m     +  74.3339
     17      1.0000        [32m0.1362[0m       0.6182      0.6626        0.3329        74.3752
     18      1.0000        [32m0.1313[0m       [35m0.6271[0m      [31m0.6964[0m        [94m0.3219[0m     +  74.2665
     19      1.0000        [32m0.1291[0m       0.6177      0.6673        0.3301        74.3071
     20      1.0000        [32m0.1221[0m       [35m0.6330[0m      [31m0.7055[0m        0.3237        74.2517
     21      1.0000        [32m0.1213[0m       0.6191      0.6705        0.3286        74.3203
     22      1.0000        [32m0.1165[0m       0.6276      0.6823        [94m0.3215[0m     +  74.2721
     23      1.0000        [32m0.1147[0m       [35m0.6543[0m      [31m0.7364[0m        [94m0.3162[0m     +  74.3314
     24      1.0000        [32m0.1138[0m       0.6174      0.6488        0.3365        74.5174
     25      1.0000        0.1142       0.6283      0.6920        0.3172        74.3000
     26      1.0000        [32m0.1118[0m       0.6401      0.7001        [94m0.3153[0m     +  74.2493
     27      1.0000        [32m0.1031[0m       0.6439      0.7262        [94m0.3129[0m     +  74.2220
     28      1.0000        0.1072       0.6220      0.6557        0.3242        74.2351
     29      1.0000        [32m0.1001[0m       0.6510      0.7237        [94m0.3097[0m     +  74.2722
     30      1.0000        [32m0.0999[0m       0.6385      0.7013        0.3139        74.2094
     31      1.0000        [32m0.0935[0m       0.6356      0.6915        0.3177        74.2516
     32      1.0000        [32m0.0920[0m       0.6337      0.6948        0.3153        74.2264
     33      1.0000        0.0937       0.6358      0.6955        0.3119        74.3394
     34      1.0000        0.0975       0.6210      0.6481        0.3286        74.3358
     35      1.0000        [32m0.0918[0m       [35m0.6655[0m      [31m0.7525[0m        [94m0.3009[0m     +  74.3034
     36      1.0000        0.0937       0.6285      0.6721        0.3206        74.2848
     37      1.0000        [32m0.0862[0m       0.6396      0.7022        0.3091        74.2811
     38      1.0000        [32m0.0838[0m       0.6370      0.6935        0.3138        74.1742
     39      1.0000        0.0849       0.6464      0.7132        0.3031        74.3059
     40      1.0000        [32m0.0793[0m       0.6252      0.6668        0.3230        74.2243
     41      1.0000        0.0852       0.6394      0.6982        0.3096        74.2298
     42      1.0000        0.0820       0.6436      0.7003        0.3067        74.2208
     43      1.0000        0.0798       0.6198      0.6420        0.3348        74.2916
     44      1.0000        [32m0.0760[0m       [35m0.6724[0m      [31m0.7534[0m        [94m0.2951[0m     +  74.3169
     45      1.0000        0.0818       0.6356      0.6781        0.3183        74.4202
     46      1.0000        0.0761       0.6408      0.6981        0.3060        74.3175
     47      1.0000        0.0814       0.6644      0.7459        [94m0.2914[0m     +  74.3546
     48      1.0000        0.0794       0.6339      0.6839        0.3144        74.3407
     49      1.0000        0.0802       0.6472      0.7065        0.3009        74.3376
     50      1.0000        [32m0.0747[0m       0.6502      0.7087        0.2979        74.1472
     51      1.0000        [32m0.0704[0m       0.6368      0.6734        0.3138        74.1552
     52      1.0000        0.0764       0.6526      0.7294        0.2997        74.1705
     53      1.0000        0.0729       0.6451      0.6847        0.3062        74.2895
     54      1.0000        0.0756       0.6443      0.7166        0.3047        74.1789
     55      1.0000        0.0716       0.6497      0.7054        0.2959        74.2012
     56      1.0000        [32m0.0684[0m       0.6394      0.6941        0.3080        74.2225
     57      1.0000        0.0706       0.6453      0.7110        0.2969        74.2883
     58      1.0000        0.0695       0.6382      0.6833        0.3044        74.5035
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 3: Test F1 Micro Score: 0.848948060486522
Iteration 3: Test F1 Macro Score: 0.8175479983560416
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_2.pt

Iteration 4: Requesting 56 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.9230[0m        [32m0.1697[0m       [35m0.6526[0m      [31m0.6910[0m        [94m0.3286[0m     +  75.9541
      2      [36m0.9734[0m        [32m0.1383[0m       0.6017      0.6442        0.3521        75.9344
      3      [36m0.9747[0m        [32m0.1298[0m       [35m0.7608[0m      [31m0.8422[0m        [94m0.2446[0m     +  75.8596
      4      [36m0.9908[0m        [32m0.0973[0m       0.7073      0.7970        0.2560        75.9630
      5      0.9908        [32m0.0885[0m       0.7347      0.8259        [94m0.2442[0m     +  75.9732
      6      [36m0.9937[0m        [32m0.0848[0m       0.7370      [31m0.8474[0m        0.2464        75.9245
      7      0.9937        [32m0.0824[0m       0.7457      [31m0.8548[0m        [94m0.2394[0m     +  75.9178
      8      0.9937        [32m0.0780[0m       0.7311      0.8336        0.2464        75.8795
      9      [36m1.0000[0m        [32m0.0744[0m       0.7453      0.8382        [94m0.2359[0m     +  75.7540
     10      1.0000        [32m0.0711[0m       0.7387      0.8410        0.2408        75.9720
     11      1.0000        [32m0.0679[0m       0.7470      0.8543        [94m0.2357[0m     +  75.8856
     12      1.0000        [32m0.0678[0m       0.7467      0.8525        0.2373        75.8841
     13      1.0000        [32m0.0665[0m       0.7384      0.8476        0.2393        75.9473
     14      1.0000        [32m0.0627[0m       0.7431      0.8418        0.2386        75.9079
     15      1.0000        0.0629       0.7337      0.8277        0.2386        75.8421
     16      1.0000        0.0640       0.7457      0.8422        [94m0.2348[0m     +  76.0222
     17      1.0000        0.0628       0.7455      0.8518        [94m0.2332[0m     +  75.8245
     18      1.0000        0.0630       0.7292      0.8347        0.2472        76.0238
     19      1.0000        [32m0.0623[0m       0.7552      [31m0.8644[0m        [94m0.2261[0m     +  75.7563
     20      1.0000        [32m0.0610[0m       0.7545      0.8563        0.2268        75.8362
     21      1.0000        [32m0.0555[0m       0.7384      0.8434        0.2474        75.7846
     22      1.0000        0.0572       0.7531      0.8544        0.2281        75.8503
     23      1.0000        0.0564       0.7573      0.8508        [94m0.2239[0m     +  75.8721
     24      1.0000        [32m0.0554[0m       0.7448      0.8387        0.2354        75.8018
     25      1.0000        [32m0.0543[0m       0.7530      0.8537        0.2264        75.8099
     26      1.0000        [32m0.0542[0m       0.7455      0.8546        0.2300        75.7345
     27      1.0000        [32m0.0532[0m       0.7450      0.8564        0.2313        75.7734
     28      1.0000        [32m0.0513[0m       0.7509      0.8606        0.2284        75.7553
     29      1.0000        [32m0.0495[0m       0.7582      0.8569        0.2248        75.8675
     30      1.0000        0.0519       0.7330      0.8322        0.2391        75.6101
     31      1.0000        0.0533       0.7422      0.8345        0.2332        75.6662
     32      1.0000        0.0495       0.7573      0.8450        [94m0.2212[0m     +  75.5933
     33      1.0000        [32m0.0491[0m       0.7608      0.8603        0.2243        75.6436
     34      1.0000        0.0493       0.7392      0.8549        0.2339        75.6896
     35      1.0000        [32m0.0472[0m       0.7502      [31m0.8673[0m        [94m0.2203[0m     +  75.6517
     36      1.0000        0.0493       0.7434      0.8541        0.2283        75.8005
     37      1.0000        [32m0.0447[0m       0.7375      0.8464        0.2416        75.6989
     38      1.0000        0.0455       0.7566      0.8603        0.2218        75.6755
     39      1.0000        [32m0.0444[0m       0.7536      0.8252        0.2213        75.6680
     40      1.0000        [32m0.0418[0m       0.7366      0.8168        0.2388        75.5985
     41      1.0000        0.0457       0.7557      0.8630        0.2244        75.6672
     42      1.0000        0.0463       0.7521      [31m0.8675[0m        [94m0.2191[0m     +  75.6199
     43      1.0000        0.0465       [35m0.7622[0m      [31m0.8728[0m        [94m0.2143[0m     +  75.7823
     44      1.0000        0.0446       0.7410      0.8505        0.2364        75.6356
     45      1.0000        0.0446       [35m0.7667[0m      0.8669        0.2177        75.6549
     46      1.0000        0.0425       0.7625      0.8504        0.2147        75.7901
     47      1.0000        0.0420       0.7578      0.8541        0.2201        75.5839
     48      1.0000        0.0422       0.7573      0.8615        0.2201        75.6813
     49      1.0000        [32m0.0407[0m       0.7526      0.8635        0.2180        75.6417
     50      1.0000        0.0423       0.7634      0.8611        0.2191        75.6750
     51      1.0000        [32m0.0399[0m       0.7533      0.8561        0.2263        75.6468
     52      1.0000        0.0400       [35m0.7705[0m      0.8707        [94m0.2118[0m     +  75.5896
     53      1.0000        0.0402       0.7547      0.8614        0.2183        75.6807
     54      1.0000        0.0401       0.7556      0.8623        0.2226        75.6181
     55      1.0000        [32m0.0382[0m       0.7674      0.8692        0.2169        75.6126
     56      1.0000        0.0394       0.7592      0.8603        0.2213        75.5429
     57      1.0000        0.0384       0.7580      0.8570        0.2228        75.6259
     58      1.0000        0.0412       0.7535      0.8513        0.2232        75.7710
     59      1.0000        0.0387       0.7655      0.8680        0.2143        75.6393
     60      1.0000        [32m0.0379[0m       0.7538      0.8612        0.2160        75.6658
     61      1.0000        [32m0.0378[0m       0.7429      0.8497        0.2343        75.6944
     62      1.0000        [32m0.0374[0m       [35m0.7719[0m      [31m0.8729[0m        0.2142        75.7130
     63      1.0000        [32m0.0354[0m       0.7580      0.8561        0.2201        75.6514
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 4: Test F1 Micro Score: 0.8818359375
Iteration 4: Test F1 Macro Score: 0.8607400546943621
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_3.pt

Iteration 5: Requesting 96 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.9367[0m        [32m0.1335[0m       [35m0.7576[0m      [31m0.8345[0m        [94m0.2351[0m     +  78.3645
      2      [36m0.9576[0m        [32m0.1065[0m       [35m0.7943[0m      [31m0.8807[0m        [94m0.2009[0m     +  78.3979
      3      [36m0.9790[0m        [32m0.0808[0m       0.7523      0.8749        0.2179        78.4091
      4      [36m0.9881[0m        [32m0.0696[0m       0.7561      0.8772        0.2143        78.4596
      5      [36m0.9919[0m        [32m0.0580[0m       [35m0.8109[0m      [31m0.8858[0m        [94m0.1915[0m     +  78.5156
      6      [36m0.9936[0m        [32m0.0531[0m       0.7863      0.8701        0.2079        78.5465
      7      [36m0.9951[0m        [32m0.0506[0m       [35m0.8111[0m      0.8849        [94m0.1898[0m     +  78.4631
      8      0.9947        [32m0.0491[0m       0.8073      [31m0.8912[0m        [94m0.1882[0m     +  78.5469
      9      [36m0.9968[0m        [32m0.0464[0m       0.7837      0.8770        0.2043        78.5720
     10      0.9968        0.0473       0.7911      0.8844        [94m0.1872[0m     +  78.4484
     11      0.9968        [32m0.0437[0m       0.7806      0.8831        0.2033        78.4278
     12      0.9968        0.0456       0.7578      0.8769        0.2209        78.3322
     13      0.9968        0.0442       0.7309      0.8666        0.2395        78.3569
     14      0.9968        0.0455       0.7363      0.8670        0.2482        78.4289
     15      0.9968        [32m0.0409[0m       0.7656      0.8788        0.2174        78.3270
     16      [36m1.0000[0m        [32m0.0396[0m       0.7684      0.8778        0.2050        78.3303
     17      0.9936        0.0426       0.7312      0.8660        0.2513        78.3197
     18      0.9872        0.0533       0.7906      0.8810        0.2030        78.3649
     19      1.0000        [32m0.0383[0m       0.7911      0.8740        0.2091        78.3388
     20      1.0000        0.0394       0.7957      0.8660        0.2071        78.3503
     21      1.0000        [32m0.0367[0m       0.7861      0.8506        0.2109        78.4206
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 5: Test F1 Micro Score: 0.9076562499999999
Iteration 5: Test F1 Macro Score: 0.8948627266136602
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_4.pt

Iteration 6: Requesting 176 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.9370[0m        [32m0.1326[0m       [35m0.7568[0m      [31m0.8694[0m        [94m0.2139[0m     +  83.6124
      2      [36m0.9414[0m        [32m0.1163[0m       0.7465      [31m0.8709[0m        0.2427        83.6780
      3      [36m0.9428[0m        [32m0.1019[0m       [35m0.7689[0m      [31m0.8853[0m        [94m0.2037[0m     +  83.6239
      4      [36m0.9734[0m        [32m0.0839[0m       0.7052      0.8291        0.2513        83.5677
      5      [36m0.9823[0m        [32m0.0657[0m       [35m0.8005[0m      0.8820        [94m0.1896[0m     +  83.5306
      6      [36m0.9903[0m        [32m0.0552[0m       0.7891      [31m0.8882[0m        0.2028        83.6173
      7      0.9858        [32m0.0544[0m       0.7962      0.8465        0.1921        83.5306
      8      [36m0.9942[0m        [32m0.0463[0m       0.7997      0.8642        [94m0.1877[0m     +  83.5153
      9      [36m0.9962[0m        [32m0.0430[0m       [35m0.8214[0m      [31m0.8940[0m        [94m0.1769[0m     +  83.5542
     10      [36m0.9981[0m        [32m0.0405[0m       0.8207      0.8931        [94m0.1752[0m     +  83.5121
     11      0.9981        [32m0.0382[0m       [35m0.8252[0m      [31m0.8980[0m        0.1761        83.4948
     12      0.9981        [32m0.0376[0m       [35m0.8278[0m      [31m0.8986[0m        [94m0.1745[0m     +  83.5115
     13      0.9981        [32m0.0367[0m       0.8234      0.8969        0.1790        83.5344
     14      0.9981        [32m0.0346[0m       0.8231      0.8960        0.1794        83.4791
     15      0.9981        0.0350       0.8231      0.8963        0.1764        83.4629
     16      0.9981        [32m0.0331[0m       0.8234      0.8941        0.1758        83.4719
     17      0.9981        [32m0.0329[0m       0.8210      0.8959        0.1821        83.4827
     18      0.9981        [32m0.0314[0m       0.8085      0.8878        0.1825        83.4794
     19      0.9981        [32m0.0307[0m       0.8231      0.8937        0.1763        83.4795
     20      [36m1.0000[0m        [32m0.0280[0m       0.8247      0.8966        0.1782        83.4386
     21      1.0000        [32m0.0274[0m       0.8233      0.8947        0.1793        83.4845
     22      1.0000        [32m0.0269[0m       0.8201      0.8900        0.1827        83.6026
     23      1.0000        0.0274       0.8217      0.8975        0.1819        83.5762
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 6: Test F1 Micro Score: 0.9081123244929796
Iteration 6: Test F1 Macro Score: 0.8838215529602751
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_5.pt

Iteration 7: Requesting 320 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp      dur
-------  ----------  ------------  -----------  ----------  ------------  ----  -------
      1      [36m0.9627[0m        [32m0.0905[0m       [35m0.7764[0m      [31m0.8533[0m        [94m0.1838[0m     +  92.9626
      2      [36m0.9703[0m        [32m0.0718[0m       [35m0.8326[0m      [31m0.8901[0m        [94m0.1617[0m     +  93.0959
      3      [36m0.9825[0m        [32m0.0557[0m       0.8234      [31m0.9023[0m        0.1693        93.0987
      4      [36m0.9933[0m        [32m0.0444[0m       0.8262      0.8981        0.1664        92.7801
      5      [36m0.9941[0m        [32m0.0399[0m       0.8273      0.8994        0.1679        92.8406
      6      [36m0.9972[0m        [32m0.0371[0m       0.8212      0.8893        0.1784        92.7796
      7      [36m0.9978[0m        [32m0.0327[0m       0.8161      0.8875        0.1789        92.7945
      8      0.9958        0.0351       0.8229      0.9007        0.1819        92.8649
      9      [36m0.9978[0m        [32m0.0313[0m       0.8224      0.8915        0.1720        92.8485
     10      0.9973        [32m0.0293[0m       0.8297      0.9018        0.1640        92.7495
     11      [36m1.0000[0m        [32m0.0271[0m       0.8108      0.8948        0.1887        92.9551
     12      0.9990        [32m0.0254[0m       0.8210      0.8843        0.1701        92.8574
     13      1.0000        [32m0.0246[0m       0.8177      0.8987        0.1822        92.9571
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 7: Test F1 Micro Score: 0.9161392405063291
Iteration 7: Test F1 Macro Score: 0.8927721332884081
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_6.pt

Iteration 8: Requesting 560 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9531[0m        [32m0.0980[0m       [35m0.8373[0m      [31m0.9058[0m        [94m0.1561[0m     +  109.2366
      2      [36m0.9776[0m        [32m0.0718[0m       [35m0.8378[0m      [31m0.9065[0m        0.1581        109.2516
      3      [36m0.9829[0m        [32m0.0609[0m       0.8378      0.9018        0.1570        109.3852
      4      [36m0.9839[0m        [32m0.0529[0m       0.8345      0.8967        0.1599        109.0958
      5      [36m0.9857[0m        [32m0.0470[0m       0.8240      0.9015        0.1807        109.3141
      6      [36m0.9922[0m        [32m0.0401[0m       0.8260      0.9025        0.1793        109.4218
      7      0.9905        [32m0.0377[0m       0.8153      0.8964        0.2063        109.2125
      8      0.9921        [32m0.0356[0m       0.8307      0.9006        0.1648        109.2431
      9      0.9895        0.0361       0.8250      0.9025        0.1733        109.2795
     10      0.9907        [32m0.0354[0m       0.8193      0.8914        0.1779        109.4138
     11      0.9907        [32m0.0322[0m       0.8172      0.8766        0.1716        109.2238
     12      [36m0.9930[0m        [32m0.0299[0m       0.8193      0.8964        0.1879        109.3853
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 8: Test F1 Micro Score: 0.927372596887397
Iteration 8: Test F1 Macro Score: 0.9143056245235108
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_7.pt

Iteration 9: Requesting 1000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9584[0m        [32m0.0933[0m       [35m0.8231[0m      [31m0.9001[0m        [94m0.1604[0m     +  138.3785
      2      [36m0.9745[0m        [32m0.0669[0m       [35m0.8288[0m      [31m0.9035[0m        [94m0.1530[0m     +  138.3912
      3      [36m0.9786[0m        [32m0.0579[0m       0.8243      0.8987        0.1611        138.5715
      4      [36m0.9815[0m        [32m0.0536[0m       [35m0.8425[0m      0.8973        0.1600        138.6005
      5      [36m0.9848[0m        [32m0.0459[0m       0.8109      0.8826        0.1834        138.4696
      6      [36m0.9880[0m        [32m0.0433[0m       [35m0.8450[0m      0.8959        0.1583        138.4169
      7      0.9877        [32m0.0391[0m       0.8217      0.8959        0.1787        138.5027
      8      [36m0.9921[0m        [32m0.0305[0m       [35m0.8457[0m      0.9005        0.1576        138.3583
      9      [36m0.9922[0m        [32m0.0271[0m       0.8234      0.8878        0.1778        138.5511
     10      [36m0.9954[0m        [32m0.0252[0m       0.7896      0.8807        0.2080        138.5112
     11      0.9906        0.0308       0.8127      0.8667        0.1981        138.4533
     12      [36m0.9965[0m        [32m0.0219[0m       0.8356      0.8941        0.1733        138.2699
     13      [36m0.9973[0m        [32m0.0192[0m       0.8405      0.8969        0.1756        138.4594
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 9: Test F1 Micro Score: 0.9329253563088815
Iteration 9: Test F1 Macro Score: 0.9144479239636056
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_8.pt

Iteration 10: Requesting 1776 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9716[0m        [32m0.0704[0m       [35m0.8375[0m      [31m0.9044[0m        [94m0.1573[0m     +  190.1553
      2      [36m0.9763[0m        [32m0.0592[0m       0.8306      0.8964        0.1639        190.1369
      3      [36m0.9829[0m        [32m0.0477[0m       [35m0.8408[0m      [31m0.9078[0m        0.1741        190.2273
      4      [36m0.9831[0m        [32m0.0449[0m       0.8264      0.8983        0.1749        190.2546
      5      [36m0.9871[0m        [32m0.0369[0m       0.8269      0.8963        0.1890        190.3345
      6      [36m0.9878[0m        [32m0.0347[0m       0.8297      0.8941        0.1850        190.8393
      7      [36m0.9902[0m        [32m0.0300[0m       0.8328      0.8801        0.1873        190.3144
      8      [36m0.9904[0m        [32m0.0268[0m       [35m0.8432[0m      0.8916        0.1871        190.1939
      9      0.9880        0.0322       0.8377      0.8982        0.1932        190.4539
     10      0.9902        0.0270       0.7856      0.8647        0.2253        190.3843
     11      [36m0.9930[0m        [32m0.0222[0m       0.8026      0.8354        0.2404        190.2634
     12      [36m0.9946[0m        [32m0.0180[0m       0.8325      0.8798        0.2088        190.3479
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 10: Test F1 Micro Score: 0.9363150971136733
Iteration 10: Test F1 Macro Score: 0.9213653357492908
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_9.pt

Iteration 11: Requesting 3160 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9710[0m        [32m0.0658[0m       [35m0.8562[0m      [31m0.8929[0m        [94m0.1648[0m     +  281.8976
      2      [36m0.9781[0m        [32m0.0530[0m       [35m0.8649[0m      [31m0.9075[0m        [94m0.1430[0m     +  283.2461
      3      [36m0.9826[0m        [32m0.0440[0m       0.8505      0.9037        0.1559        282.5959
      4      [36m0.9841[0m        [32m0.0393[0m       0.8601      [31m0.9084[0m        0.1461        296.1674
      5      [36m0.9845[0m        [32m0.0353[0m       0.8460      [31m0.9100[0m        0.1728        282.9637
      6      [36m0.9868[0m        [32m0.0300[0m       0.8401      0.9072        0.1761        282.4870
      7      [36m0.9878[0m        [32m0.0283[0m       0.8382      0.9057        0.1895        282.6083
      8      [36m0.9885[0m        [32m0.0267[0m       0.8464      0.9091        0.1884        282.6227
      9      [36m0.9905[0m        [32m0.0222[0m       0.8365      0.9046        0.1982        283.0030
     10      [36m0.9938[0m        [32m0.0185[0m       0.8392      0.9083        0.1925        282.5538
     11      0.9913        0.0201       0.8543      0.9088        0.1793        282.7014
     12      0.9922        0.0185       0.8370      0.9027        0.1989        282.9147
     13      [36m0.9952[0m        [32m0.0132[0m       0.8424      0.9050        0.2044        282.5884
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 11: Test F1 Micro Score: 0.9465116279069767
Iteration 11: Test F1 Macro Score: 0.9370266959198951
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_10.pt

Iteration 12: Requesting 5624 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9759[0m        [32m0.0529[0m       [35m0.8269[0m      [31m0.8650[0m        [94m0.1528[0m     +  445.7889
      2      [36m0.9791[0m        [32m0.0445[0m       [35m0.8349[0m      [31m0.8904[0m        0.1615        447.0247
      3      [36m0.9816[0m        [32m0.0385[0m       [35m0.8464[0m      [31m0.9022[0m        [94m0.1467[0m     +  447.2757
      4      [36m0.9831[0m        [32m0.0333[0m       0.8321      0.8859        0.1744        447.1343
      5      [36m0.9858[0m        [32m0.0294[0m       0.8458      0.8865        0.1629        446.7518
      6      [36m0.9869[0m        [32m0.0261[0m       [35m0.8637[0m      [31m0.9047[0m        [94m0.1464[0m     +  447.0370
      7      [36m0.9884[0m        [32m0.0232[0m       0.8457      0.8799        0.1767        446.9509
      8      [36m0.9910[0m        [32m0.0203[0m       0.8359      0.8860        0.1768        447.1102
      9      [36m0.9920[0m        [32m0.0172[0m       0.8458      0.8946        0.1641        447.1333
     10      0.9920        [32m0.0170[0m       0.8632      [31m0.9127[0m        0.1599        446.9375
     11      [36m0.9942[0m        [32m0.0135[0m       0.8363      0.8906        0.1982        447.1061
     12      0.9941        0.0140       0.8469      0.9040        0.1980        446.6671
     13      [36m0.9951[0m        [32m0.0118[0m       0.8392      0.9016        0.2199        447.2014
     14      [36m0.9956[0m        [32m0.0107[0m       0.8521      0.9076        0.2141        446.6780
     15      0.9954        [32m0.0107[0m       0.8332      0.8805        0.2425        446.5580
     16      [36m0.9958[0m        [32m0.0100[0m       0.8420      0.9065        0.2384        447.2646
     17      [36m0.9971[0m        [32m0.0074[0m       0.8465      0.9046        0.2421        450.5569
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 12: Test F1 Micro Score: 0.951175120677376
Iteration 12: Test F1 Macro Score: 0.9392852949912919
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_11.pt

Iteration 13: Requesting 10000 samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9815[0m        [32m0.0353[0m       [35m0.8467[0m      [31m0.9079[0m        [94m0.1289[0m     +  737.7753
      2      [36m0.9839[0m        [32m0.0301[0m       [35m0.8483[0m      0.9035        0.1462        739.5388
      3      [36m0.9865[0m        [32m0.0258[0m       0.8439      0.8980        0.1674        739.6701
      4      [36m0.9875[0m        [32m0.0230[0m       0.8441      0.8997        0.1629        739.2534
      5      [36m0.9892[0m        [32m0.0200[0m       0.8427      0.9025        0.1665        739.6089
      6      [36m0.9909[0m        [32m0.0177[0m       0.8231      0.8985        0.1984        739.0389
      7      [36m0.9921[0m        [32m0.0152[0m       0.8207      0.8980        0.2355        738.9680
      8      [36m0.9931[0m        [32m0.0133[0m       0.8356      0.9012        0.2092        739.1862
      9      [36m0.9938[0m        [32m0.0121[0m       0.8411      0.9039        0.2145        738.8481
     10      [36m0.9943[0m        [32m0.0113[0m       0.8352      0.9025        0.2312        737.9388
     11      [36m0.9953[0m        [32m0.0099[0m       [35m0.8507[0m      [31m0.9086[0m        0.2220        738.6211
     12      [36m0.9954[0m        [32m0.0097[0m       0.8313      0.8964        0.2535        738.3879
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 13: Test F1 Micro Score: 0.9430179659187292
Iteration 13: Test F1 Macro Score: 0.9320997714200802
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_12.pt

Iteration 14: Requesting all remaining samples.
Re-initializing module.
Re-initializing criterion.
Re-initializing optimizer.
  epoch    train_f1    train_loss    valid_acc    valid_f1    valid_loss    cp       dur
-------  ----------  ------------  -----------  ----------  ------------  ----  --------
      1      [36m0.9831[0m        [32m0.0324[0m       [35m0.8484[0m      [31m0.9096[0m        [94m0.1392[0m     +  854.1508
      2      [36m0.9850[0m        [32m0.0279[0m       0.8477      [31m0.9124[0m        0.1430        857.2125
      3      [36m0.9877[0m        [32m0.0228[0m       0.8382      0.8963        0.1591        857.3555
      4      [36m0.9886[0m        [32m0.0207[0m       [35m0.8523[0m      [31m0.9159[0m        0.1690        856.1391
      5      [36m0.9911[0m        [32m0.0175[0m       0.8309      0.9047        0.2073        858.2450
      6      [36m0.9913[0m        [32m0.0159[0m       0.8321      0.9039        0.2184        857.8863
      7      [36m0.9927[0m        [32m0.0141[0m       0.8345      0.9028        0.2182        857.0952
      8      [36m0.9939[0m        [32m0.0123[0m       0.8451      0.9051        0.2173        857.6660
      9      [36m0.9946[0m        [32m0.0107[0m       0.8293      0.8974        0.2397        857.9738
     10      0.9943        [32m0.0103[0m       0.8352      0.9039        0.2646        857.7070
     11      [36m0.9954[0m        [32m0.0099[0m       0.8365      0.8998        0.2559        858.0044
     12      [36m0.9959[0m        [32m0.0087[0m       0.8425      0.9066        0.2409        857.7839
/home/hpc/iwfa/iwfa044h/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).
  from pandas.core.computation.check import NUMEXPR_INSTALLED
Using cache found in /home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main
/home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
/home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
/home/hpc/iwfa/iwfa044h/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
Stopping since valid_loss has not improved in the last 12 epochs.
Iteration 14: Test F1 Micro Score: 0.9444016633297398
Iteration 14: Test F1 Macro Score: 0.9322078532018949
Model checkpoint saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/model_checkpoint_iteration_13.pt
Pickle file saved to /home/woody/iwfa/iwfa044h/CleanLab_Test/ActiveLearningApproaches/EOD/Results/RandomSampling/Multilabel/DinoL/seed_43_100Epoch/random_sampling_results_for_multiClass_classification_s43.pickle
=== JOB_STATISTICS ===
=== current date     : Fri 17 Jan 2025 10:07:03 AM CET
= Job-ID             : 974474 on tinygpu
= Job-Name           : MinicondaName
= Job-Command        : /home/woody/iwfa/iwfa044h/runner1.sh
= Initial workdir    : /home/woody/iwfa/iwfa044h
= Queue/Partition    : a100
= Slurm account      : iwfa with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 16:39:23
= Total RAM usage    : 75.0 GiB of requested  GiB (%)   
= Node list          : tg091
= Subm/Elig/Start/End: 2025-01-16T09:25:34 / 2025-01-16T09:25:34 / 2025-01-16T17:27:40 / 2025-01-17T10:07:03
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           58.4G   104.9G   209.7G        N/A     147K     500K   1,000K        N/A    
!!! /home/woody       1054.7G  1000.0G  1500.0G      5days   1,813K   5,000K   7,500K        N/A !!!
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:01:00.0, 1848314, 95 %, 16 %, 7066 MiB, 59912824 ms
